{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba71d050",
   "metadata": {},
   "source": [
    "### Model Training Summary\n",
    "\n",
    "#### Dataset\n",
    "- **Train Data** includes outliers.\n",
    "\n",
    "#### Base Model Training\n",
    "- **Model Types**:  \n",
    "  - *Linear Models*: Linear Regression, Ridge, Lasso  \n",
    "  - *Bagging*: Random Forest  \n",
    "  - *Boosting*: LightGBM, XGBoost, CatBoost\n",
    "- **Hyperparameter Tuning**:  \n",
    "  - Linear & Bagging: Manual combinational tuning  \n",
    "  - Boosting: Optuna\n",
    "\n",
    "#### Outlier Handling Approaches\n",
    "- Repeat base model training\n",
    "- **Decision**: Model trained **with outliers** performed better\n",
    "\n",
    "#### Feature Selection (LightGBM)\n",
    "- **Prior Filtering**: Kolmogorov-Smirnov statistic  \n",
    "- **Post-training Filtering**: Remove features with importance based on percentiles and iteratively perform across a range \n",
    "- Retrain the LightGBM model\n",
    "\n",
    "#### Model Averaging\n",
    "- **Inputs**: Top models trained on data *with* outliers (excluding Linear)  \n",
    "- **Weighted Averaging**: Bayesian Model Averaging  \n",
    "  - Weight ‚àù inverse RMSE  \n",
    "  - Final target = weighted average of predictions\n",
    "\n",
    "#### Model Stacking\n",
    "- Use top model predictions as inputs to a meta-model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da784cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pylab\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import Ridge, RidgeCV,LogisticRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, train_test_split,KFold\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d45871",
   "metadata": {},
   "source": [
    "### Importing feature engineered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0837e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the preprocessed dataset\n",
    "train=pd.read_csv('train_engineered.csv', parse_dates=[\"first_active_month\"])\n",
    "test=pd.read_csv('test_engineered.csv', parse_dates=[\"first_active_month\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b50006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>target_class</th>\n",
       "      <th>hist_month_nunique</th>\n",
       "      <th>hist_hour_mean</th>\n",
       "      <th>hist_hour_min</th>\n",
       "      <th>hist_hour_max</th>\n",
       "      <th>hist_day_nunique</th>\n",
       "      <th>hist_weekend_sum</th>\n",
       "      <th>hist_weekend_mean</th>\n",
       "      <th>hist_weekofyear_mean</th>\n",
       "      <th>hist_weekofyear_min</th>\n",
       "      <th>hist_weekofyear_max</th>\n",
       "      <th>hist_dayofweek_mean</th>\n",
       "      <th>hist_dayofweek_min</th>\n",
       "      <th>hist_dayofweek_max</th>\n",
       "      <th>hist_year_nunique</th>\n",
       "      <th>hist_subsector_id_nunique</th>\n",
       "      <th>hist_merchant_id_nunique</th>\n",
       "      <th>hist_merchant_category_id_nunique</th>\n",
       "      <th>hist_price_nunique</th>\n",
       "      <th>hist_city_id_nunique</th>\n",
       "      <th>hist_state_id_nunique</th>\n",
       "      <th>hist_category_2=1.0_sum</th>\n",
       "      <th>hist_category_2=1.0_mean</th>\n",
       "      <th>hist_category_2=3.0_sum</th>\n",
       "      <th>hist_category_2=3.0_mean</th>\n",
       "      <th>hist_category_2=5.0_sum</th>\n",
       "      <th>hist_category_2=5.0_mean</th>\n",
       "      <th>hist_category_2=2.0_sum</th>\n",
       "      <th>hist_category_2=2.0_mean</th>\n",
       "      <th>hist_category_2=4.0_sum</th>\n",
       "      <th>hist_category_2=4.0_mean</th>\n",
       "      <th>hist_category_3=1.0_sum</th>\n",
       "      <th>hist_category_3=1.0_mean</th>\n",
       "      <th>hist_category_3=2.0_sum</th>\n",
       "      <th>hist_category_3=2.0_mean</th>\n",
       "      <th>hist_category_3=3.0_sum</th>\n",
       "      <th>hist_category_3=3.0_mean</th>\n",
       "      <th>hist_month_lag=-8_nunique</th>\n",
       "      <th>hist_month_lag=-7_nunique</th>\n",
       "      <th>hist_month_lag=-6_nunique</th>\n",
       "      <th>hist_month_lag=-5_nunique</th>\n",
       "      <th>hist_month_lag=-11_nunique</th>\n",
       "      <th>hist_month_lag=0_sum</th>\n",
       "      <th>hist_month_lag=0_mean</th>\n",
       "      <th>hist_month_lag=-3_nunique</th>\n",
       "      <th>hist_month_lag=-9_nunique</th>\n",
       "      <th>hist_month_lag=-4_nunique</th>\n",
       "      <th>hist_month_lag=-1_sum</th>\n",
       "      <th>hist_month_lag=-1_mean</th>\n",
       "      <th>hist_month_lag=-13_nunique</th>\n",
       "      <th>hist_month_lag=-10_nunique</th>\n",
       "      <th>hist_month_lag=-12_nunique</th>\n",
       "      <th>hist_month_lag=-2_sum</th>\n",
       "      <th>hist_month_lag=-2_mean</th>\n",
       "      <th>hist_EasterDay_2017_sum</th>\n",
       "      <th>hist_EasterDay_2017_mean</th>\n",
       "      <th>hist_AllSoulsDay_2017_sum</th>\n",
       "      <th>hist_AllSoulsDay_2017_mean</th>\n",
       "      <th>hist_ChristmasDay_2017_sum</th>\n",
       "      <th>hist_ChristmasDay_2017_mean</th>\n",
       "      <th>hist_FathersDay_2017_sum</th>\n",
       "      <th>hist_FathersDay_2017_mean</th>\n",
       "      <th>hist_ChildrenDay_2017_sum</th>\n",
       "      <th>hist_ChildrenDay_2017_mean</th>\n",
       "      <th>hist_BlackFriday_2017_sum</th>\n",
       "      <th>hist_BlackFriday_2017_mean</th>\n",
       "      <th>hist_ValentineDay_2017_sum</th>\n",
       "      <th>hist_ValentineDay_2017_mean</th>\n",
       "      <th>hist_MothersDay_2018_sum</th>\n",
       "      <th>hist_MothersDay_2018_mean</th>\n",
       "      <th>hist_purchase_amount_sum</th>\n",
       "      <th>hist_purchase_amount_max</th>\n",
       "      <th>hist_purchase_amount_min</th>\n",
       "      <th>hist_purchase_amount_mean</th>\n",
       "      <th>hist_purchase_amount_var</th>\n",
       "      <th>hist_installments_sum</th>\n",
       "      <th>hist_installments_max</th>\n",
       "      <th>hist_installments_min</th>\n",
       "      <th>hist_installments_mean</th>\n",
       "      <th>hist_installments_var</th>\n",
       "      <th>hist_installments_std</th>\n",
       "      <th>hist_installments_skew</th>\n",
       "      <th>hist_purchase_date_max</th>\n",
       "      <th>hist_purchase_date_min</th>\n",
       "      <th>hist_month_lag_mean</th>\n",
       "      <th>hist_month_lag_std</th>\n",
       "      <th>hist_month_lag_min</th>\n",
       "      <th>hist_month_lag_max</th>\n",
       "      <th>hist_month_lag_skew</th>\n",
       "      <th>hist_month_diff_mean</th>\n",
       "      <th>hist_authorized_flag_sum</th>\n",
       "      <th>hist_authorized_flag_mean</th>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <th>hist_category_1_mean</th>\n",
       "      <th>hist_card_id_size</th>\n",
       "      <th>hist_installments_quantiles_var</th>\n",
       "      <th>hist_installments_quantiles_mean</th>\n",
       "      <th>hist_installments_quantiles_skew</th>\n",
       "      <th>hist_purchase_amount_quantiles_var</th>\n",
       "      <th>hist_purchase_amount_quantiles_mean</th>\n",
       "      <th>hist_purchase_amount_quantiles_skew</th>\n",
       "      <th>hist_amount_month_ratio_mean</th>\n",
       "      <th>hist_amount_month_ratio_std</th>\n",
       "      <th>hist_amount_month_ratio_min</th>\n",
       "      <th>hist_amount_month_ratio_max</th>\n",
       "      <th>hist_amount_month_ratio_skew</th>\n",
       "      <th>hist_purchase_date_diff</th>\n",
       "      <th>hist_purchase_date_average</th>\n",
       "      <th>hist_purchase_date_uptonow</th>\n",
       "      <th>hist_of_hist_purchase_date_average</th>\n",
       "      <th>hist_purchase_amount_diff</th>\n",
       "      <th>hist_purchase_count_ratio</th>\n",
       "      <th>hist_purchase_recency</th>\n",
       "      <th>hist_category_2_pa_mean</th>\n",
       "      <th>hist_category_3_pa_mean</th>\n",
       "      <th>hist_merchant_id_count_mean</th>\n",
       "      <th>hist_month_lag_0_-1_ratio</th>\n",
       "      <th>hist_month_lag_0_-2_ratio</th>\n",
       "      <th>new_hist_month_nunique</th>\n",
       "      <th>new_hist_hour_mean</th>\n",
       "      <th>new_hist_hour_min</th>\n",
       "      <th>new_hist_hour_max</th>\n",
       "      <th>new_hist_day_nunique</th>\n",
       "      <th>new_hist_weekend_sum</th>\n",
       "      <th>new_hist_weekend_mean</th>\n",
       "      <th>new_hist_weekofyear_mean</th>\n",
       "      <th>new_hist_weekofyear_min</th>\n",
       "      <th>new_hist_weekofyear_max</th>\n",
       "      <th>new_hist_dayofweek_mean</th>\n",
       "      <th>new_hist_dayofweek_min</th>\n",
       "      <th>new_hist_dayofweek_max</th>\n",
       "      <th>new_hist_year_nunique</th>\n",
       "      <th>new_hist_subsector_id_nunique</th>\n",
       "      <th>new_hist_merchant_id_nunique</th>\n",
       "      <th>new_hist_merchant_category_id_nunique</th>\n",
       "      <th>new_hist_price_nunique</th>\n",
       "      <th>new_hist_city_id_nunique</th>\n",
       "      <th>new_hist_state_id_nunique</th>\n",
       "      <th>new_hist_category_2=1.0_sum</th>\n",
       "      <th>new_hist_category_2=1.0_mean</th>\n",
       "      <th>new_hist_category_2=3.0_sum</th>\n",
       "      <th>new_hist_category_2=3.0_mean</th>\n",
       "      <th>new_hist_category_2=2.0_sum</th>\n",
       "      <th>new_hist_category_2=2.0_mean</th>\n",
       "      <th>new_hist_category_2=4.0_sum</th>\n",
       "      <th>new_hist_category_2=4.0_mean</th>\n",
       "      <th>new_hist_category_2=5.0_sum</th>\n",
       "      <th>new_hist_category_2=5.0_mean</th>\n",
       "      <th>new_hist_category_3=2.0_sum</th>\n",
       "      <th>new_hist_category_3=2.0_mean</th>\n",
       "      <th>new_hist_category_3=1.0_sum</th>\n",
       "      <th>new_hist_category_3=1.0_mean</th>\n",
       "      <th>new_hist_category_3=3.0_sum</th>\n",
       "      <th>new_hist_category_3=3.0_mean</th>\n",
       "      <th>new_hist_month_lag=1_sum</th>\n",
       "      <th>new_hist_month_lag=1_mean</th>\n",
       "      <th>new_hist_month_lag=2_sum</th>\n",
       "      <th>new_hist_month_lag=2_mean</th>\n",
       "      <th>new_hist_EasterDay_2017_sum</th>\n",
       "      <th>new_hist_EasterDay_2017_mean</th>\n",
       "      <th>new_hist_AllSoulsDay_2017_sum</th>\n",
       "      <th>new_hist_AllSoulsDay_2017_mean</th>\n",
       "      <th>new_hist_ChristmasDay_2017_sum</th>\n",
       "      <th>new_hist_ChristmasDay_2017_mean</th>\n",
       "      <th>new_hist_FathersDay_2017_sum</th>\n",
       "      <th>new_hist_FathersDay_2017_mean</th>\n",
       "      <th>new_hist_ChildrenDay_2017_sum</th>\n",
       "      <th>new_hist_ChildrenDay_2017_mean</th>\n",
       "      <th>new_hist_BlackFriday_2017_sum</th>\n",
       "      <th>new_hist_BlackFriday_2017_mean</th>\n",
       "      <th>new_hist_ValentineDay_2017_sum</th>\n",
       "      <th>new_hist_ValentineDay_2017_mean</th>\n",
       "      <th>new_hist_MothersDay_2018_sum</th>\n",
       "      <th>new_hist_MothersDay_2018_mean</th>\n",
       "      <th>new_hist_purchase_amount_sum</th>\n",
       "      <th>new_hist_purchase_amount_max</th>\n",
       "      <th>new_hist_purchase_amount_min</th>\n",
       "      <th>new_hist_purchase_amount_mean</th>\n",
       "      <th>new_hist_purchase_amount_var</th>\n",
       "      <th>new_hist_installments_sum</th>\n",
       "      <th>new_hist_installments_max</th>\n",
       "      <th>new_hist_installments_min</th>\n",
       "      <th>new_hist_installments_mean</th>\n",
       "      <th>new_hist_installments_var</th>\n",
       "      <th>new_hist_installments_std</th>\n",
       "      <th>new_hist_installments_skew</th>\n",
       "      <th>new_hist_purchase_date_max</th>\n",
       "      <th>new_hist_purchase_date_min</th>\n",
       "      <th>new_hist_month_lag_mean</th>\n",
       "      <th>new_hist_month_lag_std</th>\n",
       "      <th>new_hist_month_lag_min</th>\n",
       "      <th>new_hist_month_lag_max</th>\n",
       "      <th>new_hist_month_lag_skew</th>\n",
       "      <th>new_hist_month_diff_mean</th>\n",
       "      <th>new_hist_authorized_flag_sum</th>\n",
       "      <th>new_hist_authorized_flag_mean</th>\n",
       "      <th>new_hist_category_1_sum</th>\n",
       "      <th>new_hist_category_1_mean</th>\n",
       "      <th>new_hist_card_id_size</th>\n",
       "      <th>new_hist_installments_quantiles_var</th>\n",
       "      <th>new_hist_installments_quantiles_mean</th>\n",
       "      <th>new_hist_installments_quantiles_skew</th>\n",
       "      <th>new_hist_purchase_amount_quantiles_var</th>\n",
       "      <th>new_hist_purchase_amount_quantiles_mean</th>\n",
       "      <th>new_hist_purchase_amount_quantiles_skew</th>\n",
       "      <th>new_hist_purchase_date_diff</th>\n",
       "      <th>new_hist_purchase_date_average</th>\n",
       "      <th>new_hist_purchase_date_uptonow</th>\n",
       "      <th>new_hist_of_new_hist_purchase_date_average</th>\n",
       "      <th>new_hist_purchase_amount_diff</th>\n",
       "      <th>new_hist_purchase_count_ratio</th>\n",
       "      <th>new_hist_purchase_recency</th>\n",
       "      <th>new_hist_category_2_pa_mean</th>\n",
       "      <th>new_hist_category_3_pa_mean</th>\n",
       "      <th>new_hist_merchant_id_count_mean</th>\n",
       "      <th>new_hist_month_lag_1_2_ratio</th>\n",
       "      <th>new_hist_r_quantile</th>\n",
       "      <th>new_hist_f_quantile</th>\n",
       "      <th>new_hist_m_quantile</th>\n",
       "      <th>new_hist_RFMindex</th>\n",
       "      <th>new_hist_RFMScore</th>\n",
       "      <th>hist_r_quantile</th>\n",
       "      <th>hist_f_quantile</th>\n",
       "      <th>hist_m_quantile</th>\n",
       "      <th>hist_RFMindex</th>\n",
       "      <th>hist_RFMScore</th>\n",
       "      <th>outliers</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>hist_first_buy</th>\n",
       "      <th>new_hist_first_buy</th>\n",
       "      <th>card_id_total</th>\n",
       "      <th>purchase_amount_total</th>\n",
       "      <th>days_feature1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13.315385</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>90</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>33.073077</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>3.211538</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>257</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.088462</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.080769</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0.219231</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>325</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>690</td>\n",
       "      <td>2.653846</td>\n",
       "      <td>630</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>296</td>\n",
       "      <td>1.138462</td>\n",
       "      <td>198</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18784.99</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>72.249960</td>\n",
       "      <td>19930.8790</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.123314</td>\n",
       "      <td>7.920770</td>\n",
       "      <td>1.519551e+09</td>\n",
       "      <td>1.498573e+09</td>\n",
       "      <td>-3.911538</td>\n",
       "      <td>2.397687</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065960</td>\n",
       "      <td>12.107692</td>\n",
       "      <td>247</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.743035</td>\n",
       "      <td>1.953846</td>\n",
       "      <td>0.105732</td>\n",
       "      <td>5.515717</td>\n",
       "      <td>10.841782</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>153.846160</td>\n",
       "      <td>10.299970</td>\n",
       "      <td>242</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>365</td>\n",
       "      <td>225.246154</td>\n",
       "      <td>1995.00</td>\n",
       "      <td>1.069959</td>\n",
       "      <td>365.603299</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>2.736842</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.869565</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>13.304348</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>5.565217</td>\n",
       "      <td>2618.490000</td>\n",
       "      <td>300.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>113.847390</td>\n",
       "      <td>8168.77640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.525001e+09</td>\n",
       "      <td>1.520259e+09</td>\n",
       "      <td>1.478261</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.323286e-02</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.703557</td>\n",
       "      <td>2.608696</td>\n",
       "      <td>-0.528976</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.347826</td>\n",
       "      <td>302.0</td>\n",
       "      <td>126.782609</td>\n",
       "      <td>285.00</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>302.525637</td>\n",
       "      <td>617.09357</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>323</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>433</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>635</td>\n",
       "      <td>26</td>\n",
       "      <td>277.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>21403.48</td>\n",
       "      <td>3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>14.717143</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>132</td>\n",
       "      <td>0.377143</td>\n",
       "      <td>25.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>3.362857</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>142</td>\n",
       "      <td>57</td>\n",
       "      <td>231</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>276</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>72</td>\n",
       "      <td>0.205714</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.145714</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0.134286</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>317</td>\n",
       "      <td>0.905714</td>\n",
       "      <td>326</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>539</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>643</td>\n",
       "      <td>1.837143</td>\n",
       "      <td>267</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>165</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>224</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34213.79</td>\n",
       "      <td>3578.48</td>\n",
       "      <td>3.00</td>\n",
       "      <td>97.753685</td>\n",
       "      <td>65634.3600</td>\n",
       "      <td>573</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.637143</td>\n",
       "      <td>3.125837</td>\n",
       "      <td>1.768004</td>\n",
       "      <td>4.203557</td>\n",
       "      <td>1.517438e+09</td>\n",
       "      <td>1.483720e+09</td>\n",
       "      <td>-5.031429</td>\n",
       "      <td>3.804934</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.258151</td>\n",
       "      <td>13.125714</td>\n",
       "      <td>339</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>31</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>350</td>\n",
       "      <td>0.167204</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>1.419543</td>\n",
       "      <td>2.375350</td>\n",
       "      <td>1.717143</td>\n",
       "      <td>0.345086</td>\n",
       "      <td>6.927029</td>\n",
       "      <td>18.247362</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>255.605710</td>\n",
       "      <td>8.885087</td>\n",
       "      <td>390</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>390</td>\n",
       "      <td>434.571429</td>\n",
       "      <td>3575.48</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>390.061701</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>2.447552</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.659996</td>\n",
       "      <td>29.98</td>\n",
       "      <td>4.99</td>\n",
       "      <td>13.943333</td>\n",
       "      <td>90.89427</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.522393e+09</td>\n",
       "      <td>1.517505e+09</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.013490e-16</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.968246</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>332.0</td>\n",
       "      <td>522.666667</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>332.716366</td>\n",
       "      <td>617.09357</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>546</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>523</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>786</td>\n",
       "      <td>5</td>\n",
       "      <td>396.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>34297.45</td>\n",
       "      <td>3144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17.906977</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>18.372093</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>3.302326</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80</td>\n",
       "      <td>1.860465</td>\n",
       "      <td>18</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>53</td>\n",
       "      <td>1.232558</td>\n",
       "      <td>5</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>51</td>\n",
       "      <td>1.186047</td>\n",
       "      <td>82</td>\n",
       "      <td>1.906977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1962.96</td>\n",
       "      <td>400.00</td>\n",
       "      <td>11.16</td>\n",
       "      <td>45.650230</td>\n",
       "      <td>3381.5176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.519759e+09</td>\n",
       "      <td>1.484123e+09</td>\n",
       "      <td>-8.604651</td>\n",
       "      <td>3.842987</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725371</td>\n",
       "      <td>12.069767</td>\n",
       "      <td>41</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869324</td>\n",
       "      <td>1.813953</td>\n",
       "      <td>0.020194</td>\n",
       "      <td>3.502454</td>\n",
       "      <td>4.476390</td>\n",
       "      <td>0.858461</td>\n",
       "      <td>30.769230</td>\n",
       "      <td>5.619474</td>\n",
       "      <td>412</td>\n",
       "      <td>9.581395</td>\n",
       "      <td>363</td>\n",
       "      <td>3947.534884</td>\n",
       "      <td>388.84</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>363.202488</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>227.8317</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.524937e+09</td>\n",
       "      <td>1.524937e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>303.261678</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>386</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>356</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>939</td>\n",
       "      <td>163</td>\n",
       "      <td>635.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1993.96</td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14.441558</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>32.012987</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2.792208</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>68</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>7</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>476</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>60</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>202</td>\n",
       "      <td>2.623377</td>\n",
       "      <td>130</td>\n",
       "      <td>1.688312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5337.59</td>\n",
       "      <td>1459.09</td>\n",
       "      <td>4.00</td>\n",
       "      <td>69.319350</td>\n",
       "      <td>30313.7660</td>\n",
       "      <td>114</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.480519</td>\n",
       "      <td>4.463431</td>\n",
       "      <td>2.112683</td>\n",
       "      <td>5.632035</td>\n",
       "      <td>1.519818e+09</td>\n",
       "      <td>1.506443e+09</td>\n",
       "      <td>-2.831169</td>\n",
       "      <td>1.802065</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.557757</td>\n",
       "      <td>12.025974</td>\n",
       "      <td>77</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>77</td>\n",
       "      <td>0.104580</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>2.432580</td>\n",
       "      <td>1.932331</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.512356</td>\n",
       "      <td>5.330545</td>\n",
       "      <td>13.393511</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>112.237686</td>\n",
       "      <td>6.966655</td>\n",
       "      <td>154</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>1455.09</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>362.510648</td>\n",
       "      <td>617.09357</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>1.509804</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>13.857143</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>381.980000</td>\n",
       "      <td>119.90</td>\n",
       "      <td>8.50</td>\n",
       "      <td>54.568573</td>\n",
       "      <td>1922.26970</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>24.142857</td>\n",
       "      <td>4.913538</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>1.524049e+09</td>\n",
       "      <td>1.520424e+09</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.229634e+00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>-0.248875</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>313.0</td>\n",
       "      <td>240.142857</td>\n",
       "      <td>111.40</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>313.541539</td>\n",
       "      <td>427.54507</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>444</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>344</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>543</td>\n",
       "      <td>25</td>\n",
       "      <td>187.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5719.57</td>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13.045113</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>21.781955</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>3.240602</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "      <td>26</td>\n",
       "      <td>124</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0.187970</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>0.804511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>7</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.345865</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>515</td>\n",
       "      <td>3.872180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33707.81</td>\n",
       "      <td>5283.96</td>\n",
       "      <td>0.50</td>\n",
       "      <td>253.442170</td>\n",
       "      <td>809650.9400</td>\n",
       "      <td>182</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.368421</td>\n",
       "      <td>3.598086</td>\n",
       "      <td>1.896862</td>\n",
       "      <td>5.419892</td>\n",
       "      <td>1.519850e+09</td>\n",
       "      <td>1.510445e+09</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>1.026700</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.295876</td>\n",
       "      <td>12.052632</td>\n",
       "      <td>128</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>15</td>\n",
       "      <td>0.112782</td>\n",
       "      <td>133</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>4.052791</td>\n",
       "      <td>1.687970</td>\n",
       "      <td>2.248120</td>\n",
       "      <td>-0.031158</td>\n",
       "      <td>19.470598</td>\n",
       "      <td>69.219261</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>406.458470</td>\n",
       "      <td>5.210617</td>\n",
       "      <td>108</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>362</td>\n",
       "      <td>87.699248</td>\n",
       "      <td>5283.46</td>\n",
       "      <td>1.220183</td>\n",
       "      <td>362.138414</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>1.985075</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.722222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13.361111</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>6.944444</td>\n",
       "      <td>4633.440000</td>\n",
       "      <td>797.12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>128.706670</td>\n",
       "      <td>22186.29900</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>4.701587</td>\n",
       "      <td>2.168314</td>\n",
       "      <td>5.946550</td>\n",
       "      <td>1.524941e+09</td>\n",
       "      <td>1.519992e+09</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>0.503953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.334486e-01</td>\n",
       "      <td>12.138889</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.053968</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>4.051370</td>\n",
       "      <td>1.907143</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>-0.631269</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>303.0</td>\n",
       "      <td>90.250000</td>\n",
       "      <td>792.12</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>303.214988</td>\n",
       "      <td>617.09357</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>312</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>482</td>\n",
       "      <td>11</td>\n",
       "      <td>121.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>38341.25</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557   0.013145   0.008752   0.011428   \n",
       "1         2017-01-01  C_ID_3d0044924f   0.010712   0.011385   0.010283   \n",
       "2         2016-08-01  C_ID_d639edf6cd   0.010610   0.008752   0.010283   \n",
       "3         2017-09-01  C_ID_186d6a6901   0.010712   0.014166   0.010283   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2   0.008058   0.014166   0.010283   \n",
       "\n",
       "     target  target_class  hist_month_nunique  hist_hour_mean  hist_hour_min  \\\n",
       "0 -0.820283             2                   9       13.315385              0   \n",
       "1  0.392913             1                  12       14.717143              0   \n",
       "2  0.688056             1                  10       17.906977              8   \n",
       "3  0.142495             1                   6       14.441558              0   \n",
       "4 -0.159749             2                   4       13.045113              0   \n",
       "\n",
       "   hist_hour_max  hist_day_nunique  hist_weekend_sum  hist_weekend_mean  \\\n",
       "0             23                31                90           0.346154   \n",
       "1             23                31               132           0.377143   \n",
       "2             23                19                11           0.255814   \n",
       "3             23                25                11           0.142857   \n",
       "4             23                30                42           0.315789   \n",
       "\n",
       "   hist_weekofyear_mean  hist_weekofyear_min  hist_weekofyear_max  \\\n",
       "0             33.073077                    1                   52   \n",
       "1             25.220000                    1                   52   \n",
       "2             18.372093                    2                   49   \n",
       "3             32.012987                    1                   52   \n",
       "4             21.781955                    1                   52   \n",
       "\n",
       "   hist_dayofweek_mean  hist_dayofweek_min  hist_dayofweek_max  \\\n",
       "0             3.211538                   0                   6   \n",
       "1             3.362857                   0                   6   \n",
       "2             3.302326                   0                   6   \n",
       "3             2.792208                   0                   6   \n",
       "4             3.240602                   0                   6   \n",
       "\n",
       "   hist_year_nunique  hist_subsector_id_nunique  hist_merchant_id_nunique  \\\n",
       "0                  2                         21                        94   \n",
       "1                  2                         24                       142   \n",
       "2                  2                          7                        13   \n",
       "3                  2                         13                        50   \n",
       "4                  2                         17                        66   \n",
       "\n",
       "   hist_merchant_category_id_nunique  hist_price_nunique  \\\n",
       "0                                 41                   5   \n",
       "1                                 57                 231   \n",
       "2                                  8                   1   \n",
       "3                                 25                  72   \n",
       "4                                 26                 124   \n",
       "\n",
       "   hist_city_id_nunique  hist_state_id_nunique  hist_category_2=1.0_sum  \\\n",
       "0                     7                      3                      257   \n",
       "1                     9                      3                      350   \n",
       "2                     5                      2                        4   \n",
       "3                     7                      5                       24   \n",
       "4                     6                      6                       25   \n",
       "\n",
       "   hist_category_2=1.0_mean  hist_category_2=3.0_sum  \\\n",
       "0                  0.988462                        0   \n",
       "1                  1.000000                        0   \n",
       "2                  0.093023                        0   \n",
       "3                  0.311688                        0   \n",
       "4                  0.187970                        0   \n",
       "\n",
       "   hist_category_2=3.0_mean  hist_category_2=5.0_sum  \\\n",
       "0                       0.0                        3   \n",
       "1                       0.0                        0   \n",
       "2                       0.0                       39   \n",
       "3                       0.0                        0   \n",
       "4                       0.0                        1   \n",
       "\n",
       "   hist_category_2=5.0_mean  hist_category_2=2.0_sum  \\\n",
       "0                  0.011538                        0   \n",
       "1                  0.000000                        0   \n",
       "2                  0.906977                        0   \n",
       "3                  0.000000                        0   \n",
       "4                  0.007519                        0   \n",
       "\n",
       "   hist_category_2=2.0_mean  hist_category_2=4.0_sum  \\\n",
       "0                       0.0                        0   \n",
       "1                       0.0                        0   \n",
       "2                       0.0                        0   \n",
       "3                       0.0                       53   \n",
       "4                       0.0                      107   \n",
       "\n",
       "   hist_category_2=4.0_mean  hist_category_3=1.0_sum  \\\n",
       "0                  0.000000                      256   \n",
       "1                  0.000000                        2   \n",
       "2                  0.000000                       43   \n",
       "3                  0.688312                        2   \n",
       "4                  0.804511                        0   \n",
       "\n",
       "   hist_category_3=1.0_mean  hist_category_3=2.0_sum  \\\n",
       "0                  0.984615                        4   \n",
       "1                  0.005714                      276   \n",
       "2                  1.000000                        0   \n",
       "3                  0.025974                       68   \n",
       "4                  0.000000                      126   \n",
       "\n",
       "   hist_category_3=2.0_mean  hist_category_3=3.0_sum  \\\n",
       "0                  0.015385                        0   \n",
       "1                  0.788571                       72   \n",
       "2                  0.000000                        0   \n",
       "3                  0.883117                        7   \n",
       "4                  0.947368                        7   \n",
       "\n",
       "   hist_category_3=3.0_mean  hist_month_lag=-8_nunique  \\\n",
       "0                  0.000000                          2   \n",
       "1                  0.205714                          2   \n",
       "2                  0.000000                          1   \n",
       "3                  0.090909                          1   \n",
       "4                  0.052632                          1   \n",
       "\n",
       "   hist_month_lag=-7_nunique  hist_month_lag=-6_nunique  \\\n",
       "0                          2                          2   \n",
       "1                          2                          2   \n",
       "2                          2                          2   \n",
       "3                          1                          1   \n",
       "4                          1                          1   \n",
       "\n",
       "   hist_month_lag=-5_nunique  hist_month_lag=-11_nunique  \\\n",
       "0                          2                           1   \n",
       "1                          2                           2   \n",
       "2                          2                           2   \n",
       "3                          2                           1   \n",
       "4                          1                           1   \n",
       "\n",
       "   hist_month_lag=0_sum  hist_month_lag=0_mean  hist_month_lag=-3_nunique  \\\n",
       "0                    23               0.088462                          2   \n",
       "1                    51               0.145714                          2   \n",
       "2                     1               0.023256                          1   \n",
       "3                    16               0.207792                          2   \n",
       "4                    35               0.263158                          2   \n",
       "\n",
       "   hist_month_lag=-9_nunique  hist_month_lag=-4_nunique  \\\n",
       "0                          1                          2   \n",
       "1                          2                          2   \n",
       "2                          2                          2   \n",
       "3                          1                          2   \n",
       "4                          1                          1   \n",
       "\n",
       "   hist_month_lag=-1_sum  hist_month_lag=-1_mean  hist_month_lag=-13_nunique  \\\n",
       "0                     21                0.080769                           1   \n",
       "1                     47                0.134286                           1   \n",
       "2                      2                0.046512                           2   \n",
       "3                      6                0.077922                           1   \n",
       "4                     46                0.345865                           1   \n",
       "\n",
       "   hist_month_lag=-10_nunique  hist_month_lag=-12_nunique  \\\n",
       "0                           1                           1   \n",
       "1                           2                           2   \n",
       "2                           2                           2   \n",
       "3                           1                           1   \n",
       "4                           1                           1   \n",
       "\n",
       "   hist_month_lag=-2_sum  hist_month_lag=-2_mean  hist_EasterDay_2017_sum  \\\n",
       "0                     57                0.219231                        0   \n",
       "1                     16                0.045714                      317   \n",
       "2                      1                0.023256                       43   \n",
       "3                      6                0.077922                        0   \n",
       "4                     31                0.233083                        0   \n",
       "\n",
       "   hist_EasterDay_2017_mean  hist_AllSoulsDay_2017_sum  \\\n",
       "0                  0.000000                        325   \n",
       "1                  0.905714                        326   \n",
       "2                  1.000000                         80   \n",
       "3                  0.000000                        476   \n",
       "4                  0.000000                          0   \n",
       "\n",
       "   hist_AllSoulsDay_2017_mean  hist_ChristmasDay_2017_sum  \\\n",
       "0                    1.250000                         690   \n",
       "1                    0.931429                         539   \n",
       "2                    1.860465                          18   \n",
       "3                    6.181818                          60   \n",
       "4                    0.000000                         515   \n",
       "\n",
       "   hist_ChristmasDay_2017_mean  hist_FathersDay_2017_sum  \\\n",
       "0                     2.653846                       630   \n",
       "1                     1.540000                       643   \n",
       "2                     0.418605                        53   \n",
       "3                     0.779221                         0   \n",
       "4                     3.872180                         0   \n",
       "\n",
       "   hist_FathersDay_2017_mean  hist_ChildrenDay_2017_sum  \\\n",
       "0                   2.423077                        296   \n",
       "1                   1.837143                        267   \n",
       "2                   1.232558                          5   \n",
       "3                   0.000000                        202   \n",
       "4                   0.000000                          0   \n",
       "\n",
       "   hist_ChildrenDay_2017_mean  hist_BlackFriday_2017_sum  \\\n",
       "0                    1.138462                        198   \n",
       "1                    0.762857                        165   \n",
       "2                    0.116279                         51   \n",
       "3                    2.623377                        130   \n",
       "4                    0.000000                         88   \n",
       "\n",
       "   hist_BlackFriday_2017_mean  hist_ValentineDay_2017_sum  \\\n",
       "0                    0.761538                           0   \n",
       "1                    0.471429                         224   \n",
       "2                    1.186047                          82   \n",
       "3                    1.688312                           0   \n",
       "4                    0.661654                           0   \n",
       "\n",
       "   hist_ValentineDay_2017_mean  hist_MothersDay_2018_sum  \\\n",
       "0                     0.000000                         0   \n",
       "1                     0.640000                         0   \n",
       "2                     1.906977                         0   \n",
       "3                     0.000000                         0   \n",
       "4                     0.000000                         0   \n",
       "\n",
       "   hist_MothersDay_2018_mean  hist_purchase_amount_sum  \\\n",
       "0                        0.0                  18784.99   \n",
       "1                        0.0                  34213.79   \n",
       "2                        0.0                   1962.96   \n",
       "3                        0.0                   5337.59   \n",
       "4                        0.0                  33707.81   \n",
       "\n",
       "   hist_purchase_amount_max  hist_purchase_amount_min  \\\n",
       "0                   2000.00                      5.00   \n",
       "1                   3578.48                      3.00   \n",
       "2                    400.00                     11.16   \n",
       "3                   1459.09                      4.00   \n",
       "4                   5283.96                      0.50   \n",
       "\n",
       "   hist_purchase_amount_mean  hist_purchase_amount_var  hist_installments_sum  \\\n",
       "0                  72.249960                19930.8790                      4   \n",
       "1                  97.753685                65634.3600                    573   \n",
       "2                  45.650230                 3381.5176                      0   \n",
       "3                  69.319350                30313.7660                    114   \n",
       "4                 253.442170               809650.9400                    182   \n",
       "\n",
       "   hist_installments_max  hist_installments_min  hist_installments_mean  \\\n",
       "0                      1                      0                0.015385   \n",
       "1                     14                      1                1.637143   \n",
       "2                      0                      0                0.000000   \n",
       "3                     14                      1                1.480519   \n",
       "4                     12                      1                1.368421   \n",
       "\n",
       "   hist_installments_var  hist_installments_std  hist_installments_skew  \\\n",
       "0               0.015206               0.123314                7.920770   \n",
       "1               3.125837               1.768004                4.203557   \n",
       "2               0.000000               0.000000                0.000000   \n",
       "3               4.463431               2.112683                5.632035   \n",
       "4               3.598086               1.896862                5.419892   \n",
       "\n",
       "   hist_purchase_date_max  hist_purchase_date_min  hist_month_lag_mean  \\\n",
       "0            1.519551e+09            1.498573e+09            -3.911538   \n",
       "1            1.517438e+09            1.483720e+09            -5.031429   \n",
       "2            1.519759e+09            1.484123e+09            -8.604651   \n",
       "3            1.519818e+09            1.506443e+09            -2.831169   \n",
       "4            1.519850e+09            1.510445e+09            -1.285714   \n",
       "\n",
       "   hist_month_lag_std  hist_month_lag_min  hist_month_lag_max  \\\n",
       "0            2.397687                  -8                   0   \n",
       "1            3.804934                 -12                   0   \n",
       "2            3.842987                 -13                   0   \n",
       "3            1.802065                  -5                   0   \n",
       "4            1.026700                  -3                   0   \n",
       "\n",
       "   hist_month_lag_skew  hist_month_diff_mean  hist_authorized_flag_sum  \\\n",
       "0             0.065960             12.107692                       247   \n",
       "1            -0.258151             13.125714                       339   \n",
       "2             0.725371             12.069767                        41   \n",
       "3             0.557757             12.025974                        77   \n",
       "4            -0.295876             12.052632                       128   \n",
       "\n",
       "   hist_authorized_flag_mean  hist_category_1_sum  hist_category_1_mean  \\\n",
       "0                   0.950000                    0              0.000000   \n",
       "1                   0.968571                   31              0.088571   \n",
       "2                   0.953488                    0              0.000000   \n",
       "3                   1.000000                   12              0.155844   \n",
       "4                   0.962406                   15              0.112782   \n",
       "\n",
       "   hist_card_id_size  hist_installments_quantiles_var  \\\n",
       "0                260                         0.000000   \n",
       "1                350                         0.167204   \n",
       "2                 43                         0.000000   \n",
       "3                 77                         0.104580   \n",
       "4                133                         0.050239   \n",
       "\n",
       "   hist_installments_quantiles_mean  hist_installments_quantiles_skew  \\\n",
       "0                          0.000000                          0.000000   \n",
       "1                          0.211429                          1.419543   \n",
       "2                          0.000000                          0.000000   \n",
       "3                          0.116883                          2.432580   \n",
       "4                          0.052632                          4.052791   \n",
       "\n",
       "   hist_purchase_amount_quantiles_var  hist_purchase_amount_quantiles_mean  \\\n",
       "0                            1.743035                             1.953846   \n",
       "1                            2.375350                             1.717143   \n",
       "2                            0.869324                             1.813953   \n",
       "3                            1.932331                             1.571429   \n",
       "4                            1.687970                             2.248120   \n",
       "\n",
       "   hist_purchase_amount_quantiles_skew  hist_amount_month_ratio_mean  \\\n",
       "0                             0.105732                      5.515717   \n",
       "1                             0.345086                      6.927029   \n",
       "2                             0.020194                      3.502454   \n",
       "3                             0.512356                      5.330545   \n",
       "4                            -0.031158                     19.470598   \n",
       "\n",
       "   hist_amount_month_ratio_std  hist_amount_month_ratio_min  \\\n",
       "0                    10.841782                     0.384615   \n",
       "1                    18.247362                     0.214286   \n",
       "2                     4.476390                     0.858461   \n",
       "3                    13.393511                     0.307692   \n",
       "4                    69.219261                     0.035714   \n",
       "\n",
       "   hist_amount_month_ratio_max  hist_amount_month_ratio_skew  \\\n",
       "0                   153.846160                     10.299970   \n",
       "1                   255.605710                      8.885087   \n",
       "2                    30.769230                      5.619474   \n",
       "3                   112.237686                      6.966655   \n",
       "4                   406.458470                      5.210617   \n",
       "\n",
       "   hist_purchase_date_diff  hist_purchase_date_average  \\\n",
       "0                      242                    0.930769   \n",
       "1                      390                    1.114286   \n",
       "2                      412                    9.581395   \n",
       "3                      154                    2.000000   \n",
       "4                      108                    0.812030   \n",
       "\n",
       "   hist_purchase_date_uptonow  hist_of_hist_purchase_date_average  \\\n",
       "0                         365                          225.246154   \n",
       "1                         390                          434.571429   \n",
       "2                         363                         3947.534884   \n",
       "3                         362                          308.000000   \n",
       "4                         362                           87.699248   \n",
       "\n",
       "   hist_purchase_amount_diff  hist_purchase_count_ratio  \\\n",
       "0                    1995.00                   1.069959   \n",
       "1                    3575.48                   0.895141   \n",
       "2                     388.84                   0.104116   \n",
       "3                    1455.09                   0.496774   \n",
       "4                    5283.46                   1.220183   \n",
       "\n",
       "   hist_purchase_recency  hist_category_2_pa_mean  hist_category_3_pa_mean  \\\n",
       "0             365.603299                546.68500                 735.6103   \n",
       "1             390.061701                546.68500                 735.6103   \n",
       "2             363.202488                546.68500                 227.8317   \n",
       "3             362.510648                617.09357                 735.6103   \n",
       "4             362.138414                546.68500                 735.6103   \n",
       "\n",
       "   hist_merchant_id_count_mean  hist_month_lag_0_-1_ratio  \\\n",
       "0                     2.736842                   1.045455   \n",
       "1                     2.447552                   1.062500   \n",
       "2                     3.071429                   0.333333   \n",
       "3                     1.509804                   2.285714   \n",
       "4                     1.985075                   0.744681   \n",
       "\n",
       "   hist_month_lag_0_-2_ratio  new_hist_month_nunique  new_hist_hour_mean  \\\n",
       "0                   0.396552                     2.0           12.869565   \n",
       "1                   3.000000                     2.0           11.166667   \n",
       "2                   0.500000                     1.0           17.000000   \n",
       "3                   2.285714                     2.0           13.000000   \n",
       "4                   1.093750                     2.0           14.722222   \n",
       "\n",
       "   new_hist_hour_min  new_hist_hour_max  new_hist_day_nunique  \\\n",
       "0                8.0               16.0                  17.0   \n",
       "1                6.0               17.0                   4.0   \n",
       "2               17.0               17.0                   1.0   \n",
       "3                7.0               21.0                   7.0   \n",
       "4                5.0               23.0                  22.0   \n",
       "\n",
       "   new_hist_weekend_sum  new_hist_weekend_mean  new_hist_weekofyear_mean  \\\n",
       "0                   6.0               0.260870                 13.304348   \n",
       "1                   0.0               0.000000                  9.000000   \n",
       "2                   1.0               1.000000                 17.000000   \n",
       "3                   3.0               0.428571                 13.857143   \n",
       "4                  12.0               0.333333                 13.361111   \n",
       "\n",
       "   new_hist_weekofyear_min  new_hist_weekofyear_max  new_hist_dayofweek_mean  \\\n",
       "0                     10.0                     17.0                 3.130435   \n",
       "1                      5.0                     13.0                 1.500000   \n",
       "2                     17.0                     17.0                 5.000000   \n",
       "3                     10.0                     16.0                 3.285714   \n",
       "4                      9.0                     17.0                 3.277778   \n",
       "\n",
       "   new_hist_dayofweek_min  new_hist_dayofweek_max  new_hist_year_nunique  \\\n",
       "0                     0.0                     6.0                    1.0   \n",
       "1                     0.0                     4.0                    1.0   \n",
       "2                     5.0                     5.0                    1.0   \n",
       "3                     1.0                     6.0                    1.0   \n",
       "4                     0.0                     6.0                    1.0   \n",
       "\n",
       "   new_hist_subsector_id_nunique  new_hist_merchant_id_nunique  \\\n",
       "0                           10.0                          23.0   \n",
       "1                            4.0                           6.0   \n",
       "2                            1.0                           1.0   \n",
       "3                            5.0                           7.0   \n",
       "4                           10.0                          36.0   \n",
       "\n",
       "   new_hist_merchant_category_id_nunique  new_hist_price_nunique  \\\n",
       "0                                   14.0                     1.0   \n",
       "1                                    5.0                     6.0   \n",
       "2                                    1.0                     1.0   \n",
       "3                                    6.0                     7.0   \n",
       "4                                   17.0                    34.0   \n",
       "\n",
       "   new_hist_city_id_nunique  new_hist_state_id_nunique  \\\n",
       "0                       3.0                        1.0   \n",
       "1                       1.0                        1.0   \n",
       "2                       1.0                        1.0   \n",
       "3                       2.0                        2.0   \n",
       "4                       5.0                        5.0   \n",
       "\n",
       "   new_hist_category_2=1.0_sum  new_hist_category_2=1.0_mean  \\\n",
       "0                         23.0                      1.000000   \n",
       "1                          6.0                      1.000000   \n",
       "2                          0.0                      0.000000   \n",
       "3                          1.0                      0.142857   \n",
       "4                          4.0                      0.111111   \n",
       "\n",
       "   new_hist_category_2=3.0_sum  new_hist_category_2=3.0_mean  \\\n",
       "0                          0.0                      0.000000   \n",
       "1                          0.0                      0.000000   \n",
       "2                          0.0                      0.000000   \n",
       "3                          0.0                      0.000000   \n",
       "4                          7.0                      0.194444   \n",
       "\n",
       "   new_hist_category_2=2.0_sum  new_hist_category_2=2.0_mean  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   new_hist_category_2=4.0_sum  new_hist_category_2=4.0_mean  \\\n",
       "0                          0.0                      0.000000   \n",
       "1                          0.0                      0.000000   \n",
       "2                          0.0                      0.000000   \n",
       "3                          6.0                      0.857143   \n",
       "4                         25.0                      0.694444   \n",
       "\n",
       "   new_hist_category_2=5.0_sum  new_hist_category_2=5.0_mean  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          1.0                           1.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   new_hist_category_3=2.0_sum  new_hist_category_3=2.0_mean  \\\n",
       "0                          0.0                      0.000000   \n",
       "1                          6.0                      1.000000   \n",
       "2                          0.0                      0.000000   \n",
       "3                          6.0                      0.857143   \n",
       "4                         34.0                      0.944444   \n",
       "\n",
       "   new_hist_category_3=1.0_sum  new_hist_category_3=1.0_mean  \\\n",
       "0                         23.0                      1.000000   \n",
       "1                          0.0                      0.000000   \n",
       "2                          1.0                      1.000000   \n",
       "3                          1.0                      0.142857   \n",
       "4                          1.0                      0.027778   \n",
       "\n",
       "   new_hist_category_3=3.0_sum  new_hist_category_3=3.0_mean  \\\n",
       "0                          0.0                      0.000000   \n",
       "1                          0.0                      0.000000   \n",
       "2                          0.0                      0.000000   \n",
       "3                          0.0                      0.000000   \n",
       "4                          1.0                      0.027778   \n",
       "\n",
       "   new_hist_month_lag=1_sum  new_hist_month_lag=1_mean  \\\n",
       "0                      12.0                   0.521739   \n",
       "1                       3.0                   0.500000   \n",
       "2                       0.0                   0.000000   \n",
       "3                       2.0                   0.285714   \n",
       "4                      16.0                   0.444444   \n",
       "\n",
       "   new_hist_month_lag=2_sum  new_hist_month_lag=2_mean  \\\n",
       "0                      11.0                   0.478261   \n",
       "1                       3.0                   0.500000   \n",
       "2                       1.0                   1.000000   \n",
       "3                       5.0                   0.714286   \n",
       "4                      20.0                   0.555556   \n",
       "\n",
       "   new_hist_EasterDay_2017_sum  new_hist_EasterDay_2017_mean  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   new_hist_AllSoulsDay_2017_sum  new_hist_AllSoulsDay_2017_mean  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   new_hist_ChristmasDay_2017_sum  new_hist_ChristmasDay_2017_mean  \\\n",
       "0                             0.0                              0.0   \n",
       "1                             0.0                              0.0   \n",
       "2                             0.0                              0.0   \n",
       "3                             0.0                              0.0   \n",
       "4                             0.0                              0.0   \n",
       "\n",
       "   new_hist_FathersDay_2017_sum  new_hist_FathersDay_2017_mean  \\\n",
       "0                           0.0                            0.0   \n",
       "1                           0.0                            0.0   \n",
       "2                           0.0                            0.0   \n",
       "3                           0.0                            0.0   \n",
       "4                           0.0                            0.0   \n",
       "\n",
       "   new_hist_ChildrenDay_2017_sum  new_hist_ChildrenDay_2017_mean  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   new_hist_BlackFriday_2017_sum  new_hist_BlackFriday_2017_mean  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   new_hist_ValentineDay_2017_sum  new_hist_ValentineDay_2017_mean  \\\n",
       "0                             0.0                              0.0   \n",
       "1                             0.0                              0.0   \n",
       "2                             0.0                              0.0   \n",
       "3                             0.0                              0.0   \n",
       "4                             0.0                              0.0   \n",
       "\n",
       "   new_hist_MothersDay_2018_sum  new_hist_MothersDay_2018_mean  \\\n",
       "0                         128.0                       5.565217   \n",
       "1                           0.0                       0.000000   \n",
       "2                          14.0                      14.000000   \n",
       "3                          77.0                      11.000000   \n",
       "4                         250.0                       6.944444   \n",
       "\n",
       "   new_hist_purchase_amount_sum  new_hist_purchase_amount_max  \\\n",
       "0                   2618.490000                        300.00   \n",
       "1                     83.659996                         29.98   \n",
       "2                     31.000000                         31.00   \n",
       "3                    381.980000                        119.90   \n",
       "4                   4633.440000                        797.12   \n",
       "\n",
       "   new_hist_purchase_amount_min  new_hist_purchase_amount_mean  \\\n",
       "0                         15.00                     113.847390   \n",
       "1                          4.99                      13.943333   \n",
       "2                         31.00                      31.000000   \n",
       "3                          8.50                      54.568573   \n",
       "4                          5.00                     128.706670   \n",
       "\n",
       "   new_hist_purchase_amount_var  new_hist_installments_sum  \\\n",
       "0                    8168.77640                        0.0   \n",
       "1                      90.89427                        6.0   \n",
       "2                           NaN                        0.0   \n",
       "3                    1922.26970                       20.0   \n",
       "4                   22186.29900                       50.0   \n",
       "\n",
       "   new_hist_installments_max  new_hist_installments_min  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        1.0                        1.0   \n",
       "2                        0.0                        0.0   \n",
       "3                       14.0                        1.0   \n",
       "4                       14.0                        1.0   \n",
       "\n",
       "   new_hist_installments_mean  new_hist_installments_var  \\\n",
       "0                    0.000000                   0.000000   \n",
       "1                    1.000000                   0.000000   \n",
       "2                    0.000000                        NaN   \n",
       "3                    2.857143                  24.142857   \n",
       "4                    1.388889                   4.701587   \n",
       "\n",
       "   new_hist_installments_std  new_hist_installments_skew  \\\n",
       "0                   0.000000                    0.000000   \n",
       "1                   0.000000                    0.000000   \n",
       "2                        NaN                         NaN   \n",
       "3                   4.913538                    2.645751   \n",
       "4                   2.168314                    5.946550   \n",
       "\n",
       "   new_hist_purchase_date_max  new_hist_purchase_date_min  \\\n",
       "0                1.525001e+09                1.520259e+09   \n",
       "1                1.522393e+09                1.517505e+09   \n",
       "2                1.524937e+09                1.524937e+09   \n",
       "3                1.524049e+09                1.520424e+09   \n",
       "4                1.524941e+09                1.519992e+09   \n",
       "\n",
       "   new_hist_month_lag_mean  new_hist_month_lag_std  new_hist_month_lag_min  \\\n",
       "0                 1.478261                0.510754                     1.0   \n",
       "1                 1.500000                0.547723                     1.0   \n",
       "2                 2.000000                     NaN                     2.0   \n",
       "3                 1.714286                0.487950                     1.0   \n",
       "4                 1.555556                0.503953                     1.0   \n",
       "\n",
       "   new_hist_month_lag_max  new_hist_month_lag_skew  new_hist_month_diff_mean  \\\n",
       "0                     2.0             9.323286e-02                 12.000000   \n",
       "1                     2.0             1.013490e-16                 13.000000   \n",
       "2                     2.0                      NaN                 12.000000   \n",
       "3                     2.0            -1.229634e+00                 12.000000   \n",
       "4                     2.0            -2.334486e-01                 12.138889   \n",
       "\n",
       "   new_hist_authorized_flag_sum  new_hist_authorized_flag_mean  \\\n",
       "0                          23.0                            1.0   \n",
       "1                           6.0                            1.0   \n",
       "2                           1.0                            1.0   \n",
       "3                           7.0                            1.0   \n",
       "4                          36.0                            1.0   \n",
       "\n",
       "   new_hist_category_1_sum  new_hist_category_1_mean  new_hist_card_id_size  \\\n",
       "0                      0.0                  0.000000                   23.0   \n",
       "1                      0.0                  0.000000                    6.0   \n",
       "2                      0.0                  0.000000                    1.0   \n",
       "3                      1.0                  0.142857                    7.0   \n",
       "4                      2.0                  0.055556                   36.0   \n",
       "\n",
       "   new_hist_installments_quantiles_var  new_hist_installments_quantiles_mean  \\\n",
       "0                             0.000000                              0.000000   \n",
       "1                             0.000000                              0.000000   \n",
       "2                                  NaN                              0.000000   \n",
       "3                             0.142857                              0.142857   \n",
       "4                             0.053968                              0.055556   \n",
       "\n",
       "   new_hist_installments_quantiles_skew  \\\n",
       "0                              0.000000   \n",
       "1                              0.000000   \n",
       "2                                   NaN   \n",
       "3                              2.645751   \n",
       "4                              4.051370   \n",
       "\n",
       "   new_hist_purchase_amount_quantiles_var  \\\n",
       "0                                1.703557   \n",
       "1                                0.266667   \n",
       "2                                     NaN   \n",
       "3                                1.238095   \n",
       "4                                1.907143   \n",
       "\n",
       "   new_hist_purchase_amount_quantiles_mean  \\\n",
       "0                                 2.608696   \n",
       "1                                 0.333333   \n",
       "2                                 1.000000   \n",
       "3                                 1.714286   \n",
       "4                                 2.583333   \n",
       "\n",
       "   new_hist_purchase_amount_quantiles_skew  new_hist_purchase_date_diff  \\\n",
       "0                                -0.528976                         54.0   \n",
       "1                                 0.968246                         56.0   \n",
       "2                                      NaN                          0.0   \n",
       "3                                -0.248875                         41.0   \n",
       "4                                -0.631269                         57.0   \n",
       "\n",
       "   new_hist_purchase_date_average  new_hist_purchase_date_uptonow  \\\n",
       "0                        2.347826                           302.0   \n",
       "1                        9.333333                           332.0   \n",
       "2                        0.000000                           303.0   \n",
       "3                        5.857143                           313.0   \n",
       "4                        1.583333                           303.0   \n",
       "\n",
       "   new_hist_of_new_hist_purchase_date_average  new_hist_purchase_amount_diff  \\\n",
       "0                                  126.782609                         285.00   \n",
       "1                                  522.666667                          24.99   \n",
       "2                                    0.000000                           0.00   \n",
       "3                                  240.142857                         111.40   \n",
       "4                                   90.250000                         792.12   \n",
       "\n",
       "   new_hist_purchase_count_ratio  new_hist_purchase_recency  \\\n",
       "0                       0.418182                 302.525637   \n",
       "1                       0.105263                 332.716366   \n",
       "2                       1.000000                 303.261678   \n",
       "3                       0.166667                 313.541539   \n",
       "4                       0.620690                 303.214988   \n",
       "\n",
       "   new_hist_category_2_pa_mean  new_hist_category_3_pa_mean  \\\n",
       "0                    617.09357                     735.6103   \n",
       "1                    617.09357                     735.6103   \n",
       "2                    546.68500                     735.6103   \n",
       "3                    427.54507                     735.6103   \n",
       "4                    617.09357                     735.6103   \n",
       "\n",
       "   new_hist_merchant_id_count_mean  new_hist_month_lag_1_2_ratio  \\\n",
       "0                         0.958333                      1.000000   \n",
       "1                         0.857143                      0.750000   \n",
       "2                         0.500000                      0.000000   \n",
       "3                         0.875000                      0.333333   \n",
       "4                         0.972973                      0.761905   \n",
       "\n",
       "   new_hist_r_quantile  new_hist_f_quantile  new_hist_m_quantile  \\\n",
       "0                    3                    2                    3   \n",
       "1                    5                    4                    6   \n",
       "2                    3                    8                    6   \n",
       "3                    4                    4                    4   \n",
       "4                    3                    1                    2   \n",
       "\n",
       "   new_hist_RFMindex  new_hist_RFMScore  hist_r_quantile  hist_f_quantile  \\\n",
       "0                323                  8                4                3   \n",
       "1                546                 15                5                2   \n",
       "2                386                 17                3                5   \n",
       "3                444                 12                3                4   \n",
       "4                312                  6                2                3   \n",
       "\n",
       "   hist_m_quantile  hist_RFMindex  hist_RFMScore  outliers  dayofweek  \\\n",
       "0                3            433             10         0          3   \n",
       "1                3            523             10         0          6   \n",
       "2                6            356             14         0          0   \n",
       "3                4            344             11         0          4   \n",
       "4                3            233              8         0          2   \n",
       "\n",
       "   weekofyear  month  elapsed_time  hist_first_buy  new_hist_first_buy  \\\n",
       "0          22      6           635              26               277.0   \n",
       "1          52      1           786               5               396.0   \n",
       "2          31      8           939             163               635.0   \n",
       "3          35      9           543              25               187.0   \n",
       "4          44     11           482              11               121.0   \n",
       "\n",
       "   card_id_total  purchase_amount_total  days_feature1  \n",
       "0          283.0               21403.48           3175  \n",
       "1          356.0               34297.45           3144  \n",
       "2           44.0                1993.96           1878  \n",
       "3           84.0                5719.57           2172  \n",
       "4          169.0               38341.25            482  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe6bf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>hist_month_nunique</th>\n",
       "      <th>hist_hour_mean</th>\n",
       "      <th>hist_hour_min</th>\n",
       "      <th>hist_hour_max</th>\n",
       "      <th>hist_day_nunique</th>\n",
       "      <th>hist_weekend_sum</th>\n",
       "      <th>hist_weekend_mean</th>\n",
       "      <th>hist_weekofyear_mean</th>\n",
       "      <th>hist_weekofyear_min</th>\n",
       "      <th>hist_weekofyear_max</th>\n",
       "      <th>hist_dayofweek_mean</th>\n",
       "      <th>hist_dayofweek_min</th>\n",
       "      <th>hist_dayofweek_max</th>\n",
       "      <th>hist_year_nunique</th>\n",
       "      <th>hist_subsector_id_nunique</th>\n",
       "      <th>hist_merchant_id_nunique</th>\n",
       "      <th>hist_merchant_category_id_nunique</th>\n",
       "      <th>hist_price_nunique</th>\n",
       "      <th>hist_city_id_nunique</th>\n",
       "      <th>hist_state_id_nunique</th>\n",
       "      <th>hist_category_2=1.0_sum</th>\n",
       "      <th>hist_category_2=1.0_mean</th>\n",
       "      <th>hist_category_2=3.0_sum</th>\n",
       "      <th>hist_category_2=3.0_mean</th>\n",
       "      <th>hist_category_2=5.0_sum</th>\n",
       "      <th>hist_category_2=5.0_mean</th>\n",
       "      <th>hist_category_2=2.0_sum</th>\n",
       "      <th>hist_category_2=2.0_mean</th>\n",
       "      <th>hist_category_2=4.0_sum</th>\n",
       "      <th>hist_category_2=4.0_mean</th>\n",
       "      <th>hist_category_3=1.0_sum</th>\n",
       "      <th>hist_category_3=1.0_mean</th>\n",
       "      <th>hist_category_3=2.0_sum</th>\n",
       "      <th>hist_category_3=2.0_mean</th>\n",
       "      <th>hist_category_3=3.0_sum</th>\n",
       "      <th>hist_category_3=3.0_mean</th>\n",
       "      <th>hist_month_lag=-8_nunique</th>\n",
       "      <th>hist_month_lag=-7_nunique</th>\n",
       "      <th>hist_month_lag=-6_nunique</th>\n",
       "      <th>hist_month_lag=-5_nunique</th>\n",
       "      <th>hist_month_lag=-11_nunique</th>\n",
       "      <th>hist_month_lag=0_sum</th>\n",
       "      <th>hist_month_lag=0_mean</th>\n",
       "      <th>hist_month_lag=-3_nunique</th>\n",
       "      <th>hist_month_lag=-9_nunique</th>\n",
       "      <th>hist_month_lag=-4_nunique</th>\n",
       "      <th>hist_month_lag=-1_sum</th>\n",
       "      <th>hist_month_lag=-1_mean</th>\n",
       "      <th>hist_month_lag=-13_nunique</th>\n",
       "      <th>hist_month_lag=-10_nunique</th>\n",
       "      <th>hist_month_lag=-12_nunique</th>\n",
       "      <th>hist_month_lag=-2_sum</th>\n",
       "      <th>hist_month_lag=-2_mean</th>\n",
       "      <th>hist_EasterDay_2017_sum</th>\n",
       "      <th>hist_EasterDay_2017_mean</th>\n",
       "      <th>hist_AllSoulsDay_2017_sum</th>\n",
       "      <th>hist_AllSoulsDay_2017_mean</th>\n",
       "      <th>hist_ChristmasDay_2017_sum</th>\n",
       "      <th>hist_ChristmasDay_2017_mean</th>\n",
       "      <th>hist_FathersDay_2017_sum</th>\n",
       "      <th>hist_FathersDay_2017_mean</th>\n",
       "      <th>hist_ChildrenDay_2017_sum</th>\n",
       "      <th>hist_ChildrenDay_2017_mean</th>\n",
       "      <th>hist_BlackFriday_2017_sum</th>\n",
       "      <th>hist_BlackFriday_2017_mean</th>\n",
       "      <th>hist_ValentineDay_2017_sum</th>\n",
       "      <th>hist_ValentineDay_2017_mean</th>\n",
       "      <th>hist_MothersDay_2018_sum</th>\n",
       "      <th>hist_MothersDay_2018_mean</th>\n",
       "      <th>hist_purchase_amount_sum</th>\n",
       "      <th>hist_purchase_amount_max</th>\n",
       "      <th>hist_purchase_amount_min</th>\n",
       "      <th>hist_purchase_amount_mean</th>\n",
       "      <th>hist_purchase_amount_var</th>\n",
       "      <th>hist_installments_sum</th>\n",
       "      <th>hist_installments_max</th>\n",
       "      <th>hist_installments_min</th>\n",
       "      <th>hist_installments_mean</th>\n",
       "      <th>hist_installments_var</th>\n",
       "      <th>hist_installments_std</th>\n",
       "      <th>hist_installments_skew</th>\n",
       "      <th>hist_purchase_date_max</th>\n",
       "      <th>hist_purchase_date_min</th>\n",
       "      <th>hist_month_lag_mean</th>\n",
       "      <th>hist_month_lag_std</th>\n",
       "      <th>hist_month_lag_min</th>\n",
       "      <th>hist_month_lag_max</th>\n",
       "      <th>hist_month_lag_skew</th>\n",
       "      <th>hist_month_diff_mean</th>\n",
       "      <th>hist_authorized_flag_sum</th>\n",
       "      <th>hist_authorized_flag_mean</th>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <th>hist_category_1_mean</th>\n",
       "      <th>hist_card_id_size</th>\n",
       "      <th>hist_installments_quantiles_var</th>\n",
       "      <th>hist_installments_quantiles_mean</th>\n",
       "      <th>hist_installments_quantiles_skew</th>\n",
       "      <th>hist_purchase_amount_quantiles_var</th>\n",
       "      <th>hist_purchase_amount_quantiles_mean</th>\n",
       "      <th>hist_purchase_amount_quantiles_skew</th>\n",
       "      <th>hist_amount_month_ratio_mean</th>\n",
       "      <th>hist_amount_month_ratio_std</th>\n",
       "      <th>hist_amount_month_ratio_min</th>\n",
       "      <th>hist_amount_month_ratio_max</th>\n",
       "      <th>hist_amount_month_ratio_skew</th>\n",
       "      <th>hist_purchase_date_diff</th>\n",
       "      <th>hist_purchase_date_average</th>\n",
       "      <th>hist_purchase_date_uptonow</th>\n",
       "      <th>hist_of_hist_purchase_date_average</th>\n",
       "      <th>hist_purchase_amount_diff</th>\n",
       "      <th>hist_purchase_count_ratio</th>\n",
       "      <th>hist_purchase_recency</th>\n",
       "      <th>hist_category_2_pa_mean</th>\n",
       "      <th>hist_category_3_pa_mean</th>\n",
       "      <th>hist_merchant_id_count_mean</th>\n",
       "      <th>hist_month_lag_0_-1_ratio</th>\n",
       "      <th>hist_month_lag_0_-2_ratio</th>\n",
       "      <th>new_hist_month_nunique</th>\n",
       "      <th>new_hist_hour_mean</th>\n",
       "      <th>new_hist_hour_min</th>\n",
       "      <th>new_hist_hour_max</th>\n",
       "      <th>new_hist_day_nunique</th>\n",
       "      <th>new_hist_weekend_sum</th>\n",
       "      <th>new_hist_weekend_mean</th>\n",
       "      <th>new_hist_weekofyear_mean</th>\n",
       "      <th>new_hist_weekofyear_min</th>\n",
       "      <th>new_hist_weekofyear_max</th>\n",
       "      <th>new_hist_dayofweek_mean</th>\n",
       "      <th>new_hist_dayofweek_min</th>\n",
       "      <th>new_hist_dayofweek_max</th>\n",
       "      <th>new_hist_year_nunique</th>\n",
       "      <th>new_hist_subsector_id_nunique</th>\n",
       "      <th>new_hist_merchant_id_nunique</th>\n",
       "      <th>new_hist_merchant_category_id_nunique</th>\n",
       "      <th>new_hist_price_nunique</th>\n",
       "      <th>new_hist_city_id_nunique</th>\n",
       "      <th>new_hist_state_id_nunique</th>\n",
       "      <th>new_hist_category_2=1.0_sum</th>\n",
       "      <th>new_hist_category_2=1.0_mean</th>\n",
       "      <th>new_hist_category_2=3.0_sum</th>\n",
       "      <th>new_hist_category_2=3.0_mean</th>\n",
       "      <th>new_hist_category_2=2.0_sum</th>\n",
       "      <th>new_hist_category_2=2.0_mean</th>\n",
       "      <th>new_hist_category_2=4.0_sum</th>\n",
       "      <th>new_hist_category_2=4.0_mean</th>\n",
       "      <th>new_hist_category_2=5.0_sum</th>\n",
       "      <th>new_hist_category_2=5.0_mean</th>\n",
       "      <th>new_hist_category_3=2.0_sum</th>\n",
       "      <th>new_hist_category_3=2.0_mean</th>\n",
       "      <th>new_hist_category_3=1.0_sum</th>\n",
       "      <th>new_hist_category_3=1.0_mean</th>\n",
       "      <th>new_hist_category_3=3.0_sum</th>\n",
       "      <th>new_hist_category_3=3.0_mean</th>\n",
       "      <th>new_hist_month_lag=1_sum</th>\n",
       "      <th>new_hist_month_lag=1_mean</th>\n",
       "      <th>new_hist_month_lag=2_sum</th>\n",
       "      <th>new_hist_month_lag=2_mean</th>\n",
       "      <th>new_hist_EasterDay_2017_sum</th>\n",
       "      <th>new_hist_EasterDay_2017_mean</th>\n",
       "      <th>new_hist_AllSoulsDay_2017_sum</th>\n",
       "      <th>new_hist_AllSoulsDay_2017_mean</th>\n",
       "      <th>new_hist_ChristmasDay_2017_sum</th>\n",
       "      <th>new_hist_ChristmasDay_2017_mean</th>\n",
       "      <th>new_hist_FathersDay_2017_sum</th>\n",
       "      <th>new_hist_FathersDay_2017_mean</th>\n",
       "      <th>new_hist_ChildrenDay_2017_sum</th>\n",
       "      <th>new_hist_ChildrenDay_2017_mean</th>\n",
       "      <th>new_hist_BlackFriday_2017_sum</th>\n",
       "      <th>new_hist_BlackFriday_2017_mean</th>\n",
       "      <th>new_hist_ValentineDay_2017_sum</th>\n",
       "      <th>new_hist_ValentineDay_2017_mean</th>\n",
       "      <th>new_hist_MothersDay_2018_sum</th>\n",
       "      <th>new_hist_MothersDay_2018_mean</th>\n",
       "      <th>new_hist_purchase_amount_sum</th>\n",
       "      <th>new_hist_purchase_amount_max</th>\n",
       "      <th>new_hist_purchase_amount_min</th>\n",
       "      <th>new_hist_purchase_amount_mean</th>\n",
       "      <th>new_hist_purchase_amount_var</th>\n",
       "      <th>new_hist_installments_sum</th>\n",
       "      <th>new_hist_installments_max</th>\n",
       "      <th>new_hist_installments_min</th>\n",
       "      <th>new_hist_installments_mean</th>\n",
       "      <th>new_hist_installments_var</th>\n",
       "      <th>new_hist_installments_std</th>\n",
       "      <th>new_hist_installments_skew</th>\n",
       "      <th>new_hist_purchase_date_max</th>\n",
       "      <th>new_hist_purchase_date_min</th>\n",
       "      <th>new_hist_month_lag_mean</th>\n",
       "      <th>new_hist_month_lag_std</th>\n",
       "      <th>new_hist_month_lag_min</th>\n",
       "      <th>new_hist_month_lag_max</th>\n",
       "      <th>new_hist_month_lag_skew</th>\n",
       "      <th>new_hist_month_diff_mean</th>\n",
       "      <th>new_hist_authorized_flag_sum</th>\n",
       "      <th>new_hist_authorized_flag_mean</th>\n",
       "      <th>new_hist_category_1_sum</th>\n",
       "      <th>new_hist_category_1_mean</th>\n",
       "      <th>new_hist_card_id_size</th>\n",
       "      <th>new_hist_installments_quantiles_var</th>\n",
       "      <th>new_hist_installments_quantiles_mean</th>\n",
       "      <th>new_hist_installments_quantiles_skew</th>\n",
       "      <th>new_hist_purchase_amount_quantiles_var</th>\n",
       "      <th>new_hist_purchase_amount_quantiles_mean</th>\n",
       "      <th>new_hist_purchase_amount_quantiles_skew</th>\n",
       "      <th>new_hist_purchase_date_diff</th>\n",
       "      <th>new_hist_purchase_date_average</th>\n",
       "      <th>new_hist_purchase_date_uptonow</th>\n",
       "      <th>new_hist_of_new_hist_purchase_date_average</th>\n",
       "      <th>new_hist_purchase_amount_diff</th>\n",
       "      <th>new_hist_purchase_count_ratio</th>\n",
       "      <th>new_hist_purchase_recency</th>\n",
       "      <th>new_hist_category_2_pa_mean</th>\n",
       "      <th>new_hist_category_3_pa_mean</th>\n",
       "      <th>new_hist_merchant_id_count_mean</th>\n",
       "      <th>new_hist_month_lag_1_2_ratio</th>\n",
       "      <th>new_hist_r_quantile</th>\n",
       "      <th>new_hist_f_quantile</th>\n",
       "      <th>new_hist_m_quantile</th>\n",
       "      <th>new_hist_RFMindex</th>\n",
       "      <th>new_hist_RFMScore</th>\n",
       "      <th>hist_r_quantile</th>\n",
       "      <th>hist_f_quantile</th>\n",
       "      <th>hist_m_quantile</th>\n",
       "      <th>hist_RFMindex</th>\n",
       "      <th>hist_RFMScore</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>hist_first_buy</th>\n",
       "      <th>new_hist_first_buy</th>\n",
       "      <th>card_id_total</th>\n",
       "      <th>purchase_amount_total</th>\n",
       "      <th>days_feature1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>0.010479</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>9</td>\n",
       "      <td>14.367647</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>34.544118</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>2.794118</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>22</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>22</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>242</td>\n",
       "      <td>3.558824</td>\n",
       "      <td>41</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>51</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>186</td>\n",
       "      <td>2.735294</td>\n",
       "      <td>114</td>\n",
       "      <td>1.676471</td>\n",
       "      <td>115</td>\n",
       "      <td>1.691176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6692.17</td>\n",
       "      <td>653.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.414260</td>\n",
       "      <td>16371.832</td>\n",
       "      <td>141</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.073529</td>\n",
       "      <td>4.248244</td>\n",
       "      <td>2.061127</td>\n",
       "      <td>2.459019</td>\n",
       "      <td>1.514510e+09</td>\n",
       "      <td>1.491330e+09</td>\n",
       "      <td>-3.632353</td>\n",
       "      <td>2.454994</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.116148</td>\n",
       "      <td>14.102941</td>\n",
       "      <td>44</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>23</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>68</td>\n",
       "      <td>0.222125</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.771559</td>\n",
       "      <td>2.037533</td>\n",
       "      <td>2.191176</td>\n",
       "      <td>-0.062233</td>\n",
       "      <td>6.509505</td>\n",
       "      <td>8.361499</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>40.868750</td>\n",
       "      <td>2.223868</td>\n",
       "      <td>268</td>\n",
       "      <td>3.941176</td>\n",
       "      <td>423</td>\n",
       "      <td>1056.235294</td>\n",
       "      <td>651.90</td>\n",
       "      <td>0.252788</td>\n",
       "      <td>423.954583</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>227.8317</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.50</td>\n",
       "      <td>242.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>102.833336</td>\n",
       "      <td>1.480608e+04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.519845e+09</td>\n",
       "      <td>1.517651e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>362.0</td>\n",
       "      <td>208.333333</td>\n",
       "      <td>225.5</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>362.202176</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>227.8317</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>655</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>7000.6700</td>\n",
       "      <td>2088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>5</td>\n",
       "      <td>14.423077</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>12.435897</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2.935897</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220</td>\n",
       "      <td>2.820513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>205</td>\n",
       "      <td>2.628205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6070.80</td>\n",
       "      <td>709.23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>77.830765</td>\n",
       "      <td>10639.974</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.064103</td>\n",
       "      <td>0.164669</td>\n",
       "      <td>0.405794</td>\n",
       "      <td>6.490915</td>\n",
       "      <td>1.518989e+09</td>\n",
       "      <td>1.484321e+09</td>\n",
       "      <td>-10.410256</td>\n",
       "      <td>2.164866</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.716127</td>\n",
       "      <td>12.153846</td>\n",
       "      <td>77</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>78</td>\n",
       "      <td>0.025308</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>6.120530</td>\n",
       "      <td>1.046953</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>-0.058309</td>\n",
       "      <td>5.942832</td>\n",
       "      <td>7.928516</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>54.556152</td>\n",
       "      <td>3.788500</td>\n",
       "      <td>401</td>\n",
       "      <td>5.141026</td>\n",
       "      <td>372</td>\n",
       "      <td>2061.551282</td>\n",
       "      <td>699.23</td>\n",
       "      <td>0.194030</td>\n",
       "      <td>372.104039</td>\n",
       "      <td>427.54507</td>\n",
       "      <td>567.6173</td>\n",
       "      <td>2.785714</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.222222</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>12.444444</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>517.40</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.488890</td>\n",
       "      <td>2.241818e+03</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.524247e+09</td>\n",
       "      <td>1.520080e+09</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.271052</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.082958e-17</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>311.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>311.249803</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>444</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>444</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6588.1997</td>\n",
       "      <td>1572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>6</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>9</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>2.153846</td>\n",
       "      <td>57</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>30</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9475.68</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>728.898440</td>\n",
       "      <td>363968.880</td>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6.846154</td>\n",
       "      <td>23.974359</td>\n",
       "      <td>4.896362</td>\n",
       "      <td>0.537639</td>\n",
       "      <td>1.517598e+09</td>\n",
       "      <td>1.503673e+09</td>\n",
       "      <td>-2.076923</td>\n",
       "      <td>1.754116</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.738523</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>13</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>-3.605551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.069110</td>\n",
       "      <td>46.407565</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>167.538470</td>\n",
       "      <td>1.331605</td>\n",
       "      <td>161</td>\n",
       "      <td>12.384615</td>\n",
       "      <td>388</td>\n",
       "      <td>1993.923077</td>\n",
       "      <td>2038.00</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>388.210382</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>227.8317</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1114.00</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>5.875280e+05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>6.363961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.520947e+09</td>\n",
       "      <td>1.519916e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>349.0</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>349.450856</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>227.8317</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>563</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>564</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10589.6800</td>\n",
       "      <td>2870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>3</td>\n",
       "      <td>17.923077</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>31.115385</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>2.461538</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>17</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>7</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3812.52</td>\n",
       "      <td>555.60</td>\n",
       "      <td>10.0</td>\n",
       "      <td>146.635390</td>\n",
       "      <td>21272.260</td>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>12.886154</td>\n",
       "      <td>3.589729</td>\n",
       "      <td>2.745882</td>\n",
       "      <td>1.519127e+09</td>\n",
       "      <td>1.512392e+09</td>\n",
       "      <td>-1.230769</td>\n",
       "      <td>0.951113</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502455</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.235385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>1.226154</td>\n",
       "      <td>3.115385</td>\n",
       "      <td>-1.201655</td>\n",
       "      <td>11.279646</td>\n",
       "      <td>11.219241</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>42.738460</td>\n",
       "      <td>1.863770</td>\n",
       "      <td>77</td>\n",
       "      <td>2.961538</td>\n",
       "      <td>370</td>\n",
       "      <td>228.038462</td>\n",
       "      <td>545.60</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>370.512049</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>227.8317</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1148.24</td>\n",
       "      <td>199.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>114.824000</td>\n",
       "      <td>2.370815e+03</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>11.211111</td>\n",
       "      <td>3.348300</td>\n",
       "      <td>2.661292</td>\n",
       "      <td>1.524000e+09</td>\n",
       "      <td>1.520162e+09</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.035098</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>-4.336374e-01</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>314.0</td>\n",
       "      <td>193.600000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>314.109456</td>\n",
       "      <td>546.68500</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>433</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>465</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4960.7600</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>12</td>\n",
       "      <td>14.436364</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>0.190909</td>\n",
       "      <td>18.836364</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2.409091</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.918182</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>6</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>219</td>\n",
       "      <td>1.990909</td>\n",
       "      <td>150</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>57</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>107</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>15</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>117</td>\n",
       "      <td>1.063636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71406.62</td>\n",
       "      <td>11000.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>649.151060</td>\n",
       "      <td>3417231.200</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.193495</td>\n",
       "      <td>0.439880</td>\n",
       "      <td>5.726916</td>\n",
       "      <td>1.519728e+09</td>\n",
       "      <td>1.483444e+09</td>\n",
       "      <td>-6.227273</td>\n",
       "      <td>4.530547</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091212</td>\n",
       "      <td>12.236364</td>\n",
       "      <td>87</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110</td>\n",
       "      <td>0.052043</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>3.977586</td>\n",
       "      <td>2.475813</td>\n",
       "      <td>2.318182</td>\n",
       "      <td>-0.355336</td>\n",
       "      <td>49.661587</td>\n",
       "      <td>142.029209</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>846.153900</td>\n",
       "      <td>4.036532</td>\n",
       "      <td>419</td>\n",
       "      <td>3.809091</td>\n",
       "      <td>363</td>\n",
       "      <td>1596.009091</td>\n",
       "      <td>10999.90</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>363.554120</td>\n",
       "      <td>617.09357</td>\n",
       "      <td>735.6103</td>\n",
       "      <td>2.291667</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11011.50</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1835.250000</td>\n",
       "      <td>1.609633e+07</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>27.466667</td>\n",
       "      <td>5.240865</td>\n",
       "      <td>2.418448</td>\n",
       "      <td>1.523535e+09</td>\n",
       "      <td>1.520132e+09</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.968246</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>-7.506571e-02</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>319.0</td>\n",
       "      <td>253.500000</td>\n",
       "      <td>9971.5</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>319.490845</td>\n",
       "      <td>617.09357</td>\n",
       "      <td>227.8317</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>342</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>82418.1200</td>\n",
       "      <td>5915.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-04-01  C_ID_0ab67a22ab   0.010479   0.014166   0.011428   \n",
       "1         2017-01-01  C_ID_130fd0cbdd   0.010610   0.014166   0.010283   \n",
       "2         2017-08-01  C_ID_b709037bc5   0.013145   0.011385   0.011428   \n",
       "3         2017-12-01  C_ID_d27d835a9f   0.010610   0.011385   0.010283   \n",
       "4         2015-12-01  C_ID_2b5e3df5c2   0.013145   0.011385   0.011428   \n",
       "\n",
       "   hist_month_nunique  hist_hour_mean  hist_hour_min  hist_hour_max  \\\n",
       "0                   9       14.367647              0             23   \n",
       "1                   5       14.423077              0             23   \n",
       "2                   6       17.000000             13             20   \n",
       "3                   3       17.923077              8             22   \n",
       "4                  12       14.436364              0             23   \n",
       "\n",
       "   hist_day_nunique  hist_weekend_sum  hist_weekend_mean  \\\n",
       "0                24                12           0.176471   \n",
       "1                27                17           0.217949   \n",
       "2                 7                 0           0.000000   \n",
       "3                11                 7           0.269231   \n",
       "4                27                21           0.190909   \n",
       "\n",
       "   hist_weekofyear_mean  hist_weekofyear_min  hist_weekofyear_max  \\\n",
       "0             34.544118                   14                   52   \n",
       "1             12.435897                    2                   21   \n",
       "2             29.000000                    2                   49   \n",
       "3             31.115385                    4                   50   \n",
       "4             18.836364                    1                   52   \n",
       "\n",
       "   hist_dayofweek_mean  hist_dayofweek_min  hist_dayofweek_max  \\\n",
       "0             2.794118                   0                   6   \n",
       "1             2.935897                   0                   6   \n",
       "2             2.615385                   1                   4   \n",
       "3             2.461538                   0                   6   \n",
       "4             2.409091                   0                   6   \n",
       "\n",
       "   hist_year_nunique  hist_subsector_id_nunique  hist_merchant_id_nunique  \\\n",
       "0                  1                         12                        24   \n",
       "1                  2                         12                        27   \n",
       "2                  2                          6                         9   \n",
       "3                  2                         11                        23   \n",
       "4                  2                         15                        47   \n",
       "\n",
       "   hist_merchant_category_id_nunique  hist_price_nunique  \\\n",
       "0                                 16                  47   \n",
       "1                                 16                  65   \n",
       "2                                  8                  13   \n",
       "3                                 18                  26   \n",
       "4                                 31                  73   \n",
       "\n",
       "   hist_city_id_nunique  hist_state_id_nunique  hist_category_2=1.0_sum  \\\n",
       "0                     7                      3                       68   \n",
       "1                     4                      3                        2   \n",
       "2                     4                      4                        2   \n",
       "3                     1                      1                       26   \n",
       "4                     5                      4                        4   \n",
       "\n",
       "   hist_category_2=1.0_mean  hist_category_2=3.0_sum  \\\n",
       "0                  1.000000                        0   \n",
       "1                  0.025641                        1   \n",
       "2                  0.153846                        0   \n",
       "3                  1.000000                        0   \n",
       "4                  0.036364                        5   \n",
       "\n",
       "   hist_category_2=3.0_mean  hist_category_2=5.0_sum  \\\n",
       "0                  0.000000                        0   \n",
       "1                  0.012821                        0   \n",
       "2                  0.000000                       11   \n",
       "3                  0.000000                        0   \n",
       "4                  0.045455                        0   \n",
       "\n",
       "   hist_category_2=5.0_mean  hist_category_2=2.0_sum  \\\n",
       "0                  0.000000                        0   \n",
       "1                  0.000000                        0   \n",
       "2                  0.846154                        0   \n",
       "3                  0.000000                        0   \n",
       "4                  0.000000                        0   \n",
       "\n",
       "   hist_category_2=2.0_mean  hist_category_2=4.0_sum  \\\n",
       "0                       0.0                        0   \n",
       "1                       0.0                       75   \n",
       "2                       0.0                        0   \n",
       "3                       0.0                        0   \n",
       "4                       0.0                      101   \n",
       "\n",
       "   hist_category_2=4.0_mean  hist_category_3=1.0_sum  \\\n",
       "0                  0.000000                        0   \n",
       "1                  0.961538                        0   \n",
       "2                  0.000000                        3   \n",
       "3                  0.000000                        2   \n",
       "4                  0.918182                        0   \n",
       "\n",
       "   hist_category_3=1.0_mean  hist_category_3=2.0_sum  \\\n",
       "0                  0.000000                       46   \n",
       "1                  0.000000                       76   \n",
       "2                  0.230769                        1   \n",
       "3                  0.076923                       17   \n",
       "4                  0.000000                      104   \n",
       "\n",
       "   hist_category_3=2.0_mean  hist_category_3=3.0_sum  \\\n",
       "0                  0.676471                       22   \n",
       "1                  0.974359                        2   \n",
       "2                  0.076923                        9   \n",
       "3                  0.653846                        7   \n",
       "4                  0.945455                        6   \n",
       "\n",
       "   hist_category_3=3.0_mean  hist_month_lag=-8_nunique  \\\n",
       "0                  0.323529                          2   \n",
       "1                  0.025641                          1   \n",
       "2                  0.692308                          1   \n",
       "3                  0.269231                          1   \n",
       "4                  0.054545                          2   \n",
       "\n",
       "   hist_month_lag=-7_nunique  hist_month_lag=-6_nunique  \\\n",
       "0                          2                          2   \n",
       "1                          1                          1   \n",
       "2                          1                          2   \n",
       "3                          1                          1   \n",
       "4                          2                          2   \n",
       "\n",
       "   hist_month_lag=-5_nunique  hist_month_lag=-11_nunique  \\\n",
       "0                          2                           1   \n",
       "1                          1                           2   \n",
       "2                          1                           1   \n",
       "3                          1                           1   \n",
       "4                          2                           2   \n",
       "\n",
       "   hist_month_lag=0_sum  hist_month_lag=0_mean  hist_month_lag=-3_nunique  \\\n",
       "0                    10               0.147059                          2   \n",
       "1                     2               0.025641                          1   \n",
       "2                     3               0.230769                          2   \n",
       "3                     9               0.346154                          1   \n",
       "4                    23               0.209091                          2   \n",
       "\n",
       "   hist_month_lag=-9_nunique  hist_month_lag=-4_nunique  \\\n",
       "0                          1                          2   \n",
       "1                          2                          1   \n",
       "2                          1                          2   \n",
       "3                          1                          1   \n",
       "4                          2                          2   \n",
       "\n",
       "   hist_month_lag=-1_sum  hist_month_lag=-1_mean  hist_month_lag=-13_nunique  \\\n",
       "0                      4                0.058824                           1   \n",
       "1                      0                0.000000                           2   \n",
       "2                      2                0.153846                           1   \n",
       "3                      2                0.076923                           1   \n",
       "4                      4                0.036364                           2   \n",
       "\n",
       "   hist_month_lag=-10_nunique  hist_month_lag=-12_nunique  \\\n",
       "0                           1                           1   \n",
       "1                           2                           2   \n",
       "2                           1                           1   \n",
       "3                           1                           1   \n",
       "4                           2                           2   \n",
       "\n",
       "   hist_month_lag=-2_sum  hist_month_lag=-2_mean  hist_EasterDay_2017_sum  \\\n",
       "0                     11                0.161765                       22   \n",
       "1                      0                0.000000                      220   \n",
       "2                      3                0.230769                        0   \n",
       "3                     15                0.576923                        0   \n",
       "4                      5                0.045455                      219   \n",
       "\n",
       "   hist_EasterDay_2017_mean  hist_AllSoulsDay_2017_sum  \\\n",
       "0                  0.323529                        242   \n",
       "1                  2.820513                          0   \n",
       "2                  0.000000                         28   \n",
       "3                  0.000000                          0   \n",
       "4                  1.990909                        150   \n",
       "\n",
       "   hist_AllSoulsDay_2017_mean  hist_ChristmasDay_2017_sum  \\\n",
       "0                    3.558824                          41   \n",
       "1                    0.000000                           0   \n",
       "2                    2.153846                          57   \n",
       "3                    0.000000                         240   \n",
       "4                    1.363636                          57   \n",
       "\n",
       "   hist_ChristmasDay_2017_mean  hist_FathersDay_2017_sum  \\\n",
       "0                     0.602941                        51   \n",
       "1                     0.000000                         0   \n",
       "2                     4.384615                         0   \n",
       "3                     9.230769                         0   \n",
       "4                     0.518182                       107   \n",
       "\n",
       "   hist_FathersDay_2017_mean  hist_ChildrenDay_2017_sum  \\\n",
       "0                   0.750000                        186   \n",
       "1                   0.000000                          0   \n",
       "2                   0.000000                          7   \n",
       "3                   0.000000                          0   \n",
       "4                   0.972727                          4   \n",
       "\n",
       "   hist_ChildrenDay_2017_mean  hist_BlackFriday_2017_sum  \\\n",
       "0                    2.735294                        114   \n",
       "1                    0.000000                          0   \n",
       "2                    0.538462                         30   \n",
       "3                    0.000000                          0   \n",
       "4                    0.036364                         15   \n",
       "\n",
       "   hist_BlackFriday_2017_mean  hist_ValentineDay_2017_sum  \\\n",
       "0                    1.676471                         115   \n",
       "1                    0.000000                         205   \n",
       "2                    2.307692                           0   \n",
       "3                    0.000000                           0   \n",
       "4                    0.136364                         117   \n",
       "\n",
       "   hist_ValentineDay_2017_mean  hist_MothersDay_2018_sum  \\\n",
       "0                     1.691176                         0   \n",
       "1                     2.628205                         0   \n",
       "2                     0.000000                         0   \n",
       "3                     0.000000                         0   \n",
       "4                     1.063636                         0   \n",
       "\n",
       "   hist_MothersDay_2018_mean  hist_purchase_amount_sum  \\\n",
       "0                        0.0                   6692.17   \n",
       "1                        0.0                   6070.80   \n",
       "2                        0.0                   9475.68   \n",
       "3                        0.0                   3812.52   \n",
       "4                        0.0                  71406.62   \n",
       "\n",
       "   hist_purchase_amount_max  hist_purchase_amount_min  \\\n",
       "0                    653.90                       2.0   \n",
       "1                    709.23                      10.0   \n",
       "2                   2178.00                     140.0   \n",
       "3                    555.60                      10.0   \n",
       "4                  11000.00                       0.1   \n",
       "\n",
       "   hist_purchase_amount_mean  hist_purchase_amount_var  hist_installments_sum  \\\n",
       "0                  98.414260                 16371.832                    141   \n",
       "1                  77.830765                 10639.974                     83   \n",
       "2                 728.898440                363968.880                     89   \n",
       "3                 146.635390                 21272.260                     68   \n",
       "4                 649.151060               3417231.200                    120   \n",
       "\n",
       "   hist_installments_max  hist_installments_min  hist_installments_mean  \\\n",
       "0                     12                      1                2.073529   \n",
       "1                      4                      1                1.064103   \n",
       "2                     14                      1                6.846154   \n",
       "3                     14                      1                2.615385   \n",
       "4                      4                      1                1.090909   \n",
       "\n",
       "   hist_installments_var  hist_installments_std  hist_installments_skew  \\\n",
       "0               4.248244               2.061127                2.459019   \n",
       "1               0.164669               0.405794                6.490915   \n",
       "2              23.974359               4.896362                0.537639   \n",
       "3              12.886154               3.589729                2.745882   \n",
       "4               0.193495               0.439880                5.726916   \n",
       "\n",
       "   hist_purchase_date_max  hist_purchase_date_min  hist_month_lag_mean  \\\n",
       "0            1.514510e+09            1.491330e+09            -3.632353   \n",
       "1            1.518989e+09            1.484321e+09           -10.410256   \n",
       "2            1.517598e+09            1.503673e+09            -2.076923   \n",
       "3            1.519127e+09            1.512392e+09            -1.230769   \n",
       "4            1.519728e+09            1.483444e+09            -6.227273   \n",
       "\n",
       "   hist_month_lag_std  hist_month_lag_min  hist_month_lag_max  \\\n",
       "0            2.454994                  -8                   0   \n",
       "1            2.164866                 -13                   0   \n",
       "2            1.754116                  -6                   0   \n",
       "3            0.951113                  -2                   0   \n",
       "4            4.530547                 -13                   0   \n",
       "\n",
       "   hist_month_lag_skew  hist_month_diff_mean  hist_authorized_flag_sum  \\\n",
       "0            -0.116148             14.102941                        44   \n",
       "1             2.716127             12.153846                        77   \n",
       "2            -0.738523             12.000000                         9   \n",
       "3             0.502455             12.000000                        26   \n",
       "4             0.091212             12.236364                        87   \n",
       "\n",
       "   hist_authorized_flag_mean  hist_category_1_sum  hist_category_1_mean  \\\n",
       "0                   0.647059                   23              0.338235   \n",
       "1                   0.987179                    2              0.025641   \n",
       "2                   0.692308                    1              0.076923   \n",
       "3                   1.000000                    0              0.000000   \n",
       "4                   0.790909                    0              0.000000   \n",
       "\n",
       "   hist_card_id_size  hist_installments_quantiles_var  \\\n",
       "0                 68                         0.222125   \n",
       "1                 78                         0.025308   \n",
       "2                 13                         0.076923   \n",
       "3                 26                         0.235385   \n",
       "4                110                         0.052043   \n",
       "\n",
       "   hist_installments_quantiles_mean  hist_installments_quantiles_skew  \\\n",
       "0                          0.323529                          0.771559   \n",
       "1                          0.025641                          6.120530   \n",
       "2                          0.923077                         -3.605551   \n",
       "3                          0.346154                          0.687052   \n",
       "4                          0.054545                          3.977586   \n",
       "\n",
       "   hist_purchase_amount_quantiles_var  hist_purchase_amount_quantiles_mean  \\\n",
       "0                            2.037533                             2.191176   \n",
       "1                            1.046953                             2.307692   \n",
       "2                            0.000000                             4.000000   \n",
       "3                            1.226154                             3.115385   \n",
       "4                            2.475813                             2.318182   \n",
       "\n",
       "   hist_purchase_amount_quantiles_skew  hist_amount_month_ratio_mean  \\\n",
       "0                            -0.062233                      6.509505   \n",
       "1                            -0.058309                      5.942832   \n",
       "2                             0.000000                     56.069110   \n",
       "3                            -1.201655                     11.279646   \n",
       "4                            -0.355336                     49.661587   \n",
       "\n",
       "   hist_amount_month_ratio_std  hist_amount_month_ratio_min  \\\n",
       "0                     8.361499                     0.125000   \n",
       "1                     7.928516                     0.714286   \n",
       "2                    46.407565                    10.769231   \n",
       "3                    11.219241                     0.769231   \n",
       "4                   142.029209                     0.007143   \n",
       "\n",
       "   hist_amount_month_ratio_max  hist_amount_month_ratio_skew  \\\n",
       "0                    40.868750                      2.223868   \n",
       "1                    54.556152                      3.788500   \n",
       "2                   167.538470                      1.331605   \n",
       "3                    42.738460                      1.863770   \n",
       "4                   846.153900                      4.036532   \n",
       "\n",
       "   hist_purchase_date_diff  hist_purchase_date_average  \\\n",
       "0                      268                    3.941176   \n",
       "1                      401                    5.141026   \n",
       "2                      161                   12.384615   \n",
       "3                       77                    2.961538   \n",
       "4                      419                    3.809091   \n",
       "\n",
       "   hist_purchase_date_uptonow  hist_of_hist_purchase_date_average  \\\n",
       "0                         423                         1056.235294   \n",
       "1                         372                         2061.551282   \n",
       "2                         388                         1993.923077   \n",
       "3                         370                          228.038462   \n",
       "4                         363                         1596.009091   \n",
       "\n",
       "   hist_purchase_amount_diff  hist_purchase_count_ratio  \\\n",
       "0                     651.90                   0.252788   \n",
       "1                     699.23                   0.194030   \n",
       "2                    2038.00                   0.080247   \n",
       "3                     545.60                   0.333333   \n",
       "4                   10999.90                   0.261905   \n",
       "\n",
       "   hist_purchase_recency  hist_category_2_pa_mean  hist_category_3_pa_mean  \\\n",
       "0             423.954583                546.68500                 227.8317   \n",
       "1             372.104039                427.54507                 567.6173   \n",
       "2             388.210382                546.68500                 227.8317   \n",
       "3             370.512049                546.68500                 227.8317   \n",
       "4             363.554120                617.09357                 735.6103   \n",
       "\n",
       "   hist_merchant_id_count_mean  hist_month_lag_0_-1_ratio  \\\n",
       "0                     2.720000                        2.0   \n",
       "1                     2.785714                        2.0   \n",
       "2                     1.300000                        1.0   \n",
       "3                     1.083333                        3.0   \n",
       "4                     2.291667                        4.6   \n",
       "\n",
       "   hist_month_lag_0_-2_ratio  new_hist_month_nunique  new_hist_hour_mean  \\\n",
       "0                   0.833333                     1.0           13.666667   \n",
       "1                   2.000000                     2.0           15.222222   \n",
       "2                   0.750000                     1.0           13.500000   \n",
       "3                   0.562500                     2.0           18.200000   \n",
       "4                   3.833333                     2.0            8.000000   \n",
       "\n",
       "   new_hist_hour_min  new_hist_hour_max  new_hist_day_nunique  \\\n",
       "0                9.0               19.0                   3.0   \n",
       "1                9.0               23.0                   7.0   \n",
       "2               13.0               14.0                   2.0   \n",
       "3               11.0               21.0                   8.0   \n",
       "4                0.0               16.0                   5.0   \n",
       "\n",
       "   new_hist_weekend_sum  new_hist_weekend_mean  new_hist_weekofyear_mean  \\\n",
       "0                   1.0               0.333333                  7.000000   \n",
       "1                   3.0               0.333333                 12.444444   \n",
       "2                   0.0               0.000000                 10.000000   \n",
       "3                   3.0               0.300000                 12.100000   \n",
       "4                   2.0               0.333333                 10.500000   \n",
       "\n",
       "   new_hist_weekofyear_min  new_hist_weekofyear_max  new_hist_dayofweek_mean  \\\n",
       "0                      5.0                      9.0                 3.666667   \n",
       "1                      9.0                     16.0                 3.000000   \n",
       "2                      9.0                     11.0                 2.000000   \n",
       "3                      9.0                     16.0                 3.200000   \n",
       "4                      9.0                     15.0                 4.000000   \n",
       "\n",
       "   new_hist_dayofweek_min  new_hist_dayofweek_max  new_hist_year_nunique  \\\n",
       "0                     2.0                     5.0                    1.0   \n",
       "1                     0.0                     6.0                    1.0   \n",
       "2                     1.0                     3.0                    1.0   \n",
       "3                     1.0                     6.0                    1.0   \n",
       "4                     2.0                     6.0                    1.0   \n",
       "\n",
       "   new_hist_subsector_id_nunique  new_hist_merchant_id_nunique  \\\n",
       "0                            3.0                           3.0   \n",
       "1                            6.0                           9.0   \n",
       "2                            2.0                           2.0   \n",
       "3                            8.0                          10.0   \n",
       "4                            4.0                           6.0   \n",
       "\n",
       "   new_hist_merchant_category_id_nunique  new_hist_price_nunique  \\\n",
       "0                                    3.0                     3.0   \n",
       "1                                    8.0                     9.0   \n",
       "2                                    2.0                     2.0   \n",
       "3                                   10.0                    10.0   \n",
       "4                                    5.0                     6.0   \n",
       "\n",
       "   new_hist_city_id_nunique  new_hist_state_id_nunique  \\\n",
       "0                       3.0                        1.0   \n",
       "1                       2.0                        2.0   \n",
       "2                       2.0                        2.0   \n",
       "3                       3.0                        3.0   \n",
       "4                       2.0                        2.0   \n",
       "\n",
       "   new_hist_category_2=1.0_sum  new_hist_category_2=1.0_mean  \\\n",
       "0                          3.0                      1.000000   \n",
       "1                          2.0                      0.222222   \n",
       "2                          1.0                      0.500000   \n",
       "3                          9.0                      0.900000   \n",
       "4                          0.0                      0.000000   \n",
       "\n",
       "   new_hist_category_2=3.0_sum  new_hist_category_2=3.0_mean  \\\n",
       "0                          0.0                      0.000000   \n",
       "1                          0.0                      0.000000   \n",
       "2                          0.0                      0.000000   \n",
       "3                          0.0                      0.000000   \n",
       "4                          1.0                      0.166667   \n",
       "\n",
       "   new_hist_category_2=2.0_sum  new_hist_category_2=2.0_mean  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   new_hist_category_2=4.0_sum  new_hist_category_2=4.0_mean  \\\n",
       "0                          0.0                      0.000000   \n",
       "1                          7.0                      0.777778   \n",
       "2                          0.0                      0.000000   \n",
       "3                          0.0                      0.000000   \n",
       "4                          5.0                      0.833333   \n",
       "\n",
       "   new_hist_category_2=5.0_sum  new_hist_category_2=5.0_mean  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          1.0                           0.5   \n",
       "3                          1.0                           0.1   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   new_hist_category_3=2.0_sum  new_hist_category_3=2.0_mean  \\\n",
       "0                          2.0                      0.666667   \n",
       "1                          8.0                      0.888889   \n",
       "2                          1.0                      0.500000   \n",
       "3                          5.0                      0.500000   \n",
       "4                          4.0                      0.666667   \n",
       "\n",
       "   new_hist_category_3=1.0_sum  new_hist_category_3=1.0_mean  \\\n",
       "0                          0.0                      0.000000   \n",
       "1                          0.0                      0.000000   \n",
       "2                          0.0                      0.000000   \n",
       "3                          0.0                      0.000000   \n",
       "4                          1.0                      0.166667   \n",
       "\n",
       "   new_hist_category_3=3.0_sum  new_hist_category_3=3.0_mean  \\\n",
       "0                          1.0                      0.333333   \n",
       "1                          1.0                      0.111111   \n",
       "2                          1.0                      0.500000   \n",
       "3                          5.0                      0.500000   \n",
       "4                          1.0                      0.166667   \n",
       "\n",
       "   new_hist_month_lag=1_sum  new_hist_month_lag=1_mean  \\\n",
       "0                       0.0                   0.000000   \n",
       "1                       5.0                   0.555556   \n",
       "2                       2.0                   1.000000   \n",
       "3                       7.0                   0.700000   \n",
       "4                       5.0                   0.833333   \n",
       "\n",
       "   new_hist_month_lag=2_sum  new_hist_month_lag=2_mean  \\\n",
       "0                       3.0                   1.000000   \n",
       "1                       4.0                   0.444444   \n",
       "2                       0.0                   0.000000   \n",
       "3                       3.0                   0.300000   \n",
       "4                       1.0                   0.166667   \n",
       "\n",
       "   new_hist_EasterDay_2017_sum  new_hist_EasterDay_2017_mean  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   new_hist_AllSoulsDay_2017_sum  new_hist_AllSoulsDay_2017_mean  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   new_hist_ChristmasDay_2017_sum  new_hist_ChristmasDay_2017_mean  \\\n",
       "0                             0.0                              0.0   \n",
       "1                             0.0                              0.0   \n",
       "2                             0.0                              0.0   \n",
       "3                             0.0                              0.0   \n",
       "4                             0.0                              0.0   \n",
       "\n",
       "   new_hist_FathersDay_2017_sum  new_hist_FathersDay_2017_mean  \\\n",
       "0                           0.0                            0.0   \n",
       "1                           0.0                            0.0   \n",
       "2                           0.0                            0.0   \n",
       "3                           0.0                            0.0   \n",
       "4                           0.0                            0.0   \n",
       "\n",
       "   new_hist_ChildrenDay_2017_sum  new_hist_ChildrenDay_2017_mean  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   new_hist_BlackFriday_2017_sum  new_hist_BlackFriday_2017_mean  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   new_hist_ValentineDay_2017_sum  new_hist_ValentineDay_2017_mean  \\\n",
       "0                             0.0                              0.0   \n",
       "1                             0.0                              0.0   \n",
       "2                             0.0                              0.0   \n",
       "3                             0.0                              0.0   \n",
       "4                             0.0                              0.0   \n",
       "\n",
       "   new_hist_MothersDay_2018_sum  new_hist_MothersDay_2018_mean  \\\n",
       "0                           0.0                            0.0   \n",
       "1                          72.0                            8.0   \n",
       "2                           0.0                            0.0   \n",
       "3                          25.0                            2.5   \n",
       "4                           0.0                            0.0   \n",
       "\n",
       "   new_hist_purchase_amount_sum  new_hist_purchase_amount_max  \\\n",
       "0                        308.50                         242.0   \n",
       "1                        517.40                         160.0   \n",
       "2                       1114.00                        1099.0   \n",
       "3                       1148.24                         199.0   \n",
       "4                      11011.50                       10000.0   \n",
       "\n",
       "   new_hist_purchase_amount_min  new_hist_purchase_amount_mean  \\\n",
       "0                          16.5                     102.833336   \n",
       "1                           4.0                      57.488890   \n",
       "2                          15.0                     557.000000   \n",
       "3                          50.0                     114.824000   \n",
       "4                          28.5                    1835.250000   \n",
       "\n",
       "   new_hist_purchase_amount_var  new_hist_installments_sum  \\\n",
       "0                  1.480608e+04                        5.0   \n",
       "1                  2.241818e+03                       11.0   \n",
       "2                  5.875280e+05                       11.0   \n",
       "3                  2.370815e+03                       29.0   \n",
       "4                  1.609633e+07                       20.0   \n",
       "\n",
       "   new_hist_installments_max  new_hist_installments_min  \\\n",
       "0                        3.0                        1.0   \n",
       "1                        3.0                        1.0   \n",
       "2                       10.0                        1.0   \n",
       "3                       12.0                        1.0   \n",
       "4                       14.0                        1.0   \n",
       "\n",
       "   new_hist_installments_mean  new_hist_installments_var  \\\n",
       "0                    1.666667                   1.333333   \n",
       "1                    1.222222                   0.444444   \n",
       "2                    5.500000                  40.500000   \n",
       "3                    2.900000                  11.211111   \n",
       "4                    3.333333                  27.466667   \n",
       "\n",
       "   new_hist_installments_std  new_hist_installments_skew  \\\n",
       "0                   1.154701                    1.732051   \n",
       "1                   0.666667                    3.000000   \n",
       "2                   6.363961                         NaN   \n",
       "3                   3.348300                    2.661292   \n",
       "4                   5.240865                    2.418448   \n",
       "\n",
       "   new_hist_purchase_date_max  new_hist_purchase_date_min  \\\n",
       "0                1.519845e+09                1.517651e+09   \n",
       "1                1.524247e+09                1.520080e+09   \n",
       "2                1.520947e+09                1.519916e+09   \n",
       "3                1.524000e+09                1.520162e+09   \n",
       "4                1.523535e+09                1.520132e+09   \n",
       "\n",
       "   new_hist_month_lag_mean  new_hist_month_lag_std  new_hist_month_lag_min  \\\n",
       "0                 2.000000                0.000000                     2.0   \n",
       "1                 1.444444                0.527046                     1.0   \n",
       "2                 1.000000                0.000000                     1.0   \n",
       "3                 1.300000                0.483046                     1.0   \n",
       "4                 1.166667                0.408248                     1.0   \n",
       "\n",
       "   new_hist_month_lag_max  new_hist_month_lag_skew  new_hist_month_diff_mean  \\\n",
       "0                     2.0                 0.000000                      14.0   \n",
       "1                     2.0                 0.271052                      12.0   \n",
       "2                     1.0                      NaN                      12.5   \n",
       "3                     2.0                 1.035098                      12.0   \n",
       "4                     2.0                 2.449490                      12.0   \n",
       "\n",
       "   new_hist_authorized_flag_sum  new_hist_authorized_flag_mean  \\\n",
       "0                           3.0                            1.0   \n",
       "1                           9.0                            1.0   \n",
       "2                           2.0                            1.0   \n",
       "3                          10.0                            1.0   \n",
       "4                           6.0                            1.0   \n",
       "\n",
       "   new_hist_category_1_sum  new_hist_category_1_mean  new_hist_card_id_size  \\\n",
       "0                      0.0                  0.000000                    3.0   \n",
       "1                      2.0                  0.222222                    9.0   \n",
       "2                      1.0                  0.500000                    2.0   \n",
       "3                      1.0                  0.100000                   10.0   \n",
       "4                      0.0                  0.000000                    6.0   \n",
       "\n",
       "   new_hist_installments_quantiles_var  new_hist_installments_quantiles_mean  \\\n",
       "0                             0.333333                              0.333333   \n",
       "1                             0.111111                              0.111111   \n",
       "2                             0.500000                              0.500000   \n",
       "3                             0.277778                              0.500000   \n",
       "4                             0.266667                              0.333333   \n",
       "\n",
       "   new_hist_installments_quantiles_skew  \\\n",
       "0                              1.732051   \n",
       "1                              3.000000   \n",
       "2                                   NaN   \n",
       "3                              0.000000   \n",
       "4                              0.968246   \n",
       "\n",
       "   new_hist_purchase_amount_quantiles_var  \\\n",
       "0                                4.000000   \n",
       "1                                1.750000   \n",
       "2                                8.000000   \n",
       "3                                0.455556   \n",
       "4                                1.466667   \n",
       "\n",
       "   new_hist_purchase_amount_quantiles_mean  \\\n",
       "0                                 2.000000   \n",
       "1                                 2.000000   \n",
       "2                                 2.000000   \n",
       "3                                 3.300000   \n",
       "4                                 2.666667   \n",
       "\n",
       "   new_hist_purchase_amount_quantiles_skew  new_hist_purchase_date_diff  \\\n",
       "0                             0.000000e+00                         25.0   \n",
       "1                             3.082958e-17                         48.0   \n",
       "2                                      NaN                         11.0   \n",
       "3                            -4.336374e-01                         44.0   \n",
       "4                            -7.506571e-02                         39.0   \n",
       "\n",
       "   new_hist_purchase_date_average  new_hist_purchase_date_uptonow  \\\n",
       "0                        8.333333                           362.0   \n",
       "1                        5.333333                           311.0   \n",
       "2                        5.500000                           349.0   \n",
       "3                        4.400000                           314.0   \n",
       "4                        6.500000                           319.0   \n",
       "\n",
       "   new_hist_of_new_hist_purchase_date_average  new_hist_purchase_amount_diff  \\\n",
       "0                                  208.333333                          225.5   \n",
       "1                                  256.000000                          156.0   \n",
       "2                                   60.500000                         1084.0   \n",
       "3                                  193.600000                          149.0   \n",
       "4                                  253.500000                         9971.5   \n",
       "\n",
       "   new_hist_purchase_count_ratio  new_hist_purchase_recency  \\\n",
       "0                       0.115385                 362.202176   \n",
       "1                       0.183673                 311.249803   \n",
       "2                       0.166667                 349.450856   \n",
       "3                       0.222222                 314.109456   \n",
       "4                       0.150000                 319.490845   \n",
       "\n",
       "   new_hist_category_2_pa_mean  new_hist_category_3_pa_mean  \\\n",
       "0                    546.68500                     227.8317   \n",
       "1                    546.68500                     735.6103   \n",
       "2                    546.68500                     227.8317   \n",
       "3                    546.68500                     735.6103   \n",
       "4                    617.09357                     227.8317   \n",
       "\n",
       "   new_hist_merchant_id_count_mean  new_hist_month_lag_1_2_ratio  \\\n",
       "0                         0.750000                          0.00   \n",
       "1                         0.900000                          1.00   \n",
       "2                         0.666667                          2.00   \n",
       "3                         0.909091                          1.75   \n",
       "4                         0.857143                          2.50   \n",
       "\n",
       "   new_hist_r_quantile  new_hist_f_quantile  new_hist_m_quantile  \\\n",
       "0                    6                    5                    5   \n",
       "1                    4                    4                    4   \n",
       "2                    5                    6                    3   \n",
       "3                    4                    3                    3   \n",
       "4                    4                    4                    1   \n",
       "\n",
       "   new_hist_RFMindex  new_hist_RFMScore  hist_r_quantile  hist_f_quantile  \\\n",
       "0                655                 16                6                4   \n",
       "1                444                 12                4                4   \n",
       "2                563                 14                5                6   \n",
       "3                433                 10                4                6   \n",
       "4                441                  9                3                4   \n",
       "\n",
       "   hist_m_quantile  hist_RFMindex  hist_RFMScore  dayofweek  weekofyear  \\\n",
       "0                4            644             14        5.0        13.0   \n",
       "1                4            444             12        6.0        52.0   \n",
       "2                4            564             15        1.0        31.0   \n",
       "3                5            465             15        4.0        48.0   \n",
       "4                2            342              9        1.0        49.0   \n",
       "\n",
       "   month  elapsed_time  hist_first_buy  new_hist_first_buy  card_id_total  \\\n",
       "0    4.0         696.0             3.0               308.0           71.0   \n",
       "1    1.0         786.0            12.0               426.0           87.0   \n",
       "2    8.0         574.0            24.0               212.0           15.0   \n",
       "3   12.0         452.0             3.0                93.0           36.0   \n",
       "4   12.0        1183.0           399.0               824.0          116.0   \n",
       "\n",
       "   purchase_amount_total  days_feature1  \n",
       "0              7000.6700         2088.0  \n",
       "1              6588.1997         1572.0  \n",
       "2             10589.6800         2870.0  \n",
       "3              4960.7600          904.0  \n",
       "4             82418.1200         5915.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e772618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numeric_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    initial_memory = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for column in df.columns:\n",
    "        column_type = df[column].dtypes\n",
    "        if column_type in numeric_types:\n",
    "            col_min = df[column].min()\n",
    "            col_max = df[column].max()\n",
    "\n",
    "            if str(column_type)[:3] == 'int':\n",
    "                if col_min > np.iinfo(np.int8).min and col_max < np.iinfo(np.int8).max:\n",
    "                    df[column] = df[column].astype(np.int8)\n",
    "                elif col_min > np.iinfo(np.int16).min and col_max < np.iinfo(np.int16).max:\n",
    "                    df[column] = df[column].astype(np.int16)\n",
    "                elif col_min > np.iinfo(np.int32).min and col_max < np.iinfo(np.int32).max:\n",
    "                    df[column] = df[column].astype(np.int32)\n",
    "                elif col_min > np.iinfo(np.int64).min and col_max < np.iinfo(np.int64).max:\n",
    "                    df[column] = df[column].astype(np.int64)\n",
    "            else:\n",
    "                if col_min > np.finfo(np.float16).min and col_max < np.finfo(np.float32).max:\n",
    "                    df[column] = df[column].astype(np.float32)\n",
    "                else:\n",
    "                    df[column] = df[column].astype(np.float64)\n",
    "\n",
    "    final_memory = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1%} reduction)'.format(\n",
    "            final_memory, (initial_memory - final_memory) / initial_memory\n",
    "        ))\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8267f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 151.35 Mb (59.4% reduction)\n",
      "Mem. usage decreased to 93.73 Mb (58.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "#Reducing the memory storage\n",
    "train=reduce_mem_usage(train)\n",
    "test=reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4468c2f",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b2ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determing the relevent columns for modelling: remove target column, outlier column and identifier column\n",
    "def derive_columns(train_df, test_df):\n",
    "    train_features = [col for col in train_df.columns if col not in ['card_id', 'first_active_month', 'target', 'outliers']]\n",
    "    test_features = [col for col in test_df.columns if col not in ['card_id', 'first_active_month', 'target', 'outliers']]\n",
    "    return train_features, test_features\n",
    "\n",
    "df_train_columns, df_test_columns = derive_columns(train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1538d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing and infinite values using median\n",
    "def fillup_null_values(train_df, test_df, train_features, test_features):\n",
    "    test_df['first_active_month'].fillna('2017-06-01', inplace=True)\n",
    "\n",
    "    for feature in train_features:\n",
    "        train_df[feature].fillna(train_df[feature].median(), inplace=True)\n",
    "\n",
    "    for feature in test_features:\n",
    "        test_df[feature].fillna(test_df[feature].median(), inplace=True)\n",
    "\n",
    "    train_df = train_df.replace(np.inf, np.nan)\n",
    "    test_df = test_df.replace(np.inf, np.nan)\n",
    "\n",
    "    purchase_amount_columns = [\n",
    "        'new_hist_purchase_amount_sum', 'new_hist_purchase_amount_min', 'new_hist_purchase_amount_mean',\n",
    "        'new_hist_purchase_amount_max', 'new_hist_purchase_amount_var', 'new_hist_purchase_amount_diff',\n",
    "        'purchase_amount_total'\n",
    "    ]\n",
    "\n",
    "    for col in purchase_amount_columns:\n",
    "        train_df[col].fillna(train_df[col].median(), inplace=True)\n",
    "        test_df[col].fillna(train_df[col].median(), inplace=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train, test = fillup_null_values(train, test, df_train_columns, df_test_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd404881",
   "metadata": {},
   "source": [
    "### Checking to make sure all the missing values are filled up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Nulls:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls</th>\n",
       "      <th>null_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nulls, null_percent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Nulls:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls</th>\n",
       "      <th>null_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nulls, null_percent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Infinities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls</th>\n",
       "      <th>null_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nulls, null_percent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Infinities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls</th>\n",
       "      <th>null_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nulls, null_percent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for missing values in train\n",
    "train_null_counts = train.isnull().sum()\n",
    "train_null_info = pd.DataFrame({\n",
    "    \"nulls\": train_null_counts,\n",
    "    \"null_percent\": train_null_counts * 100 / train.shape[0]\n",
    "})\n",
    "print(\"Train Nulls:\")\n",
    "display(train_null_info[train_null_info.nulls != 0])\n",
    "\n",
    "# Check for missing values in test\n",
    "test_null_counts = test.isnull().sum()\n",
    "test_null_info = pd.DataFrame({\n",
    "    \"nulls\": test_null_counts,\n",
    "    \"null_percent\": test_null_counts * 100 / test.shape[0]\n",
    "})\n",
    "print(\"Test Nulls:\")\n",
    "display(test_null_info[test_null_info.nulls != 0])\n",
    "\n",
    "# Check for infinite values in train (only in feature columns)\n",
    "train_inf_counts = np.isinf(train[df_train_columns]).sum()\n",
    "train_inf_info = pd.DataFrame({\n",
    "    \"nulls\": train_inf_counts,\n",
    "    \"null_percent\": train_inf_counts * 100 / train.shape[0]\n",
    "})\n",
    "print(\"Train Infinities:\")\n",
    "display(train_inf_info[train_inf_info.nulls != 0])\n",
    "\n",
    "# Check for infinite values in test (only in feature columns)\n",
    "test_inf_counts = np.isinf(test[df_test_columns]).sum()\n",
    "test_inf_info = pd.DataFrame({\n",
    "    \"nulls\": test_inf_counts,\n",
    "    \"null_percent\": test_inf_counts * 100 / test.shape[0]\n",
    "})\n",
    "print(\"Test Infinities:\")\n",
    "display(test_inf_info[test_inf_info.nulls != 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab394ee8",
   "metadata": {},
   "source": [
    "### Train-test columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f12a568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, X_test, y_train, y_test_com shapes:\n",
      "(161533, 237) (40384, 237) (161533,) (40384,)\n"
     ]
    }
   ],
   "source": [
    "# Extract features and target\n",
    "outliers = train['outliers']\n",
    "y = train['target']\n",
    "X = train[df_train_columns].copy()\n",
    "\n",
    "# Drop unwanted feature if it exists\n",
    "if \"target_class\" in X.columns:\n",
    "    X.drop(\"target_class\", axis=1, inplace=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train, X_test, y_train, y_test_com shapes:\")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81f2bf",
   "metadata": {},
   "source": [
    "## Base Modelling\n",
    "- Linear Models: Linear, Ridge, Lasso\n",
    "- Bagging Models: Random Forest\n",
    "- Boosting Models: Lightgbm, XgBoost, Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6135b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE calculator\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17881f6b",
   "metadata": {},
   "source": [
    "### Linear Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd713bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using linear regression::3.876\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train) #training the algorithm\n",
    "y_pred_linear = regressor.predict(X_test)\n",
    "rmse_linear=rmse(y_test, y_pred_linear)\n",
    "print(\"RMSE using linear regression::{:.3f}\".format(rmse_linear))\n",
    "linear_test_pred=regressor.predict(test[df_test_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id    0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the feature importance dataframe and rmse\n",
    "coef = regressor.coef_\n",
    "feature_importance_df_linear = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': coef,\n",
    "    'Importance (abs)': np.abs(coef)\n",
    "}).sort_values(by='Importance (abs)', ascending=False)\n",
    "\n",
    "linear = pd.DataFrame({\n",
    "    'card_id': test['card_id'],\n",
    "    'target': linear_test_pred\n",
    "})\n",
    "\n",
    "linear.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                card_id    target\n",
      "0       C_ID_0ab67a22ab -0.392636\n",
      "1       C_ID_130fd0cbdd -0.392636\n",
      "2       C_ID_b709037bc5 -0.392636\n",
      "3       C_ID_d27d835a9f -0.392636\n",
      "4       C_ID_2b5e3df5c2 -0.392636\n",
      "...                 ...       ...\n",
      "123618  C_ID_7a239d2eda -0.392636\n",
      "123619  C_ID_75ace375ae -0.392636\n",
      "123620  C_ID_21d56d950c -0.392636\n",
      "123621  C_ID_6c46fc5a9d -0.392636\n",
      "123622  C_ID_87e7979a5f -0.392636\n",
      "\n",
      "[123623 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(linear)\n",
    "linear.to_csv(\"linear_latest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.001\n",
      "RMSE using Ridge Regression: 3.866\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "parameters = {'alpha': [1e-4, 1e-3, 1e-2, 0.1, 1, 10]}\n",
    "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_root_mean_squared_error', cv=5, n_jobs=-1)\n",
    "ridge_regressor.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_regressor.predict(X_test)\n",
    "rmse_ridge=rmse(y_test, y_pred_ridge)\n",
    "print(\"Best alpha:\", ridge_regressor.best_params_['alpha'])\n",
    "print(\"RMSE using Ridge Regression: {:.3f}\".format(rmse_ridge))\n",
    "\n",
    "ridge_test_pred = ridge_regressor.predict(test[df_test_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40a5ce07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id    0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = ridge_regressor.best_estimator_.coef_\n",
    "feature_importance_df_ridge = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': coef,\n",
    "    'Importance (abs)': np.abs(coef)\n",
    "}).sort_values(by='Importance (abs)', ascending=False)\n",
    "\n",
    "ridge = pd.DataFrame({\n",
    "    'card_id': test['card_id'],\n",
    "    'target': ridge_test_pred\n",
    "})\n",
    "\n",
    "ridge.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3ef9233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                card_id    target\n",
      "0       C_ID_0ab67a22ab -1.121094\n",
      "1       C_ID_130fd0cbdd -0.212891\n",
      "2       C_ID_b709037bc5 -1.670898\n",
      "3       C_ID_d27d835a9f -0.887695\n",
      "4       C_ID_2b5e3df5c2 -2.569336\n",
      "...                 ...       ...\n",
      "123618  C_ID_7a239d2eda  1.839844\n",
      "123619  C_ID_75ace375ae  0.496094\n",
      "123620  C_ID_21d56d950c  1.111328\n",
      "123621  C_ID_6c46fc5a9d -3.803711\n",
      "123622  C_ID_87e7979a5f -0.849609\n",
      "\n",
      "[123623 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ridge)\n",
    "ridge.to_csv(\"ridge_latest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Lasso Regressor: 3.796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "parameters = {'alpha': [1e-3, 1e-2, 1e-1], 'max_iter': [1000, 2000]}\n",
    "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_root_mean_squared_error', cv=5)\n",
    "lasso_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lasso = lasso_regressor.predict(X_test)\n",
    "rmse_lasso=rmse(y_test, y_pred_lasso)\n",
    "print(\"RMSE for Lasso Regressor: {:.3f}\".format(rmse_lasso))\n",
    "\n",
    "lasso_test_pred = lasso_regressor.predict(test[df_test_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id    0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = lasso_regressor.best_estimator_.coef_\n",
    "feature_importance_df_lasso = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': coef,\n",
    "    'Importance (abs)': np.abs(coef)\n",
    "}).sort_values(by='Importance (abs)', ascending=False)\n",
    "\n",
    "lasso = pd.DataFrame({\n",
    "    'card_id': test['card_id'],\n",
    "    'target': lasso_test_pred\n",
    "})\n",
    "lasso.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                card_id    target\n",
      "0       C_ID_0ab67a22ab -1.209412\n",
      "1       C_ID_130fd0cbdd  0.570984\n",
      "2       C_ID_b709037bc5 -0.822876\n",
      "3       C_ID_d27d835a9f -0.099731\n",
      "4       C_ID_2b5e3df5c2 -3.321167\n",
      "...                 ...       ...\n",
      "123618  C_ID_7a239d2eda  0.637451\n",
      "123619  C_ID_75ace375ae -0.062927\n",
      "123620  C_ID_21d56d950c  0.017883\n",
      "123621  C_ID_6c46fc5a9d -2.118347\n",
      "123622  C_ID_87e7979a5f -0.049866\n",
      "\n",
      "[123623 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(lasso)\n",
    "lasso.to_csv(\"lasso_latest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b11c23f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "RMSE for Random Forest Regressor: 3.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = {\n",
    "    \"criterion\": [\"squared_error\"],\n",
    "    \"n_estimators\": [500, 1000],\n",
    "    \"max_depth\": [5, 10, 15],\n",
    "    \"max_leaf_nodes\": [5],\n",
    "    \"min_samples_split\": [8],\n",
    "    \"max_features\": [50, 100],\n",
    "    \"min_impurity_decrease\": [0.1]\n",
    "}\n",
    "\n",
    "forestRegressor = RandomForestRegressor(random_state=10)\n",
    "grid_forest = GridSearchCV(forestRegressor, param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "grid_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred_forest = grid_forest.predict(X_test)\n",
    "rmse_rf=rmse(y_test, y_pred_forest)\n",
    "print(\"RMSE for Random Forest Regressor: {:.3f}\".format(rmse(y_test, y_pred_forest)))\n",
    "\n",
    "random_forest_test_pred = grid_forest.predict(test[df_test_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed96acd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id    0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model = grid_forest.best_estimator_\n",
    "\n",
    "feature_importance_df_rf = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "rf= pd.DataFrame({\n",
    "    'card_id': test['card_id'],\n",
    "    'target': random_forest_test_pred\n",
    "})\n",
    "\n",
    "rf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c26247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                card_id    target\n",
      "0       C_ID_0ab67a22ab -3.382173\n",
      "1       C_ID_130fd0cbdd -0.110156\n",
      "2       C_ID_b709037bc5 -0.110156\n",
      "3       C_ID_d27d835a9f -0.110156\n",
      "4       C_ID_2b5e3df5c2 -0.110156\n",
      "...                 ...       ...\n",
      "123618  C_ID_7a239d2eda -0.110156\n",
      "123619  C_ID_75ace375ae -0.110156\n",
      "123620  C_ID_21d56d950c -0.110156\n",
      "123621  C_ID_6c46fc5a9d -1.275551\n",
      "123622  C_ID_87e7979a5f -0.110156\n",
      "\n",
      "[123623 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(rf)\n",
    "rf.to_csv(\"latest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f1b4f",
   "metadata": {},
   "source": [
    "## Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47dfcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference: https://github.com/optuna/optuna/blob/master/examples/lightgbm_simple.py\n",
    "def objectivelgbm(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbose': -1,\n",
    "        'learning_rate': 0.01,\n",
    "        'device': 'cpu',\n",
    "        'seed': 326,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 64),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.001, 1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.001, 1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 12),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0, 10),\n",
    "        'min_split_gain': trial.suggest_uniform('min_split_gain', 0, 10),\n",
    "        'min_child_weight': trial.suggest_uniform('min_child_weight', 0, 45),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 16, 64)\n",
    "    }\n",
    "\n",
    "    # Create LightGBM dataset\n",
    "    dtrain = lightgbm.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    ## creating folds so, training and validation can be done in folds of data\n",
    "    folds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_results = lightgbm.cv(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=10000,\n",
    "        nfold=3,\n",
    "        folds = KFold(n_splits=3, shuffle=True, random_state=42),\n",
    "        seed=47,\n",
    "        stratified=False,\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=200),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Debug output (optional)\n",
    "    print(\"CV Result Keys:\", cv_results.keys())\n",
    "\n",
    "    # Return the RMSE or L2 mean\n",
    "    for key in cv_results:\n",
    "        if \"rmse-mean\" in key or \"l2-mean\" in key:\n",
    "            return cv_results[key][-1]\n",
    "\n",
    "    raise KeyError(\"Expected metric 'rmse-mean' or 'l2-mean' not found in cv_results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference: https://colab.research.google.com/drive/1I8abciKFXBxkoXrcwLiG7_BrYskLnV8k#scrollTo=8lOM3b6iO3it\n",
    "\n",
    "# This class is used to implement early stopping in Optuna trials\n",
    "OPTUNA_EARLY_STOPPING = 20\n",
    "\n",
    "class EarlyStoppingExceeded(optuna.exceptions.OptunaError):\n",
    "    early_stop_limit = OPTUNA_EARLY_STOPPING\n",
    "    early_stop_counter = 0\n",
    "    best_score_so_far = None\n",
    "\n",
    "def early_stopping_opt(study: optuna.study.Study, trial: optuna.trial.FrozenTrial):\n",
    "    if EarlyStoppingExceeded.best_score_so_far is None:\n",
    "        EarlyStoppingExceeded.best_score_so_far = study.best_value\n",
    "\n",
    "    if study.best_value < EarlyStoppingExceeded.best_score_so_far:\n",
    "        # New best score found ‚Äî reset counter\n",
    "        EarlyStoppingExceeded.best_score_so_far = study.best_value\n",
    "        EarlyStoppingExceeded.early_stop_counter = 0\n",
    "    else:\n",
    "        # No improvement\n",
    "        EarlyStoppingExceeded.early_stop_counter += 1\n",
    "        if EarlyStoppingExceeded.early_stop_counter > EarlyStoppingExceeded.early_stop_limit:\n",
    "            # Reset for potential reuse\n",
    "            EarlyStoppingExceeded.early_stop_counter = 0\n",
    "            EarlyStoppingExceeded.best_score_so_far = None\n",
    "            raise EarlyStoppingExceeded()\n",
    "\n",
    "    print(\n",
    "        f\"EarlyStop counter currently is: {EarlyStoppingExceeded.early_stop_counter}, \"\n",
    "        f\"The current Best score is: {study.best_value} | Overall best: {EarlyStoppingExceeded.best_score_so_far}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:46:30,806] A new study created in memory with name: no-name-8273b4f0-172b-491b-8b37-b72c92f97b42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.74775 + 0.035239\n",
      "[200]\tvalid's rmse: 3.71591 + 0.0339742\n",
      "[300]\tvalid's rmse: 3.70099 + 0.0332309\n",
      "[400]\tvalid's rmse: 3.69299 + 0.0327603\n",
      "[500]\tvalid's rmse: 3.68765 + 0.0324608\n",
      "[600]\tvalid's rmse: 3.68387 + 0.0320003\n",
      "[700]\tvalid's rmse: 3.68088 + 0.0317558\n",
      "[800]\tvalid's rmse: 3.67863 + 0.031569\n",
      "[900]\tvalid's rmse: 3.67681 + 0.0313775\n",
      "[1000]\tvalid's rmse: 3.67541 + 0.0313664\n",
      "[1100]\tvalid's rmse: 3.67416 + 0.0312548\n",
      "[1200]\tvalid's rmse: 3.67304 + 0.0311451\n",
      "[1300]\tvalid's rmse: 3.67216 + 0.0310509\n",
      "[1400]\tvalid's rmse: 3.67137 + 0.0309406\n",
      "[1500]\tvalid's rmse: 3.67063 + 0.0307514\n",
      "[1600]\tvalid's rmse: 3.67001 + 0.0307044\n",
      "[1700]\tvalid's rmse: 3.66945 + 0.0306508\n",
      "[1800]\tvalid's rmse: 3.66892 + 0.0306165\n",
      "[1900]\tvalid's rmse: 3.66836 + 0.0304733\n",
      "[2000]\tvalid's rmse: 3.66801 + 0.0304594\n",
      "[2100]\tvalid's rmse: 3.66756 + 0.0302697\n",
      "[2200]\tvalid's rmse: 3.66702 + 0.0301081\n",
      "[2300]\tvalid's rmse: 3.66668 + 0.0300874\n",
      "[2400]\tvalid's rmse: 3.66641 + 0.0299962\n",
      "[2500]\tvalid's rmse: 3.66607 + 0.0299056\n",
      "[2600]\tvalid's rmse: 3.66587 + 0.02983\n",
      "[2700]\tvalid's rmse: 3.66563 + 0.0296869\n",
      "[2800]\tvalid's rmse: 3.66551 + 0.0295623\n",
      "[2900]\tvalid's rmse: 3.6654 + 0.0295197\n",
      "[3000]\tvalid's rmse: 3.66526 + 0.0295207\n",
      "[3100]\tvalid's rmse: 3.66499 + 0.0294172\n",
      "[3200]\tvalid's rmse: 3.66489 + 0.0294186\n",
      "[3300]\tvalid's rmse: 3.66472 + 0.0292297\n",
      "[3400]\tvalid's rmse: 3.66467 + 0.0292693\n",
      "[3500]\tvalid's rmse: 3.66457 + 0.0292338\n",
      "[3600]\tvalid's rmse: 3.66449 + 0.02913\n",
      "[3700]\tvalid's rmse: 3.66444 + 0.0290606\n",
      "[3800]\tvalid's rmse: 3.66436 + 0.0289476\n",
      "[3900]\tvalid's rmse: 3.66435 + 0.0288848\n",
      "[4000]\tvalid's rmse: 3.66427 + 0.0287978\n",
      "[4100]\tvalid's rmse: 3.66423 + 0.0287424\n",
      "[4200]\tvalid's rmse: 3.66423 + 0.0286765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:47:16,974] Trial 0 finished with value: 3.6642062311729426 and parameters: {'num_leaves': 52, 'colsample_bytree': 0.4906566574984655, 'subsample': 0.7029342738521519, 'max_depth': 3, 'reg_alpha': 9.157310857928474, 'reg_lambda': 5.761550213484526, 'min_split_gain': 3.7509052373466445, 'min_child_weight': 34.39170142982603, 'min_data_in_leaf': 39}. Best is trial 0 with value: 3.6642062311729426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4074]\tvalid's rmse: 3.66421 + 0.0287549\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.6642062311729426 | Overall best: 3.6642062311729426\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.77482 + 0.0363767\n",
      "[200]\tvalid's rmse: 3.74973 + 0.0356961\n",
      "[300]\tvalid's rmse: 3.73638 + 0.0354658\n",
      "[400]\tvalid's rmse: 3.72745 + 0.0354632\n",
      "[500]\tvalid's rmse: 3.72116 + 0.0353538\n",
      "[600]\tvalid's rmse: 3.71625 + 0.0351608\n",
      "[700]\tvalid's rmse: 3.71257 + 0.0348035\n",
      "[800]\tvalid's rmse: 3.70956 + 0.0346007\n",
      "[900]\tvalid's rmse: 3.70717 + 0.0343942\n",
      "[1000]\tvalid's rmse: 3.70501 + 0.0342452\n",
      "[1100]\tvalid's rmse: 3.70312 + 0.0341093\n",
      "[1200]\tvalid's rmse: 3.7015 + 0.0340201\n",
      "[1300]\tvalid's rmse: 3.70012 + 0.0339025\n",
      "[1400]\tvalid's rmse: 3.69889 + 0.0338568\n",
      "[1500]\tvalid's rmse: 3.69774 + 0.0337482\n",
      "[1600]\tvalid's rmse: 3.69673 + 0.0337067\n",
      "[1700]\tvalid's rmse: 3.69578 + 0.033625\n",
      "[1800]\tvalid's rmse: 3.69494 + 0.0335157\n",
      "[1900]\tvalid's rmse: 3.69423 + 0.0334471\n",
      "[2000]\tvalid's rmse: 3.69363 + 0.033407\n",
      "[2100]\tvalid's rmse: 3.69306 + 0.0333757\n",
      "[2200]\tvalid's rmse: 3.69256 + 0.0333497\n",
      "[2300]\tvalid's rmse: 3.69206 + 0.0332582\n",
      "[2400]\tvalid's rmse: 3.69154 + 0.0331929\n",
      "[2500]\tvalid's rmse: 3.69103 + 0.0331146\n",
      "[2600]\tvalid's rmse: 3.69053 + 0.0330449\n",
      "[2700]\tvalid's rmse: 3.69011 + 0.0329808\n",
      "[2800]\tvalid's rmse: 3.6896 + 0.0328514\n",
      "[2900]\tvalid's rmse: 3.68917 + 0.0328425\n",
      "[3000]\tvalid's rmse: 3.68884 + 0.0328185\n",
      "[3100]\tvalid's rmse: 3.68845 + 0.0326999\n",
      "[3200]\tvalid's rmse: 3.68814 + 0.0326752\n",
      "[3300]\tvalid's rmse: 3.68779 + 0.0326012\n",
      "[3400]\tvalid's rmse: 3.68754 + 0.0325612\n",
      "[3500]\tvalid's rmse: 3.68728 + 0.0324881\n",
      "[3600]\tvalid's rmse: 3.68692 + 0.0324551\n",
      "[3700]\tvalid's rmse: 3.68667 + 0.032466\n",
      "[3800]\tvalid's rmse: 3.68644 + 0.0324444\n",
      "[3900]\tvalid's rmse: 3.68621 + 0.0324029\n",
      "[4000]\tvalid's rmse: 3.68602 + 0.0323916\n",
      "[4100]\tvalid's rmse: 3.6858 + 0.0323473\n",
      "[4200]\tvalid's rmse: 3.68558 + 0.0323315\n",
      "[4300]\tvalid's rmse: 3.68541 + 0.0322917\n",
      "[4400]\tvalid's rmse: 3.68522 + 0.0322539\n",
      "[4500]\tvalid's rmse: 3.68502 + 0.0321863\n",
      "[4600]\tvalid's rmse: 3.68489 + 0.0321029\n",
      "[4700]\tvalid's rmse: 3.68472 + 0.0320173\n",
      "[4800]\tvalid's rmse: 3.6846 + 0.032009\n",
      "[4900]\tvalid's rmse: 3.68445 + 0.0319886\n",
      "[5000]\tvalid's rmse: 3.68429 + 0.0319029\n",
      "[5100]\tvalid's rmse: 3.68415 + 0.0318968\n",
      "[5200]\tvalid's rmse: 3.68401 + 0.0318433\n",
      "[5300]\tvalid's rmse: 3.68385 + 0.031752\n",
      "[5400]\tvalid's rmse: 3.68371 + 0.0317199\n",
      "[5500]\tvalid's rmse: 3.68362 + 0.0317007\n",
      "[5600]\tvalid's rmse: 3.6835 + 0.0316431\n",
      "[5700]\tvalid's rmse: 3.68341 + 0.0316018\n",
      "[5800]\tvalid's rmse: 3.68331 + 0.0315759\n",
      "[5900]\tvalid's rmse: 3.68323 + 0.0315093\n",
      "[6000]\tvalid's rmse: 3.68316 + 0.0314823\n",
      "[6100]\tvalid's rmse: 3.6831 + 0.03149\n",
      "[6200]\tvalid's rmse: 3.68305 + 0.0314684\n",
      "[6300]\tvalid's rmse: 3.68299 + 0.0314912\n",
      "[6400]\tvalid's rmse: 3.68287 + 0.0314552\n",
      "[6500]\tvalid's rmse: 3.68281 + 0.0313647\n",
      "[6600]\tvalid's rmse: 3.68273 + 0.0312585\n",
      "[6700]\tvalid's rmse: 3.68266 + 0.0312127\n",
      "[6800]\tvalid's rmse: 3.68263 + 0.0311962\n",
      "[6900]\tvalid's rmse: 3.68258 + 0.0311931\n",
      "[7000]\tvalid's rmse: 3.68255 + 0.0311772\n",
      "[7100]\tvalid's rmse: 3.68253 + 0.0311701\n",
      "[7200]\tvalid's rmse: 3.68249 + 0.0311487\n",
      "[7300]\tvalid's rmse: 3.68244 + 0.0311335\n",
      "[7400]\tvalid's rmse: 3.68241 + 0.031141\n",
      "[7500]\tvalid's rmse: 3.68238 + 0.0310996\n",
      "[7600]\tvalid's rmse: 3.68233 + 0.0310387\n",
      "[7700]\tvalid's rmse: 3.68234 + 0.0310699\n",
      "[7800]\tvalid's rmse: 3.68235 + 0.0310283\n",
      "Early stopping, best iteration is:\n",
      "[7623]\tvalid's rmse: 3.68232 + 0.0310431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:48:12,268] Trial 1 finished with value: 3.682318959326736 and parameters: {'num_leaves': 26, 'colsample_bytree': 0.3279047628045009, 'subsample': 0.523406313172624, 'max_depth': 2, 'reg_alpha': 1.4289962013927149, 'reg_lambda': 7.825257296288725, 'min_split_gain': 8.020088054213709, 'min_child_weight': 14.259725742063814, 'min_data_in_leaf': 55}. Best is trial 0 with value: 3.6642062311729426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 2, The current Best score is: 3.6642062311729426 | Overall best: 3.6642062311729426\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.80674 + 0.0375929\n",
      "[200]\tvalid's rmse: 3.79312 + 0.0372804\n",
      "[300]\tvalid's rmse: 3.7842 + 0.0370702\n",
      "[400]\tvalid's rmse: 3.77755 + 0.0369062\n",
      "[500]\tvalid's rmse: 3.77242 + 0.0367991\n",
      "[600]\tvalid's rmse: 3.76838 + 0.0367613\n",
      "[700]\tvalid's rmse: 3.76511 + 0.0367171\n",
      "[800]\tvalid's rmse: 3.76235 + 0.036644\n",
      "[900]\tvalid's rmse: 3.75994 + 0.0366006\n",
      "[1000]\tvalid's rmse: 3.75779 + 0.0365485\n",
      "[1100]\tvalid's rmse: 3.75586 + 0.0365065\n",
      "[1200]\tvalid's rmse: 3.75406 + 0.0364413\n",
      "[1300]\tvalid's rmse: 3.75242 + 0.0364004\n",
      "[1400]\tvalid's rmse: 3.75097 + 0.0363568\n",
      "[1500]\tvalid's rmse: 3.74963 + 0.0363119\n",
      "[1600]\tvalid's rmse: 3.74841 + 0.0363049\n",
      "[1700]\tvalid's rmse: 3.74726 + 0.0362895\n",
      "[1800]\tvalid's rmse: 3.7462 + 0.0362562\n",
      "[1900]\tvalid's rmse: 3.74522 + 0.0362285\n",
      "[2000]\tvalid's rmse: 3.74429 + 0.0362084\n",
      "[2100]\tvalid's rmse: 3.74343 + 0.0361884\n",
      "[2200]\tvalid's rmse: 3.74262 + 0.0361715\n",
      "[2300]\tvalid's rmse: 3.74185 + 0.0361482\n",
      "[2400]\tvalid's rmse: 3.74113 + 0.0361234\n",
      "[2500]\tvalid's rmse: 3.74045 + 0.0360903\n",
      "[2600]\tvalid's rmse: 3.73979 + 0.0360558\n",
      "[2700]\tvalid's rmse: 3.73918 + 0.0360216\n",
      "[2800]\tvalid's rmse: 3.7386 + 0.035999\n",
      "[2900]\tvalid's rmse: 3.73804 + 0.0359775\n",
      "[3000]\tvalid's rmse: 3.73751 + 0.0359612\n",
      "[3100]\tvalid's rmse: 3.737 + 0.0359342\n",
      "[3200]\tvalid's rmse: 3.73652 + 0.0359148\n",
      "[3300]\tvalid's rmse: 3.73604 + 0.0359004\n",
      "[3400]\tvalid's rmse: 3.7356 + 0.0358842\n",
      "[3500]\tvalid's rmse: 3.73517 + 0.0358504\n",
      "[3600]\tvalid's rmse: 3.73476 + 0.0358334\n",
      "[3700]\tvalid's rmse: 3.73436 + 0.0358077\n",
      "[3800]\tvalid's rmse: 3.73396 + 0.0357904\n",
      "[3900]\tvalid's rmse: 3.73358 + 0.0357811\n",
      "[4000]\tvalid's rmse: 3.73323 + 0.035767\n",
      "[4100]\tvalid's rmse: 3.73287 + 0.0357477\n",
      "[4200]\tvalid's rmse: 3.73252 + 0.0357398\n",
      "[4300]\tvalid's rmse: 3.73219 + 0.0357226\n",
      "[4400]\tvalid's rmse: 3.73188 + 0.0356986\n",
      "[4500]\tvalid's rmse: 3.73157 + 0.0356903\n",
      "[4600]\tvalid's rmse: 3.73127 + 0.0356769\n",
      "[4700]\tvalid's rmse: 3.73097 + 0.0356614\n",
      "[4800]\tvalid's rmse: 3.73068 + 0.0356508\n",
      "[4900]\tvalid's rmse: 3.73041 + 0.0356317\n",
      "[5000]\tvalid's rmse: 3.73014 + 0.0356232\n",
      "[5100]\tvalid's rmse: 3.72987 + 0.0356091\n",
      "[5200]\tvalid's rmse: 3.72962 + 0.0355948\n",
      "[5300]\tvalid's rmse: 3.72937 + 0.0355942\n",
      "[5400]\tvalid's rmse: 3.72914 + 0.0355714\n",
      "[5500]\tvalid's rmse: 3.7289 + 0.0355604\n",
      "[5600]\tvalid's rmse: 3.72866 + 0.0355506\n",
      "[5700]\tvalid's rmse: 3.72843 + 0.0355377\n",
      "[5800]\tvalid's rmse: 3.72822 + 0.0355252\n",
      "[5900]\tvalid's rmse: 3.72801 + 0.0355143\n",
      "[6000]\tvalid's rmse: 3.7278 + 0.0355017\n",
      "[6100]\tvalid's rmse: 3.7276 + 0.035501\n",
      "[6200]\tvalid's rmse: 3.72741 + 0.0354886\n",
      "[6300]\tvalid's rmse: 3.72722 + 0.035473\n",
      "[6400]\tvalid's rmse: 3.72703 + 0.035456\n",
      "[6500]\tvalid's rmse: 3.72685 + 0.0354478\n",
      "[6600]\tvalid's rmse: 3.72668 + 0.0354372\n",
      "[6700]\tvalid's rmse: 3.72651 + 0.0354293\n",
      "[6800]\tvalid's rmse: 3.72634 + 0.035416\n",
      "[6900]\tvalid's rmse: 3.72618 + 0.0354053\n",
      "[7000]\tvalid's rmse: 3.72602 + 0.0353954\n",
      "[7100]\tvalid's rmse: 3.72586 + 0.035386\n",
      "[7200]\tvalid's rmse: 3.7257 + 0.0353746\n",
      "[7300]\tvalid's rmse: 3.72555 + 0.0353572\n",
      "[7400]\tvalid's rmse: 3.7254 + 0.0353507\n",
      "[7500]\tvalid's rmse: 3.72525 + 0.0353318\n",
      "[7600]\tvalid's rmse: 3.72511 + 0.0353253\n",
      "[7700]\tvalid's rmse: 3.72497 + 0.0353163\n",
      "[7800]\tvalid's rmse: 3.72484 + 0.0353103\n",
      "[7900]\tvalid's rmse: 3.72471 + 0.0352957\n",
      "[8000]\tvalid's rmse: 3.72458 + 0.0352816\n",
      "[8100]\tvalid's rmse: 3.72445 + 0.0352724\n",
      "[8200]\tvalid's rmse: 3.72432 + 0.0352594\n",
      "[8300]\tvalid's rmse: 3.72419 + 0.0352462\n",
      "[8400]\tvalid's rmse: 3.72408 + 0.0352345\n",
      "[8500]\tvalid's rmse: 3.72396 + 0.035221\n",
      "[8600]\tvalid's rmse: 3.72384 + 0.0352051\n",
      "[8700]\tvalid's rmse: 3.72372 + 0.0351955\n",
      "[8800]\tvalid's rmse: 3.72361 + 0.0351803\n",
      "[8900]\tvalid's rmse: 3.7235 + 0.035172\n",
      "[9000]\tvalid's rmse: 3.72338 + 0.0351577\n",
      "[9100]\tvalid's rmse: 3.72328 + 0.0351409\n",
      "[9200]\tvalid's rmse: 3.72318 + 0.0351259\n",
      "[9300]\tvalid's rmse: 3.72307 + 0.035124\n",
      "[9400]\tvalid's rmse: 3.72297 + 0.0351095\n",
      "[9500]\tvalid's rmse: 3.72286 + 0.0350957\n",
      "[9600]\tvalid's rmse: 3.72276 + 0.0350905\n",
      "[9700]\tvalid's rmse: 3.72266 + 0.0350747\n",
      "[9800]\tvalid's rmse: 3.72256 + 0.0350667\n",
      "[9900]\tvalid's rmse: 3.72246 + 0.035057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:49:22,859] Trial 2 finished with value: 3.7223713334505075 and parameters: {'num_leaves': 24, 'colsample_bytree': 0.5401707174494849, 'subsample': 0.23960936456374393, 'max_depth': 1, 'reg_alpha': 1.2842258444671906, 'reg_lambda': 4.260126926348745, 'min_split_gain': 3.959708113041552, 'min_child_weight': 29.525206675760924, 'min_data_in_leaf': 29}. Best is trial 0 with value: 3.6642062311729426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\tvalid's rmse: 3.72237 + 0.0350507\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid's rmse: 3.72237 + 0.0350507\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 3, The current Best score is: 3.6642062311729426 | Overall best: 3.6642062311729426\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.70586 + 0.0334941\n",
      "[200]\tvalid's rmse: 3.67245 + 0.0321292\n",
      "[300]\tvalid's rmse: 3.66143 + 0.0315512\n",
      "[400]\tvalid's rmse: 3.65676 + 0.030799\n",
      "[500]\tvalid's rmse: 3.65506 + 0.0303017\n",
      "[600]\tvalid's rmse: 3.65424 + 0.0297755\n",
      "[700]\tvalid's rmse: 3.65333 + 0.0293881\n",
      "[800]\tvalid's rmse: 3.65287 + 0.0289331\n",
      "[900]\tvalid's rmse: 3.65251 + 0.0284988\n",
      "[1000]\tvalid's rmse: 3.65243 + 0.0283441\n",
      "[1100]\tvalid's rmse: 3.65252 + 0.0281824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:49:48,446] Trial 3 finished with value: 3.6523320773973844 and parameters: {'num_leaves': 62, 'colsample_bytree': 0.67951082278091, 'subsample': 0.028796678633287838, 'max_depth': 6, 'reg_alpha': 2.7356631107978266, 'reg_lambda': 7.9495841894215395, 'min_split_gain': 8.467485744295034, 'min_child_weight': 7.496034679939047, 'min_data_in_leaf': 20}. Best is trial 3 with value: 3.6523320773973844.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[965]\tvalid's rmse: 3.65233 + 0.0284167\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.6523320773973844 | Overall best: 3.6523320773973844\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.80995 + 0.0374374\n",
      "[200]\tvalid's rmse: 3.79714 + 0.0372277\n",
      "[300]\tvalid's rmse: 3.7881 + 0.0370632\n",
      "[400]\tvalid's rmse: 3.7812 + 0.0369407\n",
      "[500]\tvalid's rmse: 3.77583 + 0.0368672\n",
      "[600]\tvalid's rmse: 3.77146 + 0.036779\n",
      "[700]\tvalid's rmse: 3.76776 + 0.0366711\n",
      "[800]\tvalid's rmse: 3.76477 + 0.0365842\n",
      "[900]\tvalid's rmse: 3.76218 + 0.0365623\n",
      "[1000]\tvalid's rmse: 3.7599 + 0.0365531\n",
      "[1100]\tvalid's rmse: 3.75781 + 0.0364877\n",
      "[1200]\tvalid's rmse: 3.75593 + 0.0364041\n",
      "[1300]\tvalid's rmse: 3.7542 + 0.0363297\n",
      "[1400]\tvalid's rmse: 3.75269 + 0.036263\n",
      "[1500]\tvalid's rmse: 3.75135 + 0.036225\n",
      "[1600]\tvalid's rmse: 3.75006 + 0.0361733\n",
      "[1700]\tvalid's rmse: 3.74889 + 0.0361387\n",
      "[1800]\tvalid's rmse: 3.74779 + 0.0360981\n",
      "[1900]\tvalid's rmse: 3.74677 + 0.0360816\n",
      "[2000]\tvalid's rmse: 3.74584 + 0.0360557\n",
      "[2100]\tvalid's rmse: 3.74498 + 0.0360338\n",
      "[2200]\tvalid's rmse: 3.74417 + 0.0360001\n",
      "[2300]\tvalid's rmse: 3.74338 + 0.0359758\n",
      "[2400]\tvalid's rmse: 3.74265 + 0.0359357\n",
      "[2500]\tvalid's rmse: 3.74194 + 0.035908\n",
      "[2600]\tvalid's rmse: 3.74126 + 0.0358738\n",
      "[2700]\tvalid's rmse: 3.74062 + 0.0358567\n",
      "[2800]\tvalid's rmse: 3.74 + 0.035841\n",
      "[2900]\tvalid's rmse: 3.73945 + 0.035798\n",
      "[3000]\tvalid's rmse: 3.7389 + 0.0357643\n",
      "[3100]\tvalid's rmse: 3.73838 + 0.035748\n",
      "[3200]\tvalid's rmse: 3.73788 + 0.035727\n",
      "[3300]\tvalid's rmse: 3.7374 + 0.0357182\n",
      "[3400]\tvalid's rmse: 3.73693 + 0.0356979\n",
      "[3500]\tvalid's rmse: 3.7365 + 0.0356836\n",
      "[3600]\tvalid's rmse: 3.73608 + 0.0356608\n",
      "[3700]\tvalid's rmse: 3.73565 + 0.0356456\n",
      "[3800]\tvalid's rmse: 3.73525 + 0.0356294\n",
      "[3900]\tvalid's rmse: 3.73487 + 0.0356118\n",
      "[4000]\tvalid's rmse: 3.7345 + 0.0356038\n",
      "[4100]\tvalid's rmse: 3.73413 + 0.0355963\n",
      "[4200]\tvalid's rmse: 3.73377 + 0.0355847\n",
      "[4300]\tvalid's rmse: 3.73343 + 0.0355811\n",
      "[4400]\tvalid's rmse: 3.7331 + 0.0355754\n",
      "[4500]\tvalid's rmse: 3.73277 + 0.0355552\n",
      "[4600]\tvalid's rmse: 3.73246 + 0.035549\n",
      "[4700]\tvalid's rmse: 3.73214 + 0.0355392\n",
      "[4800]\tvalid's rmse: 3.73185 + 0.0355259\n",
      "[4900]\tvalid's rmse: 3.73156 + 0.0355147\n",
      "[5000]\tvalid's rmse: 3.73126 + 0.03551\n",
      "[5100]\tvalid's rmse: 3.73099 + 0.035507\n",
      "[5200]\tvalid's rmse: 3.73072 + 0.0354983\n",
      "[5300]\tvalid's rmse: 3.73047 + 0.0354877\n",
      "[5400]\tvalid's rmse: 3.73021 + 0.0354875\n",
      "[5500]\tvalid's rmse: 3.72996 + 0.035485\n",
      "[5600]\tvalid's rmse: 3.72973 + 0.0354714\n",
      "[5700]\tvalid's rmse: 3.7295 + 0.0354637\n",
      "[5800]\tvalid's rmse: 3.72927 + 0.0354607\n",
      "[5900]\tvalid's rmse: 3.72905 + 0.0354553\n",
      "[6000]\tvalid's rmse: 3.72884 + 0.0354518\n",
      "[6100]\tvalid's rmse: 3.72861 + 0.0354331\n",
      "[6200]\tvalid's rmse: 3.7284 + 0.0354162\n",
      "[6300]\tvalid's rmse: 3.72819 + 0.035408\n",
      "[6400]\tvalid's rmse: 3.72799 + 0.0353929\n",
      "[6500]\tvalid's rmse: 3.7278 + 0.0353742\n",
      "[6600]\tvalid's rmse: 3.72761 + 0.0353515\n",
      "[6700]\tvalid's rmse: 3.72743 + 0.0353356\n",
      "[6800]\tvalid's rmse: 3.72724 + 0.0353249\n",
      "[6900]\tvalid's rmse: 3.72707 + 0.0353027\n",
      "[7000]\tvalid's rmse: 3.72688 + 0.0352865\n",
      "[7100]\tvalid's rmse: 3.7267 + 0.0352728\n",
      "[7200]\tvalid's rmse: 3.72654 + 0.0352566\n",
      "[7300]\tvalid's rmse: 3.72636 + 0.0352358\n",
      "[7400]\tvalid's rmse: 3.72621 + 0.0352146\n",
      "[7500]\tvalid's rmse: 3.72604 + 0.0352054\n",
      "[7600]\tvalid's rmse: 3.7259 + 0.0351819\n",
      "[7700]\tvalid's rmse: 3.72574 + 0.0351687\n",
      "[7800]\tvalid's rmse: 3.72559 + 0.035152\n",
      "[7900]\tvalid's rmse: 3.72544 + 0.0351473\n",
      "[8000]\tvalid's rmse: 3.7253 + 0.0351321\n",
      "[8100]\tvalid's rmse: 3.72515 + 0.0351269\n",
      "[8200]\tvalid's rmse: 3.72501 + 0.0351122\n",
      "[8300]\tvalid's rmse: 3.72488 + 0.0351121\n",
      "[8400]\tvalid's rmse: 3.72475 + 0.0351041\n",
      "[8500]\tvalid's rmse: 3.72461 + 0.0351027\n",
      "[8600]\tvalid's rmse: 3.72448 + 0.0350873\n",
      "[8700]\tvalid's rmse: 3.72435 + 0.0350804\n",
      "[8800]\tvalid's rmse: 3.72423 + 0.0350687\n",
      "[8900]\tvalid's rmse: 3.7241 + 0.0350637\n",
      "[9000]\tvalid's rmse: 3.72398 + 0.035069\n",
      "[9100]\tvalid's rmse: 3.72385 + 0.0350605\n",
      "[9200]\tvalid's rmse: 3.72373 + 0.0350403\n",
      "[9300]\tvalid's rmse: 3.72361 + 0.0350425\n",
      "[9400]\tvalid's rmse: 3.7235 + 0.035038\n",
      "[9500]\tvalid's rmse: 3.72339 + 0.0350276\n",
      "[9600]\tvalid's rmse: 3.72328 + 0.0350181\n",
      "[9700]\tvalid's rmse: 3.72316 + 0.0350107\n",
      "[9800]\tvalid's rmse: 3.72306 + 0.0350024\n",
      "[9900]\tvalid's rmse: 3.72296 + 0.0349893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:50:26,698] Trial 4 finished with value: 3.7228520514447667 and parameters: {'num_leaves': 53, 'colsample_bytree': 0.15451124364423524, 'subsample': 0.6180584313434653, 'max_depth': 1, 'reg_alpha': 7.686851893261943, 'reg_lambda': 1.8552171590831856, 'min_split_gain': 0.21671599843512968, 'min_child_weight': 3.309548038391468, 'min_data_in_leaf': 64}. Best is trial 3 with value: 3.6523320773973844.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\tvalid's rmse: 3.72285 + 0.0349937\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid's rmse: 3.72285 + 0.0349937\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.6523320773973844 | Overall best: 3.6523320773973844\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.70551 + 0.0337809\n",
      "[200]\tvalid's rmse: 3.67236 + 0.0329626\n",
      "[300]\tvalid's rmse: 3.66194 + 0.0314246\n",
      "[400]\tvalid's rmse: 3.65707 + 0.0301178\n",
      "[500]\tvalid's rmse: 3.65523 + 0.0298035\n",
      "[600]\tvalid's rmse: 3.65445 + 0.0292728\n",
      "[700]\tvalid's rmse: 3.65399 + 0.0290707\n",
      "[800]\tvalid's rmse: 3.65354 + 0.0288883\n",
      "[900]\tvalid's rmse: 3.65341 + 0.0286747\n",
      "[1000]\tvalid's rmse: 3.6537 + 0.0289578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:50:53,818] Trial 5 finished with value: 3.6533851233934875 and parameters: {'num_leaves': 56, 'colsample_bytree': 0.8095254634633988, 'subsample': 0.2746061213513488, 'max_depth': 8, 'reg_alpha': 6.1366373066360955, 'reg_lambda': 7.204054633173108, 'min_split_gain': 4.745124630704929, 'min_child_weight': 12.95775278572205, 'min_data_in_leaf': 41}. Best is trial 3 with value: 3.6523320773973844.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[858]\tvalid's rmse: 3.65339 + 0.0287793\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 2, The current Best score is: 3.6523320773973844 | Overall best: 3.6523320773973844\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.70947 + 0.0338588\n",
      "[200]\tvalid's rmse: 3.67428 + 0.0325246\n",
      "[300]\tvalid's rmse: 3.66194 + 0.0312746\n",
      "[400]\tvalid's rmse: 3.65664 + 0.0308729\n",
      "[500]\tvalid's rmse: 3.65409 + 0.0306779\n",
      "[600]\tvalid's rmse: 3.65265 + 0.0303785\n",
      "[700]\tvalid's rmse: 3.65176 + 0.0301237\n",
      "[800]\tvalid's rmse: 3.65095 + 0.029999\n",
      "[900]\tvalid's rmse: 3.65054 + 0.0297634\n",
      "[1000]\tvalid's rmse: 3.65019 + 0.029782\n",
      "[1100]\tvalid's rmse: 3.64994 + 0.0296852\n",
      "[1200]\tvalid's rmse: 3.64996 + 0.0296397\n",
      "[1300]\tvalid's rmse: 3.6498 + 0.0295903\n",
      "[1400]\tvalid's rmse: 3.64984 + 0.0295431\n",
      "[1500]\tvalid's rmse: 3.64999 + 0.0294332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:51:16,526] Trial 6 finished with value: 3.6497535991342627 and parameters: {'num_leaves': 61, 'colsample_bytree': 0.4276349712856633, 'subsample': 0.8375512213670602, 'max_depth': 6, 'reg_alpha': 6.548900529933036, 'reg_lambda': 6.728810124639134, 'min_split_gain': 7.882720918442249, 'min_child_weight': 16.56497493186302, 'min_data_in_leaf': 45}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1331]\tvalid's rmse: 3.64975 + 0.0295309\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.71591 + 0.0350782\n",
      "[200]\tvalid's rmse: 3.68187 + 0.0334318\n",
      "[300]\tvalid's rmse: 3.66816 + 0.0323976\n",
      "[400]\tvalid's rmse: 3.66072 + 0.0318408\n",
      "[500]\tvalid's rmse: 3.65673 + 0.031094\n",
      "[600]\tvalid's rmse: 3.65447 + 0.0307917\n",
      "[700]\tvalid's rmse: 3.65326 + 0.0306778\n",
      "[800]\tvalid's rmse: 3.6525 + 0.0305674\n",
      "[900]\tvalid's rmse: 3.65185 + 0.030269\n",
      "[1000]\tvalid's rmse: 3.65136 + 0.0301853\n",
      "[1100]\tvalid's rmse: 3.65102 + 0.0300277\n",
      "[1200]\tvalid's rmse: 3.65102 + 0.0298459\n",
      "[1300]\tvalid's rmse: 3.65121 + 0.0296308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:51:37,334] Trial 7 finished with value: 3.6509239787301575 and parameters: {'num_leaves': 29, 'colsample_bytree': 0.4763385981434082, 'subsample': 0.9838626437596595, 'max_depth': 9, 'reg_alpha': 1.121797104753105, 'reg_lambda': 7.961603210671257, 'min_split_gain': 4.728102950976238, 'min_child_weight': 2.2868978527298074, 'min_data_in_leaf': 57}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1130]\tvalid's rmse: 3.65092 + 0.0299483\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.71518 + 0.0348626\n",
      "[200]\tvalid's rmse: 3.68159 + 0.0332671\n",
      "[300]\tvalid's rmse: 3.66843 + 0.0329851\n",
      "[400]\tvalid's rmse: 3.66144 + 0.0321156\n",
      "[500]\tvalid's rmse: 3.65736 + 0.0317088\n",
      "[600]\tvalid's rmse: 3.65527 + 0.0312028\n",
      "[700]\tvalid's rmse: 3.65385 + 0.0307975\n",
      "[800]\tvalid's rmse: 3.6532 + 0.0306635\n",
      "[900]\tvalid's rmse: 3.65275 + 0.0304227\n",
      "[1000]\tvalid's rmse: 3.65224 + 0.0302669\n",
      "[1100]\tvalid's rmse: 3.65187 + 0.0300545\n",
      "[1200]\tvalid's rmse: 3.65163 + 0.030058\n",
      "[1300]\tvalid's rmse: 3.65171 + 0.0298365\n",
      "[1400]\tvalid's rmse: 3.65187 + 0.0296582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:52:07,759] Trial 8 finished with value: 3.651596089127329 and parameters: {'num_leaves': 27, 'colsample_bytree': 0.5995280645110045, 'subsample': 0.7157734880558585, 'max_depth': 11, 'reg_alpha': 6.733364269321134, 'reg_lambda': 8.67093282195492, 'min_split_gain': 4.636752147233418, 'min_child_weight': 25.575897269284937, 'min_data_in_leaf': 59}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid's rmse: 3.6516 + 0.030033\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 2, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.7173 + 0.0337275\n",
      "[200]\tvalid's rmse: 3.68484 + 0.0328212\n",
      "[300]\tvalid's rmse: 3.67174 + 0.0319333\n",
      "[400]\tvalid's rmse: 3.66516 + 0.0312629\n",
      "[500]\tvalid's rmse: 3.66155 + 0.0303241\n",
      "[600]\tvalid's rmse: 3.65959 + 0.0298405\n",
      "[700]\tvalid's rmse: 3.65847 + 0.0296131\n",
      "[800]\tvalid's rmse: 3.65759 + 0.0294841\n",
      "[900]\tvalid's rmse: 3.65704 + 0.0295846\n",
      "[1000]\tvalid's rmse: 3.65659 + 0.0295438\n",
      "[1100]\tvalid's rmse: 3.65636 + 0.0294473\n",
      "[1200]\tvalid's rmse: 3.65615 + 0.0292863\n",
      "[1300]\tvalid's rmse: 3.65613 + 0.0292195\n",
      "[1400]\tvalid's rmse: 3.65609 + 0.0290335\n",
      "[1500]\tvalid's rmse: 3.656 + 0.0288309\n",
      "[1600]\tvalid's rmse: 3.65625 + 0.0286565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:52:40,401] Trial 9 finished with value: 3.6559676270980996 and parameters: {'num_leaves': 24, 'colsample_bytree': 0.8909756583633489, 'subsample': 0.8172668535192549, 'max_depth': 10, 'reg_alpha': 2.5914307121991556, 'reg_lambda': 2.2359140772922914, 'min_split_gain': 8.874417984331957, 'min_child_weight': 33.0330564688089, 'min_data_in_leaf': 21}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\tvalid's rmse: 3.65641 + 0.0286376\n",
      "Early stopping, best iteration is:\n",
      "[1503]\tvalid's rmse: 3.65597 + 0.0288069\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 3, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.78429 + 0.0371537\n",
      "[200]\tvalid's rmse: 3.75123 + 0.036671\n",
      "[300]\tvalid's rmse: 3.73139 + 0.036048\n",
      "[400]\tvalid's rmse: 3.71868 + 0.0356237\n",
      "[500]\tvalid's rmse: 3.70921 + 0.0351396\n",
      "[600]\tvalid's rmse: 3.70242 + 0.0349214\n",
      "[700]\tvalid's rmse: 3.69608 + 0.0345911\n",
      "[800]\tvalid's rmse: 3.69138 + 0.0344358\n",
      "[900]\tvalid's rmse: 3.68776 + 0.0343059\n",
      "[1000]\tvalid's rmse: 3.68475 + 0.0342097\n",
      "[1100]\tvalid's rmse: 3.68218 + 0.0341833\n",
      "[1200]\tvalid's rmse: 3.68014 + 0.0340321\n",
      "[1300]\tvalid's rmse: 3.67812 + 0.0338573\n",
      "[1400]\tvalid's rmse: 3.67687 + 0.0336972\n",
      "[1500]\tvalid's rmse: 3.67537 + 0.0336655\n",
      "[1600]\tvalid's rmse: 3.67424 + 0.0336701\n",
      "[1700]\tvalid's rmse: 3.67328 + 0.0335925\n",
      "[1800]\tvalid's rmse: 3.67228 + 0.0335431\n",
      "[1900]\tvalid's rmse: 3.6718 + 0.0334446\n",
      "[2000]\tvalid's rmse: 3.67114 + 0.0334418\n",
      "[2100]\tvalid's rmse: 3.67054 + 0.0333449\n",
      "[2200]\tvalid's rmse: 3.67015 + 0.0332352\n",
      "[2300]\tvalid's rmse: 3.66963 + 0.0332162\n",
      "[2400]\tvalid's rmse: 3.66931 + 0.0331502\n",
      "[2500]\tvalid's rmse: 3.66895 + 0.0329958\n",
      "[2600]\tvalid's rmse: 3.66868 + 0.0329383\n",
      "[2700]\tvalid's rmse: 3.66829 + 0.0328889\n",
      "[2800]\tvalid's rmse: 3.66792 + 0.032818\n",
      "[2900]\tvalid's rmse: 3.66778 + 0.0327855\n",
      "[3000]\tvalid's rmse: 3.66769 + 0.0327986\n",
      "[3100]\tvalid's rmse: 3.66756 + 0.0327366\n",
      "[3200]\tvalid's rmse: 3.66751 + 0.0328\n",
      "[3300]\tvalid's rmse: 3.66724 + 0.0327214\n",
      "[3400]\tvalid's rmse: 3.66697 + 0.0326396\n",
      "[3500]\tvalid's rmse: 3.66675 + 0.0326593\n",
      "[3600]\tvalid's rmse: 3.66669 + 0.0326613\n",
      "[3700]\tvalid's rmse: 3.6667 + 0.0326446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:53:06,241] Trial 10 finished with value: 3.666643598739771 and parameters: {'num_leaves': 39, 'colsample_bytree': 0.0338579303502719, 'subsample': 0.9672949258069266, 'max_depth': 5, 'reg_alpha': 4.40886826109604, 'reg_lambda': 4.478391715400955, 'min_split_gain': 6.869152365028446, 'min_child_weight': 44.733838769838414, 'min_data_in_leaf': 48}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3589]\tvalid's rmse: 3.66664 + 0.0326575\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 4, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.71511 + 0.0356893\n",
      "[200]\tvalid's rmse: 3.67927 + 0.0340549\n",
      "[300]\tvalid's rmse: 3.66548 + 0.0330222\n",
      "[400]\tvalid's rmse: 3.65885 + 0.0324539\n",
      "[500]\tvalid's rmse: 3.65505 + 0.0322859\n",
      "[600]\tvalid's rmse: 3.65304 + 0.0317298\n",
      "[700]\tvalid's rmse: 3.65188 + 0.0315672\n",
      "[800]\tvalid's rmse: 3.65101 + 0.031087\n",
      "[900]\tvalid's rmse: 3.65063 + 0.0308916\n",
      "[1000]\tvalid's rmse: 3.65048 + 0.0307067\n",
      "[1100]\tvalid's rmse: 3.65024 + 0.0306309\n",
      "[1200]\tvalid's rmse: 3.65019 + 0.0304315\n",
      "[1300]\tvalid's rmse: 3.65006 + 0.0303556\n",
      "[1400]\tvalid's rmse: 3.65019 + 0.0302482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:53:27,628] Trial 11 finished with value: 3.650026895600351 and parameters: {'num_leaves': 39, 'colsample_bytree': 0.3519120277987564, 'subsample': 0.9768533379098526, 'max_depth': 8, 'reg_alpha': 4.435174912412183, 'reg_lambda': 9.986808962823643, 'min_split_gain': 6.424122237840328, 'min_child_weight': 17.78362821536283, 'min_data_in_leaf': 49}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1295]\tvalid's rmse: 3.65003 + 0.0303668\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 5, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.71457 + 0.0350927\n",
      "[200]\tvalid's rmse: 3.67845 + 0.0329879\n",
      "[300]\tvalid's rmse: 3.66469 + 0.0320137\n",
      "[400]\tvalid's rmse: 3.65817 + 0.031654\n",
      "[500]\tvalid's rmse: 3.6545 + 0.0311082\n",
      "[600]\tvalid's rmse: 3.65256 + 0.0309632\n",
      "[700]\tvalid's rmse: 3.65166 + 0.0307663\n",
      "[800]\tvalid's rmse: 3.65072 + 0.0305155\n",
      "[900]\tvalid's rmse: 3.65032 + 0.0302745\n",
      "[1000]\tvalid's rmse: 3.65001 + 0.0301311\n",
      "[1100]\tvalid's rmse: 3.64996 + 0.0302379\n",
      "[1200]\tvalid's rmse: 3.64997 + 0.0301308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:53:45,666] Trial 12 finished with value: 3.6498623421741 and parameters: {'num_leaves': 41, 'colsample_bytree': 0.3330835614926805, 'subsample': 0.8668035563576346, 'max_depth': 7, 'reg_alpha': 4.636305879253671, 'reg_lambda': 9.511701799031957, 'min_split_gain': 6.12730383437229, 'min_child_weight': 18.803824201736884, 'min_data_in_leaf': 45}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1057]\tvalid's rmse: 3.64986 + 0.0302046\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 6, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.74064 + 0.0349515\n",
      "[200]\tvalid's rmse: 3.70463 + 0.0333725\n",
      "[300]\tvalid's rmse: 3.68815 + 0.0327663\n",
      "[400]\tvalid's rmse: 3.67912 + 0.0323445\n",
      "[500]\tvalid's rmse: 3.6735 + 0.0320192\n",
      "[600]\tvalid's rmse: 3.66955 + 0.0318761\n",
      "[700]\tvalid's rmse: 3.66725 + 0.0316683\n",
      "[800]\tvalid's rmse: 3.66544 + 0.0314263\n",
      "[900]\tvalid's rmse: 3.66414 + 0.0310892\n",
      "[1000]\tvalid's rmse: 3.66304 + 0.0308622\n",
      "[1100]\tvalid's rmse: 3.66208 + 0.030774\n",
      "[1200]\tvalid's rmse: 3.66135 + 0.0305704\n",
      "[1300]\tvalid's rmse: 3.66069 + 0.0305767\n",
      "[1400]\tvalid's rmse: 3.65998 + 0.0306058\n",
      "[1500]\tvalid's rmse: 3.65954 + 0.0303857\n",
      "[1600]\tvalid's rmse: 3.65906 + 0.0302577\n",
      "[1700]\tvalid's rmse: 3.65866 + 0.0301729\n",
      "[1800]\tvalid's rmse: 3.65836 + 0.0301634\n",
      "[1900]\tvalid's rmse: 3.65803 + 0.0301902\n",
      "[2000]\tvalid's rmse: 3.6578 + 0.0302306\n",
      "[2100]\tvalid's rmse: 3.65768 + 0.030144\n",
      "[2200]\tvalid's rmse: 3.6576 + 0.0300965\n",
      "[2300]\tvalid's rmse: 3.65758 + 0.0298942\n",
      "[2400]\tvalid's rmse: 3.65751 + 0.0297954\n",
      "[2500]\tvalid's rmse: 3.65752 + 0.0297465\n",
      "[2600]\tvalid's rmse: 3.65754 + 0.0297577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:54:05,897] Trial 13 finished with value: 3.6574830289617757 and parameters: {'num_leaves': 44, 'colsample_bytree': 0.24194667186339394, 'subsample': 0.8199247025974504, 'max_depth': 4, 'reg_alpha': 5.593226969022002, 'reg_lambda': 5.820732653102329, 'min_split_gain': 9.917943443758858, 'min_child_weight': 20.860387380039015, 'min_data_in_leaf': 36}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2434]\tvalid's rmse: 3.65748 + 0.0298376\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 7, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.7256 + 0.0346673\n",
      "[200]\tvalid's rmse: 3.69063 + 0.0327144\n",
      "[300]\tvalid's rmse: 3.67544 + 0.0324627\n",
      "[400]\tvalid's rmse: 3.66695 + 0.0318659\n",
      "[500]\tvalid's rmse: 3.6617 + 0.0313533\n",
      "[600]\tvalid's rmse: 3.65863 + 0.0307664\n",
      "[700]\tvalid's rmse: 3.65653 + 0.0302392\n",
      "[800]\tvalid's rmse: 3.65521 + 0.0299492\n",
      "[900]\tvalid's rmse: 3.65434 + 0.029765\n",
      "[1000]\tvalid's rmse: 3.65356 + 0.0297269\n",
      "[1100]\tvalid's rmse: 3.65285 + 0.029569\n",
      "[1200]\tvalid's rmse: 3.6523 + 0.0293745\n",
      "[1300]\tvalid's rmse: 3.65187 + 0.0293356\n",
      "[1400]\tvalid's rmse: 3.65157 + 0.0290873\n",
      "[1500]\tvalid's rmse: 3.65131 + 0.0288679\n",
      "[1600]\tvalid's rmse: 3.6512 + 0.0286095\n",
      "[1700]\tvalid's rmse: 3.65114 + 0.0283363\n",
      "[1800]\tvalid's rmse: 3.65116 + 0.0283109\n",
      "[1900]\tvalid's rmse: 3.65113 + 0.0281063\n",
      "[2000]\tvalid's rmse: 3.65109 + 0.0279563\n",
      "[2100]\tvalid's rmse: 3.65091 + 0.0278687\n",
      "[2200]\tvalid's rmse: 3.65092 + 0.0277572\n",
      "[2300]\tvalid's rmse: 3.65085 + 0.0275711\n",
      "[2400]\tvalid's rmse: 3.65094 + 0.0274582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:54:32,244] Trial 14 finished with value: 3.6508374609172485 and parameters: {'num_leaves': 17, 'colsample_bytree': 0.3766749595339761, 'subsample': 0.3969162198058458, 'max_depth': 7, 'reg_alpha': 8.11812844750212, 'reg_lambda': 9.831495993913192, 'min_split_gain': 6.544105892397953, 'min_child_weight': 10.957218055409198, 'min_data_in_leaf': 46}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500]\tvalid's rmse: 3.65115 + 0.0274167\n",
      "Early stopping, best iteration is:\n",
      "[2301]\tvalid's rmse: 3.65084 + 0.0275705\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 8, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.72531 + 0.0357811\n",
      "[200]\tvalid's rmse: 3.68816 + 0.0345255\n",
      "[300]\tvalid's rmse: 3.67232 + 0.033686\n",
      "[400]\tvalid's rmse: 3.66454 + 0.033476\n",
      "[500]\tvalid's rmse: 3.65944 + 0.0333604\n",
      "[600]\tvalid's rmse: 3.65689 + 0.0330169\n",
      "[700]\tvalid's rmse: 3.6551 + 0.0326698\n",
      "[800]\tvalid's rmse: 3.65403 + 0.0322838\n",
      "[900]\tvalid's rmse: 3.65323 + 0.0321441\n",
      "[1000]\tvalid's rmse: 3.65274 + 0.0319367\n",
      "[1100]\tvalid's rmse: 3.65237 + 0.0318808\n",
      "[1200]\tvalid's rmse: 3.65203 + 0.0317272\n",
      "[1300]\tvalid's rmse: 3.65178 + 0.0315166\n",
      "[1400]\tvalid's rmse: 3.6517 + 0.0315099\n",
      "[1500]\tvalid's rmse: 3.65163 + 0.0315611\n",
      "[1600]\tvalid's rmse: 3.65157 + 0.0315259\n",
      "[1700]\tvalid's rmse: 3.65171 + 0.0315295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:54:48,864] Trial 15 finished with value: 3.651523855478008 and parameters: {'num_leaves': 64, 'colsample_bytree': 0.15592256763002432, 'subsample': 0.8384716183827953, 'max_depth': 6, 'reg_alpha': 3.8844152966799936, 'reg_lambda': 6.0021666187462355, 'min_split_gain': 2.2232258598166412, 'min_child_weight': 23.71586481282736, 'min_data_in_leaf': 32}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1570]\tvalid's rmse: 3.65152 + 0.0315771\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 9, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.70845 + 0.0343607\n",
      "[200]\tvalid's rmse: 3.67451 + 0.0330678\n",
      "[300]\tvalid's rmse: 3.66325 + 0.0321553\n",
      "[400]\tvalid's rmse: 3.65769 + 0.0308202\n",
      "[500]\tvalid's rmse: 3.65479 + 0.0302915\n",
      "[600]\tvalid's rmse: 3.65328 + 0.030037\n",
      "[700]\tvalid's rmse: 3.65243 + 0.029711\n",
      "[800]\tvalid's rmse: 3.65217 + 0.0291961\n",
      "[900]\tvalid's rmse: 3.65208 + 0.0290685\n",
      "[1000]\tvalid's rmse: 3.6521 + 0.0288038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:55:13,564] Trial 16 finished with value: 3.6519470009834425 and parameters: {'num_leaves': 47, 'colsample_bytree': 0.6882808924183685, 'subsample': 0.573667032488253, 'max_depth': 12, 'reg_alpha': 7.185285272605169, 'reg_lambda': 3.6510014498226644, 'min_split_gain': 7.241507784437335, 'min_child_weight': 18.239302528711, 'min_data_in_leaf': 44}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[881]\tvalid's rmse: 3.65195 + 0.0291\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 10, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.73331 + 0.0343335\n",
      "[200]\tvalid's rmse: 3.69788 + 0.0323871\n",
      "[300]\tvalid's rmse: 3.6819 + 0.0315738\n",
      "[400]\tvalid's rmse: 3.67425 + 0.0309669\n",
      "[500]\tvalid's rmse: 3.66991 + 0.0306692\n",
      "[600]\tvalid's rmse: 3.66686 + 0.0304337\n",
      "[700]\tvalid's rmse: 3.66482 + 0.0302066\n",
      "[800]\tvalid's rmse: 3.6633 + 0.0299686\n",
      "[900]\tvalid's rmse: 3.66218 + 0.0297459\n",
      "[1000]\tvalid's rmse: 3.66131 + 0.0296043\n",
      "[1100]\tvalid's rmse: 3.66054 + 0.0294494\n",
      "[1200]\tvalid's rmse: 3.65999 + 0.0293834\n",
      "[1300]\tvalid's rmse: 3.65947 + 0.0292485\n",
      "[1400]\tvalid's rmse: 3.6589 + 0.0291151\n",
      "[1500]\tvalid's rmse: 3.6585 + 0.0290071\n",
      "[1600]\tvalid's rmse: 3.65819 + 0.0288614\n",
      "[1700]\tvalid's rmse: 3.65779 + 0.0287377\n",
      "[1800]\tvalid's rmse: 3.65749 + 0.0288225\n",
      "[1900]\tvalid's rmse: 3.65723 + 0.0288677\n",
      "[2000]\tvalid's rmse: 3.65712 + 0.0288095\n",
      "[2100]\tvalid's rmse: 3.65689 + 0.0287786\n",
      "[2200]\tvalid's rmse: 3.65688 + 0.0287153\n",
      "[2300]\tvalid's rmse: 3.6569 + 0.0286727\n",
      "[2400]\tvalid's rmse: 3.65681 + 0.0286638\n",
      "[2500]\tvalid's rmse: 3.65678 + 0.028587\n",
      "[2600]\tvalid's rmse: 3.65684 + 0.0284371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:55:40,161] Trial 17 finished with value: 3.6567545218950177 and parameters: {'num_leaves': 34, 'colsample_bytree': 0.40097491232960003, 'subsample': 0.7170189607095988, 'max_depth': 4, 'reg_alpha': 9.229053979277156, 'reg_lambda': 0.24669627682806272, 'min_split_gain': 5.773902609589757, 'min_child_weight': 40.83213746562113, 'min_data_in_leaf': 51}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2700]\tvalid's rmse: 3.65702 + 0.0284054\n",
      "Early stopping, best iteration is:\n",
      "[2506]\tvalid's rmse: 3.65675 + 0.0286108\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 11, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.7871 + 0.0371851\n",
      "[200]\tvalid's rmse: 3.75878 + 0.0366598\n",
      "[300]\tvalid's rmse: 3.74137 + 0.0363852\n",
      "[400]\tvalid's rmse: 3.72743 + 0.0359772\n",
      "[500]\tvalid's rmse: 3.71635 + 0.0357949\n",
      "[600]\tvalid's rmse: 3.7091 + 0.0355575\n",
      "[700]\tvalid's rmse: 3.70331 + 0.0354303\n",
      "[800]\tvalid's rmse: 3.69893 + 0.0352092\n",
      "[900]\tvalid's rmse: 3.69508 + 0.0351433\n",
      "[1000]\tvalid's rmse: 3.69227 + 0.0349805\n",
      "[1100]\tvalid's rmse: 3.68917 + 0.03502\n",
      "[1200]\tvalid's rmse: 3.68646 + 0.0349281\n",
      "[1300]\tvalid's rmse: 3.68428 + 0.0348975\n",
      "[1400]\tvalid's rmse: 3.68312 + 0.0348339\n",
      "[1500]\tvalid's rmse: 3.68165 + 0.0347011\n",
      "[1600]\tvalid's rmse: 3.68063 + 0.0346625\n",
      "[1700]\tvalid's rmse: 3.67955 + 0.0347013\n",
      "[1800]\tvalid's rmse: 3.67869 + 0.0347434\n",
      "[1900]\tvalid's rmse: 3.6779 + 0.0346115\n",
      "[2000]\tvalid's rmse: 3.67702 + 0.0345969\n",
      "[2100]\tvalid's rmse: 3.67635 + 0.0345589\n",
      "[2200]\tvalid's rmse: 3.67586 + 0.0345006\n",
      "[2300]\tvalid's rmse: 3.67524 + 0.0344707\n",
      "[2400]\tvalid's rmse: 3.67479 + 0.0343877\n",
      "[2500]\tvalid's rmse: 3.67424 + 0.0344804\n",
      "[2600]\tvalid's rmse: 3.67403 + 0.0344251\n",
      "[2700]\tvalid's rmse: 3.67366 + 0.0343308\n",
      "[2800]\tvalid's rmse: 3.67338 + 0.0343345\n",
      "[2900]\tvalid's rmse: 3.67333 + 0.0342577\n",
      "[3000]\tvalid's rmse: 3.673 + 0.0343135\n",
      "[3100]\tvalid's rmse: 3.67291 + 0.0344632\n",
      "[3200]\tvalid's rmse: 3.67272 + 0.0344883\n",
      "[3300]\tvalid's rmse: 3.6726 + 0.0345136\n",
      "[3400]\tvalid's rmse: 3.67234 + 0.0345754\n",
      "[3500]\tvalid's rmse: 3.67234 + 0.0345915\n",
      "[3600]\tvalid's rmse: 3.67228 + 0.0347132\n",
      "Early stopping, best iteration is:\n",
      "[3421]\tvalid's rmse: 3.67224 + 0.0346035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:56:10,865] Trial 18 finished with value: 3.672238237470561 and parameters: {'num_leaves': 58, 'colsample_bytree': 0.02596367324705623, 'subsample': 0.4109595939266256, 'max_depth': 7, 'reg_alpha': 5.4324832910620975, 'reg_lambda': 6.886749249237038, 'min_split_gain': 9.864730245858702, 'min_child_weight': 26.631183083799513, 'min_data_in_leaf': 32}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 12, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.73231 + 0.0356619\n",
      "[200]\tvalid's rmse: 3.69593 + 0.0340866\n",
      "[300]\tvalid's rmse: 3.67983 + 0.0332473\n",
      "[400]\tvalid's rmse: 3.67101 + 0.0326935\n",
      "[500]\tvalid's rmse: 3.66578 + 0.0323588\n",
      "[600]\tvalid's rmse: 3.66213 + 0.0319517\n",
      "[700]\tvalid's rmse: 3.65947 + 0.0313505\n",
      "[800]\tvalid's rmse: 3.6578 + 0.0311061\n",
      "[900]\tvalid's rmse: 3.65658 + 0.03088\n",
      "[1000]\tvalid's rmse: 3.65564 + 0.0306023\n",
      "[1100]\tvalid's rmse: 3.6549 + 0.0306368\n",
      "[1200]\tvalid's rmse: 3.65438 + 0.0304623\n",
      "[1300]\tvalid's rmse: 3.65405 + 0.0301985\n",
      "[1400]\tvalid's rmse: 3.6537 + 0.030098\n",
      "[1500]\tvalid's rmse: 3.65344 + 0.0299733\n",
      "[1600]\tvalid's rmse: 3.65334 + 0.0299156\n",
      "[1700]\tvalid's rmse: 3.65318 + 0.029833\n",
      "[1800]\tvalid's rmse: 3.65316 + 0.0297912\n",
      "[1900]\tvalid's rmse: 3.65322 + 0.0297198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:56:29,127] Trial 19 finished with value: 3.6530859897390386 and parameters: {'num_leaves': 49, 'colsample_bytree': 0.16783403682806372, 'subsample': 0.8782270410881754, 'max_depth': 5, 'reg_alpha': 3.3962313251199174, 'reg_lambda': 8.911092840489285, 'min_split_gain': 7.694287776172869, 'min_child_weight': 7.710237175442112, 'min_data_in_leaf': 27}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1765]\tvalid's rmse: 3.65309 + 0.0298903\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 13, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.72047 + 0.035828\n",
      "[200]\tvalid's rmse: 3.68513 + 0.0350331\n",
      "[300]\tvalid's rmse: 3.67027 + 0.0339735\n",
      "[400]\tvalid's rmse: 3.66236 + 0.03381\n",
      "[500]\tvalid's rmse: 3.65771 + 0.0332092\n",
      "[600]\tvalid's rmse: 3.65463 + 0.0329206\n",
      "[700]\tvalid's rmse: 3.65286 + 0.0324521\n",
      "[800]\tvalid's rmse: 3.65189 + 0.0322872\n",
      "[900]\tvalid's rmse: 3.6512 + 0.0319883\n",
      "[1000]\tvalid's rmse: 3.65076 + 0.0317361\n",
      "[1100]\tvalid's rmse: 3.65024 + 0.0316727\n",
      "[1200]\tvalid's rmse: 3.65012 + 0.0314969\n",
      "[1300]\tvalid's rmse: 3.65005 + 0.0313802\n",
      "[1400]\tvalid's rmse: 3.64995 + 0.0312084\n",
      "[1500]\tvalid's rmse: 3.65009 + 0.0308792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:56:48,082] Trial 20 finished with value: 3.6498840808655117 and parameters: {'num_leaves': 33, 'colsample_bytree': 0.2731389398267008, 'subsample': 0.6665843598170456, 'max_depth': 9, 'reg_alpha': 6.367248696434057, 'reg_lambda': 9.050442065670781, 'min_split_gain': 2.506140081168553, 'min_child_weight': 18.164679575113855, 'min_data_in_leaf': 40}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1362]\tvalid's rmse: 3.64988 + 0.031308\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 14, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.72149 + 0.0355481\n",
      "[200]\tvalid's rmse: 3.68604 + 0.0342048\n",
      "[300]\tvalid's rmse: 3.67095 + 0.0337836\n",
      "[400]\tvalid's rmse: 3.66288 + 0.0330226\n",
      "[500]\tvalid's rmse: 3.65812 + 0.0326647\n",
      "[600]\tvalid's rmse: 3.65531 + 0.0321914\n",
      "[700]\tvalid's rmse: 3.65347 + 0.0318875\n",
      "[800]\tvalid's rmse: 3.65252 + 0.031872\n",
      "[900]\tvalid's rmse: 3.65172 + 0.0316362\n",
      "[1000]\tvalid's rmse: 3.6511 + 0.0314934\n",
      "[1100]\tvalid's rmse: 3.65076 + 0.0313399\n",
      "[1200]\tvalid's rmse: 3.65057 + 0.0313875\n",
      "[1300]\tvalid's rmse: 3.65048 + 0.0311395\n",
      "[1400]\tvalid's rmse: 3.65045 + 0.0309855\n",
      "[1500]\tvalid's rmse: 3.65048 + 0.0308935\n",
      "[1600]\tvalid's rmse: 3.65053 + 0.0306622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:57:12,270] Trial 21 finished with value: 3.650381784704502 and parameters: {'num_leaves': 32, 'colsample_bytree': 0.2607800823716987, 'subsample': 0.659680654037139, 'max_depth': 9, 'reg_alpha': 6.273876659071654, 'reg_lambda': 8.972665108759541, 'min_split_gain': 2.199299520000385, 'min_child_weight': 17.01241184360931, 'min_data_in_leaf': 41}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1468]\tvalid's rmse: 3.65038 + 0.030988\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 15, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.71748 + 0.0355717\n",
      "[200]\tvalid's rmse: 3.6816 + 0.0340061\n",
      "[300]\tvalid's rmse: 3.66712 + 0.0336188\n",
      "[400]\tvalid's rmse: 3.66015 + 0.0330127\n",
      "[500]\tvalid's rmse: 3.65614 + 0.032751\n",
      "[600]\tvalid's rmse: 3.65357 + 0.0323779\n",
      "[700]\tvalid's rmse: 3.65231 + 0.0322625\n",
      "[800]\tvalid's rmse: 3.65144 + 0.0321207\n",
      "[900]\tvalid's rmse: 3.65074 + 0.031816\n",
      "[1000]\tvalid's rmse: 3.65043 + 0.0318813\n",
      "[1100]\tvalid's rmse: 3.6503 + 0.0319944\n",
      "[1200]\tvalid's rmse: 3.65029 + 0.0317811\n",
      "[1300]\tvalid's rmse: 3.65038 + 0.031676\n",
      "[1400]\tvalid's rmse: 3.65054 + 0.0316255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:57:32,074] Trial 22 finished with value: 3.6501941364380186 and parameters: {'num_leaves': 43, 'colsample_bytree': 0.27101103134878035, 'subsample': 0.7551046546977208, 'max_depth': 8, 'reg_alpha': 8.286760603414367, 'reg_lambda': 6.798835905036802, 'min_split_gain': 2.69996976521302, 'min_child_weight': 20.625847024816935, 'min_data_in_leaf': 35}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1237]\tvalid's rmse: 3.65019 + 0.0317367\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 16, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.71562 + 0.0352147\n",
      "[200]\tvalid's rmse: 3.68054 + 0.0343784\n",
      "[300]\tvalid's rmse: 3.66735 + 0.033495\n",
      "[400]\tvalid's rmse: 3.66051 + 0.0326685\n",
      "[500]\tvalid's rmse: 3.65653 + 0.0320199\n",
      "[600]\tvalid's rmse: 3.65431 + 0.0313717\n",
      "[700]\tvalid's rmse: 3.65299 + 0.0311326\n",
      "[800]\tvalid's rmse: 3.65229 + 0.0310944\n",
      "[900]\tvalid's rmse: 3.65177 + 0.0310383\n",
      "[1000]\tvalid's rmse: 3.65145 + 0.0308477\n",
      "[1100]\tvalid's rmse: 3.65128 + 0.0307949\n",
      "[1200]\tvalid's rmse: 3.65127 + 0.0305737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:57:54,028] Trial 23 finished with value: 3.651221255253944 and parameters: {'num_leaves': 34, 'colsample_bytree': 0.4509539023861425, 'subsample': 0.8993554244589413, 'max_depth': 10, 'reg_alpha': 5.0983500401405335, 'reg_lambda': 9.216037638939326, 'min_split_gain': 0.687446051819218, 'min_child_weight': 9.817588788731303, 'min_data_in_leaf': 52}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1088]\tvalid's rmse: 3.65122 + 0.0308027\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 17, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.72106 + 0.0347149\n",
      "[200]\tvalid's rmse: 3.68725 + 0.0328846\n",
      "[300]\tvalid's rmse: 3.67298 + 0.0325298\n",
      "[400]\tvalid's rmse: 3.66527 + 0.0317708\n",
      "[500]\tvalid's rmse: 3.66078 + 0.0312598\n",
      "[600]\tvalid's rmse: 3.65832 + 0.0308614\n",
      "[700]\tvalid's rmse: 3.65662 + 0.0305822\n",
      "[800]\tvalid's rmse: 3.65558 + 0.0303778\n",
      "[900]\tvalid's rmse: 3.6547 + 0.0303087\n",
      "[1000]\tvalid's rmse: 3.65403 + 0.0302611\n",
      "[1100]\tvalid's rmse: 3.65357 + 0.0300517\n",
      "[1200]\tvalid's rmse: 3.65325 + 0.0297869\n",
      "[1300]\tvalid's rmse: 3.65292 + 0.0296678\n",
      "[1400]\tvalid's rmse: 3.65286 + 0.0294905\n",
      "[1500]\tvalid's rmse: 3.65283 + 0.0293058\n",
      "[1600]\tvalid's rmse: 3.6526 + 0.0291891\n",
      "[1700]\tvalid's rmse: 3.65252 + 0.0290787\n",
      "[1800]\tvalid's rmse: 3.65265 + 0.0288726\n",
      "[1900]\tvalid's rmse: 3.65271 + 0.0287732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:58:21,521] Trial 24 finished with value: 3.6524741699059042 and parameters: {'num_leaves': 18, 'colsample_bytree': 0.562927440773777, 'subsample': 0.7767423445241581, 'max_depth': 7, 'reg_alpha': 6.64567385546882, 'reg_lambda': 8.37294312407475, 'min_split_gain': 5.869534579052713, 'min_child_weight': 14.881816635333976, 'min_data_in_leaf': 44}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1724]\tvalid's rmse: 3.65247 + 0.0290054\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 18, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.71896 + 0.0353963\n",
      "[200]\tvalid's rmse: 3.68314 + 0.0345139\n",
      "[300]\tvalid's rmse: 3.66899 + 0.0335123\n",
      "[400]\tvalid's rmse: 3.66135 + 0.0329836\n",
      "[500]\tvalid's rmse: 3.65704 + 0.0322176\n",
      "[600]\tvalid's rmse: 3.65463 + 0.0316119\n",
      "[700]\tvalid's rmse: 3.65323 + 0.0312464\n",
      "[800]\tvalid's rmse: 3.65221 + 0.0310885\n",
      "[900]\tvalid's rmse: 3.65164 + 0.0305862\n",
      "[1000]\tvalid's rmse: 3.65109 + 0.0306426\n",
      "[1100]\tvalid's rmse: 3.65079 + 0.0304156\n",
      "[1200]\tvalid's rmse: 3.65057 + 0.0304386\n",
      "[1300]\tvalid's rmse: 3.65066 + 0.0299812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:58:43,347] Trial 25 finished with value: 3.6505468586240286 and parameters: {'num_leaves': 36, 'colsample_bytree': 0.3044120143966735, 'subsample': 0.8980051241861495, 'max_depth': 9, 'reg_alpha': 0.014559748844666487, 'reg_lambda': 7.338415006520012, 'min_split_gain': 5.664304399391701, 'min_child_weight': 21.58432018790015, 'min_data_in_leaf': 39}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1193]\tvalid's rmse: 3.65055 + 0.0304233\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 19, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.73187 + 0.0353788\n",
      "[200]\tvalid's rmse: 3.69426 + 0.0336791\n",
      "[300]\tvalid's rmse: 3.67824 + 0.032975\n",
      "[400]\tvalid's rmse: 3.66983 + 0.0326561\n",
      "[500]\tvalid's rmse: 3.66509 + 0.0322276\n",
      "[600]\tvalid's rmse: 3.66126 + 0.0315125\n",
      "[700]\tvalid's rmse: 3.65926 + 0.0310878\n",
      "[800]\tvalid's rmse: 3.65775 + 0.0308314\n",
      "[900]\tvalid's rmse: 3.65677 + 0.030624\n",
      "[1000]\tvalid's rmse: 3.65588 + 0.0305506\n",
      "[1100]\tvalid's rmse: 3.65517 + 0.0303911\n",
      "[1200]\tvalid's rmse: 3.65462 + 0.030208\n",
      "[1300]\tvalid's rmse: 3.65431 + 0.0301857\n",
      "[1400]\tvalid's rmse: 3.65407 + 0.0299796\n",
      "[1500]\tvalid's rmse: 3.65381 + 0.0299624\n",
      "[1600]\tvalid's rmse: 3.65356 + 0.0298797\n",
      "[1700]\tvalid's rmse: 3.65353 + 0.0298068\n",
      "[1800]\tvalid's rmse: 3.65343 + 0.0297161\n",
      "[1900]\tvalid's rmse: 3.65337 + 0.0296634\n",
      "[2000]\tvalid's rmse: 3.65345 + 0.0296439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:59:01,527] Trial 26 finished with value: 3.6533238954299887 and parameters: {'num_leaves': 42, 'colsample_bytree': 0.19999500674910703, 'subsample': 0.5864344270990706, 'max_depth': 5, 'reg_alpha': 5.6727281354017585, 'reg_lambda': 9.517163340116312, 'min_split_gain': 1.075624403743431, 'min_child_weight': 6.435313383135103, 'min_data_in_leaf': 43}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1888]\tvalid's rmse: 3.65332 + 0.0296891\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      "EarlyStop counter currently is: 20, The current Best score is: 3.6497535991342627 | Overall best: 3.6497535991342627\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 3.74366 + 0.0360451\n",
      "[200]\tvalid's rmse: 3.70416 + 0.0348857\n",
      "[300]\tvalid's rmse: 3.68519 + 0.0341821\n",
      "[400]\tvalid's rmse: 3.67527 + 0.0339994\n",
      "[500]\tvalid's rmse: 3.66886 + 0.0336641\n",
      "[600]\tvalid's rmse: 3.66481 + 0.0334502\n",
      "[700]\tvalid's rmse: 3.66164 + 0.033124\n",
      "[800]\tvalid's rmse: 3.65958 + 0.0330339\n",
      "[900]\tvalid's rmse: 3.65809 + 0.0328228\n",
      "[1000]\tvalid's rmse: 3.65693 + 0.0328912\n",
      "[1100]\tvalid's rmse: 3.65593 + 0.0328294\n",
      "[1200]\tvalid's rmse: 3.65534 + 0.0326436\n",
      "[1300]\tvalid's rmse: 3.65484 + 0.032422\n",
      "[1400]\tvalid's rmse: 3.65426 + 0.0323242\n",
      "[1500]\tvalid's rmse: 3.65387 + 0.0321979\n",
      "[1600]\tvalid's rmse: 3.65377 + 0.0323335\n",
      "[1700]\tvalid's rmse: 3.65362 + 0.0323722\n",
      "[1800]\tvalid's rmse: 3.65345 + 0.0323645\n",
      "[1900]\tvalid's rmse: 3.65334 + 0.0322136\n",
      "[2000]\tvalid's rmse: 3.65324 + 0.0322903\n",
      "[2100]\tvalid's rmse: 3.65326 + 0.0323161\n",
      "[2200]\tvalid's rmse: 3.65313 + 0.0323031\n",
      "[2300]\tvalid's rmse: 3.65326 + 0.0324448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:59:24,154] Trial 27 finished with value: 3.653120255279013 and parameters: {'num_leaves': 60, 'colsample_bytree': 0.09566414786778876, 'subsample': 0.4892048543316526, 'max_depth': 6, 'reg_alpha': 4.651458071248942, 'reg_lambda': 6.539671830253673, 'min_split_gain': 3.291101380216233, 'min_child_weight': 28.65612687252055, 'min_data_in_leaf': 54}. Best is trial 6 with value: 3.6497535991342627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2199]\tvalid's rmse: 3.65312 + 0.032299\n",
      "CV Result Keys: dict_keys(['valid rmse-mean', 'valid rmse-stdv'])\n",
      " Early stopping is triggered: No improvement for the past 20 trials.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Run Optuna Study ===\n",
    "results = optuna.create_study(direction='minimize')\n",
    "\n",
    "try:\n",
    "    results.optimize(objectivelgbm, n_trials=100, callbacks=[early_stopping_opt])\n",
    "except EarlyStoppingExceeded:\n",
    "    print(f\" Early stopping is triggered: No improvement for the past {OPTUNA_EARLY_STOPPING} trials.\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "    num_leaves: 61\n",
      "    colsample_bytree: 0.4276349712856633\n",
      "    subsample: 0.8375512213670602\n",
      "    max_depth: 6\n",
      "    reg_alpha: 6.548900529933036\n",
      "    reg_lambda: 6.728810124639134\n",
      "    min_split_gain: 7.882720918442249\n",
      "    min_child_weight: 16.56497493186302\n",
      "    min_data_in_leaf: 45\n"
     ]
    }
   ],
   "source": [
    "## printing the best trial\n",
    "print('Best trial:')\n",
    "besttrial = results.best_trial\n",
    "gc.collect()\n",
    "\n",
    "for key, value in besttrial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def prediction_with_best_parameters(best_params, n_splits, X_train, y_train, \n",
    "                                    test_df, num_round=10000):\n",
    "  \n",
    "\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_predictions = np.zeros(len(X_train))\n",
    "    test_predictions = np.zeros(len(test_df))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    print(f\"Starting {n_splits}-Fold CV with LightGBM...\\n\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "        print(f\"Fold {fold + 1} | Train size: {len(train_idx)} | Validation size: {len(val_idx)}\")\n",
    "\n",
    "        dtrain = lightgbm.Dataset(X_train.iloc[train_idx], label=y_train.iloc[train_idx])\n",
    "        dvalid = lightgbm.Dataset(X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n",
    "\n",
    "        model = lightgbm.train(\n",
    "            best_params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_round,\n",
    "            valid_sets=[dtrain, dvalid],\n",
    "            callbacks=[\n",
    "                lightgbm.early_stopping(stopping_rounds=150),\n",
    "                lightgbm.log_evaluation(period=200)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_preds = model.predict(X_train.iloc[val_idx], num_iteration=model.best_iteration)\n",
    "        oof_predictions[val_idx] = val_preds\n",
    "\n",
    "        test_predictions += model.predict(test_df, num_iteration=model.best_iteration) / folds.n_splits\n",
    "\n",
    "        fold_importance = pd.DataFrame({\n",
    "            \"Feature\": X_train.columns,\n",
    "            \"importance\": model.feature_importance(),\n",
    "            \"fold\": fold + 1\n",
    "        })\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance], axis=0)\n",
    "\n",
    "        fold_rmse = np.sqrt(mean_squared_error(y_train.iloc[val_idx], val_preds))\n",
    "        print(f\"Fold {fold + 1} RMSE: {fold_rmse:.5f}\\n\")\n",
    "\n",
    "    validation_rmse = np.sqrt(mean_squared_error(y_train, oof_predictions))\n",
    "    print(\"Cross-Validated RMSE Summary\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"Overall Validation RMSE: {validation_rmse:.5f}\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    return model, oof_predictions, test_predictions, feature_importance_df, validation_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 9-Fold CV with LightGBM...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61769\tvalid_1's rmse: 3.7913\n",
      "[400]\ttraining's rmse: 3.56143\tvalid_1's rmse: 3.77114\n",
      "[600]\ttraining's rmse: 3.52698\tvalid_1's rmse: 3.76559\n",
      "[800]\ttraining's rmse: 3.49885\tvalid_1's rmse: 3.76302\n",
      "[1000]\ttraining's rmse: 3.47421\tvalid_1's rmse: 3.76259\n",
      "Early stopping, best iteration is:\n",
      "[1011]\ttraining's rmse: 3.47286\tvalid_1's rmse: 3.76249\n",
      "Fold 1 RMSE: 3.76249\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.64566\tvalid_1's rmse: 3.54131\n",
      "[400]\ttraining's rmse: 3.58981\tvalid_1's rmse: 3.52276\n",
      "[600]\ttraining's rmse: 3.55558\tvalid_1's rmse: 3.51756\n",
      "[800]\ttraining's rmse: 3.52733\tvalid_1's rmse: 3.51563\n",
      "[1000]\ttraining's rmse: 3.50327\tvalid_1's rmse: 3.51501\n",
      "[1200]\ttraining's rmse: 3.48107\tvalid_1's rmse: 3.51425\n",
      "Early stopping, best iteration is:\n",
      "[1242]\ttraining's rmse: 3.47694\tvalid_1's rmse: 3.51413\n",
      "Fold 2 RMSE: 3.51413\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62648\tvalid_1's rmse: 3.71257\n",
      "[400]\ttraining's rmse: 3.57037\tvalid_1's rmse: 3.69819\n",
      "[600]\ttraining's rmse: 3.53473\tvalid_1's rmse: 3.69512\n",
      "[800]\ttraining's rmse: 3.50579\tvalid_1's rmse: 3.69327\n",
      "Early stopping, best iteration is:\n",
      "[811]\ttraining's rmse: 3.50419\tvalid_1's rmse: 3.69305\n",
      "Fold 3 RMSE: 3.69305\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62586\tvalid_1's rmse: 3.70511\n",
      "[400]\ttraining's rmse: 3.57003\tvalid_1's rmse: 3.68927\n",
      "[600]\ttraining's rmse: 3.53531\tvalid_1's rmse: 3.68554\n",
      "[800]\ttraining's rmse: 3.50637\tvalid_1's rmse: 3.68392\n",
      "[1000]\ttraining's rmse: 3.48065\tvalid_1's rmse: 3.6837\n",
      "Early stopping, best iteration is:\n",
      "[943]\ttraining's rmse: 3.48821\tvalid_1's rmse: 3.68342\n",
      "Fold 4 RMSE: 3.68342\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62668\tvalid_1's rmse: 3.71227\n",
      "[400]\ttraining's rmse: 3.57172\tvalid_1's rmse: 3.69063\n",
      "[600]\ttraining's rmse: 3.53739\tvalid_1's rmse: 3.68626\n",
      "[800]\ttraining's rmse: 3.50947\tvalid_1's rmse: 3.68494\n",
      "[1000]\ttraining's rmse: 3.48662\tvalid_1's rmse: 3.68517\n",
      "Early stopping, best iteration is:\n",
      "[898]\ttraining's rmse: 3.49801\tvalid_1's rmse: 3.68469\n",
      "Fold 5 RMSE: 3.68469\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62597\tvalid_1's rmse: 3.72187\n",
      "[400]\ttraining's rmse: 3.57072\tvalid_1's rmse: 3.69287\n",
      "[600]\ttraining's rmse: 3.53591\tvalid_1's rmse: 3.68135\n",
      "[800]\ttraining's rmse: 3.50853\tvalid_1's rmse: 3.67588\n",
      "[1000]\ttraining's rmse: 3.48432\tvalid_1's rmse: 3.67287\n",
      "[1200]\ttraining's rmse: 3.46257\tvalid_1's rmse: 3.67122\n",
      "[1400]\ttraining's rmse: 3.44323\tvalid_1's rmse: 3.67015\n",
      "[1600]\ttraining's rmse: 3.4246\tvalid_1's rmse: 3.66932\n",
      "[1800]\ttraining's rmse: 3.40456\tvalid_1's rmse: 3.66875\n",
      "[2000]\ttraining's rmse: 3.38544\tvalid_1's rmse: 3.66862\n",
      "[2200]\ttraining's rmse: 3.36659\tvalid_1's rmse: 3.66782\n",
      "[2400]\ttraining's rmse: 3.34818\tvalid_1's rmse: 3.66745\n",
      "[2600]\ttraining's rmse: 3.32961\tvalid_1's rmse: 3.66695\n",
      "Early stopping, best iteration is:\n",
      "[2620]\ttraining's rmse: 3.32775\tvalid_1's rmse: 3.66679\n",
      "Fold 6 RMSE: 3.66679\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61746\tvalid_1's rmse: 3.78437\n",
      "[400]\ttraining's rmse: 3.56262\tvalid_1's rmse: 3.76014\n",
      "[600]\ttraining's rmse: 3.52858\tvalid_1's rmse: 3.75283\n",
      "[800]\ttraining's rmse: 3.5022\tvalid_1's rmse: 3.74951\n",
      "[1000]\ttraining's rmse: 3.47871\tvalid_1's rmse: 3.74783\n",
      "[1200]\ttraining's rmse: 3.45661\tvalid_1's rmse: 3.74738\n",
      "[1400]\ttraining's rmse: 3.43662\tvalid_1's rmse: 3.74695\n",
      "[1600]\ttraining's rmse: 3.41692\tvalid_1's rmse: 3.74655\n",
      "[1800]\ttraining's rmse: 3.39781\tvalid_1's rmse: 3.74613\n",
      "[2000]\ttraining's rmse: 3.37933\tvalid_1's rmse: 3.74637\n",
      "Early stopping, best iteration is:\n",
      "[1872]\ttraining's rmse: 3.39147\tvalid_1's rmse: 3.74589\n",
      "Fold 7 RMSE: 3.74589\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.63653\tvalid_1's rmse: 3.6362\n",
      "[400]\ttraining's rmse: 3.58046\tvalid_1's rmse: 3.61597\n",
      "[600]\ttraining's rmse: 3.54582\tvalid_1's rmse: 3.60949\n",
      "[800]\ttraining's rmse: 3.51729\tvalid_1's rmse: 3.60711\n",
      "[1000]\ttraining's rmse: 3.49284\tvalid_1's rmse: 3.60638\n",
      "[1200]\ttraining's rmse: 3.47033\tvalid_1's rmse: 3.60567\n",
      "[1400]\ttraining's rmse: 3.45081\tvalid_1's rmse: 3.60549\n",
      "Early stopping, best iteration is:\n",
      "[1271]\ttraining's rmse: 3.46349\tvalid_1's rmse: 3.60517\n",
      "Fold 8 RMSE: 3.60517\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.65468\tvalid_1's rmse: 3.46442\n",
      "[400]\ttraining's rmse: 3.59788\tvalid_1's rmse: 3.4537\n",
      "[600]\ttraining's rmse: 3.56272\tvalid_1's rmse: 3.45153\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's rmse: 3.56893\tvalid_1's rmse: 3.4513\n",
      "Fold 9 RMSE: 3.45130\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64653\n",
      "===================================\n",
      "CPU times: total: 15min 39s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm\n",
    "param = {\n",
    "    'objective'         : 'regression',\n",
    "    'boosting_type'     : 'gbdt',\n",
    "    'metric'            : 'rmse',\n",
    "    'learning_rate'     : 0.01,\n",
    "    'num_leaves': 43,\n",
    "    'colsample_bytree': 0.37833128023384316,\n",
    "    'subsample': 0.020581374607877696,\n",
    "    'max_depth': 11,\n",
    "    'reg_alpha': 4.926058053299857,\n",
    "    'reg_lambda': 8.077177812556824,\n",
    "    'min_split_gain': 4.326677551210331,\n",
    "    'min_child_weight': 441.95211148401055,\n",
    "    'min_data_in_leaf': 16,\n",
    "    'nthread'           : 8\n",
    "    \n",
    "} \n",
    "\n",
    "# Get columns present in both train and test\n",
    "df_train_columns = [col for col in df_train_columns if col in X_train.columns and col in test.columns]\n",
    "\n",
    "# Now safe to proceed\n",
    "lightbgm_reg, pred_y_train, pred_y_test, feature_importance_df_lgb, rmse_lgb = prediction_with_best_parameters(\n",
    "    best_params=param,\n",
    "    n_splits=9,\n",
    "    X_train=X_train[df_train_columns],\n",
    "    y_train=y_train,\n",
    "    test_df=test[df_train_columns],\n",
    "    num_round=10000\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d354f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.646526452818884"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-4.594532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.211414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-1.211735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.094790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.483750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123618</th>\n",
       "      <td>C_ID_7a239d2eda</td>\n",
       "      <td>0.696938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123619</th>\n",
       "      <td>C_ID_75ace375ae</td>\n",
       "      <td>-0.593808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123620</th>\n",
       "      <td>C_ID_21d56d950c</td>\n",
       "      <td>0.450743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123621</th>\n",
       "      <td>C_ID_6c46fc5a9d</td>\n",
       "      <td>-3.703065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123622</th>\n",
       "      <td>C_ID_87e7979a5f</td>\n",
       "      <td>0.157236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123623 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id    target\n",
       "0       C_ID_0ab67a22ab -4.594532\n",
       "1       C_ID_130fd0cbdd -0.211414\n",
       "2       C_ID_b709037bc5 -1.211735\n",
       "3       C_ID_d27d835a9f -0.094790\n",
       "4       C_ID_2b5e3df5c2 -1.483750\n",
       "...                 ...       ...\n",
       "123618  C_ID_7a239d2eda  0.696938\n",
       "123619  C_ID_75ace375ae -0.593808\n",
       "123620  C_ID_21d56d950c  0.450743\n",
       "123621  C_ID_6c46fc5a9d -3.703065\n",
       "123622  C_ID_87e7979a5f  0.157236\n",
       "\n",
       "[123623 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgb = test[[\"card_id\"]].copy()\n",
    "best_lgb[\"target\"] = pred_y_test\n",
    "best_lgb.to_csv(\"lgb_latest.csv\", index=False)\n",
    "best_lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "def objectiveXgBoost(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.01,\n",
    "        'tree_method': 'auto',\n",
    "        'nthread': -1,\n",
    "        'seed': 326,\n",
    "\n",
    "        # Hyperparameters to optimize\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 12),\n",
    "        'min_child_weight': trial.suggest_uniform('min_child_weight', 0, 45),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.001, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.001, 1),\n",
    "        'lambda': trial.suggest_uniform('reg_lambda', 0, 10),\n",
    "        'alpha': trial.suggest_uniform('reg_alpha', 0, 10),\n",
    "        'gamma': trial.suggest_uniform('min_split_gain', 0, 10),\n",
    "    }\n",
    "\n",
    "    # Prepare DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_result = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=10000,\n",
    "        nfold=3,\n",
    "        seed=47,\n",
    "        early_stopping_rounds=200,\n",
    "        verbose_eval=100,\n",
    "        as_pandas=True\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Return the last RMSE from cross-validation\n",
    "    if 'test-rmse-mean' in cv_result.columns:\n",
    "        return cv_result['test-rmse-mean'].iloc[-1]\n",
    "\n",
    "    raise KeyError(\"Expected metric 'test-rmse-mean' is not found in cv_result.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:31:21,550] A new study created in memory with name: no-name-d9145a30-a4e2-4eec-8eb9-ad3986c37ee6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.84055+0.03592\ttest-rmse:3.84057+0.07288\n",
      "[100]\ttrain-rmse:3.65786+0.03452\ttest-rmse:3.70113+0.07217\n",
      "[200]\ttrain-rmse:3.58527+0.03316\ttest-rmse:3.66843+0.07063\n",
      "[300]\ttrain-rmse:3.54572+0.03330\ttest-rmse:3.65838+0.07040\n",
      "[400]\ttrain-rmse:3.51831+0.03298\ttest-rmse:3.65490+0.07057\n",
      "[500]\ttrain-rmse:3.49611+0.03337\ttest-rmse:3.65330+0.07076\n",
      "[600]\ttrain-rmse:3.47562+0.03271\ttest-rmse:3.65259+0.07062\n",
      "[700]\ttrain-rmse:3.45577+0.03265\ttest-rmse:3.65218+0.07096\n",
      "[800]\ttrain-rmse:3.43839+0.03234\ttest-rmse:3.65232+0.07138\n",
      "[858]\ttrain-rmse:3.42872+0.03233\ttest-rmse:3.65241+0.07158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:31:56,431] Trial 0 finished with value: 3.6520819232464015 and parameters: {'max_depth': 6, 'min_child_weight': 43.77290506261574, 'subsample': 0.6831181237066407, 'colsample_bytree': 0.7872280217291887, 'reg_lambda': 3.723666433000502, 'reg_alpha': 5.520327441090366, 'min_split_gain': 6.467711985995857}. Best is trial 0 with value: 3.6520819232464015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 1, The current Best score is: 3.6520819232464015 | Overall best: 3.6520819232464015\n",
      "[0]\ttrain-rmse:3.84147+0.03593\ttest-rmse:3.84124+0.07285\n",
      "[100]\ttrain-rmse:3.70371+0.03417\ttest-rmse:3.72587+0.07319\n",
      "[200]\ttrain-rmse:3.65088+0.03319\ttest-rmse:3.69139+0.07166\n",
      "[300]\ttrain-rmse:3.62263+0.03255\ttest-rmse:3.67823+0.07077\n",
      "[400]\ttrain-rmse:3.60258+0.03244\ttest-rmse:3.67204+0.07048\n",
      "[500]\ttrain-rmse:3.58581+0.03223\ttest-rmse:3.66779+0.06983\n",
      "[600]\ttrain-rmse:3.57214+0.03216\ttest-rmse:3.66661+0.06944\n",
      "[700]\ttrain-rmse:3.55914+0.03230\ttest-rmse:3.66510+0.06980\n",
      "[800]\ttrain-rmse:3.54681+0.03184\ttest-rmse:3.66415+0.07012\n",
      "[900]\ttrain-rmse:3.53453+0.03220\ttest-rmse:3.66338+0.06931\n",
      "[1000]\ttrain-rmse:3.52322+0.03205\ttest-rmse:3.66324+0.06948\n",
      "[1100]\ttrain-rmse:3.51259+0.03199\ttest-rmse:3.66325+0.06960\n",
      "[1182]\ttrain-rmse:3.50348+0.03172\ttest-rmse:3.66362+0.06965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:32:36,713] Trial 1 finished with value: 3.663058825236984 and parameters: {'max_depth': 6, 'min_child_weight': 35.803137885182196, 'subsample': 0.14475963853819018, 'colsample_bytree': 0.25399642153321433, 'reg_lambda': 3.491727303193255, 'reg_alpha': 9.329912569745478, 'min_split_gain': 4.202937021267338}. Best is trial 0 with value: 3.6520819232464015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 2, The current Best score is: 3.6520819232464015 | Overall best: 3.6520819232464015\n",
      "[0]\ttrain-rmse:3.84277+0.03593\ttest-rmse:3.84238+0.07279\n",
      "[100]\ttrain-rmse:3.76617+0.03352\ttest-rmse:3.76812+0.07243\n",
      "[200]\ttrain-rmse:3.74059+0.03383\ttest-rmse:3.74477+0.07113\n",
      "[300]\ttrain-rmse:3.72633+0.03391\ttest-rmse:3.73247+0.07049\n",
      "[400]\ttrain-rmse:3.71696+0.03324\ttest-rmse:3.72478+0.07068\n",
      "[500]\ttrain-rmse:3.71035+0.03324\ttest-rmse:3.72001+0.07009\n",
      "[600]\ttrain-rmse:3.70590+0.03306\ttest-rmse:3.71699+0.07010\n",
      "[700]\ttrain-rmse:3.70168+0.03318\ttest-rmse:3.71435+0.07001\n",
      "[800]\ttrain-rmse:3.69887+0.03295\ttest-rmse:3.71316+0.07003\n",
      "[900]\ttrain-rmse:3.69614+0.03287\ttest-rmse:3.71134+0.06989\n",
      "[1000]\ttrain-rmse:3.69345+0.03265\ttest-rmse:3.70996+0.06973\n",
      "[1100]\ttrain-rmse:3.69130+0.03279\ttest-rmse:3.70929+0.06963\n",
      "[1200]\ttrain-rmse:3.68939+0.03262\ttest-rmse:3.70877+0.06978\n",
      "[1300]\ttrain-rmse:3.68754+0.03295\ttest-rmse:3.70786+0.06961\n",
      "[1400]\ttrain-rmse:3.68559+0.03276\ttest-rmse:3.70733+0.06961\n",
      "[1500]\ttrain-rmse:3.68372+0.03305\ttest-rmse:3.70675+0.06973\n",
      "[1600]\ttrain-rmse:3.68214+0.03312\ttest-rmse:3.70640+0.06973\n",
      "[1700]\ttrain-rmse:3.68036+0.03323\ttest-rmse:3.70595+0.06951\n",
      "[1800]\ttrain-rmse:3.67877+0.03318\ttest-rmse:3.70532+0.06933\n",
      "[1900]\ttrain-rmse:3.67737+0.03324\ttest-rmse:3.70465+0.06943\n",
      "[2000]\ttrain-rmse:3.67600+0.03321\ttest-rmse:3.70443+0.06941\n",
      "[2100]\ttrain-rmse:3.67476+0.03306\ttest-rmse:3.70419+0.06978\n",
      "[2200]\ttrain-rmse:3.67341+0.03286\ttest-rmse:3.70421+0.06962\n",
      "[2300]\ttrain-rmse:3.67226+0.03303\ttest-rmse:3.70440+0.06967\n",
      "[2375]\ttrain-rmse:3.67143+0.03287\ttest-rmse:3.70453+0.06965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:33:32,828] Trial 2 finished with value: 3.7040917085555325 and parameters: {'max_depth': 2, 'min_child_weight': 31.215020497313716, 'subsample': 0.056770640791965574, 'colsample_bytree': 0.8227474647967071, 'reg_lambda': 2.4980597063047663, 'reg_alpha': 3.026851523436127, 'min_split_gain': 8.043536223200686}. Best is trial 0 with value: 3.6520819232464015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 3, The current Best score is: 3.6520819232464015 | Overall best: 3.6520819232464015\n",
      "[0]\ttrain-rmse:3.84013+0.03594\ttest-rmse:3.84084+0.07282\n",
      "[100]\ttrain-rmse:3.59819+0.03388\ttest-rmse:3.70298+0.07227\n",
      "[200]\ttrain-rmse:3.47460+0.03204\ttest-rmse:3.66969+0.07128\n",
      "[300]\ttrain-rmse:3.39300+0.03017\ttest-rmse:3.66092+0.07122\n",
      "[400]\ttrain-rmse:3.32877+0.02918\ttest-rmse:3.65840+0.07123\n",
      "[500]\ttrain-rmse:3.27112+0.02826\ttest-rmse:3.65808+0.07019\n",
      "[600]\ttrain-rmse:3.21680+0.02767\ttest-rmse:3.65930+0.06969\n",
      "[669]\ttrain-rmse:3.18139+0.02685\ttest-rmse:3.66028+0.06974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:34:24,584] Trial 3 finished with value: 3.6576965785917452 and parameters: {'max_depth': 12, 'min_child_weight': 28.964701196675236, 'subsample': 0.28367548137904286, 'colsample_bytree': 0.4036819974974814, 'reg_lambda': 2.630964578719092, 'reg_alpha': 9.237245381327487, 'min_split_gain': 9.424188933592076}. Best is trial 0 with value: 3.6520819232464015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 4, The current Best score is: 3.6520819232464015 | Overall best: 3.6520819232464015\n",
      "[0]\ttrain-rmse:3.84322+0.03600\ttest-rmse:3.84274+0.07273\n",
      "[100]\ttrain-rmse:3.80470+0.03547\ttest-rmse:3.80455+0.07237\n",
      "[200]\ttrain-rmse:3.79113+0.03548\ttest-rmse:3.79131+0.07242\n",
      "[300]\ttrain-rmse:3.78187+0.03545\ttest-rmse:3.78229+0.07244\n",
      "[400]\ttrain-rmse:3.77489+0.03545\ttest-rmse:3.77550+0.07245\n",
      "[500]\ttrain-rmse:3.76947+0.03538\ttest-rmse:3.77031+0.07243\n",
      "[600]\ttrain-rmse:3.76510+0.03535\ttest-rmse:3.76624+0.07233\n",
      "[700]\ttrain-rmse:3.76140+0.03533\ttest-rmse:3.76285+0.07233\n",
      "[800]\ttrain-rmse:3.75821+0.03531\ttest-rmse:3.75995+0.07232\n",
      "[900]\ttrain-rmse:3.75541+0.03528\ttest-rmse:3.75740+0.07235\n",
      "[1000]\ttrain-rmse:3.75291+0.03526\ttest-rmse:3.75517+0.07236\n",
      "[1100]\ttrain-rmse:3.75066+0.03526\ttest-rmse:3.75314+0.07233\n",
      "[1200]\ttrain-rmse:3.74861+0.03526\ttest-rmse:3.75133+0.07231\n",
      "[1300]\ttrain-rmse:3.74674+0.03528\ttest-rmse:3.74969+0.07233\n",
      "[1400]\ttrain-rmse:3.74502+0.03529\ttest-rmse:3.74823+0.07236\n",
      "[1500]\ttrain-rmse:3.74343+0.03531\ttest-rmse:3.74684+0.07239\n",
      "[1600]\ttrain-rmse:3.74195+0.03534\ttest-rmse:3.74561+0.07239\n",
      "[1700]\ttrain-rmse:3.74058+0.03536\ttest-rmse:3.74449+0.07244\n",
      "[1800]\ttrain-rmse:3.73929+0.03538\ttest-rmse:3.74342+0.07243\n",
      "[1900]\ttrain-rmse:3.73809+0.03540\ttest-rmse:3.74237+0.07243\n",
      "[2000]\ttrain-rmse:3.73695+0.03542\ttest-rmse:3.74147+0.07247\n",
      "[2100]\ttrain-rmse:3.73587+0.03545\ttest-rmse:3.74064+0.07244\n",
      "[2200]\ttrain-rmse:3.73484+0.03546\ttest-rmse:3.73979+0.07251\n",
      "[2300]\ttrain-rmse:3.73386+0.03547\ttest-rmse:3.73904+0.07254\n",
      "[2400]\ttrain-rmse:3.73294+0.03549\ttest-rmse:3.73836+0.07252\n",
      "[2500]\ttrain-rmse:3.73206+0.03550\ttest-rmse:3.73770+0.07257\n",
      "[2600]\ttrain-rmse:3.73121+0.03551\ttest-rmse:3.73707+0.07257\n",
      "[2700]\ttrain-rmse:3.73041+0.03552\ttest-rmse:3.73653+0.07260\n",
      "[2800]\ttrain-rmse:3.72964+0.03553\ttest-rmse:3.73596+0.07261\n",
      "[2900]\ttrain-rmse:3.72891+0.03554\ttest-rmse:3.73544+0.07263\n",
      "[3000]\ttrain-rmse:3.72819+0.03555\ttest-rmse:3.73493+0.07262\n",
      "[3100]\ttrain-rmse:3.72751+0.03555\ttest-rmse:3.73445+0.07262\n",
      "[3200]\ttrain-rmse:3.72685+0.03556\ttest-rmse:3.73402+0.07263\n",
      "[3300]\ttrain-rmse:3.72621+0.03556\ttest-rmse:3.73358+0.07265\n",
      "[3400]\ttrain-rmse:3.72560+0.03557\ttest-rmse:3.73317+0.07265\n",
      "[3500]\ttrain-rmse:3.72500+0.03557\ttest-rmse:3.73277+0.07265\n",
      "[3600]\ttrain-rmse:3.72442+0.03557\ttest-rmse:3.73240+0.07272\n",
      "[3700]\ttrain-rmse:3.72386+0.03558\ttest-rmse:3.73205+0.07271\n",
      "[3800]\ttrain-rmse:3.72331+0.03557\ttest-rmse:3.73170+0.07272\n",
      "[3900]\ttrain-rmse:3.72278+0.03557\ttest-rmse:3.73137+0.07271\n",
      "[4000]\ttrain-rmse:3.72226+0.03557\ttest-rmse:3.73102+0.07272\n",
      "[4100]\ttrain-rmse:3.72176+0.03558\ttest-rmse:3.73069+0.07270\n",
      "[4200]\ttrain-rmse:3.72127+0.03558\ttest-rmse:3.73038+0.07268\n",
      "[4300]\ttrain-rmse:3.72080+0.03558\ttest-rmse:3.73010+0.07269\n",
      "[4400]\ttrain-rmse:3.72033+0.03557\ttest-rmse:3.72982+0.07267\n",
      "[4500]\ttrain-rmse:3.71988+0.03557\ttest-rmse:3.72953+0.07267\n",
      "[4600]\ttrain-rmse:3.71944+0.03557\ttest-rmse:3.72925+0.07269\n",
      "[4700]\ttrain-rmse:3.71900+0.03557\ttest-rmse:3.72898+0.07268\n",
      "[4800]\ttrain-rmse:3.71858+0.03557\ttest-rmse:3.72875+0.07267\n",
      "[4900]\ttrain-rmse:3.71817+0.03556\ttest-rmse:3.72853+0.07267\n",
      "[5000]\ttrain-rmse:3.71777+0.03556\ttest-rmse:3.72830+0.07264\n",
      "[5100]\ttrain-rmse:3.71738+0.03556\ttest-rmse:3.72807+0.07261\n",
      "[5200]\ttrain-rmse:3.71699+0.03556\ttest-rmse:3.72786+0.07260\n",
      "[5300]\ttrain-rmse:3.71662+0.03555\ttest-rmse:3.72762+0.07260\n",
      "[5400]\ttrain-rmse:3.71625+0.03555\ttest-rmse:3.72741+0.07259\n",
      "[5500]\ttrain-rmse:3.71589+0.03555\ttest-rmse:3.72724+0.07254\n",
      "[5600]\ttrain-rmse:3.71554+0.03555\ttest-rmse:3.72707+0.07254\n",
      "[5700]\ttrain-rmse:3.71519+0.03554\ttest-rmse:3.72688+0.07256\n",
      "[5800]\ttrain-rmse:3.71485+0.03554\ttest-rmse:3.72668+0.07257\n",
      "[5900]\ttrain-rmse:3.71453+0.03554\ttest-rmse:3.72652+0.07257\n",
      "[6000]\ttrain-rmse:3.71420+0.03554\ttest-rmse:3.72629+0.07256\n",
      "[6100]\ttrain-rmse:3.71387+0.03553\ttest-rmse:3.72611+0.07255\n",
      "[6200]\ttrain-rmse:3.71356+0.03553\ttest-rmse:3.72595+0.07258\n",
      "[6300]\ttrain-rmse:3.71324+0.03553\ttest-rmse:3.72576+0.07256\n",
      "[6400]\ttrain-rmse:3.71294+0.03552\ttest-rmse:3.72558+0.07255\n",
      "[6500]\ttrain-rmse:3.71264+0.03552\ttest-rmse:3.72543+0.07254\n",
      "[6600]\ttrain-rmse:3.71235+0.03552\ttest-rmse:3.72525+0.07250\n",
      "[6700]\ttrain-rmse:3.71205+0.03551\ttest-rmse:3.72509+0.07250\n",
      "[6800]\ttrain-rmse:3.71177+0.03551\ttest-rmse:3.72493+0.07250\n",
      "[6900]\ttrain-rmse:3.71149+0.03551\ttest-rmse:3.72479+0.07248\n",
      "[7000]\ttrain-rmse:3.71121+0.03551\ttest-rmse:3.72463+0.07246\n",
      "[7100]\ttrain-rmse:3.71094+0.03550\ttest-rmse:3.72447+0.07246\n",
      "[7200]\ttrain-rmse:3.71066+0.03550\ttest-rmse:3.72431+0.07245\n",
      "[7300]\ttrain-rmse:3.71040+0.03550\ttest-rmse:3.72419+0.07245\n",
      "[7400]\ttrain-rmse:3.71014+0.03550\ttest-rmse:3.72406+0.07246\n",
      "[7500]\ttrain-rmse:3.70988+0.03549\ttest-rmse:3.72393+0.07245\n",
      "[7600]\ttrain-rmse:3.70963+0.03549\ttest-rmse:3.72379+0.07241\n",
      "[7700]\ttrain-rmse:3.70937+0.03549\ttest-rmse:3.72367+0.07244\n",
      "[7800]\ttrain-rmse:3.70913+0.03548\ttest-rmse:3.72356+0.07241\n",
      "[7900]\ttrain-rmse:3.70888+0.03548\ttest-rmse:3.72344+0.07238\n",
      "[8000]\ttrain-rmse:3.70864+0.03547\ttest-rmse:3.72332+0.07240\n",
      "[8100]\ttrain-rmse:3.70840+0.03547\ttest-rmse:3.72317+0.07242\n",
      "[8200]\ttrain-rmse:3.70816+0.03547\ttest-rmse:3.72305+0.07242\n",
      "[8300]\ttrain-rmse:3.70793+0.03547\ttest-rmse:3.72295+0.07240\n",
      "[8400]\ttrain-rmse:3.70770+0.03546\ttest-rmse:3.72282+0.07239\n",
      "[8500]\ttrain-rmse:3.70747+0.03546\ttest-rmse:3.72273+0.07238\n",
      "[8600]\ttrain-rmse:3.70725+0.03546\ttest-rmse:3.72263+0.07239\n",
      "[8700]\ttrain-rmse:3.70703+0.03545\ttest-rmse:3.72255+0.07237\n",
      "[8800]\ttrain-rmse:3.70681+0.03545\ttest-rmse:3.72244+0.07236\n",
      "[8900]\ttrain-rmse:3.70660+0.03545\ttest-rmse:3.72235+0.07238\n",
      "[9000]\ttrain-rmse:3.70639+0.03544\ttest-rmse:3.72225+0.07237\n",
      "[9100]\ttrain-rmse:3.70617+0.03544\ttest-rmse:3.72216+0.07235\n",
      "[9200]\ttrain-rmse:3.70596+0.03544\ttest-rmse:3.72207+0.07235\n",
      "[9300]\ttrain-rmse:3.70576+0.03543\ttest-rmse:3.72199+0.07234\n",
      "[9400]\ttrain-rmse:3.70556+0.03543\ttest-rmse:3.72188+0.07235\n",
      "[9500]\ttrain-rmse:3.70536+0.03543\ttest-rmse:3.72180+0.07235\n",
      "[9600]\ttrain-rmse:3.70516+0.03542\ttest-rmse:3.72172+0.07236\n",
      "[9700]\ttrain-rmse:3.70496+0.03541\ttest-rmse:3.72165+0.07238\n",
      "[9800]\ttrain-rmse:3.70477+0.03541\ttest-rmse:3.72157+0.07239\n",
      "[9900]\ttrain-rmse:3.70457+0.03541\ttest-rmse:3.72144+0.07237\n",
      "[9999]\ttrain-rmse:3.70438+0.03540\ttest-rmse:3.72137+0.07238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:38:01,613] Trial 4 finished with value: 3.7213677644771894 and parameters: {'max_depth': 1, 'min_child_weight': 23.740357845659158, 'subsample': 0.8816493557068581, 'colsample_bytree': 0.8807651776359722, 'reg_lambda': 3.8798575602169674, 'reg_alpha': 6.406488421802195, 'min_split_gain': 4.107638126665676}. Best is trial 0 with value: 3.6520819232464015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 5, The current Best score is: 3.6520819232464015 | Overall best: 3.6520819232464015\n",
      "[0]\ttrain-rmse:3.84262+0.03606\ttest-rmse:3.84217+0.07274\n",
      "[100]\ttrain-rmse:3.77608+0.03616\ttest-rmse:3.77769+0.07244\n",
      "[200]\ttrain-rmse:3.75577+0.03585\ttest-rmse:3.75881+0.07243\n",
      "[300]\ttrain-rmse:3.74759+0.03614\ttest-rmse:3.75247+0.07194\n",
      "[400]\ttrain-rmse:3.74147+0.03547\ttest-rmse:3.74819+0.07222\n",
      "[500]\ttrain-rmse:3.73928+0.03584\ttest-rmse:3.74736+0.07165\n",
      "[600]\ttrain-rmse:3.73847+0.03603\ttest-rmse:3.74742+0.07168\n",
      "[654]\ttrain-rmse:3.73872+0.03557\ttest-rmse:3.74839+0.07178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:38:28,484] Trial 5 finished with value: 3.7461802265202486 and parameters: {'max_depth': 9, 'min_child_weight': 35.80280347419497, 'subsample': 0.006492173942540998, 'colsample_bytree': 0.9042502205712027, 'reg_lambda': 7.10073809741946, 'reg_alpha': 2.975342040209493, 'min_split_gain': 8.757525468923637}. Best is trial 0 with value: 3.6520819232464015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 6, The current Best score is: 3.6520819232464015 | Overall best: 3.6520819232464015\n",
      "[0]\ttrain-rmse:3.83949+0.03593\ttest-rmse:3.84071+0.07278\n",
      "[100]\ttrain-rmse:3.56129+0.03266\ttest-rmse:3.69644+0.07199\n",
      "[200]\ttrain-rmse:3.41173+0.02905\ttest-rmse:3.66274+0.07052\n",
      "[300]\ttrain-rmse:3.31081+0.02889\ttest-rmse:3.65303+0.07091\n",
      "[400]\ttrain-rmse:3.23889+0.02901\ttest-rmse:3.64968+0.07049\n",
      "[500]\ttrain-rmse:3.18331+0.02842\ttest-rmse:3.64833+0.07002\n",
      "[600]\ttrain-rmse:3.13883+0.02794\ttest-rmse:3.64788+0.07005\n",
      "[700]\ttrain-rmse:3.09605+0.02803\ttest-rmse:3.64772+0.07026\n",
      "[800]\ttrain-rmse:3.05798+0.02808\ttest-rmse:3.64799+0.07043\n",
      "[891]\ttrain-rmse:3.02394+0.02734\ttest-rmse:3.64842+0.07071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:39:19,667] Trial 6 finished with value: 3.6477015404969944 and parameters: {'max_depth': 8, 'min_child_weight': 12.63295231835534, 'subsample': 0.8856361863906584, 'colsample_bytree': 0.5192226685768537, 'reg_lambda': 9.30032304843493, 'reg_alpha': 9.969215924634227, 'min_split_gain': 0.5489609900882941}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 0, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84121+0.03592\ttest-rmse:3.84105+0.07282\n",
      "[100]\ttrain-rmse:3.68549+0.03445\ttest-rmse:3.70818+0.07195\n",
      "[200]\ttrain-rmse:3.62968+0.03407\ttest-rmse:3.67662+0.07030\n",
      "[300]\ttrain-rmse:3.59965+0.03440\ttest-rmse:3.66616+0.06985\n",
      "[400]\ttrain-rmse:3.57920+0.03463\ttest-rmse:3.66181+0.06959\n",
      "[500]\ttrain-rmse:3.56229+0.03438\ttest-rmse:3.65945+0.06941\n",
      "[600]\ttrain-rmse:3.54729+0.03416\ttest-rmse:3.65797+0.06967\n",
      "[700]\ttrain-rmse:3.53285+0.03405\ttest-rmse:3.65738+0.06991\n",
      "[800]\ttrain-rmse:3.52021+0.03428\ttest-rmse:3.65710+0.06988\n",
      "[900]\ttrain-rmse:3.50814+0.03500\ttest-rmse:3.65696+0.06977\n",
      "[1000]\ttrain-rmse:3.49612+0.03479\ttest-rmse:3.65695+0.07010\n",
      "[1081]\ttrain-rmse:3.48737+0.03479\ttest-rmse:3.65715+0.07024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:39:57,066] Trial 7 finished with value: 3.6568551699732734 and parameters: {'max_depth': 5, 'min_child_weight': 36.74193559081902, 'subsample': 0.4877282791624042, 'colsample_bytree': 0.9460658502927287, 'reg_lambda': 3.0529673829658632, 'reg_alpha': 7.72715313172056, 'min_split_gain': 6.2097053776446876}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 1, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84091+0.03593\ttest-rmse:3.84065+0.07276\n",
      "[100]\ttrain-rmse:3.68372+0.03422\ttest-rmse:3.70840+0.07212\n",
      "[200]\ttrain-rmse:3.62202+0.03457\ttest-rmse:3.67612+0.07065\n",
      "[300]\ttrain-rmse:3.58457+0.03436\ttest-rmse:3.66507+0.07054\n",
      "[400]\ttrain-rmse:3.55686+0.03399\ttest-rmse:3.66054+0.07052\n",
      "[500]\ttrain-rmse:3.53432+0.03404\ttest-rmse:3.65786+0.07075\n",
      "[600]\ttrain-rmse:3.51417+0.03366\ttest-rmse:3.65659+0.07062\n",
      "[700]\ttrain-rmse:3.49417+0.03441\ttest-rmse:3.65548+0.07074\n",
      "[800]\ttrain-rmse:3.47655+0.03493\ttest-rmse:3.65517+0.07092\n",
      "[900]\ttrain-rmse:3.45981+0.03506\ttest-rmse:3.65500+0.07095\n",
      "[1000]\ttrain-rmse:3.44334+0.03479\ttest-rmse:3.65492+0.07136\n",
      "[1100]\ttrain-rmse:3.42723+0.03479\ttest-rmse:3.65497+0.07197\n",
      "[1148]\ttrain-rmse:3.41978+0.03493\ttest-rmse:3.65511+0.07216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:40:37,909] Trial 8 finished with value: 3.654782955124709 and parameters: {'max_depth': 5, 'min_child_weight': 12.487437140081253, 'subsample': 0.7707741420300194, 'colsample_bytree': 0.9917818508885073, 'reg_lambda': 4.0512569399256915, 'reg_alpha': 8.41875067960719, 'min_split_gain': 0.48073258592792323}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 2, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84323+0.03599\ttest-rmse:3.84275+0.07273\n",
      "[100]\ttrain-rmse:3.80799+0.03568\ttest-rmse:3.80788+0.07249\n",
      "[200]\ttrain-rmse:3.79413+0.03557\ttest-rmse:3.79433+0.07264\n",
      "[300]\ttrain-rmse:3.78451+0.03552\ttest-rmse:3.78493+0.07271\n",
      "[400]\ttrain-rmse:3.77728+0.03551\ttest-rmse:3.77794+0.07266\n",
      "[500]\ttrain-rmse:3.77167+0.03542\ttest-rmse:3.77254+0.07266\n",
      "[600]\ttrain-rmse:3.76706+0.03539\ttest-rmse:3.76819+0.07264\n",
      "[700]\ttrain-rmse:3.76325+0.03536\ttest-rmse:3.76467+0.07261\n",
      "[800]\ttrain-rmse:3.75997+0.03532\ttest-rmse:3.76167+0.07258\n",
      "[900]\ttrain-rmse:3.75708+0.03527\ttest-rmse:3.75906+0.07257\n",
      "[1000]\ttrain-rmse:3.75452+0.03524\ttest-rmse:3.75676+0.07261\n",
      "[1100]\ttrain-rmse:3.75221+0.03524\ttest-rmse:3.75470+0.07264\n",
      "[1200]\ttrain-rmse:3.75010+0.03523\ttest-rmse:3.75285+0.07264\n",
      "[1300]\ttrain-rmse:3.74818+0.03524\ttest-rmse:3.75120+0.07272\n",
      "[1400]\ttrain-rmse:3.74640+0.03526\ttest-rmse:3.74966+0.07266\n",
      "[1500]\ttrain-rmse:3.74477+0.03529\ttest-rmse:3.74832+0.07264\n",
      "[1600]\ttrain-rmse:3.74325+0.03532\ttest-rmse:3.74709+0.07271\n",
      "[1700]\ttrain-rmse:3.74184+0.03534\ttest-rmse:3.74595+0.07271\n",
      "[1800]\ttrain-rmse:3.74052+0.03536\ttest-rmse:3.74486+0.07275\n",
      "[1900]\ttrain-rmse:3.73926+0.03538\ttest-rmse:3.74379+0.07275\n",
      "[2000]\ttrain-rmse:3.73808+0.03540\ttest-rmse:3.74282+0.07276\n",
      "[2100]\ttrain-rmse:3.73696+0.03541\ttest-rmse:3.74197+0.07278\n",
      "[2200]\ttrain-rmse:3.73591+0.03542\ttest-rmse:3.74115+0.07279\n",
      "[2300]\ttrain-rmse:3.73490+0.03543\ttest-rmse:3.74040+0.07285\n",
      "[2400]\ttrain-rmse:3.73396+0.03544\ttest-rmse:3.73970+0.07284\n",
      "[2500]\ttrain-rmse:3.73304+0.03545\ttest-rmse:3.73905+0.07286\n",
      "[2600]\ttrain-rmse:3.73217+0.03546\ttest-rmse:3.73832+0.07286\n",
      "[2700]\ttrain-rmse:3.73134+0.03548\ttest-rmse:3.73775+0.07288\n",
      "[2800]\ttrain-rmse:3.73055+0.03547\ttest-rmse:3.73719+0.07292\n",
      "[2900]\ttrain-rmse:3.72977+0.03548\ttest-rmse:3.73665+0.07291\n",
      "[3000]\ttrain-rmse:3.72903+0.03549\ttest-rmse:3.73610+0.07293\n",
      "[3100]\ttrain-rmse:3.72831+0.03549\ttest-rmse:3.73559+0.07295\n",
      "[3200]\ttrain-rmse:3.72763+0.03550\ttest-rmse:3.73515+0.07294\n",
      "[3300]\ttrain-rmse:3.72697+0.03550\ttest-rmse:3.73472+0.07295\n",
      "[3400]\ttrain-rmse:3.72632+0.03550\ttest-rmse:3.73425+0.07299\n",
      "[3500]\ttrain-rmse:3.72571+0.03551\ttest-rmse:3.73384+0.07300\n",
      "[3600]\ttrain-rmse:3.72511+0.03550\ttest-rmse:3.73344+0.07301\n",
      "[3700]\ttrain-rmse:3.72453+0.03551\ttest-rmse:3.73307+0.07299\n",
      "[3800]\ttrain-rmse:3.72396+0.03550\ttest-rmse:3.73270+0.07302\n",
      "[3900]\ttrain-rmse:3.72341+0.03550\ttest-rmse:3.73235+0.07297\n",
      "[4000]\ttrain-rmse:3.72288+0.03551\ttest-rmse:3.73204+0.07296\n",
      "[4100]\ttrain-rmse:3.72236+0.03551\ttest-rmse:3.73172+0.07293\n",
      "[4200]\ttrain-rmse:3.72184+0.03550\ttest-rmse:3.73136+0.07295\n",
      "[4300]\ttrain-rmse:3.72135+0.03549\ttest-rmse:3.73102+0.07296\n",
      "[4400]\ttrain-rmse:3.72087+0.03549\ttest-rmse:3.73071+0.07293\n",
      "[4500]\ttrain-rmse:3.72041+0.03548\ttest-rmse:3.73041+0.07294\n",
      "[4600]\ttrain-rmse:3.71995+0.03548\ttest-rmse:3.73014+0.07296\n",
      "[4700]\ttrain-rmse:3.71951+0.03548\ttest-rmse:3.72989+0.07297\n",
      "[4800]\ttrain-rmse:3.71907+0.03547\ttest-rmse:3.72960+0.07298\n",
      "[4900]\ttrain-rmse:3.71864+0.03547\ttest-rmse:3.72933+0.07297\n",
      "[5000]\ttrain-rmse:3.71822+0.03546\ttest-rmse:3.72912+0.07296\n",
      "[5100]\ttrain-rmse:3.71781+0.03546\ttest-rmse:3.72887+0.07292\n",
      "[5200]\ttrain-rmse:3.71741+0.03545\ttest-rmse:3.72861+0.07288\n",
      "[5300]\ttrain-rmse:3.71702+0.03545\ttest-rmse:3.72840+0.07287\n",
      "[5400]\ttrain-rmse:3.71663+0.03544\ttest-rmse:3.72818+0.07287\n",
      "[5500]\ttrain-rmse:3.71625+0.03544\ttest-rmse:3.72798+0.07285\n",
      "[5600]\ttrain-rmse:3.71587+0.03544\ttest-rmse:3.72773+0.07285\n",
      "[5700]\ttrain-rmse:3.71551+0.03544\ttest-rmse:3.72752+0.07289\n",
      "[5800]\ttrain-rmse:3.71515+0.03544\ttest-rmse:3.72731+0.07282\n",
      "[5900]\ttrain-rmse:3.71479+0.03544\ttest-rmse:3.72712+0.07283\n",
      "[6000]\ttrain-rmse:3.71445+0.03544\ttest-rmse:3.72691+0.07283\n",
      "[6100]\ttrain-rmse:3.71411+0.03544\ttest-rmse:3.72671+0.07280\n",
      "[6200]\ttrain-rmse:3.71377+0.03544\ttest-rmse:3.72656+0.07278\n",
      "[6300]\ttrain-rmse:3.71344+0.03544\ttest-rmse:3.72635+0.07274\n",
      "[6400]\ttrain-rmse:3.71311+0.03544\ttest-rmse:3.72617+0.07272\n",
      "[6500]\ttrain-rmse:3.71279+0.03544\ttest-rmse:3.72598+0.07270\n",
      "[6600]\ttrain-rmse:3.71248+0.03544\ttest-rmse:3.72579+0.07271\n",
      "[6700]\ttrain-rmse:3.71217+0.03543\ttest-rmse:3.72564+0.07270\n",
      "[6800]\ttrain-rmse:3.71187+0.03544\ttest-rmse:3.72544+0.07272\n",
      "[6900]\ttrain-rmse:3.71158+0.03543\ttest-rmse:3.72526+0.07273\n",
      "[7000]\ttrain-rmse:3.71128+0.03543\ttest-rmse:3.72510+0.07273\n",
      "[7100]\ttrain-rmse:3.71100+0.03543\ttest-rmse:3.72497+0.07271\n",
      "[7200]\ttrain-rmse:3.71071+0.03541\ttest-rmse:3.72480+0.07270\n",
      "[7300]\ttrain-rmse:3.71043+0.03542\ttest-rmse:3.72466+0.07269\n",
      "[7400]\ttrain-rmse:3.71015+0.03541\ttest-rmse:3.72452+0.07266\n",
      "[7500]\ttrain-rmse:3.70988+0.03541\ttest-rmse:3.72437+0.07267\n",
      "[7600]\ttrain-rmse:3.70961+0.03541\ttest-rmse:3.72424+0.07263\n",
      "[7700]\ttrain-rmse:3.70934+0.03541\ttest-rmse:3.72412+0.07260\n",
      "[7800]\ttrain-rmse:3.70908+0.03540\ttest-rmse:3.72399+0.07260\n",
      "[7900]\ttrain-rmse:3.70882+0.03541\ttest-rmse:3.72387+0.07263\n",
      "[8000]\ttrain-rmse:3.70857+0.03540\ttest-rmse:3.72378+0.07263\n",
      "[8100]\ttrain-rmse:3.70831+0.03539\ttest-rmse:3.72362+0.07263\n",
      "[8200]\ttrain-rmse:3.70807+0.03539\ttest-rmse:3.72351+0.07260\n",
      "[8300]\ttrain-rmse:3.70782+0.03538\ttest-rmse:3.72340+0.07260\n",
      "[8400]\ttrain-rmse:3.70758+0.03538\ttest-rmse:3.72328+0.07259\n",
      "[8500]\ttrain-rmse:3.70734+0.03538\ttest-rmse:3.72317+0.07258\n",
      "[8600]\ttrain-rmse:3.70710+0.03538\ttest-rmse:3.72306+0.07259\n",
      "[8700]\ttrain-rmse:3.70687+0.03538\ttest-rmse:3.72296+0.07259\n",
      "[8800]\ttrain-rmse:3.70664+0.03537\ttest-rmse:3.72282+0.07259\n",
      "[8900]\ttrain-rmse:3.70641+0.03538\ttest-rmse:3.72271+0.07257\n",
      "[9000]\ttrain-rmse:3.70619+0.03537\ttest-rmse:3.72264+0.07256\n",
      "[9100]\ttrain-rmse:3.70597+0.03537\ttest-rmse:3.72251+0.07257\n",
      "[9200]\ttrain-rmse:3.70575+0.03537\ttest-rmse:3.72241+0.07254\n",
      "[9300]\ttrain-rmse:3.70553+0.03536\ttest-rmse:3.72233+0.07252\n",
      "[9400]\ttrain-rmse:3.70531+0.03536\ttest-rmse:3.72223+0.07252\n",
      "[9500]\ttrain-rmse:3.70510+0.03536\ttest-rmse:3.72214+0.07253\n",
      "[9600]\ttrain-rmse:3.70489+0.03535\ttest-rmse:3.72207+0.07253\n",
      "[9700]\ttrain-rmse:3.70469+0.03535\ttest-rmse:3.72198+0.07252\n",
      "[9800]\ttrain-rmse:3.70448+0.03535\ttest-rmse:3.72188+0.07248\n",
      "[9900]\ttrain-rmse:3.70428+0.03534\ttest-rmse:3.72181+0.07250\n",
      "[9999]\ttrain-rmse:3.70408+0.03533\ttest-rmse:3.72172+0.07248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:44:09,447] Trial 9 finished with value: 3.7217241564848274 and parameters: {'max_depth': 1, 'min_child_weight': 27.11100246305306, 'subsample': 0.7558291745673642, 'colsample_bytree': 0.2914592547545947, 'reg_lambda': 4.10406677567273, 'reg_alpha': 1.5121623292976272, 'min_split_gain': 0.03662246578352346}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 3, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83832+0.03598\ttest-rmse:3.84050+0.07282\n",
      "[100]\ttrain-rmse:3.44978+0.03112\ttest-rmse:3.69484+0.07092\n",
      "[200]\ttrain-rmse:3.22033+0.02522\ttest-rmse:3.66313+0.06948\n",
      "[300]\ttrain-rmse:3.06287+0.02366\ttest-rmse:3.65501+0.06907\n",
      "[400]\ttrain-rmse:2.95263+0.02508\ttest-rmse:3.65211+0.06849\n",
      "[500]\ttrain-rmse:2.87384+0.02664\ttest-rmse:3.65132+0.06812\n",
      "[600]\ttrain-rmse:2.81636+0.02480\ttest-rmse:3.65173+0.06779\n",
      "[700]\ttrain-rmse:2.76980+0.02222\ttest-rmse:3.65229+0.06795\n",
      "[726]\ttrain-rmse:2.75812+0.02168\ttest-rmse:3.65244+0.06804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:45:11,323] Trial 10 finished with value: 3.651268963923563 and parameters: {'max_depth': 9, 'min_child_weight': 1.6407328635011886, 'subsample': 0.9944489509516301, 'colsample_bytree': 0.708826860859417, 'reg_lambda': 9.977733416837902, 'reg_alpha': 6.675543714216831, 'min_split_gain': 2.4933270802179672}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 4, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83842+0.03587\ttest-rmse:3.84072+0.07262\n",
      "[100]\ttrain-rmse:3.45524+0.03181\ttest-rmse:3.69429+0.07184\n",
      "[200]\ttrain-rmse:3.22830+0.02702\ttest-rmse:3.66212+0.07039\n",
      "[300]\ttrain-rmse:3.06890+0.02795\ttest-rmse:3.65350+0.07002\n",
      "[400]\ttrain-rmse:2.95223+0.02852\ttest-rmse:3.65078+0.07010\n",
      "[500]\ttrain-rmse:2.86534+0.02821\ttest-rmse:3.64976+0.06954\n",
      "[600]\ttrain-rmse:2.79626+0.02622\ttest-rmse:3.64937+0.06947\n",
      "[700]\ttrain-rmse:2.73734+0.02203\ttest-rmse:3.64970+0.06970\n",
      "[800]\ttrain-rmse:2.68610+0.02141\ttest-rmse:3.65016+0.06981\n",
      "[816]\ttrain-rmse:2.67752+0.02104\ttest-rmse:3.65019+0.06986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:46:19,817] Trial 11 finished with value: 3.6493317582391964 and parameters: {'max_depth': 9, 'min_child_weight': 0.969782424908059, 'subsample': 0.9328237469676067, 'colsample_bytree': 0.6254860681246641, 'reg_lambda': 9.601236742656651, 'reg_alpha': 6.941781254503683, 'min_split_gain': 2.147290043653207}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 5, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83854+0.03580\ttest-rmse:3.84092+0.07268\n",
      "[100]\ttrain-rmse:3.44663+0.03334\ttest-rmse:3.70152+0.07159\n",
      "[200]\ttrain-rmse:3.19884+0.03114\ttest-rmse:3.66712+0.07007\n",
      "[300]\ttrain-rmse:3.02293+0.02834\ttest-rmse:3.65654+0.06931\n",
      "[400]\ttrain-rmse:2.88830+0.02904\ttest-rmse:3.65303+0.06913\n",
      "[500]\ttrain-rmse:2.77834+0.02595\ttest-rmse:3.65214+0.06943\n",
      "[600]\ttrain-rmse:2.68350+0.02232\ttest-rmse:3.65218+0.06989\n",
      "[700]\ttrain-rmse:2.59952+0.02013\ttest-rmse:3.65271+0.07002\n",
      "[720]\ttrain-rmse:2.58229+0.01925\ttest-rmse:3.65274+0.07018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:47:42,246] Trial 12 finished with value: 3.6518891249631267 and parameters: {'max_depth': 10, 'min_child_weight': 0.34708113122487916, 'subsample': 0.5381706930364105, 'colsample_bytree': 0.6436863064836021, 'reg_lambda': 9.733954983216409, 'reg_alpha': 4.1758169169453785, 'min_split_gain': 1.8648764929390267}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 6, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83889+0.03592\ttest-rmse:3.84046+0.07266\n",
      "[100]\ttrain-rmse:3.52734+0.03318\ttest-rmse:3.69302+0.07133\n",
      "[200]\ttrain-rmse:3.36692+0.03138\ttest-rmse:3.66170+0.07018\n",
      "[300]\ttrain-rmse:3.26221+0.03063\ttest-rmse:3.65318+0.07010\n",
      "[400]\ttrain-rmse:3.18882+0.02875\ttest-rmse:3.65042+0.07029\n",
      "[500]\ttrain-rmse:3.13383+0.02960\ttest-rmse:3.64966+0.07015\n",
      "[600]\ttrain-rmse:3.08612+0.03115\ttest-rmse:3.64963+0.07054\n",
      "[700]\ttrain-rmse:3.04164+0.03311\ttest-rmse:3.65009+0.07092\n",
      "[757]\ttrain-rmse:3.01797+0.03364\ttest-rmse:3.65020+0.07100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:48:24,233] Trial 13 finished with value: 3.649479048286922 and parameters: {'max_depth': 8, 'min_child_weight': 12.868711727692622, 'subsample': 0.90187373835903, 'colsample_bytree': 0.5532224264946803, 'reg_lambda': 0.3171391159619139, 'reg_alpha': 9.90743870038094, 'min_split_gain': 2.1062360067020784}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 7, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84274+0.03598\ttest-rmse:3.84325+0.07275\n",
      "[100]\ttrain-rmse:3.70541+0.03568\ttest-rmse:3.79187+0.07268\n",
      "[200]\ttrain-rmse:3.58943+0.03435\ttest-rmse:3.76166+0.07228\n",
      "[300]\ttrain-rmse:3.48985+0.03376\ttest-rmse:3.74343+0.07281\n",
      "[400]\ttrain-rmse:3.40567+0.03239\ttest-rmse:3.73059+0.07238\n",
      "[500]\ttrain-rmse:3.32340+0.03129\ttest-rmse:3.72035+0.07208\n",
      "[600]\ttrain-rmse:3.24857+0.03101\ttest-rmse:3.71368+0.07192\n",
      "[700]\ttrain-rmse:3.17547+0.03049\ttest-rmse:3.70807+0.07136\n",
      "[800]\ttrain-rmse:3.11210+0.02974\ttest-rmse:3.70380+0.07129\n",
      "[900]\ttrain-rmse:3.04749+0.02890\ttest-rmse:3.70027+0.07130\n",
      "[1000]\ttrain-rmse:2.99195+0.02770\ttest-rmse:3.69809+0.07114\n",
      "[1100]\ttrain-rmse:2.93387+0.02645\ttest-rmse:3.69542+0.07115\n",
      "[1200]\ttrain-rmse:2.88018+0.02543\ttest-rmse:3.69368+0.07111\n",
      "[1300]\ttrain-rmse:2.83289+0.02511\ttest-rmse:3.69218+0.07098\n",
      "[1400]\ttrain-rmse:2.78143+0.02526\ttest-rmse:3.69095+0.07089\n",
      "[1500]\ttrain-rmse:2.73546+0.02533\ttest-rmse:3.68962+0.07083\n",
      "[1600]\ttrain-rmse:2.69168+0.02464\ttest-rmse:3.68873+0.07075\n",
      "[1700]\ttrain-rmse:2.64756+0.02369\ttest-rmse:3.68829+0.07098\n",
      "[1800]\ttrain-rmse:2.60329+0.02322\ttest-rmse:3.68754+0.07114\n",
      "[1900]\ttrain-rmse:2.56047+0.02287\ttest-rmse:3.68687+0.07098\n",
      "[2000]\ttrain-rmse:2.52148+0.02263\ttest-rmse:3.68673+0.07081\n",
      "[2100]\ttrain-rmse:2.48541+0.02234\ttest-rmse:3.68637+0.07064\n",
      "[2200]\ttrain-rmse:2.44952+0.02132\ttest-rmse:3.68604+0.07063\n",
      "[2300]\ttrain-rmse:2.41185+0.02067\ttest-rmse:3.68573+0.07048\n",
      "[2400]\ttrain-rmse:2.37593+0.02064\ttest-rmse:3.68569+0.07040\n",
      "[2500]\ttrain-rmse:2.34032+0.02046\ttest-rmse:3.68562+0.07023\n",
      "[2600]\ttrain-rmse:2.30717+0.02023\ttest-rmse:3.68563+0.07011\n",
      "[2658]\ttrain-rmse:2.28689+0.01971\ttest-rmse:3.68571+0.07013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:52:48,352] Trial 14 finished with value: 3.685487222926296 and parameters: {'max_depth': 12, 'min_child_weight': 8.52368369139165, 'subsample': 0.5544590414274537, 'colsample_bytree': 0.026831076669707965, 'reg_lambda': 7.662547111782915, 'reg_alpha': 7.480965474275368, 'min_split_gain': 1.4379230759910384}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 8, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83945+0.03586\ttest-rmse:3.84058+0.07277\n",
      "[100]\ttrain-rmse:3.56030+0.03390\ttest-rmse:3.69590+0.07219\n",
      "[200]\ttrain-rmse:3.41567+0.03235\ttest-rmse:3.66346+0.07113\n",
      "[300]\ttrain-rmse:3.32040+0.03173\ttest-rmse:3.65382+0.07086\n",
      "[400]\ttrain-rmse:3.25532+0.03068\ttest-rmse:3.65066+0.07059\n",
      "[500]\ttrain-rmse:3.20709+0.02920\ttest-rmse:3.64927+0.07049\n",
      "[600]\ttrain-rmse:3.16847+0.02912\ttest-rmse:3.64904+0.07087\n",
      "[700]\ttrain-rmse:3.13407+0.02846\ttest-rmse:3.64897+0.07109\n",
      "[800]\ttrain-rmse:3.10040+0.02922\ttest-rmse:3.64932+0.07126\n",
      "[841]\ttrain-rmse:3.08614+0.02993\ttest-rmse:3.64946+0.07155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:53:32,853] Trial 15 finished with value: 3.6488270251411348 and parameters: {'max_depth': 8, 'min_child_weight': 18.183548237968708, 'subsample': 0.9583372353529509, 'colsample_bytree': 0.4878178876263777, 'reg_lambda': 8.057065376740436, 'reg_alpha': 5.092843066867837, 'min_split_gain': 3.22899946342905}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 9, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84040+0.03600\ttest-rmse:3.84066+0.07277\n",
      "[100]\ttrain-rmse:3.62445+0.03379\ttest-rmse:3.70198+0.07213\n",
      "[200]\ttrain-rmse:3.52229+0.03223\ttest-rmse:3.66794+0.07096\n",
      "[300]\ttrain-rmse:3.45981+0.03220\ttest-rmse:3.65685+0.07005\n",
      "[400]\ttrain-rmse:3.41557+0.03094\ttest-rmse:3.65259+0.06968\n",
      "[500]\ttrain-rmse:3.38056+0.03115\ttest-rmse:3.65051+0.06922\n",
      "[600]\ttrain-rmse:3.34953+0.03011\ttest-rmse:3.64956+0.06943\n",
      "[700]\ttrain-rmse:3.32026+0.03042\ttest-rmse:3.64960+0.06958\n",
      "[800]\ttrain-rmse:3.29512+0.02955\ttest-rmse:3.64942+0.07002\n",
      "[900]\ttrain-rmse:3.26978+0.02873\ttest-rmse:3.64951+0.07027\n",
      "[989]\ttrain-rmse:3.24745+0.02891\ttest-rmse:3.64969+0.07070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:54:13,766] Trial 16 finished with value: 3.6493131868109026 and parameters: {'max_depth': 7, 'min_child_weight': 18.690352986828195, 'subsample': 0.6721981623706799, 'colsample_bytree': 0.4309770322416786, 'reg_lambda': 7.335086734806044, 'reg_alpha': 0.10535229725971096, 'min_split_gain': 3.486132448351329}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 10, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84201+0.03598\ttest-rmse:3.84164+0.07275\n",
      "[100]\ttrain-rmse:3.73063+0.03500\ttest-rmse:3.73949+0.07322\n",
      "[200]\ttrain-rmse:3.68628+0.03407\ttest-rmse:3.70504+0.07209\n",
      "[300]\ttrain-rmse:3.66133+0.03375\ttest-rmse:3.68932+0.07190\n",
      "[400]\ttrain-rmse:3.64496+0.03365\ttest-rmse:3.68145+0.07135\n",
      "[500]\ttrain-rmse:3.63176+0.03368\ttest-rmse:3.67621+0.07115\n",
      "[600]\ttrain-rmse:3.62043+0.03333\ttest-rmse:3.67270+0.07095\n",
      "[700]\ttrain-rmse:3.61006+0.03320\ttest-rmse:3.67033+0.07126\n",
      "[800]\ttrain-rmse:3.60085+0.03315\ttest-rmse:3.66842+0.07117\n",
      "[900]\ttrain-rmse:3.59212+0.03325\ttest-rmse:3.66692+0.07098\n",
      "[1000]\ttrain-rmse:3.58420+0.03287\ttest-rmse:3.66586+0.07114\n",
      "[1100]\ttrain-rmse:3.57661+0.03293\ttest-rmse:3.66527+0.07084\n",
      "[1200]\ttrain-rmse:3.56890+0.03306\ttest-rmse:3.66469+0.07080\n",
      "[1300]\ttrain-rmse:3.56143+0.03312\ttest-rmse:3.66412+0.07077\n",
      "[1400]\ttrain-rmse:3.55412+0.03337\ttest-rmse:3.66367+0.07094\n",
      "[1500]\ttrain-rmse:3.54715+0.03333\ttest-rmse:3.66346+0.07100\n",
      "[1600]\ttrain-rmse:3.54033+0.03306\ttest-rmse:3.66310+0.07121\n",
      "[1700]\ttrain-rmse:3.53386+0.03275\ttest-rmse:3.66294+0.07132\n",
      "[1800]\ttrain-rmse:3.52711+0.03269\ttest-rmse:3.66289+0.07112\n",
      "[1900]\ttrain-rmse:3.52100+0.03255\ttest-rmse:3.66284+0.07123\n",
      "[2000]\ttrain-rmse:3.51466+0.03253\ttest-rmse:3.66264+0.07120\n",
      "[2100]\ttrain-rmse:3.50832+0.03260\ttest-rmse:3.66274+0.07115\n",
      "[2200]\ttrain-rmse:3.50213+0.03262\ttest-rmse:3.66250+0.07114\n",
      "[2300]\ttrain-rmse:3.49609+0.03258\ttest-rmse:3.66239+0.07105\n",
      "[2400]\ttrain-rmse:3.49017+0.03228\ttest-rmse:3.66229+0.07112\n",
      "[2500]\ttrain-rmse:3.48400+0.03226\ttest-rmse:3.66244+0.07127\n",
      "[2539]\ttrain-rmse:3.48160+0.03220\ttest-rmse:3.66236+0.07123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:55:23,332] Trial 17 finished with value: 3.6622246058304833 and parameters: {'max_depth': 4, 'min_child_weight': 18.751155350740305, 'subsample': 0.39237452748817436, 'colsample_bytree': 0.23110520191305728, 'reg_lambda': 5.891034553154699, 'reg_alpha': 4.718544896555623, 'min_split_gain': 5.827521036602659}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 11, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83713+0.03598\ttest-rmse:3.84092+0.07268\n",
      "[100]\ttrain-rmse:3.36263+0.03353\ttest-rmse:3.69847+0.07024\n",
      "[200]\ttrain-rmse:3.06728+0.03049\ttest-rmse:3.66502+0.06836\n",
      "[300]\ttrain-rmse:2.85930+0.02566\ttest-rmse:3.65592+0.06755\n",
      "[400]\ttrain-rmse:2.70750+0.02667\ttest-rmse:3.65333+0.06725\n",
      "[500]\ttrain-rmse:2.58892+0.02436\ttest-rmse:3.65237+0.06781\n",
      "[600]\ttrain-rmse:2.49387+0.02179\ttest-rmse:3.65296+0.06826\n",
      "[683]\ttrain-rmse:2.42623+0.02085\ttest-rmse:3.65334+0.06871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:56:53,481] Trial 18 finished with value: 3.6522307417795603 and parameters: {'max_depth': 11, 'min_child_weight': 8.499213202272005, 'subsample': 0.8189225281315118, 'colsample_bytree': 0.49606190197460603, 'reg_lambda': 8.85806608343721, 'reg_alpha': 3.3057618600819167, 'min_split_gain': 3.1946421723032308}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 12, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84040+0.03596\ttest-rmse:3.84079+0.07278\n",
      "[100]\ttrain-rmse:3.61937+0.03300\ttest-rmse:3.70258+0.07252\n",
      "[200]\ttrain-rmse:3.51078+0.03222\ttest-rmse:3.66852+0.07135\n",
      "[300]\ttrain-rmse:3.44188+0.03157\ttest-rmse:3.65774+0.07049\n",
      "[400]\ttrain-rmse:3.39305+0.03009\ttest-rmse:3.65336+0.07029\n",
      "[500]\ttrain-rmse:3.35682+0.02964\ttest-rmse:3.65129+0.07017\n",
      "[600]\ttrain-rmse:3.32751+0.02972\ttest-rmse:3.65045+0.07008\n",
      "[700]\ttrain-rmse:3.30267+0.02929\ttest-rmse:3.65000+0.07010\n",
      "[800]\ttrain-rmse:3.27876+0.03068\ttest-rmse:3.64977+0.07034\n",
      "[900]\ttrain-rmse:3.25576+0.03188\ttest-rmse:3.64985+0.07045\n",
      "[968]\ttrain-rmse:3.24062+0.03251\ttest-rmse:3.65012+0.07066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:57:37,670] Trial 19 finished with value: 3.6495884628362245 and parameters: {'max_depth': 7, 'min_child_weight': 17.762971489732262, 'subsample': 0.9997839923777945, 'colsample_bytree': 0.37463249551647315, 'reg_lambda': 8.412074885365675, 'reg_alpha': 1.065264427911913, 'min_split_gain': 5.218419992302572}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 13, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84193+0.03601\ttest-rmse:3.84209+0.07281\n",
      "[100]\ttrain-rmse:3.63733+0.03438\ttest-rmse:3.72918+0.07309\n",
      "[200]\ttrain-rmse:3.51213+0.03271\ttest-rmse:3.68912+0.07264\n",
      "[300]\ttrain-rmse:3.42408+0.03025\ttest-rmse:3.67300+0.07248\n",
      "[400]\ttrain-rmse:3.35748+0.02937\ttest-rmse:3.66614+0.07189\n",
      "[500]\ttrain-rmse:3.30037+0.02976\ttest-rmse:3.66162+0.07132\n",
      "[600]\ttrain-rmse:3.25113+0.02834\ttest-rmse:3.65899+0.07098\n",
      "[700]\ttrain-rmse:3.20462+0.02838\ttest-rmse:3.65752+0.07080\n",
      "[800]\ttrain-rmse:3.16050+0.02730\ttest-rmse:3.65624+0.07053\n",
      "[900]\ttrain-rmse:3.12002+0.02661\ttest-rmse:3.65566+0.07045\n",
      "[1000]\ttrain-rmse:3.08364+0.02567\ttest-rmse:3.65534+0.07044\n",
      "[1100]\ttrain-rmse:3.04737+0.02450\ttest-rmse:3.65495+0.07066\n",
      "[1200]\ttrain-rmse:3.01206+0.02438\ttest-rmse:3.65501+0.07092\n",
      "[1300]\ttrain-rmse:2.97699+0.02463\ttest-rmse:3.65504+0.07083\n",
      "[1400]\ttrain-rmse:2.94420+0.02445\ttest-rmse:3.65519+0.07069\n",
      "[1480]\ttrain-rmse:2.91824+0.02395\ttest-rmse:3.65541+0.07084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:58:51,331] Trial 20 finished with value: 3.6548318451098134 and parameters: {'max_depth': 8, 'min_child_weight': 6.885158467734288, 'subsample': 0.6622595327019652, 'colsample_bytree': 0.1093902618685676, 'reg_lambda': 6.007645706577969, 'reg_alpha': 5.577109259797602, 'min_split_gain': 0.9161462188680318}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 14, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84035+0.03604\ttest-rmse:3.84067+0.07266\n",
      "[100]\ttrain-rmse:3.62297+0.03331\ttest-rmse:3.70158+0.07278\n",
      "[200]\ttrain-rmse:3.52026+0.03211\ttest-rmse:3.66798+0.07120\n",
      "[300]\ttrain-rmse:3.45747+0.03222\ttest-rmse:3.65729+0.07057\n",
      "[400]\ttrain-rmse:3.41347+0.03174\ttest-rmse:3.65327+0.07047\n",
      "[500]\ttrain-rmse:3.37750+0.03239\ttest-rmse:3.65148+0.07026\n",
      "[600]\ttrain-rmse:3.34615+0.03117\ttest-rmse:3.65092+0.07041\n",
      "[700]\ttrain-rmse:3.31708+0.03117\ttest-rmse:3.65059+0.07062\n",
      "[800]\ttrain-rmse:3.29118+0.02964\ttest-rmse:3.65064+0.07133\n",
      "[900]\ttrain-rmse:3.26559+0.02925\ttest-rmse:3.65101+0.07182\n",
      "[938]\ttrain-rmse:3.25581+0.02928\ttest-rmse:3.65093+0.07201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 18:59:30,549] Trial 21 finished with value: 3.650474637624837 and parameters: {'max_depth': 7, 'min_child_weight': 18.44860746410804, 'subsample': 0.6865696537014969, 'colsample_bytree': 0.4420374687058355, 'reg_lambda': 6.949241755835816, 'reg_alpha': 0.08500960494730163, 'min_split_gain': 3.6976067775808428}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 15, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83935+0.03600\ttest-rmse:3.84067+0.07265\n",
      "[100]\ttrain-rmse:3.55612+0.03392\ttest-rmse:3.69643+0.07274\n",
      "[200]\ttrain-rmse:3.40792+0.03054\ttest-rmse:3.66386+0.07217\n",
      "[300]\ttrain-rmse:3.31016+0.02967\ttest-rmse:3.65394+0.07145\n",
      "[400]\ttrain-rmse:3.24386+0.02879\ttest-rmse:3.65074+0.07118\n",
      "[500]\ttrain-rmse:3.19389+0.02861\ttest-rmse:3.64989+0.07108\n",
      "[600]\ttrain-rmse:3.15156+0.03008\ttest-rmse:3.64952+0.07123\n",
      "[700]\ttrain-rmse:3.11124+0.02970\ttest-rmse:3.64953+0.07185\n",
      "[776]\ttrain-rmse:3.08218+0.02947\ttest-rmse:3.64960+0.07177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 19:00:12,541] Trial 22 finished with value: 3.6493691711912883 and parameters: {'max_depth': 8, 'min_child_weight': 13.977953518717499, 'subsample': 0.8317721157737584, 'colsample_bytree': 0.5519743938855338, 'reg_lambda': 7.91062495733099, 'reg_alpha': 1.976424739854973, 'min_split_gain': 2.8181194746079994}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 16, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83946+0.03584\ttest-rmse:3.84072+0.07266\n",
      "[100]\ttrain-rmse:3.52815+0.03298\ttest-rmse:3.70005+0.07185\n",
      "[200]\ttrain-rmse:3.35525+0.03093\ttest-rmse:3.66497+0.07187\n",
      "[300]\ttrain-rmse:3.24066+0.03003\ttest-rmse:3.65475+0.07037\n",
      "[400]\ttrain-rmse:3.16038+0.02721\ttest-rmse:3.65157+0.07029\n",
      "[500]\ttrain-rmse:3.09882+0.02681\ttest-rmse:3.65063+0.07017\n",
      "[600]\ttrain-rmse:3.04348+0.02607\ttest-rmse:3.65056+0.07066\n",
      "[700]\ttrain-rmse:2.99436+0.02538\ttest-rmse:3.65078+0.07113\n",
      "[800]\ttrain-rmse:2.94741+0.02637\ttest-rmse:3.65176+0.07143\n",
      "[856]\ttrain-rmse:2.92048+0.02617\ttest-rmse:3.65217+0.07137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 19:01:12,525] Trial 23 finished with value: 3.6504393184773574 and parameters: {'max_depth': 10, 'min_child_weight': 22.573589333541396, 'subsample': 0.6212239768597037, 'colsample_bytree': 0.36811714336790835, 'reg_lambda': 8.91150445321173, 'reg_alpha': 0.3162778303808622, 'min_split_gain': 1.2081429697913646}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 17, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84181+0.03603\ttest-rmse:3.84141+0.07272\n",
      "[100]\ttrain-rmse:3.71845+0.03463\ttest-rmse:3.72838+0.07312\n",
      "[200]\ttrain-rmse:3.67291+0.03407\ttest-rmse:3.69420+0.07184\n",
      "[300]\ttrain-rmse:3.64745+0.03412\ttest-rmse:3.68031+0.07129\n",
      "[400]\ttrain-rmse:3.62961+0.03419\ttest-rmse:3.67314+0.07080\n",
      "[500]\ttrain-rmse:3.61515+0.03394\ttest-rmse:3.66904+0.07084\n",
      "[600]\ttrain-rmse:3.60241+0.03380\ttest-rmse:3.66647+0.07097\n",
      "[700]\ttrain-rmse:3.59087+0.03418\ttest-rmse:3.66456+0.07098\n",
      "[800]\ttrain-rmse:3.58045+0.03416\ttest-rmse:3.66329+0.07111\n",
      "[900]\ttrain-rmse:3.57064+0.03437\ttest-rmse:3.66211+0.07131\n",
      "[1000]\ttrain-rmse:3.56152+0.03445\ttest-rmse:3.66117+0.07165\n",
      "[1100]\ttrain-rmse:3.55280+0.03450\ttest-rmse:3.66065+0.07178\n",
      "[1200]\ttrain-rmse:3.54421+0.03443\ttest-rmse:3.66034+0.07189\n",
      "[1300]\ttrain-rmse:3.53588+0.03472\ttest-rmse:3.65988+0.07195\n",
      "[1400]\ttrain-rmse:3.52807+0.03487\ttest-rmse:3.65959+0.07216\n",
      "[1500]\ttrain-rmse:3.52037+0.03479\ttest-rmse:3.65953+0.07226\n",
      "[1600]\ttrain-rmse:3.51254+0.03445\ttest-rmse:3.65942+0.07255\n",
      "[1700]\ttrain-rmse:3.50482+0.03436\ttest-rmse:3.65942+0.07272\n",
      "[1800]\ttrain-rmse:3.49715+0.03431\ttest-rmse:3.65931+0.07280\n",
      "[1900]\ttrain-rmse:3.48984+0.03439\ttest-rmse:3.65932+0.07299\n",
      "[2000]\ttrain-rmse:3.48223+0.03380\ttest-rmse:3.65941+0.07298\n",
      "[2054]\ttrain-rmse:3.47815+0.03359\ttest-rmse:3.65932+0.07316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 19:02:11,139] Trial 24 finished with value: 3.6592317543698427 and parameters: {'max_depth': 4, 'min_child_weight': 15.832945828148333, 'subsample': 0.7702971152769883, 'colsample_bytree': 0.4814059831000709, 'reg_lambda': 6.229378476907275, 'reg_alpha': 4.0504996785974505, 'min_split_gain': 4.7851191407263425}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 18, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84010+0.03594\ttest-rmse:3.84077+0.07268\n",
      "[100]\ttrain-rmse:3.60747+0.03381\ttest-rmse:3.69644+0.07188\n",
      "[200]\ttrain-rmse:3.49953+0.03100\ttest-rmse:3.66424+0.07200\n",
      "[300]\ttrain-rmse:3.43303+0.03130\ttest-rmse:3.65451+0.07153\n",
      "[400]\ttrain-rmse:3.38591+0.03107\ttest-rmse:3.65124+0.07156\n",
      "[500]\ttrain-rmse:3.34945+0.03183\ttest-rmse:3.65001+0.07149\n",
      "[600]\ttrain-rmse:3.31916+0.03269\ttest-rmse:3.64976+0.07170\n",
      "[700]\ttrain-rmse:3.29190+0.03213\ttest-rmse:3.64960+0.07191\n",
      "[800]\ttrain-rmse:3.26687+0.03203\ttest-rmse:3.64994+0.07244\n",
      "[900]\ttrain-rmse:3.24282+0.03351\ttest-rmse:3.65007+0.07282\n",
      "[903]\ttrain-rmse:3.24203+0.03354\ttest-rmse:3.65006+0.07280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 19:02:50,468] Trial 25 finished with value: 3.6495836052815114 and parameters: {'max_depth': 7, 'min_child_weight': 21.60792142169935, 'subsample': 0.9166087041263974, 'colsample_bytree': 0.6056409510522126, 'reg_lambda': 5.111341156228755, 'reg_alpha': 2.145146601345055, 'min_split_gain': 3.0356228073773863}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 19, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.83928+0.03594\ttest-rmse:3.84101+0.07281\n",
      "[100]\ttrain-rmse:3.50985+0.03210\ttest-rmse:3.70879+0.07150\n",
      "[200]\ttrain-rmse:3.30704+0.03032\ttest-rmse:3.67248+0.07079\n",
      "[300]\ttrain-rmse:3.16193+0.02784\ttest-rmse:3.66120+0.06890\n",
      "[400]\ttrain-rmse:3.05383+0.02563\ttest-rmse:3.65681+0.06840\n",
      "[500]\ttrain-rmse:2.96163+0.02126\ttest-rmse:3.65531+0.06773\n",
      "[600]\ttrain-rmse:2.88160+0.02010\ttest-rmse:3.65517+0.06793\n",
      "[700]\ttrain-rmse:2.80893+0.01936\ttest-rmse:3.65559+0.06782\n",
      "[742]\ttrain-rmse:2.77882+0.01853\ttest-rmse:3.65586+0.06782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 19:03:51,716] Trial 26 finished with value: 3.6548051133904953 and parameters: {'max_depth': 10, 'min_child_weight': 5.9928013914225255, 'subsample': 0.4394044788665, 'colsample_bytree': 0.30432009367198776, 'reg_lambda': 7.0525890342561075, 'reg_alpha': 5.973829445571876, 'min_split_gain': 3.6650206178244136}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStop counter currently is: 20, The current Best score is: 3.6477015404969944 | Overall best: 3.6477015404969944\n",
      "[0]\ttrain-rmse:3.84222+0.03605\ttest-rmse:3.84191+0.07274\n",
      "[100]\ttrain-rmse:3.71454+0.03505\ttest-rmse:3.73279+0.07330\n",
      "[200]\ttrain-rmse:3.65796+0.03455\ttest-rmse:3.69534+0.07241\n",
      "[300]\ttrain-rmse:3.62455+0.03427\ttest-rmse:3.67923+0.07190\n",
      "[400]\ttrain-rmse:3.60012+0.03371\ttest-rmse:3.67074+0.07092\n",
      "[500]\ttrain-rmse:3.57998+0.03370\ttest-rmse:3.66572+0.07071\n",
      "[600]\ttrain-rmse:3.56202+0.03363\ttest-rmse:3.66247+0.07045\n",
      "[700]\ttrain-rmse:3.54556+0.03329\ttest-rmse:3.66046+0.07022\n",
      "[800]\ttrain-rmse:3.53065+0.03341\ttest-rmse:3.65874+0.07015\n",
      "[900]\ttrain-rmse:3.51637+0.03394\ttest-rmse:3.65781+0.07016\n",
      "[1000]\ttrain-rmse:3.50370+0.03370\ttest-rmse:3.65721+0.07033\n",
      "[1100]\ttrain-rmse:3.49154+0.03370\ttest-rmse:3.65664+0.07051\n",
      "[1200]\ttrain-rmse:3.47910+0.03355\ttest-rmse:3.65623+0.07069\n",
      "[1300]\ttrain-rmse:3.46692+0.03309\ttest-rmse:3.65572+0.07077\n",
      "[1400]\ttrain-rmse:3.45556+0.03318\ttest-rmse:3.65538+0.07090\n",
      "[1500]\ttrain-rmse:3.44432+0.03318\ttest-rmse:3.65530+0.07099\n",
      "[1600]\ttrain-rmse:3.43350+0.03321\ttest-rmse:3.65517+0.07114\n",
      "[1700]\ttrain-rmse:3.42239+0.03289\ttest-rmse:3.65500+0.07122\n",
      "[1800]\ttrain-rmse:3.41127+0.03250\ttest-rmse:3.65483+0.07137\n",
      "[1900]\ttrain-rmse:3.40058+0.03194\ttest-rmse:3.65475+0.07140\n",
      "[2000]\ttrain-rmse:3.39012+0.03201\ttest-rmse:3.65464+0.07153\n",
      "[2100]\ttrain-rmse:3.37942+0.03189\ttest-rmse:3.65473+0.07130\n",
      "[2200]\ttrain-rmse:3.36854+0.03155\ttest-rmse:3.65461+0.07141\n",
      "[2300]\ttrain-rmse:3.35812+0.03151\ttest-rmse:3.65476+0.07147\n",
      "[2369]\ttrain-rmse:3.35073+0.03140\ttest-rmse:3.65491+0.07155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 19:05:03,779] Trial 27 finished with value: 3.654551050879382 and parameters: {'max_depth': 5, 'min_child_weight': 10.744492917078997, 'subsample': 0.8479718773417751, 'colsample_bytree': 0.17152995442494956, 'reg_lambda': 8.25879350659341, 'reg_alpha': 8.379227088555918, 'min_split_gain': 7.0145295224624205}. Best is trial 6 with value: 3.6477015404969944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Early stopping triggered: There is no improvement for 20 trials.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Run Optuna Study ===\n",
    "results = optuna.create_study(direction='minimize')\n",
    "\n",
    "try:\n",
    "    results.optimize(objectiveXgBoost, n_trials=100, callbacks=[early_stopping_opt])\n",
    "except EarlyStoppingExceeded:\n",
    "    print(f\" Early stopping triggered: There is no improvement for {OPTUNA_EARLY_STOPPING} trials.\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "    max_depth: 8\n",
      "    min_child_weight: 12.63295231835534\n",
      "    subsample: 0.8856361863906584\n",
      "    colsample_bytree: 0.5192226685768537\n",
      "    reg_lambda: 9.30032304843493\n",
      "    reg_alpha: 9.969215924634227\n",
      "    min_split_gain: 0.5489609900882941\n"
     ]
    }
   ],
   "source": [
    "## printing the best trial\n",
    "print('Best trial:')\n",
    "besttrial = results.best_trial\n",
    "gc.collect()\n",
    "\n",
    "for key, value in besttrial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def prediction_with_best_parameters_XgBoost(best_params, n_splits, X_train, y_train, \n",
    "                                             test_df, num_round=10000):\n",
    "    ''' \n",
    "    Train and predict target values using XGBoost with best parameters via K-Fold CV. \n",
    "    Also returns out-of-fold validation RMSE and feature importances.\n",
    "    '''\n",
    "\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_predictions = np.zeros(len(X_train))\n",
    "    test_predictions = np.zeros(len(test_df))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    print(f\"Starting {n_splits}-Fold CV with XGBoost...\\n\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "        print(f\"Fold {fold + 1} | Train size: {len(train_idx)} | Validation size: {len(val_idx)}\")\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest = xgb.DMatrix(test_df)\n",
    "\n",
    "        model = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_round,\n",
    "            evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "            early_stopping_rounds=150,\n",
    "            verbose_eval=200\n",
    "        )\n",
    "\n",
    "        # Validation and test predictions\n",
    "        val_preds = model.predict(dval, iteration_range=(0, model.best_iteration + 1))\n",
    "        oof_predictions[val_idx] = val_preds\n",
    "        test_predictions += model.predict(dtest, iteration_range=(0, model.best_iteration + 1)) / n_splits\n",
    "\n",
    "        # Feature importances (gain-based)\n",
    "        importance_dict = model.get_score(importance_type='gain')\n",
    "        fold_importance_df = pd.DataFrame({\n",
    "            \"Feature\": list(importance_dict.keys()),\n",
    "            \"importance\": list(importance_dict.values()),\n",
    "            \"fold\": fold + 1\n",
    "        })\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        fold_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        print(f\"Fold {fold + 1} RMSE: {fold_rmse:.5f}\\n\")\n",
    "\n",
    "    # Overall RMSE\n",
    "    validation_rmse = np.sqrt(mean_squared_error(y_train, oof_predictions))\n",
    "    print(\"Cross-Validated RMSE Summary\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"Overall Validation RMSE: {validation_rmse:.5f}\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    return model, oof_predictions, test_predictions, feature_importance_df, validation_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 9-Fold CV with XGBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "[0]\ttrain-rmse:3.82619\tvalid-rmse:3.95324\n",
      "[200]\ttrain-rmse:3.52880\tvalid-rmse:3.77788\n",
      "[400]\ttrain-rmse:3.44473\tvalid-rmse:3.76025\n",
      "[600]\ttrain-rmse:3.39521\tvalid-rmse:3.75562\n",
      "[800]\ttrain-rmse:3.35370\tvalid-rmse:3.75462\n",
      "[926]\ttrain-rmse:3.32791\tvalid-rmse:3.75440\n",
      "Fold 1 RMSE: 3.75432\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.85895\tvalid-rmse:3.68856\n",
      "[200]\ttrain-rmse:3.55950\tvalid-rmse:3.53101\n",
      "[400]\ttrain-rmse:3.47374\tvalid-rmse:3.51662\n",
      "[600]\ttrain-rmse:3.42383\tvalid-rmse:3.51487\n",
      "[770]\ttrain-rmse:3.38638\tvalid-rmse:3.51482\n",
      "Fold 2 RMSE: 3.51432\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83746\tvalid-rmse:3.86321\n",
      "[200]\ttrain-rmse:3.53865\tvalid-rmse:3.70489\n",
      "[400]\ttrain-rmse:3.45300\tvalid-rmse:3.69641\n",
      "[600]\ttrain-rmse:3.40103\tvalid-rmse:3.69475\n",
      "[800]\ttrain-rmse:3.35769\tvalid-rmse:3.69394\n",
      "[940]\ttrain-rmse:3.32880\tvalid-rmse:3.69488\n",
      "Fold 3 RMSE: 3.69382\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83805\tvalid-rmse:3.85896\n",
      "[200]\ttrain-rmse:3.53949\tvalid-rmse:3.69646\n",
      "[400]\ttrain-rmse:3.45183\tvalid-rmse:3.68496\n",
      "[600]\ttrain-rmse:3.39982\tvalid-rmse:3.68295\n",
      "[763]\ttrain-rmse:3.36335\tvalid-rmse:3.68382\n",
      "Fold 4 RMSE: 3.68243\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83441\tvalid-rmse:3.88762\n",
      "[200]\ttrain-rmse:3.53920\tvalid-rmse:3.70109\n",
      "[400]\ttrain-rmse:3.45393\tvalid-rmse:3.68709\n",
      "[600]\ttrain-rmse:3.40461\tvalid-rmse:3.68610\n",
      "[746]\ttrain-rmse:3.37364\tvalid-rmse:3.68675\n",
      "Fold 5 RMSE: 3.68604\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83053\tvalid-rmse:3.92060\n",
      "[200]\ttrain-rmse:3.54286\tvalid-rmse:3.69790\n",
      "[400]\ttrain-rmse:3.45929\tvalid-rmse:3.67524\n",
      "[600]\ttrain-rmse:3.41170\tvalid-rmse:3.66767\n",
      "[800]\ttrain-rmse:3.37161\tvalid-rmse:3.66489\n",
      "[1000]\ttrain-rmse:3.33223\tvalid-rmse:3.66224\n",
      "[1200]\ttrain-rmse:3.29641\tvalid-rmse:3.66029\n",
      "[1400]\ttrain-rmse:3.26024\tvalid-rmse:3.65857\n",
      "[1600]\ttrain-rmse:3.22416\tvalid-rmse:3.65796\n",
      "[1800]\ttrain-rmse:3.18824\tvalid-rmse:3.65762\n",
      "[1895]\ttrain-rmse:3.17223\tvalid-rmse:3.65834\n",
      "Fold 6 RMSE: 3.65728\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.82491\tvalid-rmse:3.96261\n",
      "[200]\ttrain-rmse:3.52976\tvalid-rmse:3.77764\n",
      "[400]\ttrain-rmse:3.44458\tvalid-rmse:3.75970\n",
      "[600]\ttrain-rmse:3.39749\tvalid-rmse:3.75391\n",
      "[800]\ttrain-rmse:3.35814\tvalid-rmse:3.75209\n",
      "[1000]\ttrain-rmse:3.32066\tvalid-rmse:3.75166\n",
      "[1200]\ttrain-rmse:3.28383\tvalid-rmse:3.75100\n",
      "[1400]\ttrain-rmse:3.24781\tvalid-rmse:3.75122\n",
      "[1600]\ttrain-rmse:3.21278\tvalid-rmse:3.75160\n",
      "[1630]\ttrain-rmse:3.20809\tvalid-rmse:3.75181\n",
      "Fold 7 RMSE: 3.75064\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.84450\tvalid-rmse:3.80911\n",
      "[200]\ttrain-rmse:3.55058\tvalid-rmse:3.62210\n",
      "[400]\ttrain-rmse:3.46037\tvalid-rmse:3.60698\n",
      "[600]\ttrain-rmse:3.40697\tvalid-rmse:3.60399\n",
      "[800]\ttrain-rmse:3.36521\tvalid-rmse:3.60320\n",
      "[913]\ttrain-rmse:3.34380\tvalid-rmse:3.60285\n",
      "Fold 8 RMSE: 3.60275\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.86818\tvalid-rmse:3.61155\n",
      "[200]\ttrain-rmse:3.56686\tvalid-rmse:3.45174\n",
      "[400]\ttrain-rmse:3.47986\tvalid-rmse:3.44560\n",
      "[600]\ttrain-rmse:3.42848\tvalid-rmse:3.44509\n",
      "[730]\ttrain-rmse:3.40056\tvalid-rmse:3.44573\n",
      "Fold 9 RMSE: 3.44484\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64427\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param = {\n",
    "    'objective': 'reg:squarederror',               # XGBoost regression objective\n",
    "    'eval_metric': 'rmse',                         # Evaluation metric\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 37.21919431321118,\n",
    "    'subsample':  0.8199037878263149,\n",
    "    'colsample_bytree': 0.5893702702557324,\n",
    "    'reg_lambda': 2.6736872463331904,              # L2 regularization\n",
    "    'reg_alpha': 6.053754999193514,               # L1 regularization\n",
    "    'verbosity': 0,                                # Quiet logging\n",
    "    'tree_method': 'auto',                         # Set to 'gpu_hist' if using GPU\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Get columns present in both train and test\n",
    "df_train_columns = [col for col in df_train_columns if col in X_train.columns and col in test.columns]\n",
    "\n",
    "# Now safe to proceed\n",
    "xgboost_reg, pred_y_train, pred_y_test, feature_importance_df_xgboost, rmse_xgb = prediction_with_best_parameters_XgBoost(\n",
    "    best_params=param,\n",
    "    n_splits=9,\n",
    "    X_train=X_train[df_train_columns],\n",
    "    y_train=y_train,\n",
    "    test_df=test[df_train_columns],\n",
    "    num_round=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-3.589379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.319195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.932363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.107968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.686628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123618</th>\n",
       "      <td>C_ID_7a239d2eda</td>\n",
       "      <td>0.810003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123619</th>\n",
       "      <td>C_ID_75ace375ae</td>\n",
       "      <td>-0.522023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123620</th>\n",
       "      <td>C_ID_21d56d950c</td>\n",
       "      <td>0.573167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123621</th>\n",
       "      <td>C_ID_6c46fc5a9d</td>\n",
       "      <td>-3.674056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123622</th>\n",
       "      <td>C_ID_87e7979a5f</td>\n",
       "      <td>0.068958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123623 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id    target\n",
       "0       C_ID_0ab67a22ab -3.589379\n",
       "1       C_ID_130fd0cbdd -0.319195\n",
       "2       C_ID_b709037bc5 -0.932363\n",
       "3       C_ID_d27d835a9f -0.107968\n",
       "4       C_ID_2b5e3df5c2 -1.686628\n",
       "...                 ...       ...\n",
       "123618  C_ID_7a239d2eda  0.810003\n",
       "123619  C_ID_75ace375ae -0.522023\n",
       "123620  C_ID_21d56d950c  0.573167\n",
       "123621  C_ID_6c46fc5a9d -3.674056\n",
       "123622  C_ID_87e7979a5f  0.068958\n",
       "\n",
       "[123623 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb = test[[\"card_id\"]].copy()\n",
    "best_xgb[\"target\"] = pred_y_test\n",
    "best_xgb.to_csv(\"xgb_latest.csv\", index=False)\n",
    "best_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import Pool, cv\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "def objectiveCb(trial):\n",
    "    # Define CatBoost hyperparameters\n",
    "    params = {\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'RMSE',\n",
    "        'learning_rate': 0.01,\n",
    "        'iterations': 10000,  # acts like num_boost_round\n",
    "        'random_seed': 326,\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 200,\n",
    "\n",
    "        # Hyperparameters to tune\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-2, 10),\n",
    "        'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_uniform('random_strength', 0.0, 1.0),\n",
    "        'rsm': trial.suggest_uniform('rsm', 0.001, 1.0),  # similar to colsample_bytree\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255)\n",
    "    }\n",
    "\n",
    "    # Create CatBoost Pool object\n",
    "    train_pool = Pool(X_train, label=y_train)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_result = cv(\n",
    "        params=params,\n",
    "        pool=train_pool,\n",
    "        fold_count=3,\n",
    "        partition_random_seed=47,\n",
    "        early_stopping_rounds=params['early_stopping_rounds'],\n",
    "        verbose=False,\n",
    "        plot=False\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Return the last test RMSE\n",
    "    if 'test-RMSE-mean' in cv_result.columns:\n",
    "        return cv_result['test-RMSE-mean'].iloc[-1]\n",
    "\n",
    "    raise KeyError(\"Expected metric 'test-RMSE-mean' not found in cv_result.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:06:02,179] A new study created in memory with name: no-name-9ba4dfaa-10e7-46b9-87e7-69135cf6b672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.605761338\n",
      "bestIteration = 2550\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.664003862\n",
      "bestIteration = 2446\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:08:34,737] Trial 0 finished with value: 3.662034801070693 and parameters: {'depth': 5, 'l2_leaf_reg': 0.09554061341326782, 'bagging_temperature': 0.6337723219067859, 'random_strength': 0.6374073754244817, 'rsm': 0.230887502873491, 'border_count': 132}. Best is trial 0 with value: 3.662034801070693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.715595035\n",
      "bestIteration = 3875\n",
      "\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.662034801070693 | Overall best: 3.662034801070693\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.600915302\n",
      "bestIteration = 1430\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.652668002\n",
      "bestIteration = 2247\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:15:09,895] Trial 1 finished with value: 3.656725161380266 and parameters: {'depth': 9, 'l2_leaf_reg': 0.7642962079537129, 'bagging_temperature': 0.16991610720919903, 'random_strength': 0.39079224629248754, 'rsm': 0.7603072767418755, 'border_count': 171}. Best is trial 1 with value: 3.656725161380266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.715899739\n",
      "bestIteration = 1410\n",
      "\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.656725161380266 | Overall best: 3.656725161380266\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.617508887\n",
      "bestIteration = 4277\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.673921798\n",
      "bestIteration = 5414\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:17:28,239] Trial 2 finished with value: 3.6728260042337193 and parameters: {'depth': 3, 'l2_leaf_reg': 1.7213596430156903, 'bagging_temperature': 0.1674805502660478, 'random_strength': 0.2018003444755676, 'rsm': 0.44572108470514765, 'border_count': 243}. Best is trial 1 with value: 3.656725161380266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.726613004\n",
      "bestIteration = 6902\n",
      "\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.656725161380266 | Overall best: 3.656725161380266\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.599126723\n",
      "bestIteration = 1324\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.657506289\n",
      "bestIteration = 1641\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:21:45,885] Trial 3 finished with value: 3.657033041693508 and parameters: {'depth': 8, 'l2_leaf_reg': 0.13897227986864782, 'bagging_temperature': 0.5284678676799665, 'random_strength': 0.7862325138049985, 'rsm': 0.7132374480190331, 'border_count': 90}. Best is trial 1 with value: 3.656725161380266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.71394153\n",
      "bestIteration = 1828\n",
      "\n",
      "EarlyStop counter currently is: 2, The current Best score is: 3.656725161380266 | Overall best: 3.656725161380266\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.621345994\n",
      "bestIteration = 3086\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.679046184\n",
      "bestIteration = 3150\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:23:16,013] Trial 4 finished with value: 3.6770464513582914 and parameters: {'depth': 3, 'l2_leaf_reg': 0.09592915681527683, 'bagging_temperature': 0.04113839812017639, 'random_strength': 0.20427502129355068, 'rsm': 0.932205303119413, 'border_count': 201}. Best is trial 1 with value: 3.656725161380266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.729909625\n",
      "bestIteration = 4653\n",
      "\n",
      "EarlyStop counter currently is: 3, The current Best score is: 3.656725161380266 | Overall best: 3.656725161380266\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.600390618\n",
      "bestIteration = 1540\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.650345745\n",
      "bestIteration = 2848\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:25:11,656] Trial 5 finished with value: 3.6560333009600186 and parameters: {'depth': 10, 'l2_leaf_reg': 0.015820428220703855, 'bagging_temperature': 0.7358892219232541, 'random_strength': 0.681936046594734, 'rsm': 0.08099465698891221, 'border_count': 170}. Best is trial 5 with value: 3.6560333009600186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.715315634\n",
      "bestIteration = 1772\n",
      "\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.6560333009600186 | Overall best: 3.6560333009600186\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.600970745\n",
      "bestIteration = 879\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.653066321\n",
      "bestIteration = 1797\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:31:24,680] Trial 6 finished with value: 3.6575648241344676 and parameters: {'depth': 10, 'l2_leaf_reg': 0.09065270853383321, 'bagging_temperature': 0.43188287850480134, 'random_strength': 0.5639891186651733, 'rsm': 0.9237957391011689, 'border_count': 185}. Best is trial 5 with value: 3.6560333009600186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.717609075\n",
      "bestIteration = 1129\n",
      "\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.6560333009600186 | Overall best: 3.6560333009600186\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.618430801\n",
      "bestIteration = 4358\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.67650322\n",
      "bestIteration = 3611\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:33:01,245] Trial 7 finished with value: 3.6746091014709115 and parameters: {'depth': 3, 'l2_leaf_reg': 0.06355856378911232, 'bagging_temperature': 0.12598725405370015, 'random_strength': 0.4496204837825126, 'rsm': 0.4447584333718995, 'border_count': 222}. Best is trial 5 with value: 3.6560333009600186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.728667098\n",
      "bestIteration = 3868\n",
      "\n",
      "EarlyStop counter currently is: 2, The current Best score is: 3.6560333009600186 | Overall best: 3.6560333009600186\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.60192706\n",
      "bestIteration = 1608\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.654233291\n",
      "bestIteration = 2750\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:37:24,338] Trial 8 finished with value: 3.6565774643868263 and parameters: {'depth': 7, 'l2_leaf_reg': 1.0206841881284687, 'bagging_temperature': 0.6771317658161838, 'random_strength': 0.624303883482712, 'rsm': 0.8588355575153394, 'border_count': 65}. Best is trial 5 with value: 3.6560333009600186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.713104583\n",
      "bestIteration = 2212\n",
      "\n",
      "EarlyStop counter currently is: 3, The current Best score is: 3.6560333009600186 | Overall best: 3.6560333009600186\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.605982866\n",
      "bestIteration = 2482\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.661965879\n",
      "bestIteration = 2636\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:39:52,016] Trial 9 finished with value: 3.6624067747131512 and parameters: {'depth': 5, 'l2_leaf_reg': 0.031599542683012946, 'bagging_temperature': 0.8927015274322352, 'random_strength': 0.7892505444092618, 'rsm': 0.1996767572865912, 'border_count': 154}. Best is trial 5 with value: 3.6560333009600186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.718405065\n",
      "bestIteration = 3518\n",
      "\n",
      "EarlyStop counter currently is: 4, The current Best score is: 3.6560333009600186 | Overall best: 3.6560333009600186\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.615912082\n",
      "bestIteration = 9866\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.67292294\n",
      "bestIteration = 9963\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:40:58,336] Trial 10 finished with value: 3.671748186872842 and parameters: {'depth': 10, 'l2_leaf_reg': 0.010682948948055758, 'bagging_temperature': 0.9810850746164714, 'random_strength': 0.9507121511176301, 'rsm': 0.0056406890996473225, 'border_count': 117}. Best is trial 5 with value: 3.6560333009600186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.726118366\n",
      "bestIteration = 9976\n",
      "\n",
      "EarlyStop counter currently is: 5, The current Best score is: 3.6560333009600186 | Overall best: 3.6560333009600186\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.59713331\n",
      "bestIteration = 2766\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.654146692\n",
      "bestIteration = 2856\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:45:23,150] Trial 11 finished with value: 3.6548177811046823 and parameters: {'depth': 7, 'l2_leaf_reg': 8.347714885449914, 'bagging_temperature': 0.7425698301642416, 'random_strength': 0.7106356179831418, 'rsm': 0.6670987922240437, 'border_count': 39}. Best is trial 11 with value: 3.6548177811046823.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.712823289\n",
      "bestIteration = 2085\n",
      "\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.6548177811046823 | Overall best: 3.6548177811046823\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.600609994\n",
      "bestIteration = 2405\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.654910503\n",
      "bestIteration = 5648\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:48:10,792] Trial 12 finished with value: 3.65693630577373 and parameters: {'depth': 6, 'l2_leaf_reg': 8.797753311475722, 'bagging_temperature': 0.8035173556162037, 'random_strength': 0.8146962260963436, 'rsm': 0.6082807381439608, 'border_count': 39}. Best is trial 11 with value: 3.6548177811046823.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.714985761\n",
      "bestIteration = 2802\n",
      "\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.6548177811046823 | Overall best: 3.6548177811046823\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.599086884\n",
      "bestIteration = 2304\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.651297643\n",
      "bestIteration = 4565\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 14:53:33,423] Trial 13 finished with value: 3.6545692070701805 and parameters: {'depth': 8, 'l2_leaf_reg': 7.506873650488615, 'bagging_temperature': 0.7514491005346495, 'random_strength': 0.944919442387568, 'rsm': 0.24356914632307475, 'border_count': 109}. Best is trial 13 with value: 3.6545692070701805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.712828846\n",
      "bestIteration = 3518\n",
      "\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.6545692070701805 | Overall best: 3.6545692070701805\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.598095251\n",
      "bestIteration = 2641\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.651940501\n",
      "bestIteration = 5217\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:00:38,564] Trial 14 finished with value: 3.654295361487882 and parameters: {'depth': 8, 'l2_leaf_reg': 9.741379820875464, 'bagging_temperature': 0.4522525030990654, 'random_strength': 0.9526650586346972, 'rsm': 0.3348815965025285, 'border_count': 97}. Best is trial 14 with value: 3.654295361487882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.712364638\n",
      "bestIteration = 3812\n",
      "\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.654295361487882 | Overall best: 3.654295361487882\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.601403139\n",
      "bestIteration = 1928\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.652344808\n",
      "bestIteration = 3762\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:05:09,361] Trial 15 finished with value: 3.6561209672617507 and parameters: {'depth': 8, 'l2_leaf_reg': 3.164274707752115, 'bagging_temperature': 0.36295134257913864, 'random_strength': 0.9994420149628376, 'rsm': 0.2945482050115249, 'border_count': 101}. Best is trial 14 with value: 3.654295361487882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.713979389\n",
      "bestIteration = 2193\n",
      "\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.654295361487882 | Overall best: 3.654295361487882\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.598475102\n",
      "bestIteration = 1826\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.651775287\n",
      "bestIteration = 3501\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:10:48,761] Trial 16 finished with value: 3.6538611561140066 and parameters: {'depth': 8, 'l2_leaf_reg': 3.600161766525168, 'bagging_temperature': 0.5650740373332666, 'random_strength': 0.9097027708092873, 'rsm': 0.3966425821962165, 'border_count': 73}. Best is trial 16 with value: 3.6538611561140066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.710951161\n",
      "bestIteration = 3169\n",
      "\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.6538611561140066 | Overall best: 3.6538611561140066\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.598459453\n",
      "bestIteration = 1663\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.650071457\n",
      "bestIteration = 2097\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:15:26,803] Trial 17 finished with value: 3.653372402685593 and parameters: {'depth': 9, 'l2_leaf_reg': 0.41489584979864597, 'bagging_temperature': 0.3103960946343626, 'random_strength': 0.04546385302870681, 'rsm': 0.3644388247150329, 'border_count': 63}. Best is trial 17 with value: 3.653372402685593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.71090647\n",
      "bestIteration = 1163\n",
      "\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.653372402685593 | Overall best: 3.653372402685593\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.597543334\n",
      "bestIteration = 1147\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.649664548\n",
      "bestIteration = 1914\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:20:19,636] Trial 18 finished with value: 3.653184237286519 and parameters: {'depth': 9, 'l2_leaf_reg': 0.38818149959034703, 'bagging_temperature': 0.3269909352627561, 'random_strength': 0.004495074377728704, 'rsm': 0.558683934388709, 'border_count': 69}. Best is trial 18 with value: 3.653184237286519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.711564743\n",
      "bestIteration = 1700\n",
      "\n",
      "EarlyStop counter currently is: 0, The current Best score is: 3.653184237286519 | Overall best: 3.653184237286519\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.597790358\n",
      "bestIteration = 1653\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.650504146\n",
      "bestIteration = 1833\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:25:14,079] Trial 19 finished with value: 3.6548633371221158 and parameters: {'depth': 9, 'l2_leaf_reg': 0.30061309608853876, 'bagging_temperature': 0.31259695179439695, 'random_strength': 0.0405648521471038, 'rsm': 0.560294459973752, 'border_count': 71}. Best is trial 18 with value: 3.653184237286519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.715482624\n",
      "bestIteration = 1320\n",
      "\n",
      "EarlyStop counter currently is: 1, The current Best score is: 3.653184237286519 | Overall best: 3.653184237286519\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.599044359\n",
      "bestIteration = 1103\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.652629831\n",
      "bestIteration = 1832\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:29:35,552] Trial 20 finished with value: 3.655173457024803 and parameters: {'depth': 9, 'l2_leaf_reg': 0.3009433327993182, 'bagging_temperature': 0.24982886707470747, 'random_strength': 0.027306337030404138, 'rsm': 0.5260495994657006, 'border_count': 55}. Best is trial 18 with value: 3.653184237286519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.712543927\n",
      "bestIteration = 1318\n",
      "\n",
      "EarlyStop counter currently is: 2, The current Best score is: 3.653184237286519 | Overall best: 3.653184237286519\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.59915072\n",
      "bestIteration = 1257\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.652143324\n",
      "bestIteration = 1725\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:34:33,542] Trial 21 finished with value: 3.655069107950041 and parameters: {'depth': 9, 'l2_leaf_reg': 0.5138551392355142, 'bagging_temperature': 0.5533458766718103, 'random_strength': 0.15943887777421792, 'rsm': 0.39434194605066536, 'border_count': 78}. Best is trial 18 with value: 3.653184237286519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.712745356\n",
      "bestIteration = 1934\n",
      "\n",
      "EarlyStop counter currently is: 3, The current Best score is: 3.653184237286519 | Overall best: 3.653184237286519\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 3.599775778\n",
      "bestIteration = 2271\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 3.653497427\n",
      "bestIteration = 2982\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 15:39:19,452] Trial 22 finished with value: 3.6559804716045576 and parameters: {'depth': 7, 'l2_leaf_reg': 3.20424207369242, 'bagging_temperature': 0.35805110874980034, 'random_strength': 0.31329963511121645, 'rsm': 0.37040817880462973, 'border_count': 50}. Best is trial 18 with value: 3.653184237286519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 3.714071204\n",
      "bestIteration = 2364\n",
      "\n",
      "EarlyStop counter currently is: 4, The current Best score is: 3.653184237286519 | Overall best: 3.653184237286519\n",
      "Training on fold [0/3]\n"
     ]
    }
   ],
   "source": [
    "results = optuna.create_study(direction='minimize')\n",
    "\n",
    "try:\n",
    "    results.optimize(objectiveCb, n_trials=100, callbacks=[early_stopping_opt])\n",
    "except EarlyStoppingExceeded:\n",
    "    print(f\"The early stopping is triggered: No improvement for {OPTUNA_EARLY_STOPPING} trials.\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "    depth: 10\n",
      "    l2_leaf_reg: 1.2297568843822138\n",
      "    bagging_temperature: 0.005930619695782013\n",
      "    random_strength: 0.6978589723700884\n",
      "    rsm: 0.3340893547465042\n",
      "    border_count: 40\n"
     ]
    }
   ],
   "source": [
    "## printing the best trial\n",
    "print('Best trial:')\n",
    "besttrial = results.best_trial\n",
    "gc.collect()\n",
    "\n",
    "for key, value in besttrial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "def prediction_with_best_parameters_CatBoost(best_params, n_splits, X_train, y_train, \n",
    "                                             test_df, num_round=10000):\n",
    "\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_predictions = np.zeros(len(X_train))\n",
    "    test_predictions = np.zeros(len(test_df))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    print(f\"Starting {n_splits}-Fold CV with CatBoost...\\n\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "        print(f\"Fold {fold + 1} | Train size: {len(train_idx)} | Validation size: {len(val_idx)}\")\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr)\n",
    "        val_pool = Pool(X_val, y_val)\n",
    "        test_pool = Pool(test_df)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            iterations=num_round,\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            depth=best_params['max_depth'],\n",
    "            l2_leaf_reg=best_params['reg_lambda'],\n",
    "            random_strength=best_params['reg_alpha'],\n",
    "            bagging_temperature=best_params['subsample'],  # substitute for subsample\n",
    "            rsm=best_params['colsample_bytree'],           # feature sampling\n",
    "            min_data_in_leaf=int(best_params.get('min_data_in_leaf', 1)),\n",
    "\n",
    "            loss_function='RMSE',\n",
    "            eval_metric='RMSE',\n",
    "            random_seed=42,\n",
    "            early_stopping_rounds=150,\n",
    "            verbose=200\n",
    "        )\n",
    "\n",
    "        model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "        val_preds = model.predict(val_pool)\n",
    "        oof_predictions[val_idx] = val_preds\n",
    "        test_predictions += model.predict(test_pool) / n_splits\n",
    "\n",
    "        # Feature importance\n",
    "        fold_importance_df = pd.DataFrame({\n",
    "            \"Feature\": X_train.columns,\n",
    "            \"importance\": model.get_feature_importance(),\n",
    "            \"fold\": fold + 1\n",
    "        })\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        fold_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        print(f\"Fold {fold + 1} RMSE: {fold_rmse:.5f}\\n\")\n",
    "\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_train, oof_predictions))\n",
    "    print(\"Cross-Validated RMSE Summary\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"Overall Validation RMSE: {val_rmse:.5f}\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    return model, oof_predictions, test_predictions, feature_importance_df, val_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 9-Fold CV with CatBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "0:\tlearn: 3.8267121\ttest: 3.9534196\tbest: 3.9534196 (0)\ttotal: 222ms\tremaining: 36m 57s\n",
      "200:\tlearn: 3.5952555\ttest: 3.7959898\tbest: 3.7959898 (200)\ttotal: 20.8s\tremaining: 16m 51s\n",
      "400:\tlearn: 3.5401616\ttest: 3.7800779\tbest: 3.7800779 (400)\ttotal: 40.3s\tremaining: 16m 4s\n",
      "600:\tlearn: 3.4979044\ttest: 3.7738702\tbest: 3.7738702 (600)\ttotal: 59.7s\tremaining: 15m 33s\n",
      "800:\tlearn: 3.4640014\ttest: 3.7693821\tbest: 3.7693821 (800)\ttotal: 1m 18s\tremaining: 15m 6s\n",
      "1000:\tlearn: 3.4333233\ttest: 3.7660201\tbest: 3.7659375 (997)\ttotal: 1m 37s\tremaining: 14m 40s\n",
      "1200:\tlearn: 3.4043011\ttest: 3.7643784\tbest: 3.7643784 (1200)\ttotal: 1m 56s\tremaining: 14m 16s\n",
      "1400:\tlearn: 3.3781999\ttest: 3.7634767\tbest: 3.7633905 (1392)\ttotal: 2m 14s\tremaining: 13m 46s\n",
      "1600:\tlearn: 3.3495063\ttest: 3.7620091\tbest: 3.7620091 (1600)\ttotal: 2m 31s\tremaining: 13m 15s\n",
      "1800:\tlearn: 3.3242394\ttest: 3.7611852\tbest: 3.7611391 (1796)\ttotal: 2m 48s\tremaining: 12m 48s\n",
      "2000:\tlearn: 3.2975410\ttest: 3.7607005\tbest: 3.7606343 (1996)\ttotal: 3m 6s\tremaining: 12m 24s\n",
      "2200:\tlearn: 3.2743861\ttest: 3.7599947\tbest: 3.7599331 (2197)\ttotal: 3m 23s\tremaining: 12m\n",
      "2400:\tlearn: 3.2512039\ttest: 3.7593638\tbest: 3.7592972 (2366)\ttotal: 3m 40s\tremaining: 11m 37s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.759297199\n",
      "bestIteration = 2366\n",
      "\n",
      "Shrink model to first 2367 iterations.\n",
      "Fold 1 RMSE: 3.75930\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8595456\ttest: 3.6887246\tbest: 3.6887246 (0)\ttotal: 73.5ms\tremaining: 12m 14s\n",
      "200:\tlearn: 3.6293010\ttest: 3.5470618\tbest: 3.5470618 (200)\ttotal: 18.8s\tremaining: 15m 17s\n",
      "400:\tlearn: 3.5688844\ttest: 3.5337149\tbest: 3.5337149 (400)\ttotal: 36.5s\tremaining: 14m 32s\n",
      "600:\tlearn: 3.5254930\ttest: 3.5291276\tbest: 3.5290187 (591)\ttotal: 53.5s\tremaining: 13m 56s\n",
      "800:\tlearn: 3.4879948\ttest: 3.5249553\tbest: 3.5249257 (798)\ttotal: 1m 10s\tremaining: 13m 35s\n",
      "1000:\tlearn: 3.4552648\ttest: 3.5238343\tbest: 3.5238320 (999)\ttotal: 1m 28s\tremaining: 13m 11s\n",
      "1200:\tlearn: 3.4281092\ttest: 3.5226438\tbest: 3.5226207 (1199)\ttotal: 1m 45s\tremaining: 12m 50s\n",
      "1400:\tlearn: 3.4011368\ttest: 3.5212836\tbest: 3.5212366 (1385)\ttotal: 2m 1s\tremaining: 12m 28s\n",
      "1600:\tlearn: 3.3731965\ttest: 3.5206402\tbest: 3.5206310 (1599)\ttotal: 2m 18s\tremaining: 12m 7s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.520417423\n",
      "bestIteration = 1644\n",
      "\n",
      "Shrink model to first 1645 iterations.\n",
      "Fold 2 RMSE: 3.52042\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8382724\ttest: 3.8635879\tbest: 3.8635879 (0)\ttotal: 89.6ms\tremaining: 14m 55s\n",
      "200:\tlearn: 3.6092140\ttest: 3.7150436\tbest: 3.7150436 (200)\ttotal: 18.9s\tremaining: 15m 20s\n",
      "400:\tlearn: 3.5472434\ttest: 3.7026246\tbest: 3.7026246 (400)\ttotal: 36.7s\tremaining: 14m 39s\n",
      "600:\tlearn: 3.5033486\ttest: 3.6978053\tbest: 3.6978053 (600)\ttotal: 54.3s\tremaining: 14m 9s\n",
      "800:\tlearn: 3.4679900\ttest: 3.6964014\tbest: 3.6963988 (790)\ttotal: 1m 11s\tremaining: 13m 41s\n",
      "1000:\tlearn: 3.4363497\ttest: 3.6947734\tbest: 3.6947330 (997)\ttotal: 1m 28s\tremaining: 13m 16s\n",
      "1200:\tlearn: 3.4068700\ttest: 3.6942272\tbest: 3.6941170 (1189)\ttotal: 1m 46s\tremaining: 12m 57s\n",
      "1400:\tlearn: 3.3788290\ttest: 3.6942160\tbest: 3.6939754 (1293)\ttotal: 2m 3s\tremaining: 12m 35s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.693975445\n",
      "bestIteration = 1293\n",
      "\n",
      "Shrink model to first 1294 iterations.\n",
      "Fold 3 RMSE: 3.69398\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8386870\ttest: 3.8590512\tbest: 3.8590512 (0)\ttotal: 68.2ms\tremaining: 11m 21s\n",
      "200:\tlearn: 3.6062876\ttest: 3.7086030\tbest: 3.7086030 (200)\ttotal: 18.7s\tremaining: 15m 13s\n",
      "400:\tlearn: 3.5457759\ttest: 3.6932683\tbest: 3.6932683 (400)\ttotal: 36.3s\tremaining: 14m 28s\n",
      "600:\tlearn: 3.5003026\ttest: 3.6883735\tbest: 3.6883735 (600)\ttotal: 53.7s\tremaining: 14m\n",
      "800:\tlearn: 3.4660935\ttest: 3.6863419\tbest: 3.6861808 (774)\ttotal: 1m 10s\tremaining: 13m 34s\n",
      "1000:\tlearn: 3.4365063\ttest: 3.6855762\tbest: 3.6855026 (962)\ttotal: 1m 28s\tremaining: 13m 12s\n",
      "1200:\tlearn: 3.4083795\ttest: 3.6858287\tbest: 3.6854128 (1084)\ttotal: 1m 45s\tremaining: 12m 49s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.685412787\n",
      "bestIteration = 1084\n",
      "\n",
      "Shrink model to first 1085 iterations.\n",
      "Fold 4 RMSE: 3.68541\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8351070\ttest: 3.8884365\tbest: 3.8884365 (0)\ttotal: 67.9ms\tremaining: 11m 18s\n",
      "200:\tlearn: 3.6073271\ttest: 3.7168880\tbest: 3.7168880 (200)\ttotal: 18.6s\tremaining: 15m 8s\n",
      "400:\tlearn: 3.5443640\ttest: 3.7005256\tbest: 3.7005256 (400)\ttotal: 36.1s\tremaining: 14m 24s\n",
      "600:\tlearn: 3.5022240\ttest: 3.6959768\tbest: 3.6959369 (598)\ttotal: 53.3s\tremaining: 13m 52s\n",
      "800:\tlearn: 3.4663829\ttest: 3.6931320\tbest: 3.6931320 (800)\ttotal: 1m 10s\tremaining: 13m 28s\n",
      "1000:\tlearn: 3.4348677\ttest: 3.6912649\tbest: 3.6912469 (996)\ttotal: 1m 27s\tremaining: 13m 4s\n",
      "1200:\tlearn: 3.4061677\ttest: 3.6899106\tbest: 3.6898248 (1183)\ttotal: 1m 43s\tremaining: 12m 41s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.689709859\n",
      "bestIteration = 1246\n",
      "\n",
      "Shrink model to first 1247 iterations.\n",
      "Fold 5 RMSE: 3.68971\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8309611\ttest: 3.9206991\tbest: 3.9206991 (0)\ttotal: 96.1ms\tremaining: 16m\n",
      "200:\tlearn: 3.6088699\ttest: 3.7210346\tbest: 3.7210346 (200)\ttotal: 18.7s\tremaining: 15m 9s\n",
      "400:\tlearn: 3.5531288\ttest: 3.7008461\tbest: 3.7008461 (400)\ttotal: 36.2s\tremaining: 14m 25s\n",
      "600:\tlearn: 3.5114721\ttest: 3.6911736\tbest: 3.6911619 (598)\ttotal: 53.4s\tremaining: 13m 54s\n",
      "800:\tlearn: 3.4792798\ttest: 3.6853684\tbest: 3.6853670 (795)\ttotal: 1m 10s\tremaining: 13m 26s\n",
      "1000:\tlearn: 3.4495573\ttest: 3.6812918\tbest: 3.6812822 (999)\ttotal: 1m 27s\tremaining: 13m 2s\n",
      "1200:\tlearn: 3.4237401\ttest: 3.6791241\tbest: 3.6791241 (1200)\ttotal: 1m 43s\tremaining: 12m 40s\n",
      "1400:\tlearn: 3.3991102\ttest: 3.6773472\tbest: 3.6772019 (1368)\ttotal: 2m\tremaining: 12m 21s\n",
      "1600:\tlearn: 3.3738297\ttest: 3.6755787\tbest: 3.6755787 (1600)\ttotal: 2m 17s\tremaining: 12m 2s\n",
      "1800:\tlearn: 3.3494825\ttest: 3.6734243\tbest: 3.6734243 (1800)\ttotal: 2m 34s\tremaining: 11m 44s\n",
      "2000:\tlearn: 3.3275970\ttest: 3.6712835\tbest: 3.6712835 (2000)\ttotal: 2m 51s\tremaining: 11m 25s\n",
      "2200:\tlearn: 3.3050499\ttest: 3.6697988\tbest: 3.6697465 (2199)\ttotal: 3m 8s\tremaining: 11m 7s\n",
      "2400:\tlearn: 3.2846808\ttest: 3.6686241\tbest: 3.6685461 (2393)\ttotal: 3m 25s\tremaining: 10m 49s\n",
      "2600:\tlearn: 3.2654277\ttest: 3.6673688\tbest: 3.6673589 (2591)\ttotal: 3m 41s\tremaining: 10m 31s\n",
      "2800:\tlearn: 3.2448639\ttest: 3.6660200\tbest: 3.6660049 (2798)\ttotal: 3m 58s\tremaining: 10m 13s\n",
      "3000:\tlearn: 3.2251584\ttest: 3.6650405\tbest: 3.6650357 (2988)\ttotal: 4m 15s\tremaining: 9m 56s\n",
      "3200:\tlearn: 3.2064116\ttest: 3.6644389\tbest: 3.6644377 (3192)\ttotal: 4m 32s\tremaining: 9m 38s\n",
      "3400:\tlearn: 3.1873782\ttest: 3.6638521\tbest: 3.6638521 (3400)\ttotal: 4m 49s\tremaining: 9m 21s\n",
      "3600:\tlearn: 3.1703441\ttest: 3.6629337\tbest: 3.6629337 (3600)\ttotal: 5m 6s\tremaining: 9m 4s\n",
      "3800:\tlearn: 3.1507673\ttest: 3.6621452\tbest: 3.6621358 (3799)\ttotal: 5m 23s\tremaining: 8m 46s\n",
      "4000:\tlearn: 3.1319240\ttest: 3.6618359\tbest: 3.6618359 (4000)\ttotal: 5m 40s\tremaining: 8m 29s\n",
      "4200:\tlearn: 3.1130628\ttest: 3.6616539\tbest: 3.6616422 (4198)\ttotal: 5m 57s\tremaining: 8m 12s\n",
      "4400:\tlearn: 3.0961103\ttest: 3.6609952\tbest: 3.6609278 (4376)\ttotal: 6m 14s\tremaining: 7m 55s\n",
      "4600:\tlearn: 3.0779769\ttest: 3.6602983\tbest: 3.6602053 (4593)\ttotal: 6m 31s\tremaining: 7m 38s\n",
      "4800:\tlearn: 3.0609415\ttest: 3.6595220\tbest: 3.6594257 (4770)\ttotal: 6m 47s\tremaining: 7m 21s\n",
      "5000:\tlearn: 3.0445698\ttest: 3.6593257\tbest: 3.6591664 (4973)\ttotal: 7m 4s\tremaining: 7m 4s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.659166437\n",
      "bestIteration = 4973\n",
      "\n",
      "Shrink model to first 4974 iterations.\n",
      "Fold 6 RMSE: 3.65917\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8256209\ttest: 3.9627326\tbest: 3.9627326 (0)\ttotal: 111ms\tremaining: 18m 29s\n",
      "200:\tlearn: 3.6002766\ttest: 3.7901212\tbest: 3.7901212 (200)\ttotal: 18.6s\tremaining: 15m 7s\n",
      "400:\tlearn: 3.5404587\ttest: 3.7726243\tbest: 3.7726243 (400)\ttotal: 36.5s\tremaining: 14m 32s\n",
      "600:\tlearn: 3.5001291\ttest: 3.7656610\tbest: 3.7656192 (597)\ttotal: 53.5s\tremaining: 13m 57s\n",
      "800:\tlearn: 3.4670245\ttest: 3.7623496\tbest: 3.7622923 (792)\ttotal: 1m 10s\tremaining: 13m 29s\n",
      "1000:\tlearn: 3.4383331\ttest: 3.7595823\tbest: 3.7594923 (991)\ttotal: 1m 27s\tremaining: 13m 4s\n",
      "1200:\tlearn: 3.4108044\ttest: 3.7577351\tbest: 3.7577351 (1200)\ttotal: 1m 43s\tremaining: 12m 41s\n",
      "1400:\tlearn: 3.3849173\ttest: 3.7565982\tbest: 3.7565926 (1396)\ttotal: 2m\tremaining: 12m 21s\n",
      "1600:\tlearn: 3.3599734\ttest: 3.7556059\tbest: 3.7555943 (1599)\ttotal: 2m 17s\tremaining: 11m 59s\n",
      "1800:\tlearn: 3.3376145\ttest: 3.7548258\tbest: 3.7547321 (1783)\ttotal: 2m 33s\tremaining: 11m 40s\n",
      "2000:\tlearn: 3.3167771\ttest: 3.7542342\tbest: 3.7542291 (1993)\ttotal: 2m 50s\tremaining: 11m 20s\n",
      "2200:\tlearn: 3.2947774\ttest: 3.7532494\tbest: 3.7531784 (2192)\ttotal: 3m 6s\tremaining: 11m 1s\n",
      "2400:\tlearn: 3.2734556\ttest: 3.7529119\tbest: 3.7529119 (2400)\ttotal: 3m 23s\tremaining: 10m 44s\n",
      "2600:\tlearn: 3.2518553\ttest: 3.7518392\tbest: 3.7518208 (2590)\ttotal: 3m 40s\tremaining: 10m 27s\n",
      "2800:\tlearn: 3.2305578\ttest: 3.7508773\tbest: 3.7508773 (2800)\ttotal: 3m 57s\tremaining: 10m 9s\n",
      "3000:\tlearn: 3.2105276\ttest: 3.7500408\tbest: 3.7499667 (2988)\ttotal: 4m 13s\tremaining: 9m 52s\n",
      "3200:\tlearn: 3.1898015\ttest: 3.7497952\tbest: 3.7497565 (3177)\ttotal: 4m 30s\tremaining: 9m 34s\n",
      "3400:\tlearn: 3.1688532\ttest: 3.7489345\tbest: 3.7489345 (3400)\ttotal: 4m 47s\tremaining: 9m 17s\n",
      "3600:\tlearn: 3.1492711\ttest: 3.7489520\tbest: 3.7485101 (3501)\ttotal: 5m 4s\tremaining: 9m\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.748510147\n",
      "bestIteration = 3501\n",
      "\n",
      "Shrink model to first 3502 iterations.\n",
      "Fold 7 RMSE: 3.74851\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8448914\ttest: 3.8094298\tbest: 3.8094298 (0)\ttotal: 77ms\tremaining: 12m 50s\n",
      "200:\tlearn: 3.6177067\ttest: 3.6428804\tbest: 3.6428804 (200)\ttotal: 18.7s\tremaining: 15m 14s\n",
      "400:\tlearn: 3.5523709\ttest: 3.6259580\tbest: 3.6259580 (400)\ttotal: 36.6s\tremaining: 14m 35s\n",
      "600:\tlearn: 3.5086540\ttest: 3.6201904\tbest: 3.6201904 (600)\ttotal: 53.7s\tremaining: 13m 59s\n",
      "800:\tlearn: 3.4734809\ttest: 3.6169726\tbest: 3.6169447 (799)\ttotal: 1m 10s\tremaining: 13m 33s\n",
      "1000:\tlearn: 3.4418231\ttest: 3.6146171\tbest: 3.6146171 (1000)\ttotal: 1m 27s\tremaining: 13m 9s\n",
      "1200:\tlearn: 3.4135786\ttest: 3.6133742\tbest: 3.6133742 (1200)\ttotal: 1m 44s\tremaining: 12m 47s\n",
      "1400:\tlearn: 3.3872388\ttest: 3.6132872\tbest: 3.6129840 (1321)\ttotal: 2m 1s\tremaining: 12m 26s\n",
      "1600:\tlearn: 3.3613771\ttest: 3.6126428\tbest: 3.6125473 (1583)\ttotal: 2m 18s\tremaining: 12m 4s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.612531537\n",
      "bestIteration = 1637\n",
      "\n",
      "Shrink model to first 1638 iterations.\n",
      "Fold 8 RMSE: 3.61253\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8686557\ttest: 3.6121450\tbest: 3.6121450 (0)\ttotal: 104ms\tremaining: 17m 22s\n",
      "200:\tlearn: 3.6347632\ttest: 3.4706745\tbest: 3.4706745 (200)\ttotal: 19.2s\tremaining: 15m 34s\n",
      "400:\tlearn: 3.5718487\ttest: 3.4598135\tbest: 3.4598135 (400)\ttotal: 37.3s\tremaining: 14m 52s\n",
      "600:\tlearn: 3.5291064\ttest: 3.4566320\tbest: 3.4565693 (586)\ttotal: 54.9s\tremaining: 14m 18s\n",
      "800:\tlearn: 3.4926164\ttest: 3.4552774\tbest: 3.4551434 (785)\ttotal: 1m 12s\tremaining: 13m 51s\n",
      "1000:\tlearn: 3.4601990\ttest: 3.4546992\tbest: 3.4546403 (994)\ttotal: 1m 29s\tremaining: 13m 27s\n",
      "1200:\tlearn: 3.4315437\ttest: 3.4546120\tbest: 3.4543254 (1074)\ttotal: 1m 47s\tremaining: 13m 6s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.454325396\n",
      "bestIteration = 1074\n",
      "\n",
      "Shrink model to first 1075 iterations.\n",
      "Fold 9 RMSE: 3.45433\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64830\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat_params = {\n",
    "    'learning_rate': 0.01,                         # Assuming you use the same learning rate\n",
    "    'max_depth': 9,\n",
    "    'reg_lambda': 2.5402159444927617,              # L2 regularization (CatBoost: l2_leaf_reg)\n",
    "    'reg_alpha': 0.21948592159535407,              # Random strength (acts similar to L1)\n",
    "    'subsample': 0.41414360841134634,              # bagging_temperature\n",
    "    'colsample_bytree': 0.739079421019534,         # rsm (feature sampling ratio)\n",
    "    'border_count': 33                             # Used in CatBoost for binarization\n",
    "}\n",
    "\n",
    "\n",
    "# Get columns present in both train and test\n",
    "catboost_reg, pred_y_train, pred_y_test, feature_importance_df_cat, rmse_cat = prediction_with_best_parameters_CatBoost(\n",
    "    best_params=cat_params,\n",
    "    n_splits=9,\n",
    "    X_train=X_train[df_train_columns],\n",
    "    y_train=y_train,\n",
    "    test_df=test[df_train_columns],\n",
    "    \n",
    "    num_round=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-4.054263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.394248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.983232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.107130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.431350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123618</th>\n",
       "      <td>C_ID_7a239d2eda</td>\n",
       "      <td>0.813895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123619</th>\n",
       "      <td>C_ID_75ace375ae</td>\n",
       "      <td>-0.384389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123620</th>\n",
       "      <td>C_ID_21d56d950c</td>\n",
       "      <td>0.674899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123621</th>\n",
       "      <td>C_ID_6c46fc5a9d</td>\n",
       "      <td>-3.451968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123622</th>\n",
       "      <td>C_ID_87e7979a5f</td>\n",
       "      <td>0.206487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123623 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id    target\n",
       "0       C_ID_0ab67a22ab -4.054263\n",
       "1       C_ID_130fd0cbdd -0.394248\n",
       "2       C_ID_b709037bc5 -0.983232\n",
       "3       C_ID_d27d835a9f -0.107130\n",
       "4       C_ID_2b5e3df5c2 -1.431350\n",
       "...                 ...       ...\n",
       "123618  C_ID_7a239d2eda  0.813895\n",
       "123619  C_ID_75ace375ae -0.384389\n",
       "123620  C_ID_21d56d950c  0.674899\n",
       "123621  C_ID_6c46fc5a9d -3.451968\n",
       "123622  C_ID_87e7979a5f  0.206487\n",
       "\n",
       "[123623 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cb = test[[\"card_id\"]].copy()\n",
    "best_cb[\"target\"] = pred_y_test\n",
    "best_cb.to_csv(\"cb_latest.csv\", index=False)\n",
    "best_cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Model      RMSE\n",
      "4       XGBoost  3.644275\n",
      "6      LightGBM  3.646526\n",
      "5      CatBoost  3.648302\n",
      "2         Lasso  3.796042\n",
      "3  RandomForest  3.796886\n",
      "1         Ridge  3.865673\n",
      "0        Linear  3.876082\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x2000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Step 1: Store RMSE results\n",
    "rmse_results = {\n",
    "    'Linear': rmse_linear,\n",
    "    'Ridge': rmse_ridge,\n",
    "    'Lasso': rmse_lasso,\n",
    "    'RandomForest': rmse_rf,\n",
    "    'XGBoost': rmse_xgb,\n",
    "    'CatBoost': rmse_cat,\n",
    "    'LightGBM': rmse_lgb\n",
    "}\n",
    "\n",
    "rmse_df = pd.DataFrame(list(rmse_results.items()), columns=['Model', 'RMSE'])\n",
    "print(rmse_df.sort_values(by='RMSE'))\n",
    "\n",
    "# Step 2: Collect importance DataFrames (top 10 features)\n",
    "importance_dfs = {\n",
    "    'Linear': feature_importance_df_linear,\n",
    "    'Ridge': feature_importance_df_ridge,\n",
    "    'Lasso': feature_importance_df_lasso,\n",
    "    'Random Forest': feature_importance_df_rf,\n",
    "    'LightGBM': feature_importance_df_lgb,\n",
    "    'XGBoost': feature_importance_df_xgboost,\n",
    "    'CatBoost': feature_importance_df_cat,\n",
    "}\n",
    "\n",
    "# Step 3: Plot in a 2x4 grid\n",
    "fig, axes = plt.subplots(4, 2, figsize=(40,20))\n",
    "axes = axes.flatten()\n",
    "top_n = 10\n",
    "\n",
    "for idx, (model_name, imp_df) in enumerate(importance_dfs.items()):\n",
    "    if imp_df is not None:\n",
    "        # Handle different column names\n",
    "        if 'Importance' in imp_df.columns:\n",
    "            col = 'Importance'\n",
    "        elif 'Importance (abs)' in imp_df.columns:\n",
    "            col = 'Importance (abs)'\n",
    "        elif 'importance' in imp_df.columns:\n",
    "            col = 'importance'\n",
    "        else:\n",
    "            axes[idx].axis('off')\n",
    "            axes[idx].set_title(f\"{model_name}\\n(No Valid Importance Column)\")\n",
    "            continue\n",
    "\n",
    "        # Plot top N features\n",
    "        imp_data = imp_df.groupby('Feature')[col].mean().sort_values(ascending=False).head(top_n)\n",
    "        sns.barplot(x=imp_data.values, y=imp_data.index, ax=axes[idx], palette='viridis')\n",
    "        axes[idx].set_title(f\"{model_name} (Top {top_n})\")\n",
    "    else:\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f\"{model_name}\\n(No Importance)\")\n",
    "\n",
    "fig.suptitle('Feature Importances Across Models (Top 10)', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474c43e",
   "metadata": {},
   "source": [
    "## Outlier Classification \n",
    "https://www.kaggle.com/competitions/elo-merchant-category-recommendation/discussion/82166 \n",
    "\n",
    "Step-by-step breakdown:\n",
    "1. Outlier Classification\n",
    "2. Regression trained on non-outliers\n",
    "3. Combine output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551c52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:04:48,220] A new study created in memory with name: no-name-ac8f2606-8951-4a84-8301-5c60db15cbcd\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[524]\tvalid_0's auc: 0.908278\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's auc: 0.904106\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's auc: 0.887999\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[450]\tvalid_0's auc: 0.911203\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\tvalid_0's auc: 0.898619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.902041:   2%|‚ñè         | 1/50 [00:42<34:22, 42.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:05:30,314] Trial 0 finished with value: 0.9020408337721243 and parameters: {'learning_rate': 0.005142057216379833, 'num_leaves': 49, 'max_depth': 6, 'min_child_samples': 20, 'subsample': 0.9860651760942388, 'colsample_bytree': 0.9071169583177614, 'reg_alpha': 0.00827341250893475, 'reg_lambda': 0.01575670541220875}. Best is trial 0 with value: 0.9020408337721243.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[298]\tvalid_0's auc: 0.909057\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.903425\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's auc: 0.895153\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's auc: 0.912655\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:   4%|‚ñç         | 2/50 [01:06<25:10, 31.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[274]\tvalid_0's auc: 0.900211\n",
      "[I 2025-04-21 02:05:54,336] Trial 1 finished with value: 0.9041002568046432 and parameters: {'learning_rate': 0.013848664658270107, 'num_leaves': 69, 'max_depth': 15, 'min_child_samples': 97, 'subsample': 0.848251915906681, 'colsample_bytree': 0.6242533857211783, 'reg_alpha': 0.0022874276986830358, 'reg_lambda': 0.0018052984530000996}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.907024\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.90305\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.894974\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.912279\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:   6%|‚ñå         | 3/50 [01:19<18:16, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.895342\n",
      "[I 2025-04-21 02:06:07,985] Trial 2 finished with value: 0.902533925809686 and parameters: {'learning_rate': 0.04738041288659489, 'num_leaves': 69, 'max_depth': 15, 'min_child_samples': 55, 'subsample': 0.8986446980529709, 'colsample_bytree': 0.7610217358996776, 'reg_alpha': 0.019594960981199235, 'reg_lambda': 0.05024062476174596}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Early Stop Counter: 1/10 | Current Best AUC: 0.90410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.902076\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.901452\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.890704\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.905343\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:   8%|‚ñä         | 4/50 [01:32<14:42, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.895181\n",
      "[I 2025-04-21 02:06:20,816] Trial 3 finished with value: 0.898951242607037 and parameters: {'learning_rate': 0.06057193113256887, 'num_leaves': 129, 'max_depth': 9, 'min_child_samples': 55, 'subsample': 0.8260422486545256, 'colsample_bytree': 0.6986943427543482, 'reg_alpha': 4.445732791144305, 'reg_lambda': 0.08559011498759538}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Early Stop Counter: 2/10 | Current Best AUC: 0.90410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's auc: 0.905197\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.899594\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's auc: 0.890884\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's auc: 0.913501\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:  10%|‚ñà         | 5/50 [02:04<17:45, 23.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's auc: 0.892464\n",
      "[I 2025-04-21 02:06:52,464] Trial 4 finished with value: 0.9003280664171942 and parameters: {'learning_rate': 0.01753451875724792, 'num_leaves': 94, 'max_depth': 12, 'min_child_samples': 72, 'subsample': 0.8891075526373837, 'colsample_bytree': 0.99432223974373, 'reg_alpha': 3.265556302360968, 'reg_lambda': 1.1955464303739851}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Early Stop Counter: 3/10 | Current Best AUC: 0.90410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.907771\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.904883\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.893097\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.909548\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:  12%|‚ñà‚ñè        | 6/50 [02:16<14:31, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.899901\n",
      "[I 2025-04-21 02:07:04,723] Trial 5 finished with value: 0.9030401505221916 and parameters: {'learning_rate': 0.07432218232204715, 'num_leaves': 40, 'max_depth': 13, 'min_child_samples': 68, 'subsample': 0.7553505632048776, 'colsample_bytree': 0.9960540987189306, 'reg_alpha': 2.6430059298098274, 'reg_lambda': 0.0012271969070840234}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Early Stop Counter: 4/10 | Current Best AUC: 0.90410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's auc: 0.909966\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[945]\tvalid_0's auc: 0.905444\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[982]\tvalid_0's auc: 0.893984\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[878]\tvalid_0's auc: 0.906062\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:  14%|‚ñà‚ñç        | 7/50 [02:49<17:18, 24.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's auc: 0.900159\n",
      "[I 2025-04-21 02:07:37,862] Trial 6 finished with value: 0.903122773593077 and parameters: {'learning_rate': 0.00715858877846095, 'num_leaves': 148, 'max_depth': 3, 'min_child_samples': 45, 'subsample': 0.8781706312960857, 'colsample_bytree': 0.6070574353618032, 'reg_alpha': 0.004938717846808039, 'reg_lambda': 6.637622205021046}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Early Stop Counter: 5/10 | Current Best AUC: 0.90410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.900523\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.890314\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.888287\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.902537\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:  16%|‚ñà‚ñå        | 8/50 [03:02<14:27, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.88654\n",
      "[I 2025-04-21 02:07:51,035] Trial 7 finished with value: 0.8936400374867655 and parameters: {'learning_rate': 0.08356700306037769, 'num_leaves': 136, 'max_depth': 9, 'min_child_samples': 53, 'subsample': 0.6032575524414793, 'colsample_bytree': 0.9068511279994007, 'reg_alpha': 0.06758662437205287, 'reg_lambda': 0.03209854369452321}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Early Stop Counter: 6/10 | Current Best AUC: 0.90410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.901096\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[295]\tvalid_0's auc: 0.902919\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's auc: 0.889341\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[345]\tvalid_0's auc: 0.912534\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[915]\tvalid_0's auc: 0.899802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:  18%|‚ñà‚ñä        | 9/50 [03:41<18:00, 26.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:08:29,924] Trial 8 finished with value: 0.9011384563264169 and parameters: {'learning_rate': 0.005165361126383822, 'num_leaves': 59, 'max_depth': 8, 'min_child_samples': 15, 'subsample': 0.9560146165790344, 'colsample_bytree': 0.940133913836856, 'reg_alpha': 4.859200056172298, 'reg_lambda': 0.02437504257893757}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Early Stop Counter: 7/10 | Current Best AUC: 0.90410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[357]\tvalid_0's auc: 0.906995\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.902265\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's auc: 0.89183\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's auc: 0.913116\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.9041:  20%|‚ñà‚ñà        | 10/50 [04:12<18:34, 27.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[344]\tvalid_0's auc: 0.898446\n",
      "[I 2025-04-21 02:09:01,142] Trial 9 finished with value: 0.9025304549713511 and parameters: {'learning_rate': 0.011829938645586307, 'num_leaves': 113, 'max_depth': 13, 'min_child_samples': 13, 'subsample': 0.9498021732845708, 'colsample_bytree': 0.6834429163504852, 'reg_alpha': 2.6993627027373015, 'reg_lambda': 0.01681210709452497}. Best is trial 1 with value: 0.9041002568046432.\n",
      "Early Stop Counter: 8/10 | Current Best AUC: 0.90410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's auc: 0.910474\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's auc: 0.907077\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's auc: 0.89763\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's auc: 0.910169\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.905433:  22%|‚ñà‚ñà‚ñè       | 11/50 [04:26<15:21, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's auc: 0.901815\n",
      "[I 2025-04-21 02:09:15,152] Trial 10 finished with value: 0.9054330936987487 and parameters: {'learning_rate': 0.029937357771089627, 'num_leaves': 23, 'max_depth': 11, 'min_child_samples': 99, 'subsample': 0.7068394529816686, 'colsample_bytree': 0.6061158569763994, 'reg_alpha': 0.0010010357052208116, 'reg_lambda': 0.0011361128807327388}. Best is trial 10 with value: 0.9054330936987487.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.91098\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's auc: 0.907834\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's auc: 0.897227\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.908811\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.905433:  24%|‚ñà‚ñà‚ñç       | 12/50 [04:40<13:00, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's auc: 0.901715\n",
      "[I 2025-04-21 02:09:28,659] Trial 11 finished with value: 0.9053133433285714 and parameters: {'learning_rate': 0.03099410756892407, 'num_leaves': 21, 'max_depth': 15, 'min_child_samples': 100, 'subsample': 0.697731789499501, 'colsample_bytree': 0.6000573333464279, 'reg_alpha': 0.0010578506180133544, 'reg_lambda': 0.001374539698765895}. Best is trial 10 with value: 0.9054330936987487.\n",
      "Early Stop Counter: 1/10 | Current Best AUC: 0.90543\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's auc: 0.910802\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.908516\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's auc: 0.896921\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.909509\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.905472:  26%|‚ñà‚ñà‚ñå       | 13/50 [04:54<11:26, 18.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.901611\n",
      "[I 2025-04-21 02:09:42,650] Trial 12 finished with value: 0.9054716956768424 and parameters: {'learning_rate': 0.032633282012262954, 'num_leaves': 21, 'max_depth': 11, 'min_child_samples': 99, 'subsample': 0.708092847068655, 'colsample_bytree': 0.8188904884202239, 'reg_alpha': 0.001271632390392323, 'reg_lambda': 0.00406675255428421}. Best is trial 12 with value: 0.9054716956768424.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.911807\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.907838\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's auc: 0.898545\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.910089\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.905647:  28%|‚ñà‚ñà‚ñä       | 14/50 [05:07<10:13, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's auc: 0.899955\n",
      "[I 2025-04-21 02:09:56,192] Trial 13 finished with value: 0.9056468907311268 and parameters: {'learning_rate': 0.032063812041793927, 'num_leaves': 20, 'max_depth': 11, 'min_child_samples': 82, 'subsample': 0.6976156120334995, 'colsample_bytree': 0.8279802395687021, 'reg_alpha': 0.44041617289573726, 'reg_lambda': 0.006613409828727906}. Best is trial 13 with value: 0.9056468907311268.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.909795\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.904047\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.894663\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.910865\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.905647:  30%|‚ñà‚ñà‚ñà       | 15/50 [05:20<09:09, 15.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's auc: 0.900322\n",
      "[I 2025-04-21 02:10:08,790] Trial 14 finished with value: 0.9039383545397708 and parameters: {'learning_rate': 0.038571092218478716, 'num_leaves': 38, 'max_depth': 7, 'min_child_samples': 83, 'subsample': 0.6276031277741171, 'colsample_bytree': 0.8293898450330635, 'reg_alpha': 0.18730991756155183, 'reg_lambda': 0.005541976055504182}. Best is trial 13 with value: 0.9056468907311268.\n",
      "Early Stop Counter: 1/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.905841\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.900758\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.892958\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.914273\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.905647:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [05:36<08:59, 15.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.899766\n",
      "[I 2025-04-21 02:10:25,079] Trial 15 finished with value: 0.9027191068690545 and parameters: {'learning_rate': 0.03030212574546494, 'num_leaves': 91, 'max_depth': 11, 'min_child_samples': 84, 'subsample': 0.7643913944753156, 'colsample_bytree': 0.8172388799411184, 'reg_alpha': 0.4061604118335919, 'reg_lambda': 0.5295066948290618}. Best is trial 13 with value: 0.9056468907311268.\n",
      "Early Stop Counter: 2/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's auc: 0.911419\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.905399\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's auc: 0.896395\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's auc: 0.911457\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.905647:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [05:56<09:24, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[303]\tvalid_0's auc: 0.89996\n",
      "[I 2025-04-21 02:10:45,028] Trial 16 finished with value: 0.9049261117045457 and parameters: {'learning_rate': 0.01678312946628388, 'num_leaves': 33, 'max_depth': 11, 'min_child_samples': 84, 'subsample': 0.6740753102164957, 'colsample_bytree': 0.7617612850413877, 'reg_alpha': 0.4442980227682068, 'reg_lambda': 0.004486411190161996}. Best is trial 13 with value: 0.9056468907311268.\n",
      "Early Stop Counter: 3/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.908781\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.902906\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.892751\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.910718\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.905647:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [06:08<08:18, 15.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.897046\n",
      "[I 2025-04-21 02:10:57,045] Trial 17 finished with value: 0.9024403299090554 and parameters: {'learning_rate': 0.05105061579437781, 'num_leaves': 56, 'max_depth': 6, 'min_child_samples': 35, 'subsample': 0.7570417322626112, 'colsample_bytree': 0.8586081736712639, 'reg_alpha': 0.044162185658990265, 'reg_lambda': 0.33216420685737097}. Best is trial 13 with value: 0.9056468907311268.\n",
      "Early Stop Counter: 4/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's auc: 0.911276\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's auc: 0.906805\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.897507\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.910641\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [06:27<08:31, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's auc: 0.902017\n",
      "[I 2025-04-21 02:11:15,680] Trial 18 finished with value: 0.9056493150492022 and parameters: {'learning_rate': 0.02291734212023442, 'num_leaves': 20, 'max_depth': 10, 'min_child_samples': 69, 'subsample': 0.6562011691040252, 'colsample_bytree': 0.770950019909995, 'reg_alpha': 0.7847249411191018, 'reg_lambda': 0.007234679752289443}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's auc: 0.910933\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's auc: 0.906537\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's auc: 0.895149\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.907083\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [06:43<08:10, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's auc: 0.901131\n",
      "[I 2025-04-21 02:11:31,698] Trial 19 finished with value: 0.9041665791588194 and parameters: {'learning_rate': 0.02201001458426091, 'num_leaves': 71, 'max_depth': 4, 'min_child_samples': 70, 'subsample': 0.6549699861964676, 'colsample_bytree': 0.772753259716274, 'reg_alpha': 0.8876797894526502, 'reg_lambda': 0.011367518576853898}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 1/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.904333\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.901622\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[467]\tvalid_0's auc: 0.891932\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's auc: 0.91004\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[452]\tvalid_0's auc: 0.898374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [07:12<09:44, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:12:00,685] Trial 20 finished with value: 0.9012600678385743 and parameters: {'learning_rate': 0.01057919565646981, 'num_leaves': 112, 'max_depth': 9, 'min_child_samples': 64, 'subsample': 0.64798899332263, 'colsample_bytree': 0.7091459778962623, 'reg_alpha': 1.0117942330754046, 'reg_lambda': 0.19255828430813623}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 2/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.910669\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's auc: 0.906982\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's auc: 0.898278\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.90984\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [07:29<08:58, 19.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.90015\n",
      "[I 2025-04-21 02:12:17,806] Trial 21 finished with value: 0.9051836795140626 and parameters: {'learning_rate': 0.022823799034523293, 'num_leaves': 22, 'max_depth': 10, 'min_child_samples': 88, 'subsample': 0.7166719506341177, 'colsample_bytree': 0.8576001774660494, 'reg_alpha': 0.1384719029267704, 'reg_lambda': 0.0046863807727114725}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 3/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's auc: 0.911503\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.904728\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's auc: 0.897313\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's auc: 0.910554\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [07:46<08:18, 18.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's auc: 0.900503\n",
      "[I 2025-04-21 02:12:34,503] Trial 22 finished with value: 0.90492024056662 and parameters: {'learning_rate': 0.02342181876603382, 'num_leaves': 34, 'max_depth': 13, 'min_child_samples': 92, 'subsample': 0.7888329105805283, 'colsample_bytree': 0.7895644547360647, 'reg_alpha': 0.3277059038566553, 'reg_lambda': 0.00784229415370645}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 4/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.910074\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.904496\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.896865\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.912542\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [07:59<07:22, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.900078\n",
      "[I 2025-04-21 02:12:48,119] Trial 23 finished with value: 0.9048111815567312 and parameters: {'learning_rate': 0.035850617104913725, 'num_leaves': 44, 'max_depth': 10, 'min_child_samples': 77, 'subsample': 0.7292829737040608, 'colsample_bytree': 0.7404576672231107, 'reg_alpha': 1.0409003174952323, 'reg_lambda': 0.0032215306609742816}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 5/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.910549\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.906915\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.89626\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.911864\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [08:12<06:31, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.898513\n",
      "[I 2025-04-21 02:13:00,618] Trial 24 finished with value: 0.9048198314625389 and parameters: {'learning_rate': 0.04492513026588421, 'num_leaves': 29, 'max_depth': 12, 'min_child_samples': 79, 'subsample': 0.672860706933714, 'colsample_bytree': 0.8474981616717444, 'reg_alpha': 0.03517968770895292, 'reg_lambda': 0.0024761125794957157}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 6/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's auc: 0.909588\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.903241\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.895137\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.91237\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [08:30<06:33, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's auc: 0.899385\n",
      "[I 2025-04-21 02:13:18,710] Trial 25 finished with value: 0.9039441828063642 and parameters: {'learning_rate': 0.024502388731419522, 'num_leaves': 55, 'max_depth': 10, 'min_child_samples': 63, 'subsample': 0.6109235088579464, 'colsample_bytree': 0.8897057589684068, 'reg_alpha': 0.01291374994011465, 'reg_lambda': 0.07190809576442901}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 7/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.909252\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.905955\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.896056\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.910362\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [08:40<05:36, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.901142\n",
      "[I 2025-04-21 02:13:29,207] Trial 26 finished with value: 0.9045534398332951 and parameters: {'learning_rate': 0.06470135260061156, 'num_leaves': 21, 'max_depth': 8, 'min_child_samples': 92, 'subsample': 0.6873823039848884, 'colsample_bytree': 0.8087855391092795, 'reg_alpha': 8.667170903005971, 'reg_lambda': 0.008340579551489955}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 8/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.908144\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.902829\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.894643\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.907266\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [08:50<04:48, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.896635\n",
      "[I 2025-04-21 02:13:38,760] Trial 27 finished with value: 0.9019033832829673 and parameters: {'learning_rate': 0.09774471695720831, 'num_leaves': 45, 'max_depth': 12, 'min_child_samples': 75, 'subsample': 0.7349311082144329, 'colsample_bytree': 0.7271918397900119, 'reg_alpha': 0.2004814701307664, 'reg_lambda': 0.036347716316194593}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 9/10 | Current Best AUC: 0.90565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's auc: 0.910188\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.906829\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's auc: 0.89785\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.911015\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.905649:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [09:08<07:10, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's auc: 0.899862\n",
      "[I 2025-04-21 02:13:56,432] Trial 28 finished with value: 0.9051488706029364 and parameters: {'learning_rate': 0.01825790225695514, 'num_leaves': 31, 'max_depth': 14, 'min_child_samples': 91, 'subsample': 0.6458383013405962, 'colsample_bytree': 0.6610886494509206, 'reg_alpha': 1.4921843415184473, 'reg_lambda': 0.0030247775087603227}. Best is trial 18 with value: 0.9056493150492022.\n",
      "Early Stop Counter: 10/10 | Current Best AUC: 0.90565\n",
      "Early stopping triggered.\n",
      "\n",
      " Best AUC: 0.9056493150492022\n",
      " Best hyperparameters:\n",
      "    learning_rate: 0.02291734212023442\n",
      "    num_leaves: 20\n",
      "    max_depth: 10\n",
      "    min_child_samples: 69\n",
      "    subsample: 0.6562011691040252\n",
      "    colsample_bytree: 0.770950019909995\n",
      "    reg_alpha: 0.7847249411191018\n",
      "    reg_lambda: 0.007234679752289443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# === Prepare Data ===\n",
    "df_train_columns_clf = [col for col in df_train_columns if col != 'target_class']\n",
    "X1 = train[df_train_columns_clf]\n",
    "y1 = train['outliers']  # Binary labels based on your quantile logic\n",
    "\n",
    "# Split for final validation (to evaluate the best model later)\n",
    "X_tr, X_vr, y_tr, y_vr = train_test_split(\n",
    "    X1, y1, test_size=0.2, stratify=y1, random_state=42\n",
    ")\n",
    "\n",
    "# === Optuna Objective Function ===\n",
    "def objective(trial):\n",
    "    param_grid = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'random_state': 42,\n",
    "        'class_weight': 'balanced',\n",
    "\n",
    "        # Hyperparameters to tune\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.005, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        'min_child_samples': trial.suggest_int(\"min_child_samples\", 10, 100),\n",
    "        'subsample': trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X_tr, y_tr):\n",
    "        X_t, X_v = X_tr.iloc[train_idx], X_tr.iloc[valid_idx]\n",
    "        y_t, y_v = y_tr.iloc[train_idx], y_tr.iloc[valid_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**param_grid, n_estimators=1000)\n",
    "\n",
    "        model.fit(\n",
    "            X_t, y_t,\n",
    "            eval_set=[(X_v, y_v)],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(50),\n",
    "                lgb.log_evaluation(0)\n",
    "            ],\n",
    "        )\n",
    "        preds = model.predict_proba(X_v)[:, 1]\n",
    "        auc = roc_auc_score(y_v, preds)\n",
    "        scores.append(auc)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# === Optuna Early Stopping Callback with Logging ===\n",
    "\n",
    "class OptunaEarlyStopCounter:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_value = None\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        if self.best_value is None or study.best_value > self.best_value:\n",
    "            self.best_value = study.best_value\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"Early Stop Counter: {self.counter}/{self.patience} | Current Best AUC: {self.best_value:.5f}\")\n",
    "            if self.counter >= self.patience:\n",
    "                raise optuna.exceptions.OptunaError(\"Early stopping triggered.\")\n",
    "\n",
    "# === Run Optuna Study ===\n",
    "early_stop_cb = OptunaEarlyStopCounter(patience=10)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "try:\n",
    "    study.optimize(objective, n_trials=50, show_progress_bar=True, callbacks=[early_stop_cb])\n",
    "except optuna.exceptions.OptunaError as e:\n",
    "    print(str(e))\n",
    "\n",
    "print(\"\\n Best AUC:\", study.best_value)\n",
    "print(\" Best hyperparameters:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c586f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.89337\n",
      "[200]\tvalid_0's auc: 0.89567\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's auc: 0.895709\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92     39943\n",
      "           1       0.05      0.78      0.10       441\n",
      "\n",
      "    accuracy                           0.85     40384\n",
      "   macro avg       0.53      0.82      0.51     40384\n",
      "weighted avg       0.99      0.85      0.91     40384\n",
      "\n",
      "AUC on hold-out validation: 0.8957\n"
     ]
    }
   ],
   "source": [
    "# Retrain best model on full training set\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "    'random_state': 42,\n",
    "    'class_weight': 'balanced'\n",
    "})\n",
    "\n",
    "best_model = lgb.LGBMClassifier(**best_params, n_estimators=1000)\n",
    "\n",
    "best_model.fit(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    eval_set=[(X_vr, y_vr)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(50),\n",
    "        lgb.log_evaluation(100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Final Evaluation\n",
    "val_preds = best_model.predict(X_vr)\n",
    "val_probs = best_model.predict_proba(X_vr)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_vr, val_preds))\n",
    "\n",
    "print(f\"AUC on hold-out validation: {roc_auc_score(y_vr, val_probs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5dea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier\n",
      "0    122119\n",
      "1      1504\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === Inference: Predict Outlier Probabilities on Test Set ===\n",
    "\n",
    "# Ensure the same feature set is used as during training\n",
    "X_test_clf = test[df_train_columns_clf]\n",
    "\n",
    "# Predict probabilities using the best tuned model\n",
    "test_outlier_probs = best_model.predict_proba(X_test_clf)[:, 1]\n",
    "\n",
    "# Set a threshold to define what counts as an outlier\n",
    "outlier_threshold = 0.9  # You can tune this based on desired precision/recall tradeoff\n",
    "\n",
    "# Apply threshold to get binary outlier flags\n",
    "test['outlier'] = (test_outlier_probs >= outlier_threshold).astype(int)\n",
    "\n",
    "# Optional: Inspect counts\n",
    "print(test['outlier'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23872209",
   "metadata": {},
   "source": [
    "### Training Model with train data with no outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042d86f",
   "metadata": {},
   "source": [
    "#### Prepare Test Set\n",
    "- Remove Outliers identified and replace with -33\n",
    "- Obtained filtered test set to train model (No Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ef51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PART 1: PREPARE TEST FEATURES FOR REGRESSION ===\n",
    "\n",
    "# Use your outlier prediction (already in 'test[\"outlier\"]')\n",
    "test_result = test.copy()\n",
    "\n",
    "# Mask for non-outlier rows\n",
    "non_outlier_mask = test_result['outlier'] == 0\n",
    "\n",
    "# Use the same feature columns as used during training (df_train_columns)\n",
    "test_features_for_reg = test_result.loc[non_outlier_mask, df_train_columns_clf]\n",
    "\n",
    "# Prepare placeholder for predictions\n",
    "test_result['target'] = -33.2  # Default for outliers (will remain for outlier rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1be470",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "- Prepare trainset with no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1cf40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shapes:\n",
      "X_train_all: (159768, 237)\n",
      "X_test_com:  (39942, 237)\n",
      "y_train_all: (159768,)\n",
      "y_test_com:  (39942,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ‚úÖ RMSE metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# ‚úÖ Filter only non-outlier rows from training data\n",
    "non_outlier_train_mask = train['outliers'] == 0\n",
    "X_filtered = train.loc[non_outlier_train_mask, df_train_columns_clf]\n",
    "y_filtered = train.loc[non_outlier_train_mask, 'target']\n",
    "\n",
    "# ‚úÖ Split into train/test for regression model evaluation\n",
    "X_train_all, X_test_com, y_train_all, y_test_com = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.20, random_state=20\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Shapes:\")\n",
    "print(f\"X_train_all: {X_train_all.shape}\")\n",
    "print(f\"X_test_com:  {X_test_com.shape}\")\n",
    "print(f\"y_train_all: {y_train_all.shape}\")\n",
    "print(f\"y_test_com:  {y_test_com.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531fdc2",
   "metadata": {},
   "source": [
    "### Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d983d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Linear Regression: 1.73112\n",
      "Nulls in submission: 0\n",
      "           card_id    target\n",
      "0  C_ID_0ab67a22ab -0.031743\n",
      "1  C_ID_130fd0cbdd -0.031743\n",
      "2  C_ID_b709037bc5 -0.031743\n",
      "3  C_ID_d27d835a9f -0.031743\n",
      "4  C_ID_2b5e3df5c2 -0.031743\n",
      "üìÅ Submission saved to 'data/linear_ou_latest.csv'\n"
     ]
    }
   ],
   "source": [
    "# === PART 2: LINEAR REGRESSION (Non-Outliers Only, Clean Version) ===\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Train the model on non-outlier training data\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_all, y_train_all)\n",
    "\n",
    "# 2. Predict on validation set for internal performance check\n",
    "y_pred_linear = linear_model.predict(X_test_com)\n",
    "rmse_linear = rmse(y_test_com, y_pred_linear)\n",
    "print(f\"RMSE using Linear Regression: {rmse_linear:.5f}\")\n",
    "\n",
    "# 3. Predict on test rows not flagged as outliers\n",
    "linear_test_pred = linear_model.predict(test_features_for_reg)\n",
    "\n",
    "# 4. Create a copy of test_result and insert predictions only for non-outlier rows\n",
    "submission_linear = test_result.copy()\n",
    "submission_linear.loc[submission_linear['outlier'] == 0, 'target'] = linear_test_pred\n",
    "\n",
    "# 5. Prepare and save final submission\n",
    "final_submission = submission_linear[['card_id', 'target']].copy()\n",
    "print(\"Nulls in submission:\", final_submission.isnull().sum().sum())\n",
    "print(final_submission.head())\n",
    "\n",
    "final_submission.to_csv(\"linear_ou_latest.csv\", index=False)\n",
    "print(\"üìÅ Submission saved to 'data/linear_ou_latest.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10468902",
   "metadata": {},
   "source": [
    "## Model 2: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b108eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Ridge Regression: 1.60514\n",
      "Best hyperparameters for Ridge: {'alpha': 10}\n",
      "üîç Nulls in submission: 0\n",
      "           card_id    target\n",
      "0  C_ID_0ab67a22ab -0.187019\n",
      "1  C_ID_130fd0cbdd  0.386745\n",
      "2  C_ID_b709037bc5 -0.760468\n",
      "3  C_ID_d27d835a9f -0.544922\n",
      "4  C_ID_2b5e3df5c2 -2.676373\n",
      "Submission saved to 'data/ridge_latest_ou.csv'\n"
     ]
    }
   ],
   "source": [
    "# === PART 2: RIDGE REGRESSION (Non-Outliers Only, Clean Version) ===\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define model and hyperparameter grid\n",
    "ridge = Ridge()\n",
    "param_grid = {'alpha': [1e-4, 1e-3, 1e-2, 0.1, 1, 10]}\n",
    "\n",
    "# 2. Perform grid search\n",
    "ridge_regressor = GridSearchCV(\n",
    "    ridge,\n",
    "    param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "ridge_regressor.fit(X_train_all, y_train_all)\n",
    "\n",
    "# 3. Evaluate on validation split\n",
    "y_pred_ridge = ridge_regressor.predict(X_test_com)\n",
    "rmse_ridge = rmse(y_test_com, y_pred_ridge)\n",
    "print(\"RMSE using Ridge Regression: {:.5f}\".format(rmse_ridge))\n",
    "print(\"Best hyperparameters for Ridge:\", ridge_regressor.best_params_)\n",
    "\n",
    "# 4. Predict on non-outlier test set\n",
    "ridge_test_pred = ridge_regressor.predict(test_features_for_reg)\n",
    "\n",
    "# 5. Create clean submission\n",
    "submission_ridge = test_result.copy()\n",
    "submission_ridge.loc[submission_ridge['outlier'] == 0, 'target'] = ridge_test_pred\n",
    "\n",
    "# 6. Save submission\n",
    "final_submission = submission_ridge[['card_id', 'target']].copy()\n",
    "print(\"üîç Nulls in submission:\", final_submission.isnull().sum().sum())\n",
    "print(final_submission.head())\n",
    "\n",
    "final_submission.to_csv(\"ridge_latest_ou.csv\", index=False)\n",
    "print(\"Submission saved to 'data/ridge_latest_ou.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a85305",
   "metadata": {},
   "source": [
    "## Model 3: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b655944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Lasso Regression: 1.61352\n",
      "Best hyperparameters for Lasso: {'alpha': 0.1, 'max_iter': 1000}\n",
      "Nulls in submission: 0\n",
      "           card_id    target\n",
      "0  C_ID_0ab67a22ab -0.167480\n",
      "1  C_ID_130fd0cbdd -0.440430\n",
      "2  C_ID_b709037bc5 -0.464966\n",
      "3  C_ID_d27d835a9f -0.268555\n",
      "4  C_ID_2b5e3df5c2 -2.734863\n",
      "üìÅ Submission saved to 'data/lasso_latest_ou.csv'\n"
     ]
    }
   ],
   "source": [
    "# === PART 2: LASSO REGRESSION (Non-Outliers Only, Clean Version) ===\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define model and parameter grid\n",
    "lasso = Lasso()\n",
    "param_grid = {\n",
    "    'alpha': [1e-3, 1e-2, 1e-1],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# 2. Run GridSearchCV\n",
    "lasso_regressor = GridSearchCV(\n",
    "    lasso,\n",
    "    param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lasso_regressor.fit(X_train_all, y_train_all)\n",
    "\n",
    "# 3. Evaluate on validation split\n",
    "y_pred_lasso = lasso_regressor.predict(X_test_com)\n",
    "rmse_lasso = rmse(y_test_com, y_pred_lasso)\n",
    "print(\"RMSE using Lasso Regression: {:.5f}\".format(rmse_lasso))\n",
    "print(\"Best hyperparameters for Lasso:\", lasso_regressor.best_params_)\n",
    "\n",
    "# 4. Predict on non-outlier test set rows\n",
    "lasso_test_pred = lasso_regressor.predict(test_features_for_reg)\n",
    "\n",
    "# 5. Create clean submission\n",
    "submission_lasso = test_result.copy()\n",
    "submission_lasso.loc[submission_lasso['outlier'] == 0, 'target'] = lasso_test_pred\n",
    "\n",
    "# 6. Save submission\n",
    "final_submission = submission_lasso[['card_id', 'target']].copy()\n",
    "print(\"Nulls in submission:\", final_submission.isnull().sum().sum())\n",
    "print(final_submission.head())\n",
    "\n",
    "final_submission.to_csv(\"lasso_latest_ou.csv\", index=False)\n",
    "print(\"üìÅ Submission saved to 'data/lasso_latest_ou.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25d9f9",
   "metadata": {},
   "source": [
    "## Model 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9229805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      " RMSE using Random Forest: 1.67368\n",
      " Best hyperparameters for Random Forest: {'criterion': 'squared_error', 'max_depth': 5, 'max_features': 100, 'max_leaf_nodes': 5, 'min_impurity_decrease': 0.1, 'min_samples_split': 8, 'n_estimators': 1000}\n",
      "Nulls in submission: 0\n",
      "           card_id    target\n",
      "0  C_ID_0ab67a22ab -0.036689\n",
      "1  C_ID_130fd0cbdd -0.408318\n",
      "2  C_ID_b709037bc5 -0.382665\n",
      "3  C_ID_d27d835a9f -0.408318\n",
      "4  C_ID_2b5e3df5c2 -0.465860\n",
      " Submission saved to 'data/rf_latest_ou.csv'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"criterion\": [\"squared_error\"],\n",
    "    \"n_estimators\": [500, 1000],\n",
    "    \"max_depth\": [5, 10, 15],\n",
    "    \"max_leaf_nodes\": [5],\n",
    "    \"min_samples_split\": [8],\n",
    "    \"max_features\": [50, 100],\n",
    "    \"min_impurity_decrease\": [0.1]\n",
    "}\n",
    "\n",
    "# 2. Initialize model and run GridSearchCV\n",
    "forest_regressor = RandomForestRegressor(random_state=10)\n",
    "grid_forest = GridSearchCV(\n",
    "    forest_regressor,\n",
    "    param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=2,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_forest.fit(X_train_all, y_train_all)\n",
    "\n",
    "# 3. Evaluate on validation set\n",
    "y_pred_forest = grid_forest.predict(X_test_com)\n",
    "rmse_rf = rmse(y_test_com, y_pred_forest)\n",
    "print(\" RMSE using Random Forest: {:.5f}\".format(rmse_rf))\n",
    "print(\" Best hyperparameters for Random Forest:\", grid_forest.best_params_)\n",
    "\n",
    "# 4. Predict on non-outlier test set\n",
    "rf_test_pred = grid_forest.predict(test_features_for_reg)\n",
    "\n",
    "# 5. Create clean submission copy\n",
    "submission_rf = test_result.copy()\n",
    "submission_rf.loc[submission_rf['outlier'] == 0, 'target'] = rf_test_pred\n",
    "\n",
    "# 6. Save final submission\n",
    "final_submission = submission_rf[['card_id', 'target']].copy()\n",
    "print(\"Nulls in submission:\", final_submission.isnull().sum().sum())\n",
    "print(final_submission.head())\n",
    "\n",
    "final_submission.to_csv(\"rf_latest_ou.csv\", index=False)\n",
    "print(\" Submission saved to 'data/rf_latest_ou.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7195b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import gc\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "def lgb_objective(trial):\n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'device': 'cpu',\n",
    "        'seed': 326,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 64),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.001, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.001, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 12),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 10.0),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.0, 45.0),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 16, 64)\n",
    "    }\n",
    "\n",
    "    dtrain_lgb = lgb.Dataset(X_train_all, label=y_train_all, free_raw_data=False)\n",
    "\n",
    "    cv_result = lgb.cv(\n",
    "        params=lgb_params,\n",
    "        train_set=dtrain_lgb,\n",
    "        num_boost_round=10000,\n",
    "        nfold=3,\n",
    "        seed=47,\n",
    "        stratified=False,\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=200),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "    for key in cv_result:\n",
    "        if \"rmse-mean\" in key:\n",
    "            return cv_result[key][-1]\n",
    "\n",
    "    raise KeyError(\"Expected metric 'rmse-mean' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf2017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:46:07,341] A new study created in memory with name: no-name-483bdb48-e5c1-4c3c-a304-97a26777d4f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.6037 + 0.00657507\n",
      "[200]\tvalid's rmse: 1.57532 + 0.00575277\n",
      "[300]\tvalid's rmse: 1.56488 + 0.00530812\n",
      "[400]\tvalid's rmse: 1.56 + 0.00511818\n",
      "[500]\tvalid's rmse: 1.55727 + 0.00497773\n",
      "[600]\tvalid's rmse: 1.55566 + 0.00486237\n",
      "[700]\tvalid's rmse: 1.55469 + 0.00482902\n",
      "[800]\tvalid's rmse: 1.55414 + 0.00482574\n",
      "[900]\tvalid's rmse: 1.55379 + 0.00483888\n",
      "[1000]\tvalid's rmse: 1.55356 + 0.00477279\n",
      "[1100]\tvalid's rmse: 1.55347 + 0.0047459\n",
      "[1200]\tvalid's rmse: 1.55338 + 0.00469731\n",
      "[1300]\tvalid's rmse: 1.55332 + 0.00462164\n",
      "[1400]\tvalid's rmse: 1.55331 + 0.00456164\n",
      "[1500]\tvalid's rmse: 1.55331 + 0.00455019\n",
      "[1600]\tvalid's rmse: 1.55333 + 0.00453707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:46:33,288] Trial 0 finished with value: 1.5533001323896398 and parameters: {'num_leaves': 42, 'colsample_bytree': 0.37692751057866997, 'subsample': 0.46978199497844275, 'max_depth': 11, 'reg_alpha': 0.23693486293439814, 'reg_lambda': 0.7361224235435659, 'min_split_gain': 0.12442001060349428, 'min_child_weight': 29.838642338355235, 'min_data_in_leaf': 46}. Best is trial 0 with value: 1.5533001323896398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1460]\tvalid's rmse: 1.5533 + 0.00455734\n",
      "Trial 0: Initial best score set to 1.55330\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.59925 + 0.0064509\n",
      "[200]\tvalid's rmse: 1.57134 + 0.00543828\n",
      "[300]\tvalid's rmse: 1.56176 + 0.00498728\n",
      "[400]\tvalid's rmse: 1.55745 + 0.00477558\n",
      "[500]\tvalid's rmse: 1.55524 + 0.00464913\n",
      "[600]\tvalid's rmse: 1.55411 + 0.00456461\n",
      "[700]\tvalid's rmse: 1.55346 + 0.00452336\n",
      "[800]\tvalid's rmse: 1.55325 + 0.00452825\n",
      "[900]\tvalid's rmse: 1.55325 + 0.00453118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:46:52,359] Trial 1 finished with value: 1.553246339332967 and parameters: {'num_leaves': 62, 'colsample_bytree': 0.5394690104188404, 'subsample': 0.5487292412977833, 'max_depth': 11, 'reg_alpha': 3.6566727270294974, 'reg_lambda': 5.895113065517759, 'min_split_gain': 7.327100366071249, 'min_child_weight': 20.08236936649359, 'min_data_in_leaf': 34}. Best is trial 1 with value: 1.553246339332967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid's rmse: 1.55325 + 0.00453118\n",
      "Early stopping, best iteration is:\n",
      "[804]\tvalid's rmse: 1.55325 + 0.00453166\n",
      "Trial 1: Improved score: 1.55325 (Previous best: 1.55330)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60715 + 0.00676876\n",
      "[200]\tvalid's rmse: 1.57882 + 0.00591897\n",
      "[300]\tvalid's rmse: 1.56734 + 0.00549929\n",
      "[400]\tvalid's rmse: 1.56176 + 0.00520023\n",
      "[500]\tvalid's rmse: 1.55855 + 0.00507619\n",
      "[600]\tvalid's rmse: 1.55655 + 0.00500357\n",
      "[700]\tvalid's rmse: 1.55534 + 0.00486276\n",
      "[800]\tvalid's rmse: 1.55461 + 0.00484457\n",
      "[900]\tvalid's rmse: 1.55428 + 0.00487785\n",
      "[1000]\tvalid's rmse: 1.55422 + 0.00487999\n",
      "[1100]\tvalid's rmse: 1.5542 + 0.00487871\n",
      "[1200]\tvalid's rmse: 1.55419 + 0.00487812\n",
      "[1300]\tvalid's rmse: 1.55419 + 0.00487812\n",
      "Early stopping, best iteration is:\n",
      "[1127]\tvalid's rmse: 1.55419 + 0.00487812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:47:05,742] Trial 2 finished with value: 1.554194355417514 and parameters: {'num_leaves': 41, 'colsample_bytree': 0.23100498754733056, 'subsample': 0.14953432834844718, 'max_depth': 11, 'reg_alpha': 1.8220198195878512, 'reg_lambda': 1.6222300912772114, 'min_split_gain': 9.444331479324868, 'min_child_weight': 18.456694117058912, 'min_data_in_leaf': 16}. Best is trial 1 with value: 1.553246339332967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: No improvement. Counter = 1, Best Score = 1.55325\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.59961 + 0.00629225\n",
      "[200]\tvalid's rmse: 1.57208 + 0.00521834\n",
      "[300]\tvalid's rmse: 1.56272 + 0.00466593\n",
      "[400]\tvalid's rmse: 1.55835 + 0.00442091\n",
      "[500]\tvalid's rmse: 1.55619 + 0.0042675\n",
      "[600]\tvalid's rmse: 1.55487 + 0.00427442\n",
      "[700]\tvalid's rmse: 1.55408 + 0.00420475\n",
      "[800]\tvalid's rmse: 1.55373 + 0.00415616\n",
      "[900]\tvalid's rmse: 1.55362 + 0.00415955\n",
      "[1000]\tvalid's rmse: 1.55362 + 0.00415955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:47:29,592] Trial 3 finished with value: 1.5536199256080572 and parameters: {'num_leaves': 53, 'colsample_bytree': 0.877346361587851, 'subsample': 0.19265931541754414, 'max_depth': 11, 'reg_alpha': 3.963370935212076, 'reg_lambda': 1.0960837085247643, 'min_split_gain': 6.63668875312122, 'min_child_weight': 16.362993119052483, 'min_data_in_leaf': 33}. Best is trial 1 with value: 1.553246339332967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[895]\tvalid's rmse: 1.55362 + 0.00415955\n",
      "Trial 3: No improvement. Counter = 2, Best Score = 1.55325\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60278 + 0.00671202\n",
      "[200]\tvalid's rmse: 1.57435 + 0.00583535\n",
      "[300]\tvalid's rmse: 1.56382 + 0.00541517\n",
      "[400]\tvalid's rmse: 1.55901 + 0.00511559\n",
      "[500]\tvalid's rmse: 1.55645 + 0.00494847\n",
      "[600]\tvalid's rmse: 1.55483 + 0.0048787\n",
      "[700]\tvalid's rmse: 1.55394 + 0.00481925\n",
      "[800]\tvalid's rmse: 1.5534 + 0.00476959\n",
      "[900]\tvalid's rmse: 1.55308 + 0.00476242\n",
      "[1000]\tvalid's rmse: 1.55292 + 0.00475053\n",
      "[1100]\tvalid's rmse: 1.55281 + 0.00469957\n",
      "[1200]\tvalid's rmse: 1.55275 + 0.00463175\n",
      "[1300]\tvalid's rmse: 1.5527 + 0.00456234\n",
      "[1400]\tvalid's rmse: 1.55271 + 0.00451226\n",
      "[1500]\tvalid's rmse: 1.55276 + 0.00443407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:47:54,220] Trial 4 finished with value: 1.552685657057788 and parameters: {'num_leaves': 56, 'colsample_bytree': 0.31092474272896053, 'subsample': 0.7108765435141681, 'max_depth': 9, 'reg_alpha': 2.0525595868048905, 'reg_lambda': 9.107462002062745, 'min_split_gain': 1.507042482956863, 'min_child_weight': 17.41743271363207, 'min_data_in_leaf': 32}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1344]\tvalid's rmse: 1.55269 + 0.00455904\n",
      "Trial 4: Improved score: 1.55269 (Previous best: 1.55325)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.66712 + 0.00798861\n",
      "[200]\tvalid's rmse: 1.64741 + 0.00770002\n",
      "[300]\tvalid's rmse: 1.63501 + 0.00739065\n",
      "[400]\tvalid's rmse: 1.62699 + 0.00709917\n",
      "[500]\tvalid's rmse: 1.62141 + 0.00686071\n",
      "[600]\tvalid's rmse: 1.61709 + 0.00673067\n",
      "[700]\tvalid's rmse: 1.61347 + 0.00663205\n",
      "[800]\tvalid's rmse: 1.61038 + 0.00652748\n",
      "[900]\tvalid's rmse: 1.60774 + 0.00643731\n",
      "[1000]\tvalid's rmse: 1.60544 + 0.00636197\n",
      "[1100]\tvalid's rmse: 1.60341 + 0.0063021\n",
      "[1200]\tvalid's rmse: 1.60162 + 0.00624859\n",
      "[1300]\tvalid's rmse: 1.60002 + 0.00618939\n",
      "[1400]\tvalid's rmse: 1.59856 + 0.00613054\n",
      "[1500]\tvalid's rmse: 1.59723 + 0.00608245\n",
      "[1600]\tvalid's rmse: 1.596 + 0.00603586\n",
      "[1700]\tvalid's rmse: 1.59486 + 0.00598881\n",
      "[1800]\tvalid's rmse: 1.59381 + 0.00594909\n",
      "[1900]\tvalid's rmse: 1.59284 + 0.00591552\n",
      "[2000]\tvalid's rmse: 1.59194 + 0.00587976\n",
      "[2100]\tvalid's rmse: 1.5911 + 0.00585056\n",
      "[2200]\tvalid's rmse: 1.59031 + 0.00582195\n",
      "[2300]\tvalid's rmse: 1.58959 + 0.0057963\n",
      "[2400]\tvalid's rmse: 1.5889 + 0.00577117\n",
      "[2500]\tvalid's rmse: 1.58826 + 0.0057449\n",
      "[2600]\tvalid's rmse: 1.58766 + 0.00572967\n",
      "[2700]\tvalid's rmse: 1.58709 + 0.00570581\n",
      "[2800]\tvalid's rmse: 1.58655 + 0.00568289\n",
      "[2900]\tvalid's rmse: 1.58604 + 0.00565581\n",
      "[3000]\tvalid's rmse: 1.58556 + 0.00563488\n",
      "[3100]\tvalid's rmse: 1.58511 + 0.00560995\n",
      "[3200]\tvalid's rmse: 1.58469 + 0.00558153\n",
      "[3300]\tvalid's rmse: 1.58428 + 0.00556004\n",
      "[3400]\tvalid's rmse: 1.5839 + 0.00553787\n",
      "[3500]\tvalid's rmse: 1.58353 + 0.0055189\n",
      "[3600]\tvalid's rmse: 1.58317 + 0.00550133\n",
      "[3700]\tvalid's rmse: 1.58284 + 0.00547812\n",
      "[3800]\tvalid's rmse: 1.58251 + 0.00546419\n",
      "[3900]\tvalid's rmse: 1.58219 + 0.00544999\n",
      "[4000]\tvalid's rmse: 1.5819 + 0.00543219\n",
      "[4100]\tvalid's rmse: 1.58161 + 0.00541675\n",
      "[4200]\tvalid's rmse: 1.58133 + 0.00539846\n",
      "[4300]\tvalid's rmse: 1.58107 + 0.00538337\n",
      "[4400]\tvalid's rmse: 1.58082 + 0.00536691\n",
      "[4500]\tvalid's rmse: 1.58058 + 0.0053493\n",
      "[4600]\tvalid's rmse: 1.58035 + 0.00533453\n",
      "[4700]\tvalid's rmse: 1.58012 + 0.00531766\n",
      "[4800]\tvalid's rmse: 1.57991 + 0.0053\n",
      "[4900]\tvalid's rmse: 1.57971 + 0.00528726\n",
      "[5000]\tvalid's rmse: 1.57951 + 0.00526915\n",
      "[5100]\tvalid's rmse: 1.57932 + 0.00525566\n",
      "[5200]\tvalid's rmse: 1.57914 + 0.00524486\n",
      "[5300]\tvalid's rmse: 1.57896 + 0.00523174\n",
      "[5400]\tvalid's rmse: 1.57878 + 0.00521899\n",
      "[5500]\tvalid's rmse: 1.57862 + 0.00520868\n",
      "[5600]\tvalid's rmse: 1.57845 + 0.00519834\n",
      "[5700]\tvalid's rmse: 1.5783 + 0.00518873\n",
      "[5800]\tvalid's rmse: 1.57814 + 0.00517729\n",
      "[5900]\tvalid's rmse: 1.57799 + 0.00516652\n",
      "[6000]\tvalid's rmse: 1.57785 + 0.00515866\n",
      "[6100]\tvalid's rmse: 1.57771 + 0.00515119\n",
      "[6200]\tvalid's rmse: 1.57758 + 0.00514317\n",
      "[6300]\tvalid's rmse: 1.57744 + 0.00513213\n",
      "[6400]\tvalid's rmse: 1.57731 + 0.00512545\n",
      "[6500]\tvalid's rmse: 1.57719 + 0.00511663\n",
      "[6600]\tvalid's rmse: 1.57707 + 0.00510846\n",
      "[6700]\tvalid's rmse: 1.57695 + 0.00510164\n",
      "[6800]\tvalid's rmse: 1.57684 + 0.00509526\n",
      "[6900]\tvalid's rmse: 1.57672 + 0.00508459\n",
      "[7000]\tvalid's rmse: 1.57661 + 0.0050771\n",
      "[7100]\tvalid's rmse: 1.57651 + 0.00506692\n",
      "[7200]\tvalid's rmse: 1.5764 + 0.00505989\n",
      "[7300]\tvalid's rmse: 1.5763 + 0.00505352\n",
      "[7400]\tvalid's rmse: 1.57621 + 0.00504679\n",
      "[7500]\tvalid's rmse: 1.57611 + 0.00503932\n",
      "[7600]\tvalid's rmse: 1.57602 + 0.00503427\n",
      "[7700]\tvalid's rmse: 1.57593 + 0.0050269\n",
      "[7800]\tvalid's rmse: 1.57584 + 0.0050197\n",
      "[7900]\tvalid's rmse: 1.57575 + 0.00501179\n",
      "[8000]\tvalid's rmse: 1.57567 + 0.00500886\n",
      "[8100]\tvalid's rmse: 1.57559 + 0.00500229\n",
      "[8200]\tvalid's rmse: 1.57551 + 0.00499871\n",
      "[8300]\tvalid's rmse: 1.57543 + 0.00499253\n",
      "[8400]\tvalid's rmse: 1.57535 + 0.00498979\n",
      "[8500]\tvalid's rmse: 1.57528 + 0.00498522\n",
      "[8600]\tvalid's rmse: 1.57521 + 0.00498303\n",
      "[8700]\tvalid's rmse: 1.57514 + 0.00497709\n",
      "[8800]\tvalid's rmse: 1.57507 + 0.00497607\n",
      "[8900]\tvalid's rmse: 1.575 + 0.00497377\n",
      "[9000]\tvalid's rmse: 1.57493 + 0.00497152\n",
      "[9100]\tvalid's rmse: 1.57487 + 0.00496959\n",
      "[9200]\tvalid's rmse: 1.5748 + 0.00496715\n",
      "[9300]\tvalid's rmse: 1.57474 + 0.00496524\n",
      "[9400]\tvalid's rmse: 1.57468 + 0.00496556\n",
      "[9500]\tvalid's rmse: 1.57462 + 0.00496023\n",
      "[9600]\tvalid's rmse: 1.57456 + 0.00495813\n",
      "[9700]\tvalid's rmse: 1.57451 + 0.00495547\n",
      "[9800]\tvalid's rmse: 1.57445 + 0.0049512\n",
      "[9900]\tvalid's rmse: 1.5744 + 0.00495018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:49:11,598] Trial 5 finished with value: 1.5743415718117024 and parameters: {'num_leaves': 63, 'colsample_bytree': 0.9330628082301959, 'subsample': 0.7655773686542127, 'max_depth': 1, 'reg_alpha': 8.742691060136428, 'reg_lambda': 6.289266040766477, 'min_split_gain': 4.761966425046721, 'min_child_weight': 41.871180714629524, 'min_data_in_leaf': 39}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\tvalid's rmse: 1.57434 + 0.00494415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid's rmse: 1.57434 + 0.00494415\n",
      "Trial 5: No improvement. Counter = 1, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.64271 + 0.00753649\n",
      "[200]\tvalid's rmse: 1.61929 + 0.00677869\n",
      "[300]\tvalid's rmse: 1.6077 + 0.00630985\n",
      "[400]\tvalid's rmse: 1.59992 + 0.00608171\n",
      "[500]\tvalid's rmse: 1.5943 + 0.00585296\n",
      "[600]\tvalid's rmse: 1.58992 + 0.00571436\n",
      "[700]\tvalid's rmse: 1.58631 + 0.00559075\n",
      "[800]\tvalid's rmse: 1.58344 + 0.00543862\n",
      "[900]\tvalid's rmse: 1.58099 + 0.00524777\n",
      "[1000]\tvalid's rmse: 1.57884 + 0.00517216\n",
      "[1100]\tvalid's rmse: 1.577 + 0.00511709\n",
      "[1200]\tvalid's rmse: 1.5754 + 0.00508242\n",
      "[1300]\tvalid's rmse: 1.57397 + 0.00506979\n",
      "[1400]\tvalid's rmse: 1.57276 + 0.00506206\n",
      "[1500]\tvalid's rmse: 1.57166 + 0.00503678\n",
      "[1600]\tvalid's rmse: 1.57071 + 0.00501581\n",
      "[1700]\tvalid's rmse: 1.56988 + 0.00494725\n",
      "[1800]\tvalid's rmse: 1.56913 + 0.00490869\n",
      "[1900]\tvalid's rmse: 1.56846 + 0.00488036\n",
      "[2000]\tvalid's rmse: 1.56787 + 0.00484724\n",
      "[2100]\tvalid's rmse: 1.56733 + 0.0048236\n",
      "[2200]\tvalid's rmse: 1.56685 + 0.00480738\n",
      "[2300]\tvalid's rmse: 1.5664 + 0.00478005\n",
      "[2400]\tvalid's rmse: 1.56598 + 0.00474095\n",
      "[2500]\tvalid's rmse: 1.56561 + 0.00472102\n",
      "[2600]\tvalid's rmse: 1.56525 + 0.00467813\n",
      "[2700]\tvalid's rmse: 1.56491 + 0.00464829\n",
      "[2800]\tvalid's rmse: 1.56463 + 0.00462539\n",
      "[2900]\tvalid's rmse: 1.56434 + 0.0046004\n",
      "[3000]\tvalid's rmse: 1.56405 + 0.00458929\n",
      "[3100]\tvalid's rmse: 1.5638 + 0.00457519\n",
      "[3200]\tvalid's rmse: 1.56356 + 0.0045488\n",
      "[3300]\tvalid's rmse: 1.56334 + 0.00452901\n",
      "[3400]\tvalid's rmse: 1.56313 + 0.00451476\n",
      "[3500]\tvalid's rmse: 1.56293 + 0.00450574\n",
      "[3600]\tvalid's rmse: 1.56275 + 0.00448499\n",
      "[3700]\tvalid's rmse: 1.56257 + 0.00449321\n",
      "[3800]\tvalid's rmse: 1.56242 + 0.00449505\n",
      "[3900]\tvalid's rmse: 1.56225 + 0.00448692\n",
      "[4000]\tvalid's rmse: 1.56211 + 0.00448131\n",
      "[4100]\tvalid's rmse: 1.56197 + 0.00447628\n",
      "[4200]\tvalid's rmse: 1.56184 + 0.00445727\n",
      "[4300]\tvalid's rmse: 1.5617 + 0.00444602\n",
      "[4400]\tvalid's rmse: 1.56158 + 0.00445914\n",
      "[4500]\tvalid's rmse: 1.56146 + 0.0044762\n",
      "[4600]\tvalid's rmse: 1.56135 + 0.00448161\n",
      "[4700]\tvalid's rmse: 1.56123 + 0.00449427\n",
      "[4800]\tvalid's rmse: 1.5611 + 0.00451075\n",
      "[4900]\tvalid's rmse: 1.561 + 0.00450892\n",
      "[5000]\tvalid's rmse: 1.5609 + 0.00452636\n",
      "[5100]\tvalid's rmse: 1.56081 + 0.00454062\n",
      "[5200]\tvalid's rmse: 1.56071 + 0.00454545\n",
      "[5300]\tvalid's rmse: 1.56063 + 0.00455324\n",
      "[5400]\tvalid's rmse: 1.56058 + 0.0045584\n",
      "[5500]\tvalid's rmse: 1.56057 + 0.00457307\n",
      "[5600]\tvalid's rmse: 1.56055 + 0.00459862\n",
      "[5700]\tvalid's rmse: 1.56053 + 0.00461168\n",
      "[5800]\tvalid's rmse: 1.56053 + 0.00461168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:50:04,364] Trial 6 finished with value: 1.560533137823749 and parameters: {'num_leaves': 59, 'colsample_bytree': 0.862529714605889, 'subsample': 0.44810658642300544, 'max_depth': 2, 'reg_alpha': 5.888956378674234, 'reg_lambda': 4.156748997192095, 'min_split_gain': 6.200494612864969, 'min_child_weight': 39.55402345593559, 'min_data_in_leaf': 56}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5665]\tvalid's rmse: 1.56053 + 0.00461194\n",
      "Trial 6: No improvement. Counter = 2, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.59914 + 0.00647995\n",
      "[200]\tvalid's rmse: 1.57126 + 0.00547037\n",
      "[300]\tvalid's rmse: 1.56179 + 0.00502289\n",
      "[400]\tvalid's rmse: 1.55743 + 0.00475659\n",
      "[500]\tvalid's rmse: 1.55522 + 0.00455392\n",
      "[600]\tvalid's rmse: 1.55407 + 0.00449697\n",
      "[700]\tvalid's rmse: 1.55358 + 0.0045107\n",
      "[800]\tvalid's rmse: 1.55354 + 0.00453226\n",
      "[900]\tvalid's rmse: 1.55354 + 0.00453226\n",
      "Early stopping, best iteration is:\n",
      "[739]\tvalid's rmse: 1.55354 + 0.00453226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:50:21,359] Trial 7 finished with value: 1.5535371639912248 and parameters: {'num_leaves': 58, 'colsample_bytree': 0.683507869714594, 'subsample': 0.5837319741571481, 'max_depth': 12, 'reg_alpha': 9.482165235433824, 'reg_lambda': 0.25749723525223533, 'min_split_gain': 7.8987270257831, 'min_child_weight': 43.82593483217144, 'min_data_in_leaf': 51}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7: No improvement. Counter = 3, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.64494 + 0.00733503\n",
      "[200]\tvalid's rmse: 1.61982 + 0.00664274\n",
      "[300]\tvalid's rmse: 1.60425 + 0.00598603\n",
      "[400]\tvalid's rmse: 1.59532 + 0.00565126\n",
      "[500]\tvalid's rmse: 1.58765 + 0.00536472\n",
      "[600]\tvalid's rmse: 1.583 + 0.0052328\n",
      "[700]\tvalid's rmse: 1.57867 + 0.00510187\n",
      "[800]\tvalid's rmse: 1.57543 + 0.00496364\n",
      "[900]\tvalid's rmse: 1.57243 + 0.00489853\n",
      "[1000]\tvalid's rmse: 1.5702 + 0.00488384\n",
      "[1100]\tvalid's rmse: 1.56863 + 0.0048299\n",
      "[1200]\tvalid's rmse: 1.56685 + 0.00480677\n",
      "[1300]\tvalid's rmse: 1.56571 + 0.00482412\n",
      "[1400]\tvalid's rmse: 1.56463 + 0.0048045\n",
      "[1500]\tvalid's rmse: 1.56362 + 0.004793\n",
      "[1600]\tvalid's rmse: 1.56254 + 0.00477316\n",
      "[1700]\tvalid's rmse: 1.5618 + 0.00476688\n",
      "[1800]\tvalid's rmse: 1.56111 + 0.00475655\n",
      "[1900]\tvalid's rmse: 1.56043 + 0.00474604\n",
      "[2000]\tvalid's rmse: 1.55981 + 0.00473289\n",
      "[2100]\tvalid's rmse: 1.55917 + 0.00471167\n",
      "[2200]\tvalid's rmse: 1.55877 + 0.00469019\n",
      "[2300]\tvalid's rmse: 1.55846 + 0.0046965\n",
      "[2400]\tvalid's rmse: 1.55816 + 0.00469525\n",
      "[2500]\tvalid's rmse: 1.55797 + 0.00468914\n",
      "[2600]\tvalid's rmse: 1.55768 + 0.00468987\n",
      "[2700]\tvalid's rmse: 1.55747 + 0.00470199\n",
      "[2800]\tvalid's rmse: 1.55725 + 0.00468216\n",
      "[2900]\tvalid's rmse: 1.55702 + 0.00467345\n",
      "[3000]\tvalid's rmse: 1.55683 + 0.00468398\n",
      "[3100]\tvalid's rmse: 1.55668 + 0.00467294\n",
      "[3200]\tvalid's rmse: 1.55654 + 0.00468552\n",
      "[3300]\tvalid's rmse: 1.55644 + 0.00466877\n",
      "[3400]\tvalid's rmse: 1.55635 + 0.00467417\n",
      "[3500]\tvalid's rmse: 1.55623 + 0.00467372\n",
      "[3600]\tvalid's rmse: 1.55616 + 0.00466166\n",
      "[3700]\tvalid's rmse: 1.55608 + 0.00466154\n",
      "[3800]\tvalid's rmse: 1.556 + 0.00465975\n",
      "[3900]\tvalid's rmse: 1.55596 + 0.00465275\n",
      "[4000]\tvalid's rmse: 1.55594 + 0.00463802\n",
      "[4100]\tvalid's rmse: 1.55587 + 0.00460554\n",
      "[4200]\tvalid's rmse: 1.55579 + 0.00460005\n",
      "[4300]\tvalid's rmse: 1.55577 + 0.00458792\n",
      "[4400]\tvalid's rmse: 1.55572 + 0.00461109\n",
      "[4500]\tvalid's rmse: 1.5557 + 0.00459324\n",
      "[4600]\tvalid's rmse: 1.55568 + 0.00457975\n",
      "[4700]\tvalid's rmse: 1.55565 + 0.0045842\n",
      "[4800]\tvalid's rmse: 1.55562 + 0.00458182\n",
      "[4900]\tvalid's rmse: 1.55562 + 0.00459301\n",
      "[5000]\tvalid's rmse: 1.55562 + 0.00460188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:50:52,441] Trial 8 finished with value: 1.5556050796358976 and parameters: {'num_leaves': 59, 'colsample_bytree': 0.0325988384609827, 'subsample': 0.818570016153064, 'max_depth': 5, 'reg_alpha': 0.784230034155512, 'reg_lambda': 5.015648270562213, 'min_split_gain': 1.4815730528354643, 'min_child_weight': 32.63798294917918, 'min_data_in_leaf': 25}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4879]\tvalid's rmse: 1.55561 + 0.00458749\n",
      "Trial 8: No improvement. Counter = 4, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.61185 + 0.00693394\n",
      "[200]\tvalid's rmse: 1.58376 + 0.00632597\n",
      "[300]\tvalid's rmse: 1.57209 + 0.00578992\n",
      "[400]\tvalid's rmse: 1.56611 + 0.00550089\n",
      "[500]\tvalid's rmse: 1.56237 + 0.00529643\n",
      "[600]\tvalid's rmse: 1.55996 + 0.00515831\n",
      "[700]\tvalid's rmse: 1.55825 + 0.00506631\n",
      "[800]\tvalid's rmse: 1.55707 + 0.00503179\n",
      "[900]\tvalid's rmse: 1.55624 + 0.00494367\n",
      "[1000]\tvalid's rmse: 1.55568 + 0.00489682\n",
      "[1100]\tvalid's rmse: 1.55522 + 0.00488098\n",
      "[1200]\tvalid's rmse: 1.55489 + 0.00483774\n",
      "[1300]\tvalid's rmse: 1.55463 + 0.00475761\n",
      "[1400]\tvalid's rmse: 1.55448 + 0.00475179\n",
      "[1500]\tvalid's rmse: 1.55446 + 0.00476522\n",
      "[1600]\tvalid's rmse: 1.55445 + 0.00476594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:51:10,477] Trial 9 finished with value: 1.5544523414280313 and parameters: {'num_leaves': 29, 'colsample_bytree': 0.28953392910121134, 'subsample': 0.21614310632765446, 'max_depth': 5, 'reg_alpha': 5.370880522407554, 'reg_lambda': 7.8764446518610045, 'min_split_gain': 6.775834045953674, 'min_child_weight': 33.959621074550704, 'min_data_in_leaf': 55}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1444]\tvalid's rmse: 1.55445 + 0.00476814\n",
      "Trial 9: No improvement. Counter = 5, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.6563 + 0.00755386\n",
      "[200]\tvalid's rmse: 1.62938 + 0.00693178\n",
      "[300]\tvalid's rmse: 1.61451 + 0.00645831\n",
      "[400]\tvalid's rmse: 1.60474 + 0.00605112\n",
      "[500]\tvalid's rmse: 1.59773 + 0.00570823\n",
      "[600]\tvalid's rmse: 1.59387 + 0.00550216\n",
      "[700]\tvalid's rmse: 1.58935 + 0.00532982\n",
      "[800]\tvalid's rmse: 1.58581 + 0.00518717\n",
      "[900]\tvalid's rmse: 1.58265 + 0.00503995\n",
      "[1000]\tvalid's rmse: 1.58 + 0.00491038\n",
      "[1100]\tvalid's rmse: 1.57774 + 0.00480994\n",
      "[1200]\tvalid's rmse: 1.57594 + 0.00472976\n",
      "[1300]\tvalid's rmse: 1.57418 + 0.00470251\n",
      "[1400]\tvalid's rmse: 1.57283 + 0.00464404\n",
      "[1500]\tvalid's rmse: 1.57144 + 0.00459969\n",
      "[1600]\tvalid's rmse: 1.57039 + 0.00459149\n",
      "[1700]\tvalid's rmse: 1.5693 + 0.00459413\n",
      "[1800]\tvalid's rmse: 1.56825 + 0.00457998\n",
      "[1900]\tvalid's rmse: 1.5674 + 0.00456119\n",
      "[2000]\tvalid's rmse: 1.56664 + 0.00454766\n",
      "[2100]\tvalid's rmse: 1.56592 + 0.00454603\n",
      "[2200]\tvalid's rmse: 1.56541 + 0.00452644\n",
      "[2300]\tvalid's rmse: 1.56485 + 0.00452087\n",
      "[2400]\tvalid's rmse: 1.56426 + 0.0045081\n",
      "[2500]\tvalid's rmse: 1.56372 + 0.00451631\n",
      "[2600]\tvalid's rmse: 1.56331 + 0.00450713\n",
      "[2700]\tvalid's rmse: 1.56296 + 0.00452908\n",
      "[2800]\tvalid's rmse: 1.56263 + 0.00452907\n",
      "[2900]\tvalid's rmse: 1.56232 + 0.00451728\n",
      "[3000]\tvalid's rmse: 1.56205 + 0.00450159\n",
      "[3100]\tvalid's rmse: 1.56167 + 0.00449922\n",
      "[3200]\tvalid's rmse: 1.56136 + 0.00449866\n",
      "[3300]\tvalid's rmse: 1.56106 + 0.00448831\n",
      "[3400]\tvalid's rmse: 1.56086 + 0.00449282\n",
      "[3500]\tvalid's rmse: 1.56063 + 0.00449518\n",
      "[3600]\tvalid's rmse: 1.56046 + 0.00450394\n",
      "[3700]\tvalid's rmse: 1.5603 + 0.00450439\n",
      "[3800]\tvalid's rmse: 1.56016 + 0.00449554\n",
      "[3900]\tvalid's rmse: 1.56 + 0.00447628\n",
      "[4000]\tvalid's rmse: 1.55988 + 0.00446489\n",
      "[4100]\tvalid's rmse: 1.55977 + 0.00445801\n",
      "[4200]\tvalid's rmse: 1.55963 + 0.00445114\n",
      "[4300]\tvalid's rmse: 1.55947 + 0.00443222\n",
      "[4400]\tvalid's rmse: 1.55934 + 0.00441638\n",
      "[4500]\tvalid's rmse: 1.55921 + 0.0044411\n",
      "[4600]\tvalid's rmse: 1.55909 + 0.00445739\n",
      "[4700]\tvalid's rmse: 1.55902 + 0.00445947\n",
      "[4800]\tvalid's rmse: 1.55892 + 0.00448306\n",
      "[4900]\tvalid's rmse: 1.55887 + 0.00448053\n",
      "[5000]\tvalid's rmse: 1.55883 + 0.00448042\n",
      "[5100]\tvalid's rmse: 1.55879 + 0.00447403\n",
      "[5200]\tvalid's rmse: 1.55873 + 0.00447466\n",
      "[5300]\tvalid's rmse: 1.55867 + 0.00447546\n",
      "[5400]\tvalid's rmse: 1.55863 + 0.00446553\n",
      "[5500]\tvalid's rmse: 1.5586 + 0.00448634\n",
      "[5600]\tvalid's rmse: 1.55855 + 0.00447419\n",
      "[5700]\tvalid's rmse: 1.55855 + 0.00446995\n",
      "[5800]\tvalid's rmse: 1.55854 + 0.00447613\n",
      "[5900]\tvalid's rmse: 1.55854 + 0.00446889\n",
      "[6000]\tvalid's rmse: 1.55852 + 0.00445895\n",
      "[6100]\tvalid's rmse: 1.55852 + 0.00446162\n",
      "[6200]\tvalid's rmse: 1.55852 + 0.00446496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:51:41,200] Trial 10 finished with value: 1.5585122594158756 and parameters: {'num_leaves': 16, 'colsample_bytree': 0.0226371378090649, 'subsample': 0.9989292546994215, 'max_depth': 8, 'reg_alpha': 2.41162062273833, 'reg_lambda': 9.62510324240721, 'min_split_gain': 2.992269974388675, 'min_child_weight': 3.2823040643190957, 'min_data_in_leaf': 24}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6074]\tvalid's rmse: 1.55851 + 0.004461\n",
      "Trial 10: No improvement. Counter = 6, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60118 + 0.00651911\n",
      "[200]\tvalid's rmse: 1.57293 + 0.00550644\n",
      "[300]\tvalid's rmse: 1.56307 + 0.00497737\n",
      "[400]\tvalid's rmse: 1.55853 + 0.00479666\n",
      "[500]\tvalid's rmse: 1.55613 + 0.00456133\n",
      "[600]\tvalid's rmse: 1.55478 + 0.00452807\n",
      "[700]\tvalid's rmse: 1.55401 + 0.00454513\n",
      "[800]\tvalid's rmse: 1.55358 + 0.0045596\n",
      "[900]\tvalid's rmse: 1.55332 + 0.00449522\n",
      "[1000]\tvalid's rmse: 1.55321 + 0.00442984\n",
      "[1100]\tvalid's rmse: 1.55313 + 0.00440308\n",
      "[1200]\tvalid's rmse: 1.55313 + 0.00432602\n",
      "[1300]\tvalid's rmse: 1.55314 + 0.00429434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:52:04,572] Trial 11 finished with value: 1.5531009259336752 and parameters: {'num_leaves': 50, 'colsample_bytree': 0.5493674140219386, 'subsample': 0.6213353956792792, 'max_depth': 8, 'reg_alpha': 3.718324197975887, 'reg_lambda': 9.740746166101555, 'min_split_gain': 4.215088944866796, 'min_child_weight': 8.257746156296554, 'min_data_in_leaf': 34}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid's rmse: 1.5531 + 0.00435169\n",
      "Trial 11: No improvement. Counter = 7, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60146 + 0.00661479\n",
      "[200]\tvalid's rmse: 1.57321 + 0.00571593\n",
      "[300]\tvalid's rmse: 1.56331 + 0.00520038\n",
      "[400]\tvalid's rmse: 1.55869 + 0.00492736\n",
      "[500]\tvalid's rmse: 1.55637 + 0.00473294\n",
      "[600]\tvalid's rmse: 1.555 + 0.00461004\n",
      "[700]\tvalid's rmse: 1.55417 + 0.00454842\n",
      "[800]\tvalid's rmse: 1.55371 + 0.00450991\n",
      "[900]\tvalid's rmse: 1.55344 + 0.0045043\n",
      "[1000]\tvalid's rmse: 1.55329 + 0.00447089\n",
      "[1100]\tvalid's rmse: 1.55315 + 0.00448105\n",
      "[1200]\tvalid's rmse: 1.55311 + 0.00445988\n",
      "[1300]\tvalid's rmse: 1.55312 + 0.00444269\n",
      "[1400]\tvalid's rmse: 1.55313 + 0.00439989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:52:29,800] Trial 12 finished with value: 1.5530931527953282 and parameters: {'num_leaves': 49, 'colsample_bytree': 0.559288888233924, 'subsample': 0.7303064055347396, 'max_depth': 8, 'reg_alpha': 7.038931471958094, 'reg_lambda': 9.872818339897961, 'min_split_gain': 3.3195861273048597, 'min_child_weight': 7.912074026276446, 'min_data_in_leaf': 64}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1266]\tvalid's rmse: 1.55309 + 0.00444513\n",
      "Trial 12: No improvement. Counter = 8, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60104 + 0.00652687\n",
      "[200]\tvalid's rmse: 1.57297 + 0.00539812\n",
      "[300]\tvalid's rmse: 1.56325 + 0.00497037\n",
      "[400]\tvalid's rmse: 1.55866 + 0.00476479\n",
      "[500]\tvalid's rmse: 1.55633 + 0.00460729\n",
      "[600]\tvalid's rmse: 1.555 + 0.00457455\n",
      "[700]\tvalid's rmse: 1.55418 + 0.00451308\n",
      "[800]\tvalid's rmse: 1.55374 + 0.00451251\n",
      "[900]\tvalid's rmse: 1.5535 + 0.00445986\n",
      "[1000]\tvalid's rmse: 1.55338 + 0.00446216\n",
      "[1100]\tvalid's rmse: 1.55334 + 0.0044485\n",
      "[1200]\tvalid's rmse: 1.55338 + 0.00442444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:52:55,346] Trial 13 finished with value: 1.55332912919115 and parameters: {'num_leaves': 48, 'colsample_bytree': 0.6883005171634258, 'subsample': 0.7941489305842991, 'max_depth': 8, 'reg_alpha': 7.25168377462146, 'reg_lambda': 8.23581509030992, 'min_split_gain': 2.5418146076811023, 'min_child_weight': 11.708813548529644, 'min_data_in_leaf': 64}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1038]\tvalid's rmse: 1.55333 + 0.00445616\n",
      "Trial 13: No improvement. Counter = 9, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60722 + 0.00680266\n",
      "[200]\tvalid's rmse: 1.57905 + 0.00606161\n",
      "[300]\tvalid's rmse: 1.56805 + 0.00552153\n",
      "[400]\tvalid's rmse: 1.56254 + 0.00518464\n",
      "[500]\tvalid's rmse: 1.55949 + 0.00500138\n",
      "[600]\tvalid's rmse: 1.55744 + 0.00486487\n",
      "[700]\tvalid's rmse: 1.55618 + 0.00474206\n",
      "[800]\tvalid's rmse: 1.55528 + 0.00471659\n",
      "[900]\tvalid's rmse: 1.55469 + 0.0047058\n",
      "[1000]\tvalid's rmse: 1.55427 + 0.00469683\n",
      "[1100]\tvalid's rmse: 1.55394 + 0.00466837\n",
      "[1200]\tvalid's rmse: 1.55374 + 0.00464775\n",
      "[1300]\tvalid's rmse: 1.55359 + 0.00461553\n",
      "[1400]\tvalid's rmse: 1.55348 + 0.00460166\n",
      "[1500]\tvalid's rmse: 1.5534 + 0.00457894\n",
      "[1600]\tvalid's rmse: 1.55331 + 0.00457853\n",
      "[1700]\tvalid's rmse: 1.5533 + 0.00452643\n",
      "[1800]\tvalid's rmse: 1.55334 + 0.00450538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:53:24,750] Trial 14 finished with value: 1.5532851423999412 and parameters: {'num_leaves': 32, 'colsample_bytree': 0.40512397339316375, 'subsample': 0.9981653664650897, 'max_depth': 6, 'reg_alpha': 7.223760959579337, 'reg_lambda': 7.93826142833742, 'min_split_gain': 0.3296204941148029, 'min_child_weight': 2.5015910635281386, 'min_data_in_leaf': 63}. Best is trial 4 with value: 1.552685657057788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1641]\tvalid's rmse: 1.55329 + 0.00456021\n",
      "Trial 14: No improvement. Counter = 10, Best Score = 1.55269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60785 + 0.00674015\n",
      "[200]\tvalid's rmse: 1.57858 + 0.00593477\n",
      "[300]\tvalid's rmse: 1.56705 + 0.00557435\n",
      "[400]\tvalid's rmse: 1.56127 + 0.00532061\n",
      "[500]\tvalid's rmse: 1.55823 + 0.00516439\n",
      "[600]\tvalid's rmse: 1.55634 + 0.00511956\n",
      "[700]\tvalid's rmse: 1.55502 + 0.00501952\n",
      "[800]\tvalid's rmse: 1.55419 + 0.00502604\n",
      "[900]\tvalid's rmse: 1.55359 + 0.00501251\n",
      "[1000]\tvalid's rmse: 1.55325 + 0.00494232\n",
      "[1100]\tvalid's rmse: 1.55301 + 0.00494452\n",
      "[1200]\tvalid's rmse: 1.55285 + 0.00495154\n",
      "[1300]\tvalid's rmse: 1.55273 + 0.00492018\n",
      "[1400]\tvalid's rmse: 1.55261 + 0.00487524\n",
      "[1500]\tvalid's rmse: 1.55259 + 0.00486404\n",
      "[1600]\tvalid's rmse: 1.55261 + 0.00484848\n",
      "[1700]\tvalid's rmse: 1.55262 + 0.00480712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:53:47,252] Trial 15 finished with value: 1.552587900356654 and parameters: {'num_leaves': 49, 'colsample_bytree': 0.17813737707712285, 'subsample': 0.335990676440344, 'max_depth': 9, 'reg_alpha': 6.9604181385472605, 'reg_lambda': 9.829256500060684, 'min_split_gain': 3.3033480174852747, 'min_child_weight': 23.892386140038887, 'min_data_in_leaf': 46}. Best is trial 15 with value: 1.552587900356654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1572]\tvalid's rmse: 1.55259 + 0.00485477\n",
      "Trial 15: Improved score: 1.55259 (Previous best: 1.55269)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.61178 + 0.00675728\n",
      "[200]\tvalid's rmse: 1.58224 + 0.00591601\n",
      "[300]\tvalid's rmse: 1.57031 + 0.0054721\n",
      "[400]\tvalid's rmse: 1.56388 + 0.00513918\n",
      "[500]\tvalid's rmse: 1.56014 + 0.00498067\n",
      "[600]\tvalid's rmse: 1.55784 + 0.00487186\n",
      "[700]\tvalid's rmse: 1.55643 + 0.00480941\n",
      "[800]\tvalid's rmse: 1.55548 + 0.00476032\n",
      "[900]\tvalid's rmse: 1.55479 + 0.00473856\n",
      "[1000]\tvalid's rmse: 1.55431 + 0.00471912\n",
      "[1100]\tvalid's rmse: 1.55403 + 0.00469477\n",
      "[1200]\tvalid's rmse: 1.55374 + 0.00464814\n",
      "[1300]\tvalid's rmse: 1.55356 + 0.00461246\n",
      "[1400]\tvalid's rmse: 1.55346 + 0.00454134\n",
      "[1500]\tvalid's rmse: 1.55335 + 0.0045051\n",
      "[1600]\tvalid's rmse: 1.55328 + 0.00444457\n",
      "[1700]\tvalid's rmse: 1.55325 + 0.00439419\n",
      "[1800]\tvalid's rmse: 1.5532 + 0.00433371\n",
      "[1900]\tvalid's rmse: 1.55315 + 0.00429481\n",
      "[2000]\tvalid's rmse: 1.55312 + 0.00423316\n",
      "[2100]\tvalid's rmse: 1.55311 + 0.00424976\n",
      "[2200]\tvalid's rmse: 1.55311 + 0.00422013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:54:06,991] Trial 16 finished with value: 1.5530841109016755 and parameters: {'num_leaves': 34, 'colsample_bytree': 0.169613095627632, 'subsample': 0.0028016372663065003, 'max_depth': 9, 'reg_alpha': 2.621784505247498, 'reg_lambda': 3.5407114898253105, 'min_split_gain': 2.0101789408045048, 'min_child_weight': 25.38936992252546, 'min_data_in_leaf': 44}. Best is trial 15 with value: 1.552587900356654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2072]\tvalid's rmse: 1.55308 + 0.00425123\n",
      "Trial 16: No improvement. Counter = 1, Best Score = 1.55259\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.61122 + 0.00675536\n",
      "[200]\tvalid's rmse: 1.58172 + 0.00593746\n",
      "[300]\tvalid's rmse: 1.56985 + 0.0054644\n",
      "[400]\tvalid's rmse: 1.56374 + 0.00520727\n",
      "[500]\tvalid's rmse: 1.56009 + 0.00499844\n",
      "[600]\tvalid's rmse: 1.5577 + 0.00489138\n",
      "[700]\tvalid's rmse: 1.55617 + 0.00477355\n",
      "[800]\tvalid's rmse: 1.55512 + 0.00473517\n",
      "[900]\tvalid's rmse: 1.5544 + 0.00464842\n",
      "[1000]\tvalid's rmse: 1.55383 + 0.00462785\n",
      "[1100]\tvalid's rmse: 1.55345 + 0.00462226\n",
      "[1200]\tvalid's rmse: 1.55321 + 0.0045807\n",
      "[1300]\tvalid's rmse: 1.55305 + 0.00452457\n",
      "[1400]\tvalid's rmse: 1.55293 + 0.00446446\n",
      "[1500]\tvalid's rmse: 1.55284 + 0.00443682\n",
      "[1600]\tvalid's rmse: 1.55278 + 0.00440188\n",
      "[1700]\tvalid's rmse: 1.55276 + 0.00437399\n",
      "[1800]\tvalid's rmse: 1.55272 + 0.00436049\n",
      "[1900]\tvalid's rmse: 1.55269 + 0.0043469\n",
      "[2000]\tvalid's rmse: 1.55269 + 0.00429792\n",
      "[2100]\tvalid's rmse: 1.55262 + 0.00430662\n",
      "[2200]\tvalid's rmse: 1.55266 + 0.00429287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:54:33,167] Trial 17 finished with value: 1.5526127668878364 and parameters: {'num_leaves': 54, 'colsample_bytree': 0.12342903709321701, 'subsample': 0.36741002559594294, 'max_depth': 9, 'reg_alpha': 6.222169722660697, 'reg_lambda': 8.533181778156402, 'min_split_gain': 1.4310205284358108, 'min_child_weight': 24.661244715803996, 'min_data_in_leaf': 27}. Best is trial 15 with value: 1.552587900356654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2090]\tvalid's rmse: 1.55261 + 0.00429269\n",
      "Trial 17: No improvement. Counter = 2, Best Score = 1.55259\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.63583 + 0.00725759\n",
      "[200]\tvalid's rmse: 1.6097 + 0.00656358\n",
      "[300]\tvalid's rmse: 1.59698 + 0.00615816\n",
      "[400]\tvalid's rmse: 1.58935 + 0.00590641\n",
      "[500]\tvalid's rmse: 1.58377 + 0.00565733\n",
      "[600]\tvalid's rmse: 1.57958 + 0.00547151\n",
      "[700]\tvalid's rmse: 1.57632 + 0.00531371\n",
      "[800]\tvalid's rmse: 1.57354 + 0.00523922\n",
      "[900]\tvalid's rmse: 1.57119 + 0.00517612\n",
      "[1000]\tvalid's rmse: 1.56921 + 0.0051125\n",
      "[1100]\tvalid's rmse: 1.56761 + 0.00502595\n",
      "[1200]\tvalid's rmse: 1.56627 + 0.00498677\n",
      "[1300]\tvalid's rmse: 1.56513 + 0.00493359\n",
      "[1400]\tvalid's rmse: 1.56412 + 0.00490898\n",
      "[1500]\tvalid's rmse: 1.56329 + 0.00487011\n",
      "[1600]\tvalid's rmse: 1.56251 + 0.0048485\n",
      "[1700]\tvalid's rmse: 1.56177 + 0.00482308\n",
      "[1800]\tvalid's rmse: 1.56119 + 0.00480836\n",
      "[1900]\tvalid's rmse: 1.56068 + 0.00479775\n",
      "[2000]\tvalid's rmse: 1.56028 + 0.00477167\n",
      "[2100]\tvalid's rmse: 1.55993 + 0.00473652\n",
      "[2200]\tvalid's rmse: 1.55961 + 0.00472605\n",
      "[2300]\tvalid's rmse: 1.55932 + 0.00471415\n",
      "[2400]\tvalid's rmse: 1.55903 + 0.0046838\n",
      "[2500]\tvalid's rmse: 1.55878 + 0.0046928\n",
      "[2600]\tvalid's rmse: 1.55856 + 0.00469874\n",
      "[2700]\tvalid's rmse: 1.55838 + 0.00467943\n",
      "[2800]\tvalid's rmse: 1.55819 + 0.00468536\n",
      "[2900]\tvalid's rmse: 1.55801 + 0.00468399\n",
      "[3000]\tvalid's rmse: 1.55784 + 0.0046782\n",
      "[3100]\tvalid's rmse: 1.55771 + 0.00468484\n",
      "[3200]\tvalid's rmse: 1.55756 + 0.00466321\n",
      "[3300]\tvalid's rmse: 1.55745 + 0.00463434\n",
      "[3400]\tvalid's rmse: 1.55734 + 0.00461974\n",
      "[3500]\tvalid's rmse: 1.55725 + 0.00460179\n",
      "[3600]\tvalid's rmse: 1.55715 + 0.00460525\n",
      "[3700]\tvalid's rmse: 1.55707 + 0.00460635\n",
      "[3800]\tvalid's rmse: 1.55699 + 0.0045768\n",
      "[3900]\tvalid's rmse: 1.55694 + 0.00456756\n",
      "[4000]\tvalid's rmse: 1.55687 + 0.0045526\n",
      "[4100]\tvalid's rmse: 1.55678 + 0.00455252\n",
      "[4200]\tvalid's rmse: 1.55671 + 0.00454725\n",
      "[4300]\tvalid's rmse: 1.55667 + 0.00454741\n",
      "[4400]\tvalid's rmse: 1.55665 + 0.00456471\n",
      "[4500]\tvalid's rmse: 1.55664 + 0.00458085\n",
      "[4600]\tvalid's rmse: 1.55663 + 0.00458186\n",
      "[4700]\tvalid's rmse: 1.55663 + 0.00458186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:55:06,735] Trial 18 finished with value: 1.556633686410338 and parameters: {'num_leaves': 45, 'colsample_bytree': 0.12440520503098317, 'subsample': 0.3670730533073758, 'max_depth': 3, 'reg_alpha': 8.361448242207981, 'reg_lambda': 7.178747116104439, 'min_split_gain': 3.9784406513437407, 'min_child_weight': 24.79692736936043, 'min_data_in_leaf': 24}. Best is trial 15 with value: 1.552587900356654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4561]\tvalid's rmse: 1.55663 + 0.00458301\n",
      "Trial 18: No improvement. Counter = 3, Best Score = 1.55259\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.61657 + 0.0068397\n",
      "[200]\tvalid's rmse: 1.58774 + 0.00600074\n",
      "[300]\tvalid's rmse: 1.57437 + 0.00546557\n",
      "[400]\tvalid's rmse: 1.56692 + 0.00522002\n",
      "[500]\tvalid's rmse: 1.56269 + 0.00505864\n",
      "[600]\tvalid's rmse: 1.55977 + 0.00496871\n",
      "[700]\tvalid's rmse: 1.55808 + 0.00484974\n",
      "[800]\tvalid's rmse: 1.55681 + 0.00480838\n",
      "[900]\tvalid's rmse: 1.55588 + 0.00478743\n",
      "[1000]\tvalid's rmse: 1.55528 + 0.0047492\n",
      "[1100]\tvalid's rmse: 1.55484 + 0.00474513\n",
      "[1200]\tvalid's rmse: 1.5545 + 0.0047583\n",
      "[1300]\tvalid's rmse: 1.55424 + 0.00475644\n",
      "[1400]\tvalid's rmse: 1.55411 + 0.00473087\n",
      "[1500]\tvalid's rmse: 1.55402 + 0.00472804\n",
      "[1600]\tvalid's rmse: 1.55396 + 0.00473781\n",
      "[1700]\tvalid's rmse: 1.55394 + 0.00474299\n",
      "[1800]\tvalid's rmse: 1.55392 + 0.00474184\n",
      "[1900]\tvalid's rmse: 1.5539 + 0.00474397\n",
      "[2000]\tvalid's rmse: 1.55389 + 0.00474482\n",
      "[2100]\tvalid's rmse: 1.55389 + 0.00474137\n",
      "[2200]\tvalid's rmse: 1.55388 + 0.00473956\n",
      "[2300]\tvalid's rmse: 1.55388 + 0.00473804\n",
      "[2400]\tvalid's rmse: 1.55388 + 0.00473775\n",
      "[2500]\tvalid's rmse: 1.55387 + 0.00473603\n",
      "[2600]\tvalid's rmse: 1.55387 + 0.00473732\n",
      "[2700]\tvalid's rmse: 1.55387 + 0.00473767\n",
      "[2800]\tvalid's rmse: 1.55387 + 0.00473767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:55:28,723] Trial 19 finished with value: 1.553866597751999 and parameters: {'num_leaves': 37, 'colsample_bytree': 0.11971555584218246, 'subsample': 0.32957309223942366, 'max_depth': 6, 'reg_alpha': 6.230162132325142, 'reg_lambda': 6.694114744046433, 'min_split_gain': 5.528439451947912, 'min_child_weight': 28.830579859014357, 'min_data_in_leaf': 16}. Best is trial 15 with value: 1.552587900356654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2688]\tvalid's rmse: 1.55387 + 0.00473767\n",
      "Trial 19: No improvement. Counter = 4, Best Score = 1.55259\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.61388 + 0.00692228\n",
      "[200]\tvalid's rmse: 1.58557 + 0.00609746\n",
      "[300]\tvalid's rmse: 1.57313 + 0.00565361\n",
      "[400]\tvalid's rmse: 1.56643 + 0.00533156\n",
      "[500]\tvalid's rmse: 1.56228 + 0.00516289\n",
      "[600]\tvalid's rmse: 1.55962 + 0.00507914\n",
      "[700]\tvalid's rmse: 1.55778 + 0.00498998\n",
      "[800]\tvalid's rmse: 1.55653 + 0.00494137\n",
      "[900]\tvalid's rmse: 1.55566 + 0.00488783\n",
      "[1000]\tvalid's rmse: 1.55508 + 0.00488877\n",
      "[1100]\tvalid's rmse: 1.55462 + 0.00485865\n",
      "[1200]\tvalid's rmse: 1.55432 + 0.00479475\n",
      "[1300]\tvalid's rmse: 1.55406 + 0.0047667\n",
      "[1400]\tvalid's rmse: 1.55388 + 0.00475703\n",
      "[1500]\tvalid's rmse: 1.55373 + 0.00475228\n",
      "[1600]\tvalid's rmse: 1.55361 + 0.00469099\n",
      "[1700]\tvalid's rmse: 1.55355 + 0.00466587\n",
      "[1800]\tvalid's rmse: 1.55352 + 0.00465856\n",
      "[1900]\tvalid's rmse: 1.55347 + 0.00462955\n",
      "[2000]\tvalid's rmse: 1.55343 + 0.00462931\n",
      "[2100]\tvalid's rmse: 1.55339 + 0.00459981\n",
      "[2200]\tvalid's rmse: 1.55336 + 0.00456546\n",
      "[2300]\tvalid's rmse: 1.55332 + 0.00454155\n",
      "[2400]\tvalid's rmse: 1.55334 + 0.00452984\n",
      "[2500]\tvalid's rmse: 1.55333 + 0.00448698\n",
      "Early stopping, best iteration is:\n",
      "[2329]\tvalid's rmse: 1.55331 + 0.00454447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:55:50,468] Trial 20 finished with value: 1.5533093059513317 and parameters: {'num_leaves': 23, 'colsample_bytree': 0.21836348546297815, 'subsample': 0.3185143944890483, 'max_depth': 10, 'reg_alpha': 4.680347891926547, 'reg_lambda': 8.475429773934012, 'min_split_gain': 1.0450720404580518, 'min_child_weight': 36.9824197071791, 'min_data_in_leaf': 42}. Best is trial 15 with value: 1.552587900356654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20: No improvement. Counter = 5, Best Score = 1.55259\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60237 + 0.00672521\n",
      "[200]\tvalid's rmse: 1.57402 + 0.00596866\n",
      "[300]\tvalid's rmse: 1.56369 + 0.00548801\n",
      "[400]\tvalid's rmse: 1.55895 + 0.00522579\n",
      "[500]\tvalid's rmse: 1.55637 + 0.00515662\n",
      "[600]\tvalid's rmse: 1.55481 + 0.00502938\n",
      "[700]\tvalid's rmse: 1.55389 + 0.00500095\n",
      "[800]\tvalid's rmse: 1.55339 + 0.00497543\n",
      "[900]\tvalid's rmse: 1.55304 + 0.00488612\n",
      "[1000]\tvalid's rmse: 1.55288 + 0.00485434\n",
      "[1100]\tvalid's rmse: 1.55279 + 0.0047763\n",
      "[1200]\tvalid's rmse: 1.55276 + 0.00471296\n",
      "[1300]\tvalid's rmse: 1.55276 + 0.00462613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:56:12,906] Trial 21 finished with value: 1.5527356608927476 and parameters: {'num_leaves': 55, 'colsample_bytree': 0.34876187597437003, 'subsample': 0.6737085818967599, 'max_depth': 9, 'reg_alpha': 6.34585158842293, 'reg_lambda': 8.780870703617525, 'min_split_gain': 1.4245798574881245, 'min_child_weight': 13.596272619006408, 'min_data_in_leaf': 27}. Best is trial 15 with value: 1.552587900356654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid's rmse: 1.55274 + 0.00475367\n",
      "Trial 21: No improvement. Counter = 6, Best Score = 1.55259\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60374 + 0.00677438\n",
      "[200]\tvalid's rmse: 1.57523 + 0.00585874\n",
      "[300]\tvalid's rmse: 1.56437 + 0.00546032\n",
      "[400]\tvalid's rmse: 1.55937 + 0.00513499\n",
      "[500]\tvalid's rmse: 1.55663 + 0.00497539\n",
      "[600]\tvalid's rmse: 1.55492 + 0.00485539\n",
      "[700]\tvalid's rmse: 1.55395 + 0.00472659\n",
      "[800]\tvalid's rmse: 1.55331 + 0.00466374\n",
      "[900]\tvalid's rmse: 1.55297 + 0.00466112\n",
      "[1000]\tvalid's rmse: 1.55279 + 0.00453409\n",
      "[1100]\tvalid's rmse: 1.55265 + 0.00448944\n",
      "[1200]\tvalid's rmse: 1.55261 + 0.00439103\n",
      "[1300]\tvalid's rmse: 1.5526 + 0.00435959\n",
      "[1400]\tvalid's rmse: 1.55258 + 0.00433918\n",
      "[1500]\tvalid's rmse: 1.55263 + 0.00433361\n",
      "[1600]\tvalid's rmse: 1.55267 + 0.00433387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:56:35,483] Trial 22 finished with value: 1.552577713099842 and parameters: {'num_leaves': 54, 'colsample_bytree': 0.2927151907272487, 'subsample': 0.42543777159061924, 'max_depth': 9, 'reg_alpha': 8.159441033850982, 'reg_lambda': 8.846913034798424, 'min_split_gain': 2.3351284480202326, 'min_child_weight': 21.51004067902625, 'min_data_in_leaf': 31}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1424]\tvalid's rmse: 1.55258 + 0.00431159\n",
      "Trial 22: Improved score: 1.55258 (Previous best: 1.55259)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.61651 + 0.00683202\n",
      "[200]\tvalid's rmse: 1.5871 + 0.00588801\n",
      "[300]\tvalid's rmse: 1.57459 + 0.00533366\n",
      "[400]\tvalid's rmse: 1.56727 + 0.00512268\n",
      "[500]\tvalid's rmse: 1.56274 + 0.00499904\n",
      "[600]\tvalid's rmse: 1.55996 + 0.00492961\n",
      "[700]\tvalid's rmse: 1.55804 + 0.0049471\n",
      "[800]\tvalid's rmse: 1.55671 + 0.00487148\n",
      "[900]\tvalid's rmse: 1.55583 + 0.00488146\n",
      "[1000]\tvalid's rmse: 1.55515 + 0.00486928\n",
      "[1100]\tvalid's rmse: 1.55464 + 0.00481673\n",
      "[1200]\tvalid's rmse: 1.55432 + 0.00476724\n",
      "[1300]\tvalid's rmse: 1.55408 + 0.0047497\n",
      "[1400]\tvalid's rmse: 1.55386 + 0.00471057\n",
      "[1500]\tvalid's rmse: 1.55367 + 0.00472866\n",
      "[1600]\tvalid's rmse: 1.55351 + 0.00471883\n",
      "[1700]\tvalid's rmse: 1.55344 + 0.00472268\n",
      "[1800]\tvalid's rmse: 1.55339 + 0.00470753\n",
      "[1900]\tvalid's rmse: 1.55335 + 0.00467725\n",
      "[2000]\tvalid's rmse: 1.55333 + 0.00466688\n",
      "[2100]\tvalid's rmse: 1.55334 + 0.00465338\n",
      "[2200]\tvalid's rmse: 1.55333 + 0.00465162\n",
      "[2300]\tvalid's rmse: 1.55333 + 0.00465057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:56:55,098] Trial 23 finished with value: 1.5533237311849801 and parameters: {'num_leaves': 52, 'colsample_bytree': 0.09577575848470721, 'subsample': 0.39469469153019776, 'max_depth': 7, 'reg_alpha': 8.147681353579877, 'reg_lambda': 7.440232752392046, 'min_split_gain': 3.5509818484764013, 'min_child_weight': 23.74639870140903, 'min_data_in_leaf': 38}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2189]\tvalid's rmse: 1.55332 + 0.00464963\n",
      "Trial 23: No improvement. Counter = 1, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60291 + 0.00661393\n",
      "[200]\tvalid's rmse: 1.57456 + 0.00573527\n",
      "[300]\tvalid's rmse: 1.56418 + 0.00524919\n",
      "[400]\tvalid's rmse: 1.55927 + 0.00501782\n",
      "[500]\tvalid's rmse: 1.55655 + 0.00481601\n",
      "[600]\tvalid's rmse: 1.55499 + 0.00472938\n",
      "[700]\tvalid's rmse: 1.5541 + 0.00472223\n",
      "[800]\tvalid's rmse: 1.55355 + 0.00467362\n",
      "[900]\tvalid's rmse: 1.55319 + 0.00462477\n",
      "[1000]\tvalid's rmse: 1.55297 + 0.0045342\n",
      "[1100]\tvalid's rmse: 1.55284 + 0.00449452\n",
      "[1200]\tvalid's rmse: 1.55276 + 0.00446836\n",
      "[1300]\tvalid's rmse: 1.55273 + 0.00444358\n",
      "[1400]\tvalid's rmse: 1.55274 + 0.00442373\n",
      "[1500]\tvalid's rmse: 1.55277 + 0.00442104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:57:20,222] Trial 24 finished with value: 1.5527179509197069 and parameters: {'num_leaves': 45, 'colsample_bytree': 0.4655052286745483, 'subsample': 0.13474495299592382, 'max_depth': 10, 'reg_alpha': 9.710216379566667, 'reg_lambda': 9.073299578841677, 'min_split_gain': 2.696411256149486, 'min_child_weight': 21.396204599399343, 'min_data_in_leaf': 21}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1329]\tvalid's rmse: 1.55272 + 0.00442011\n",
      "Trial 24: No improvement. Counter = 2, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60632 + 0.00679805\n",
      "[200]\tvalid's rmse: 1.57789 + 0.00600786\n",
      "[300]\tvalid's rmse: 1.56649 + 0.00549999\n",
      "[400]\tvalid's rmse: 1.56108 + 0.00522681\n",
      "[500]\tvalid's rmse: 1.55797 + 0.00506913\n",
      "[600]\tvalid's rmse: 1.55605 + 0.00499255\n",
      "[700]\tvalid's rmse: 1.55487 + 0.00486246\n",
      "[800]\tvalid's rmse: 1.5541 + 0.0048297\n",
      "[900]\tvalid's rmse: 1.55358 + 0.00477456\n",
      "[1000]\tvalid's rmse: 1.55325 + 0.00473277\n",
      "[1100]\tvalid's rmse: 1.55302 + 0.00471447\n",
      "[1200]\tvalid's rmse: 1.55293 + 0.00465486\n",
      "[1300]\tvalid's rmse: 1.55288 + 0.00461178\n",
      "[1400]\tvalid's rmse: 1.55285 + 0.00459091\n",
      "[1500]\tvalid's rmse: 1.55283 + 0.00455591\n",
      "[1600]\tvalid's rmse: 1.55284 + 0.00456087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:57:40,465] Trial 25 finished with value: 1.5528184998163255 and parameters: {'num_leaves': 46, 'colsample_bytree': 0.2500380453989678, 'subsample': 0.2541988622211591, 'max_depth': 7, 'reg_alpha': 7.918688454563544, 'reg_lambda': 5.568550064615888, 'min_split_gain': 2.3460692473685576, 'min_child_weight': 28.245443224484156, 'min_data_in_leaf': 29}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1466]\tvalid's rmse: 1.55282 + 0.00458626\n",
      "Trial 25: No improvement. Counter = 3, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60698 + 0.00673678\n",
      "[200]\tvalid's rmse: 1.57778 + 0.00597982\n",
      "[300]\tvalid's rmse: 1.56642 + 0.005626\n",
      "[400]\tvalid's rmse: 1.56088 + 0.00542209\n",
      "[500]\tvalid's rmse: 1.55801 + 0.00530576\n",
      "[600]\tvalid's rmse: 1.5562 + 0.00519067\n",
      "[700]\tvalid's rmse: 1.55497 + 0.00509236\n",
      "[800]\tvalid's rmse: 1.55416 + 0.00512576\n",
      "[900]\tvalid's rmse: 1.55358 + 0.00511756\n",
      "[1000]\tvalid's rmse: 1.5532 + 0.00503285\n",
      "[1100]\tvalid's rmse: 1.55293 + 0.00506001\n",
      "[1200]\tvalid's rmse: 1.5528 + 0.0050492\n",
      "[1300]\tvalid's rmse: 1.55269 + 0.00501981\n",
      "[1400]\tvalid's rmse: 1.55262 + 0.00501798\n",
      "[1500]\tvalid's rmse: 1.55263 + 0.00495859\n",
      "[1600]\tvalid's rmse: 1.55262 + 0.00488977\n",
      "[1700]\tvalid's rmse: 1.55261 + 0.00482021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:58:05,734] Trial 26 finished with value: 1.5525992360597514 and parameters: {'num_leaves': 53, 'colsample_bytree': 0.17901141949399754, 'subsample': 0.5048828182832014, 'max_depth': 10, 'reg_alpha': 9.178292644944793, 'reg_lambda': 2.997461823913657, 'min_split_gain': 0.7487001514647134, 'min_child_weight': 26.630768624385997, 'min_data_in_leaf': 48}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1565]\tvalid's rmse: 1.5526 + 0.00492804\n",
      "Trial 26: No improvement. Counter = 4, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.59975 + 0.00658843\n",
      "[200]\tvalid's rmse: 1.57202 + 0.00564093\n",
      "[300]\tvalid's rmse: 1.56211 + 0.00515717\n",
      "[400]\tvalid's rmse: 1.55773 + 0.00485205\n",
      "[500]\tvalid's rmse: 1.55544 + 0.0046893\n",
      "[600]\tvalid's rmse: 1.55414 + 0.00462441\n",
      "[700]\tvalid's rmse: 1.55348 + 0.00462838\n",
      "[800]\tvalid's rmse: 1.55309 + 0.00463084\n",
      "[900]\tvalid's rmse: 1.55285 + 0.00460125\n",
      "[1000]\tvalid's rmse: 1.55278 + 0.00451728\n",
      "[1100]\tvalid's rmse: 1.55271 + 0.00447931\n",
      "[1200]\tvalid's rmse: 1.55273 + 0.00442917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:58:31,709] Trial 27 finished with value: 1.552682862887494 and parameters: {'num_leaves': 64, 'colsample_bytree': 0.43695630989509465, 'subsample': 0.5271227853272279, 'max_depth': 12, 'reg_alpha': 9.04186593496059, 'reg_lambda': 2.622220387971547, 'min_split_gain': 0.8018928063030022, 'min_child_weight': 32.677609511230564, 'min_data_in_leaf': 48}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1075]\tvalid's rmse: 1.55268 + 0.00447707\n",
      "Trial 27: No improvement. Counter = 5, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60722 + 0.00675929\n",
      "[200]\tvalid's rmse: 1.57803 + 0.00597164\n",
      "[300]\tvalid's rmse: 1.56662 + 0.005636\n",
      "[400]\tvalid's rmse: 1.56099 + 0.00535794\n",
      "[500]\tvalid's rmse: 1.55802 + 0.00520418\n",
      "[600]\tvalid's rmse: 1.55617 + 0.00508885\n",
      "[700]\tvalid's rmse: 1.55496 + 0.00501066\n",
      "[800]\tvalid's rmse: 1.55413 + 0.00500765\n",
      "[900]\tvalid's rmse: 1.55361 + 0.00495517\n",
      "[1000]\tvalid's rmse: 1.55328 + 0.00489071\n",
      "[1100]\tvalid's rmse: 1.55306 + 0.0048529\n",
      "[1200]\tvalid's rmse: 1.55297 + 0.00484117\n",
      "[1300]\tvalid's rmse: 1.55293 + 0.00481541\n",
      "[1400]\tvalid's rmse: 1.5529 + 0.00481157\n",
      "[1500]\tvalid's rmse: 1.55289 + 0.00481224\n",
      "[1600]\tvalid's rmse: 1.55289 + 0.00481201\n",
      "[1700]\tvalid's rmse: 1.55288 + 0.00481097\n",
      "[1800]\tvalid's rmse: 1.55287 + 0.00480984\n",
      "[1900]\tvalid's rmse: 1.55287 + 0.00481116\n",
      "[2000]\tvalid's rmse: 1.55287 + 0.00481063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:58:56,812] Trial 28 finished with value: 1.5528675337004476 and parameters: {'num_leaves': 51, 'colsample_bytree': 0.1787682117275073, 'subsample': 0.46391486670639653, 'max_depth': 10, 'reg_alpha': 7.744121279490005, 'reg_lambda': 2.869640909951476, 'min_split_gain': 4.859272637446284, 'min_child_weight': 15.100757553059339, 'min_data_in_leaf': 51}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100]\tvalid's rmse: 1.55287 + 0.00481063\n",
      "Early stopping, best iteration is:\n",
      "[1909]\tvalid's rmse: 1.55287 + 0.00481133\n",
      "Trial 28: No improvement. Counter = 6, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60421 + 0.00664458\n",
      "[200]\tvalid's rmse: 1.57576 + 0.00581254\n",
      "[300]\tvalid's rmse: 1.56501 + 0.00533766\n",
      "[400]\tvalid's rmse: 1.55996 + 0.00508389\n",
      "[500]\tvalid's rmse: 1.55714 + 0.00487358\n",
      "[600]\tvalid's rmse: 1.55543 + 0.00477582\n",
      "[700]\tvalid's rmse: 1.55437 + 0.00469676\n",
      "[800]\tvalid's rmse: 1.55381 + 0.00467348\n",
      "[900]\tvalid's rmse: 1.55343 + 0.00464598\n",
      "[1000]\tvalid's rmse: 1.55317 + 0.00460219\n",
      "[1100]\tvalid's rmse: 1.55301 + 0.00457003\n",
      "[1200]\tvalid's rmse: 1.55294 + 0.00453007\n",
      "[1300]\tvalid's rmse: 1.55288 + 0.0044975\n",
      "[1400]\tvalid's rmse: 1.55284 + 0.00445696\n",
      "[1500]\tvalid's rmse: 1.55283 + 0.00442574\n",
      "[1600]\tvalid's rmse: 1.55283 + 0.00436994\n",
      "[1700]\tvalid's rmse: 1.55284 + 0.00435129\n",
      "[1800]\tvalid's rmse: 1.55285 + 0.00429146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:59:30,145] Trial 29 finished with value: 1.5527983200211928 and parameters: {'num_leaves': 42, 'colsample_bytree': 0.3783619573637036, 'subsample': 0.46686492571240573, 'max_depth': 10, 'reg_alpha': 9.10288751484616, 'reg_lambda': 4.191812861694748, 'min_split_gain': 0.4528268367024839, 'min_child_weight': 27.68341033807527, 'min_data_in_leaf': 46}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1649]\tvalid's rmse: 1.5528 + 0.00438024\n",
      "Trial 29: No improvement. Counter = 7, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60654 + 0.0067486\n",
      "[200]\tvalid's rmse: 1.57796 + 0.00593748\n",
      "[300]\tvalid's rmse: 1.56669 + 0.00548227\n",
      "[400]\tvalid's rmse: 1.56112 + 0.00511598\n",
      "[500]\tvalid's rmse: 1.55796 + 0.00494193\n",
      "[600]\tvalid's rmse: 1.55603 + 0.00484292\n",
      "[700]\tvalid's rmse: 1.55482 + 0.00476172\n",
      "[800]\tvalid's rmse: 1.55406 + 0.00472067\n",
      "[900]\tvalid's rmse: 1.55354 + 0.00469094\n",
      "[1000]\tvalid's rmse: 1.55326 + 0.00463234\n",
      "[1100]\tvalid's rmse: 1.55304 + 0.00458553\n",
      "[1200]\tvalid's rmse: 1.55291 + 0.00452721\n",
      "[1300]\tvalid's rmse: 1.55286 + 0.00447928\n",
      "[1400]\tvalid's rmse: 1.55282 + 0.00448554\n",
      "[1500]\tvalid's rmse: 1.55281 + 0.00443306\n",
      "[1600]\tvalid's rmse: 1.55281 + 0.00442928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 02:59:49,299] Trial 30 finished with value: 1.5527865609859155 and parameters: {'num_leaves': 38, 'colsample_bytree': 0.30058801594081047, 'subsample': 0.25887770177487385, 'max_depth': 12, 'reg_alpha': 9.895234270494873, 'reg_lambda': 1.9010845500847742, 'min_split_gain': 3.988042314693611, 'min_child_weight': 21.72465365041588, 'min_data_in_leaf': 38}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1473]\tvalid's rmse: 1.55279 + 0.0044482\n",
      "Trial 30: No improvement. Counter = 8, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.62077 + 0.00695333\n",
      "[200]\tvalid's rmse: 1.59133 + 0.0060067\n",
      "[300]\tvalid's rmse: 1.57793 + 0.00557662\n",
      "[400]\tvalid's rmse: 1.57039 + 0.00525812\n",
      "[500]\tvalid's rmse: 1.56539 + 0.00507425\n",
      "[600]\tvalid's rmse: 1.56226 + 0.00500809\n",
      "[700]\tvalid's rmse: 1.56004 + 0.0049569\n",
      "[800]\tvalid's rmse: 1.55854 + 0.00496653\n",
      "[900]\tvalid's rmse: 1.55723 + 0.0049311\n",
      "[1000]\tvalid's rmse: 1.55628 + 0.00494235\n",
      "[1100]\tvalid's rmse: 1.55562 + 0.00493665\n",
      "[1200]\tvalid's rmse: 1.55512 + 0.00490107\n",
      "[1300]\tvalid's rmse: 1.55474 + 0.00490348\n",
      "[1400]\tvalid's rmse: 1.55447 + 0.00484557\n",
      "[1500]\tvalid's rmse: 1.55422 + 0.00489837\n",
      "[1600]\tvalid's rmse: 1.55404 + 0.00485397\n",
      "[1700]\tvalid's rmse: 1.55393 + 0.00482031\n",
      "[1800]\tvalid's rmse: 1.55378 + 0.00484019\n",
      "[1900]\tvalid's rmse: 1.5537 + 0.00477466\n",
      "[2000]\tvalid's rmse: 1.55365 + 0.00475856\n",
      "[2100]\tvalid's rmse: 1.55359 + 0.00475842\n",
      "[2200]\tvalid's rmse: 1.55354 + 0.0047592\n",
      "[2300]\tvalid's rmse: 1.55354 + 0.00476358\n",
      "[2400]\tvalid's rmse: 1.55353 + 0.00474689\n",
      "[2500]\tvalid's rmse: 1.55351 + 0.0047176\n",
      "[2600]\tvalid's rmse: 1.55351 + 0.00469014\n",
      "[2700]\tvalid's rmse: 1.55351 + 0.00463067\n",
      "[2800]\tvalid's rmse: 1.55353 + 0.00461468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:00:18,537] Trial 31 finished with value: 1.5534802539414942 and parameters: {'num_leaves': 54, 'colsample_bytree': 0.07551284166420512, 'subsample': 0.3973800603513042, 'max_depth': 9, 'reg_alpha': 6.6821873309633535, 'reg_lambda': 9.984418263483043, 'min_split_gain': 2.016145272740509, 'min_child_weight': 26.11660354282516, 'min_data_in_leaf': 50}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2643]\tvalid's rmse: 1.55348 + 0.00467607\n",
      "Trial 31: No improvement. Counter = 9, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60737 + 0.00667393\n",
      "[200]\tvalid's rmse: 1.57778 + 0.00593396\n",
      "[300]\tvalid's rmse: 1.56664 + 0.00546806\n",
      "[400]\tvalid's rmse: 1.56099 + 0.0051568\n",
      "[500]\tvalid's rmse: 1.55778 + 0.00501125\n",
      "[600]\tvalid's rmse: 1.55593 + 0.00497947\n",
      "[700]\tvalid's rmse: 1.55484 + 0.00488594\n",
      "[800]\tvalid's rmse: 1.55415 + 0.00474873\n",
      "[900]\tvalid's rmse: 1.55361 + 0.00471671\n",
      "[1000]\tvalid's rmse: 1.55328 + 0.00468322\n",
      "[1100]\tvalid's rmse: 1.55306 + 0.00465156\n",
      "[1200]\tvalid's rmse: 1.55291 + 0.00455693\n",
      "[1300]\tvalid's rmse: 1.55285 + 0.00447477\n",
      "[1400]\tvalid's rmse: 1.55279 + 0.00444587\n",
      "[1500]\tvalid's rmse: 1.55276 + 0.00440697\n",
      "[1600]\tvalid's rmse: 1.55275 + 0.00437121\n",
      "[1700]\tvalid's rmse: 1.55279 + 0.00431145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:00:39,848] Trial 32 finished with value: 1.5527170875949743 and parameters: {'num_leaves': 57, 'colsample_bytree': 0.1699182201393471, 'subsample': 0.5240100370575235, 'max_depth': 10, 'reg_alpha': 5.6094719661111725, 'reg_lambda': 7.1140497154108635, 'min_split_gain': 0.12698522409866486, 'min_child_weight': 30.793468199463312, 'min_data_in_leaf': 42}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1582]\tvalid's rmse: 1.55272 + 0.00437693\n",
      "Trial 32: No improvement. Counter = 10, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60622 + 0.00683615\n",
      "[200]\tvalid's rmse: 1.57759 + 0.00601539\n",
      "[300]\tvalid's rmse: 1.56621 + 0.00557425\n",
      "[400]\tvalid's rmse: 1.56075 + 0.00527687\n",
      "[500]\tvalid's rmse: 1.55766 + 0.00511767\n",
      "[600]\tvalid's rmse: 1.5558 + 0.00503661\n",
      "[700]\tvalid's rmse: 1.55458 + 0.00490642\n",
      "[800]\tvalid's rmse: 1.55385 + 0.00488364\n",
      "[900]\tvalid's rmse: 1.55341 + 0.00478175\n",
      "[1000]\tvalid's rmse: 1.55311 + 0.00470307\n",
      "[1100]\tvalid's rmse: 1.55289 + 0.00470112\n",
      "[1200]\tvalid's rmse: 1.55277 + 0.00469767\n",
      "[1300]\tvalid's rmse: 1.55271 + 0.004627\n",
      "[1400]\tvalid's rmse: 1.55265 + 0.00454836\n",
      "[1500]\tvalid's rmse: 1.55262 + 0.00452021\n",
      "[1600]\tvalid's rmse: 1.55261 + 0.00448483\n",
      "[1700]\tvalid's rmse: 1.55265 + 0.00443443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:01:01,822] Trial 33 finished with value: 1.5525945266193417 and parameters: {'num_leaves': 47, 'colsample_bytree': 0.2431012986964956, 'subsample': 0.31341385530161886, 'max_depth': 9, 'reg_alpha': 7.426465456365712, 'reg_lambda': 9.172107307287153, 'min_split_gain': 1.5436584907515738, 'min_child_weight': 19.463588559738284, 'min_data_in_leaf': 30}. Best is trial 22 with value: 1.552577713099842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1566]\tvalid's rmse: 1.55259 + 0.00448806\n",
      "Trial 33: No improvement. Counter = 11, Best Score = 1.55258\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60576 + 0.00679098\n",
      "[200]\tvalid's rmse: 1.57721 + 0.00597342\n",
      "[300]\tvalid's rmse: 1.56582 + 0.00546192\n",
      "[400]\tvalid's rmse: 1.56042 + 0.00515143\n",
      "[500]\tvalid's rmse: 1.55738 + 0.00500975\n",
      "[600]\tvalid's rmse: 1.55547 + 0.00492276\n",
      "[700]\tvalid's rmse: 1.55431 + 0.00476767\n",
      "[800]\tvalid's rmse: 1.55359 + 0.00477066\n",
      "[900]\tvalid's rmse: 1.55315 + 0.00471016\n",
      "[1000]\tvalid's rmse: 1.55283 + 0.00468916\n",
      "[1100]\tvalid's rmse: 1.55263 + 0.00459727\n",
      "[1200]\tvalid's rmse: 1.55258 + 0.00455809\n",
      "[1300]\tvalid's rmse: 1.55251 + 0.00456065\n",
      "[1400]\tvalid's rmse: 1.55251 + 0.00454815\n",
      "[1500]\tvalid's rmse: 1.5525 + 0.00450909\n",
      "[1600]\tvalid's rmse: 1.5525 + 0.00449041\n",
      "[1700]\tvalid's rmse: 1.55251 + 0.00445759\n",
      "Early stopping, best iteration is:\n",
      "[1524]\tvalid's rmse: 1.55248 + 0.00450769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:01:23,850] Trial 34 finished with value: 1.5524830123157176 and parameters: {'num_leaves': 47, 'colsample_bytree': 0.25851331732605387, 'subsample': 0.30069834401349604, 'max_depth': 11, 'reg_alpha': 8.531336599706444, 'reg_lambda': 9.291480424636378, 'min_split_gain': 1.9184408425698292, 'min_child_weight': 20.457146905826168, 'min_data_in_leaf': 55}. Best is trial 34 with value: 1.5524830123157176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34: Improved score: 1.55248 (Previous best: 1.55258)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60709 + 0.00683489\n",
      "[200]\tvalid's rmse: 1.57853 + 0.00599993\n",
      "[300]\tvalid's rmse: 1.56694 + 0.0056048\n",
      "[400]\tvalid's rmse: 1.56126 + 0.00529998\n",
      "[500]\tvalid's rmse: 1.55807 + 0.00521107\n",
      "[600]\tvalid's rmse: 1.55605 + 0.00513137\n",
      "[700]\tvalid's rmse: 1.55481 + 0.00508882\n",
      "[800]\tvalid's rmse: 1.55399 + 0.00501813\n",
      "[900]\tvalid's rmse: 1.55345 + 0.00494994\n",
      "[1000]\tvalid's rmse: 1.55308 + 0.0049519\n",
      "[1100]\tvalid's rmse: 1.55285 + 0.00495012\n",
      "[1200]\tvalid's rmse: 1.55274 + 0.00488578\n",
      "[1300]\tvalid's rmse: 1.5527 + 0.00487021\n",
      "[1400]\tvalid's rmse: 1.55269 + 0.00485066\n",
      "[1500]\tvalid's rmse: 1.55268 + 0.00482226\n",
      "[1600]\tvalid's rmse: 1.55263 + 0.0047725\n",
      "[1700]\tvalid's rmse: 1.55264 + 0.00474567\n",
      "[1800]\tvalid's rmse: 1.55265 + 0.00473245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:01:44,439] Trial 35 finished with value: 1.5526175236431523 and parameters: {'num_leaves': 43, 'colsample_bytree': 0.23422856659756483, 'subsample': 0.14419572511554082, 'max_depth': 11, 'reg_alpha': 7.742103251499148, 'reg_lambda': 9.265035003580525, 'min_split_gain': 3.284319938890029, 'min_child_weight': 19.36537750690499, 'min_data_in_leaf': 59}. Best is trial 34 with value: 1.5524830123157176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1655]\tvalid's rmse: 1.55262 + 0.00473881\n",
      "Trial 35: No improvement. Counter = 1, Best Score = 1.55248\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60385 + 0.00675502\n",
      "[200]\tvalid's rmse: 1.57537 + 0.00595407\n",
      "[300]\tvalid's rmse: 1.56462 + 0.00543195\n",
      "[400]\tvalid's rmse: 1.55962 + 0.00514682\n",
      "[500]\tvalid's rmse: 1.55685 + 0.00498886\n",
      "[600]\tvalid's rmse: 1.55515 + 0.0049716\n",
      "[700]\tvalid's rmse: 1.55413 + 0.00486636\n",
      "[800]\tvalid's rmse: 1.5536 + 0.00480071\n",
      "[900]\tvalid's rmse: 1.5532 + 0.00475618\n",
      "[1000]\tvalid's rmse: 1.55298 + 0.00471308\n",
      "[1100]\tvalid's rmse: 1.55284 + 0.0046679\n",
      "[1200]\tvalid's rmse: 1.55278 + 0.00462664\n",
      "[1300]\tvalid's rmse: 1.55274 + 0.00455111\n",
      "[1400]\tvalid's rmse: 1.55274 + 0.00450313\n",
      "[1500]\tvalid's rmse: 1.55271 + 0.00449754\n",
      "[1600]\tvalid's rmse: 1.55273 + 0.00445027\n",
      "[1700]\tvalid's rmse: 1.55273 + 0.00438494\n",
      "[1800]\tvalid's rmse: 1.55279 + 0.00439676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:02:16,401] Trial 36 finished with value: 1.5526966409234324 and parameters: {'num_leaves': 47, 'colsample_bytree': 0.35207467284427424, 'subsample': 0.080975750815058, 'max_depth': 11, 'reg_alpha': 8.554738870945044, 'reg_lambda': 9.215356118379217, 'min_split_gain': 2.033531024913196, 'min_child_weight': 19.14481883229271, 'min_data_in_leaf': 34}. Best is trial 34 with value: 1.5524830123157176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1620]\tvalid's rmse: 1.5527 + 0.00444605\n",
      "Trial 36: No improvement. Counter = 2, Best Score = 1.55248\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.6069 + 0.00671502\n",
      "[200]\tvalid's rmse: 1.57836 + 0.00585431\n",
      "[300]\tvalid's rmse: 1.56689 + 0.0054053\n",
      "[400]\tvalid's rmse: 1.56132 + 0.00508496\n",
      "[500]\tvalid's rmse: 1.55811 + 0.0049935\n",
      "[600]\tvalid's rmse: 1.55618 + 0.00488075\n",
      "[700]\tvalid's rmse: 1.55505 + 0.00477926\n",
      "[800]\tvalid's rmse: 1.55449 + 0.00478944\n",
      "[900]\tvalid's rmse: 1.55427 + 0.00480097\n",
      "[1000]\tvalid's rmse: 1.55424 + 0.00480446\n",
      "[1100]\tvalid's rmse: 1.55424 + 0.0048048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:02:31,735] Trial 37 finished with value: 1.5542412387540783 and parameters: {'num_leaves': 40, 'colsample_bytree': 0.2644659843612679, 'subsample': 0.27562257048032124, 'max_depth': 11, 'reg_alpha': 4.655656385298545, 'reg_lambda': 7.764686179407581, 'min_split_gain': 9.361676103110437, 'min_child_weight': 17.244778804025874, 'min_data_in_leaf': 31}. Best is trial 34 with value: 1.5524830123157176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\tvalid's rmse: 1.55424 + 0.0048048\n",
      "Early stopping, best iteration is:\n",
      "[1012]\tvalid's rmse: 1.55424 + 0.00480482\n",
      "Trial 37: No improvement. Counter = 3, Best Score = 1.55248\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60057 + 0.00664967\n",
      "[200]\tvalid's rmse: 1.57251 + 0.00566026\n",
      "[300]\tvalid's rmse: 1.5629 + 0.00509094\n",
      "[400]\tvalid's rmse: 1.55853 + 0.00487107\n",
      "[500]\tvalid's rmse: 1.55622 + 0.00468105\n",
      "[600]\tvalid's rmse: 1.55485 + 0.00458091\n",
      "[700]\tvalid's rmse: 1.55414 + 0.00445506\n",
      "[800]\tvalid's rmse: 1.55372 + 0.00444935\n",
      "[900]\tvalid's rmse: 1.55338 + 0.00439421\n",
      "[1000]\tvalid's rmse: 1.55321 + 0.00435163\n",
      "[1100]\tvalid's rmse: 1.55314 + 0.00432085\n",
      "[1200]\tvalid's rmse: 1.55314 + 0.0043372\n",
      "[1300]\tvalid's rmse: 1.55315 + 0.00434067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:02:55,828] Trial 38 finished with value: 1.5531007006650246 and parameters: {'num_leaves': 60, 'colsample_bytree': 0.5057829557264433, 'subsample': 0.3072373326579088, 'max_depth': 7, 'reg_alpha': 7.5527059350231385, 'reg_lambda': 8.882858001643129, 'min_split_gain': 2.7591193509622975, 'min_child_weight': 12.524500646138398, 'min_data_in_leaf': 21}. Best is trial 34 with value: 1.5524830123157176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1157]\tvalid's rmse: 1.5531 + 0.00432551\n",
      "Trial 38: No improvement. Counter = 4, Best Score = 1.55248\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60509 + 0.006758\n",
      "[200]\tvalid's rmse: 1.57643 + 0.00584067\n",
      "[300]\tvalid's rmse: 1.56536 + 0.00538552\n",
      "[400]\tvalid's rmse: 1.56012 + 0.00507415\n",
      "[500]\tvalid's rmse: 1.55721 + 0.00491563\n",
      "[600]\tvalid's rmse: 1.55542 + 0.00480075\n",
      "[700]\tvalid's rmse: 1.55429 + 0.00470196\n",
      "[800]\tvalid's rmse: 1.55363 + 0.00466637\n",
      "[900]\tvalid's rmse: 1.55318 + 0.00461578\n",
      "[1000]\tvalid's rmse: 1.55292 + 0.00453683\n",
      "[1100]\tvalid's rmse: 1.55272 + 0.00449111\n",
      "[1200]\tvalid's rmse: 1.55263 + 0.00447131\n",
      "[1300]\tvalid's rmse: 1.5526 + 0.00442628\n",
      "[1400]\tvalid's rmse: 1.55261 + 0.00442365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:03:14,141] Trial 39 finished with value: 1.5526011744777992 and parameters: {'num_leaves': 43, 'colsample_bytree': 0.32005642544339413, 'subsample': 0.20759066418763844, 'max_depth': 12, 'reg_alpha': 6.73680563589914, 'reg_lambda': 9.389677972269325, 'min_split_gain': 4.441986948645084, 'min_child_weight': 22.116297693622695, 'min_data_in_leaf': 55}. Best is trial 34 with value: 1.5524830123157176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1284]\tvalid's rmse: 1.5526 + 0.00442821\n",
      "Trial 39: No improvement. Counter = 5, Best Score = 1.55248\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60253 + 0.00676079\n",
      "[200]\tvalid's rmse: 1.57421 + 0.00586486\n",
      "[300]\tvalid's rmse: 1.56373 + 0.00535798\n",
      "[400]\tvalid's rmse: 1.55886 + 0.0050891\n",
      "[500]\tvalid's rmse: 1.55631 + 0.00499655\n",
      "[600]\tvalid's rmse: 1.55476 + 0.00488434\n",
      "[700]\tvalid's rmse: 1.55389 + 0.00477623\n",
      "[800]\tvalid's rmse: 1.55337 + 0.00473754\n",
      "[900]\tvalid's rmse: 1.55304 + 0.00476095\n",
      "[1000]\tvalid's rmse: 1.55284 + 0.00472319\n",
      "[1100]\tvalid's rmse: 1.55273 + 0.0046619\n",
      "[1200]\tvalid's rmse: 1.55267 + 0.00463146\n",
      "[1300]\tvalid's rmse: 1.55264 + 0.00461707\n",
      "[1400]\tvalid's rmse: 1.55262 + 0.00462664\n",
      "[1500]\tvalid's rmse: 1.5527 + 0.00460748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:03:38,742] Trial 40 finished with value: 1.5526235328552722 and parameters: {'num_leaves': 50, 'colsample_bytree': 0.4030722656214247, 'subsample': 0.42235829520053525, 'max_depth': 8, 'reg_alpha': 8.605275264190958, 'reg_lambda': 6.325771373306157, 'min_split_gain': 2.146987653723531, 'min_child_weight': 15.046069608438213, 'min_data_in_leaf': 59}. Best is trial 34 with value: 1.5524830123157176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1392]\tvalid's rmse: 1.55262 + 0.00462724\n",
      "Trial 40: No improvement. Counter = 6, Best Score = 1.55248\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60731 + 0.00685344\n",
      "[200]\tvalid's rmse: 1.57833 + 0.00602283\n",
      "[300]\tvalid's rmse: 1.5666 + 0.00556141\n",
      "[400]\tvalid's rmse: 1.56093 + 0.00527209\n",
      "[500]\tvalid's rmse: 1.55774 + 0.00512319\n",
      "[600]\tvalid's rmse: 1.5557 + 0.0050412\n",
      "[700]\tvalid's rmse: 1.55443 + 0.00497054\n",
      "[800]\tvalid's rmse: 1.55362 + 0.0048947\n",
      "[900]\tvalid's rmse: 1.55312 + 0.00486785\n",
      "[1000]\tvalid's rmse: 1.55276 + 0.00483653\n",
      "[1100]\tvalid's rmse: 1.55251 + 0.00477829\n",
      "[1200]\tvalid's rmse: 1.55236 + 0.00476977\n",
      "[1300]\tvalid's rmse: 1.55228 + 0.00476758\n",
      "[1400]\tvalid's rmse: 1.55221 + 0.00478836\n",
      "[1500]\tvalid's rmse: 1.55217 + 0.0047959\n",
      "[1600]\tvalid's rmse: 1.55215 + 0.00477561\n",
      "[1700]\tvalid's rmse: 1.55217 + 0.00475066\n",
      "[1800]\tvalid's rmse: 1.5522 + 0.0046661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:04:00,792] Trial 41 finished with value: 1.5521295623116773 and parameters: {'num_leaves': 53, 'colsample_bytree': 0.19236545297074806, 'subsample': 0.5897876298444062, 'max_depth': 10, 'reg_alpha': 9.197679369221547, 'reg_lambda': 8.280040079097283, 'min_split_gain': 1.03758101026355, 'min_child_weight': 20.375862050559103, 'min_data_in_leaf': 53}. Best is trial 41 with value: 1.5521295623116773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1642]\tvalid's rmse: 1.55213 + 0.00476312\n",
      "Trial 41: Improved score: 1.55213 (Previous best: 1.55248)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60732 + 0.00685988\n",
      "[200]\tvalid's rmse: 1.57851 + 0.00599311\n",
      "[300]\tvalid's rmse: 1.56686 + 0.00554163\n",
      "[400]\tvalid's rmse: 1.56113 + 0.00524691\n",
      "[500]\tvalid's rmse: 1.55799 + 0.00503279\n",
      "[600]\tvalid's rmse: 1.55593 + 0.00492766\n",
      "[700]\tvalid's rmse: 1.55472 + 0.00488924\n",
      "[800]\tvalid's rmse: 1.5539 + 0.00482062\n",
      "[900]\tvalid's rmse: 1.55337 + 0.00481518\n",
      "[1000]\tvalid's rmse: 1.55303 + 0.00472003\n",
      "[1100]\tvalid's rmse: 1.55281 + 0.00467368\n",
      "[1200]\tvalid's rmse: 1.55268 + 0.00465096\n",
      "[1300]\tvalid's rmse: 1.55259 + 0.00464909\n",
      "[1400]\tvalid's rmse: 1.55249 + 0.00463824\n",
      "[1500]\tvalid's rmse: 1.55246 + 0.00463956\n",
      "[1600]\tvalid's rmse: 1.55246 + 0.00458689\n",
      "[1700]\tvalid's rmse: 1.55247 + 0.00451945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:04:25,378] Trial 42 finished with value: 1.5524441227594872 and parameters: {'num_leaves': 48, 'colsample_bytree': 0.2085669930353542, 'subsample': 0.33956465831654653, 'max_depth': 9, 'reg_alpha': 9.386162914036905, 'reg_lambda': 8.861389201320799, 'min_split_gain': 1.1226384222064123, 'min_child_weight': 20.385536859737403, 'min_data_in_leaf': 54}. Best is trial 41 with value: 1.5521295623116773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1543]\tvalid's rmse: 1.55244 + 0.00463276\n",
      "Trial 42: No improvement. Counter = 1, Best Score = 1.55213\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.62153 + 0.00695496\n",
      "[200]\tvalid's rmse: 1.59364 + 0.00602188\n",
      "[300]\tvalid's rmse: 1.57954 + 0.00553826\n",
      "[400]\tvalid's rmse: 1.57167 + 0.00529405\n",
      "[500]\tvalid's rmse: 1.56706 + 0.00511288\n",
      "[600]\tvalid's rmse: 1.56398 + 0.00505343\n",
      "[700]\tvalid's rmse: 1.56148 + 0.00497427\n",
      "[800]\tvalid's rmse: 1.55972 + 0.004955\n",
      "[900]\tvalid's rmse: 1.55827 + 0.00491522\n",
      "[1000]\tvalid's rmse: 1.55709 + 0.00492804\n",
      "[1100]\tvalid's rmse: 1.5563 + 0.00490049\n",
      "[1200]\tvalid's rmse: 1.55567 + 0.00491241\n",
      "[1300]\tvalid's rmse: 1.55527 + 0.00489952\n",
      "[1400]\tvalid's rmse: 1.55483 + 0.00492703\n",
      "[1500]\tvalid's rmse: 1.55455 + 0.00489027\n",
      "[1600]\tvalid's rmse: 1.55432 + 0.00490864\n",
      "[1700]\tvalid's rmse: 1.55416 + 0.00488951\n",
      "[1800]\tvalid's rmse: 1.55402 + 0.00486374\n",
      "[1900]\tvalid's rmse: 1.55388 + 0.00488574\n",
      "[2000]\tvalid's rmse: 1.55381 + 0.004883\n",
      "[2100]\tvalid's rmse: 1.55375 + 0.00486246\n",
      "[2200]\tvalid's rmse: 1.5537 + 0.00486982\n",
      "[2300]\tvalid's rmse: 1.55361 + 0.00481594\n",
      "[2400]\tvalid's rmse: 1.5536 + 0.00479647\n",
      "[2500]\tvalid's rmse: 1.5536 + 0.00478381\n",
      "[2600]\tvalid's rmse: 1.55358 + 0.00476197\n",
      "[2700]\tvalid's rmse: 1.55363 + 0.00477953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:04:54,887] Trial 43 finished with value: 1.5535654435299822 and parameters: {'num_leaves': 57, 'colsample_bytree': 0.0655104281252158, 'subsample': 0.6236806847262194, 'max_depth': 11, 'reg_alpha': 9.132807165692213, 'reg_lambda': 8.121443285901384, 'min_split_gain': 0.8238528611723599, 'min_child_weight': 17.32625441484203, 'min_data_in_leaf': 54}. Best is trial 41 with value: 1.5521295623116773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2561]\tvalid's rmse: 1.55357 + 0.00478323\n",
      "Trial 43: No improvement. Counter = 2, Best Score = 1.55213\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60683 + 0.00683413\n",
      "[200]\tvalid's rmse: 1.57804 + 0.00595585\n",
      "[300]\tvalid's rmse: 1.56641 + 0.00555315\n",
      "[400]\tvalid's rmse: 1.56077 + 0.00526784\n",
      "[500]\tvalid's rmse: 1.55767 + 0.00512115\n",
      "[600]\tvalid's rmse: 1.55566 + 0.00502328\n",
      "[700]\tvalid's rmse: 1.55449 + 0.00493957\n",
      "[800]\tvalid's rmse: 1.55371 + 0.00488809\n",
      "[900]\tvalid's rmse: 1.55319 + 0.0048221\n",
      "[1000]\tvalid's rmse: 1.55282 + 0.0047682\n",
      "[1100]\tvalid's rmse: 1.55263 + 0.0047297\n",
      "[1200]\tvalid's rmse: 1.55254 + 0.00469791\n",
      "[1300]\tvalid's rmse: 1.55246 + 0.00469022\n",
      "[1400]\tvalid's rmse: 1.55242 + 0.00468864\n",
      "[1500]\tvalid's rmse: 1.55241 + 0.00465144\n",
      "[1600]\tvalid's rmse: 1.55244 + 0.00460642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:05:15,258] Trial 44 finished with value: 1.5524081958460163 and parameters: {'num_leaves': 51, 'colsample_bytree': 0.21029968780976888, 'subsample': 0.5708258637488094, 'max_depth': 9, 'reg_alpha': 9.520262631845988, 'reg_lambda': 8.553632500703445, 'min_split_gain': 1.6168301413250816, 'min_child_weight': 22.700389393992353, 'min_data_in_leaf': 53}. Best is trial 41 with value: 1.5521295623116773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1489]\tvalid's rmse: 1.55241 + 0.00465936\n",
      "Trial 44: No improvement. Counter = 3, Best Score = 1.55213\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60269 + 0.00672192\n",
      "[200]\tvalid's rmse: 1.57434 + 0.00582544\n",
      "[300]\tvalid's rmse: 1.56375 + 0.00542235\n",
      "[400]\tvalid's rmse: 1.55884 + 0.00516426\n",
      "[500]\tvalid's rmse: 1.55616 + 0.00496962\n",
      "[600]\tvalid's rmse: 1.55458 + 0.00487513\n",
      "[700]\tvalid's rmse: 1.55365 + 0.00479694\n",
      "[800]\tvalid's rmse: 1.55309 + 0.00477272\n",
      "[900]\tvalid's rmse: 1.55274 + 0.00471475\n",
      "[1000]\tvalid's rmse: 1.55256 + 0.00467847\n",
      "[1100]\tvalid's rmse: 1.55247 + 0.00461873\n",
      "[1200]\tvalid's rmse: 1.55245 + 0.0045609\n",
      "[1300]\tvalid's rmse: 1.55242 + 0.00451311\n",
      "[1400]\tvalid's rmse: 1.55245 + 0.00451173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:05:38,860] Trial 45 finished with value: 1.5524115959035958 and parameters: {'num_leaves': 61, 'colsample_bytree': 0.2929150607719624, 'subsample': 0.6011147621153954, 'max_depth': 10, 'reg_alpha': 9.880657735301263, 'reg_lambda': 8.545292661472262, 'min_split_gain': 1.0948812207400325, 'min_child_weight': 20.754213084714195, 'min_data_in_leaf': 59}. Best is trial 41 with value: 1.5521295623116773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1284]\tvalid's rmse: 1.55241 + 0.00451009\n",
      "Trial 45: No improvement. Counter = 4, Best Score = 1.55213\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.6923 + 0.00809612\n",
      "[200]\tvalid's rmse: 1.67596 + 0.00791251\n",
      "[300]\tvalid's rmse: 1.66498 + 0.00774656\n",
      "[400]\tvalid's rmse: 1.65801 + 0.00758856\n",
      "[500]\tvalid's rmse: 1.65103 + 0.00741816\n",
      "[600]\tvalid's rmse: 1.64536 + 0.00726158\n",
      "[700]\tvalid's rmse: 1.63983 + 0.00709679\n",
      "[800]\tvalid's rmse: 1.63515 + 0.00692664\n",
      "[900]\tvalid's rmse: 1.6323 + 0.00680729\n",
      "[1000]\tvalid's rmse: 1.62971 + 0.00668631\n",
      "[1100]\tvalid's rmse: 1.62647 + 0.00656435\n",
      "[1200]\tvalid's rmse: 1.62449 + 0.0064738\n",
      "[1300]\tvalid's rmse: 1.62287 + 0.00636865\n",
      "[1400]\tvalid's rmse: 1.62089 + 0.00627092\n",
      "[1500]\tvalid's rmse: 1.61932 + 0.00615565\n",
      "[1600]\tvalid's rmse: 1.61845 + 0.00607314\n",
      "[1700]\tvalid's rmse: 1.61678 + 0.00597375\n",
      "[1800]\tvalid's rmse: 1.61541 + 0.00590115\n",
      "[1900]\tvalid's rmse: 1.61445 + 0.00581787\n",
      "[2000]\tvalid's rmse: 1.61342 + 0.00575035\n",
      "[2100]\tvalid's rmse: 1.61208 + 0.00566309\n",
      "[2200]\tvalid's rmse: 1.61001 + 0.00558972\n",
      "[2300]\tvalid's rmse: 1.60867 + 0.0055343\n",
      "[2400]\tvalid's rmse: 1.60692 + 0.00544933\n",
      "[2500]\tvalid's rmse: 1.60579 + 0.005382\n",
      "[2600]\tvalid's rmse: 1.60462 + 0.00530468\n",
      "[2700]\tvalid's rmse: 1.60366 + 0.00525255\n",
      "[2800]\tvalid's rmse: 1.60293 + 0.00520748\n",
      "[2900]\tvalid's rmse: 1.60229 + 0.00517864\n",
      "[3000]\tvalid's rmse: 1.60184 + 0.00514245\n",
      "[3100]\tvalid's rmse: 1.60122 + 0.00508343\n",
      "[3200]\tvalid's rmse: 1.60048 + 0.0050445\n",
      "[3300]\tvalid's rmse: 1.59999 + 0.0050243\n",
      "[3400]\tvalid's rmse: 1.59937 + 0.00497344\n",
      "[3500]\tvalid's rmse: 1.599 + 0.00493321\n",
      "[3600]\tvalid's rmse: 1.59853 + 0.00489245\n",
      "[3700]\tvalid's rmse: 1.59825 + 0.00485537\n",
      "[3800]\tvalid's rmse: 1.59783 + 0.00482814\n",
      "[3900]\tvalid's rmse: 1.59754 + 0.00478704\n",
      "[4000]\tvalid's rmse: 1.59711 + 0.00475522\n",
      "[4100]\tvalid's rmse: 1.59668 + 0.00473401\n",
      "[4200]\tvalid's rmse: 1.59619 + 0.00470796\n",
      "[4300]\tvalid's rmse: 1.59579 + 0.004685\n",
      "[4400]\tvalid's rmse: 1.59563 + 0.00464926\n",
      "[4500]\tvalid's rmse: 1.59517 + 0.00462335\n",
      "[4600]\tvalid's rmse: 1.59496 + 0.00459798\n",
      "[4700]\tvalid's rmse: 1.59464 + 0.00456511\n",
      "[4800]\tvalid's rmse: 1.59439 + 0.00455184\n",
      "[4900]\tvalid's rmse: 1.59411 + 0.00453495\n",
      "[5000]\tvalid's rmse: 1.59364 + 0.00450415\n",
      "[5100]\tvalid's rmse: 1.59326 + 0.00448214\n",
      "[5200]\tvalid's rmse: 1.59287 + 0.00445301\n",
      "[5300]\tvalid's rmse: 1.5927 + 0.00443544\n",
      "[5400]\tvalid's rmse: 1.59245 + 0.00442497\n",
      "[5500]\tvalid's rmse: 1.59212 + 0.00441066\n",
      "[5600]\tvalid's rmse: 1.59203 + 0.00438512\n",
      "[5700]\tvalid's rmse: 1.59187 + 0.00436862\n",
      "[5800]\tvalid's rmse: 1.59183 + 0.00435316\n",
      "[5900]\tvalid's rmse: 1.59158 + 0.00433439\n",
      "[6000]\tvalid's rmse: 1.59148 + 0.00432918\n",
      "[6100]\tvalid's rmse: 1.59134 + 0.00431988\n",
      "[6200]\tvalid's rmse: 1.59105 + 0.00430617\n",
      "[6300]\tvalid's rmse: 1.59083 + 0.00429759\n",
      "[6400]\tvalid's rmse: 1.59065 + 0.00428215\n",
      "[6500]\tvalid's rmse: 1.59044 + 0.0042653\n",
      "[6600]\tvalid's rmse: 1.59033 + 0.00425116\n",
      "[6700]\tvalid's rmse: 1.59026 + 0.00423726\n",
      "[6800]\tvalid's rmse: 1.59012 + 0.00422149\n",
      "[6900]\tvalid's rmse: 1.59007 + 0.00421811\n",
      "[7000]\tvalid's rmse: 1.59003 + 0.00420983\n",
      "[7100]\tvalid's rmse: 1.58994 + 0.00419327\n",
      "[7200]\tvalid's rmse: 1.58982 + 0.00418827\n",
      "[7300]\tvalid's rmse: 1.58973 + 0.00417414\n",
      "[7400]\tvalid's rmse: 1.58969 + 0.00416227\n",
      "[7500]\tvalid's rmse: 1.58955 + 0.00416214\n",
      "[7600]\tvalid's rmse: 1.58958 + 0.00415328\n",
      "[7700]\tvalid's rmse: 1.58955 + 0.00414375\n",
      "[7800]\tvalid's rmse: 1.58951 + 0.00413365\n",
      "[7900]\tvalid's rmse: 1.58948 + 0.00412997\n",
      "[8000]\tvalid's rmse: 1.58949 + 0.00412574\n",
      "[8100]\tvalid's rmse: 1.58946 + 0.00411497\n",
      "[8200]\tvalid's rmse: 1.58942 + 0.00410323\n",
      "[8300]\tvalid's rmse: 1.58921 + 0.00408936\n",
      "[8400]\tvalid's rmse: 1.58917 + 0.00407607\n",
      "[8500]\tvalid's rmse: 1.58905 + 0.00406769\n",
      "[8600]\tvalid's rmse: 1.58898 + 0.00406813\n",
      "[8700]\tvalid's rmse: 1.58902 + 0.00406725\n",
      "[8800]\tvalid's rmse: 1.58898 + 0.00404831\n",
      "[8900]\tvalid's rmse: 1.58895 + 0.00404335\n",
      "[9000]\tvalid's rmse: 1.5889 + 0.00404131\n",
      "[9100]\tvalid's rmse: 1.58884 + 0.00403512\n",
      "[9200]\tvalid's rmse: 1.58883 + 0.00403709\n",
      "[9300]\tvalid's rmse: 1.58887 + 0.00403188\n",
      "[9400]\tvalid's rmse: 1.58882 + 0.00401686\n",
      "Early stopping, best iteration is:\n",
      "[9210]\tvalid's rmse: 1.58881 + 0.00403675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:06:18,524] Trial 46 finished with value: 1.5888090131261166 and parameters: {'num_leaves': 60, 'colsample_bytree': 0.0011403484685249543, 'subsample': 0.5692398049247824, 'max_depth': 11, 'reg_alpha': 9.557740643201127, 'reg_lambda': 7.541970585974203, 'min_split_gain': 0.12075049968365037, 'min_child_weight': 8.818617189577523, 'min_data_in_leaf': 58}. Best is trial 41 with value: 1.5521295623116773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46: No improvement. Counter = 5, Best Score = 1.55213\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60616 + 0.00685569\n",
      "[200]\tvalid's rmse: 1.57722 + 0.00598634\n",
      "[300]\tvalid's rmse: 1.5657 + 0.00553265\n",
      "[400]\tvalid's rmse: 1.56015 + 0.0052795\n",
      "[500]\tvalid's rmse: 1.55709 + 0.00515341\n",
      "[600]\tvalid's rmse: 1.55517 + 0.00509224\n",
      "[700]\tvalid's rmse: 1.55402 + 0.00497506\n",
      "[800]\tvalid's rmse: 1.55329 + 0.0049075\n",
      "[900]\tvalid's rmse: 1.55281 + 0.00489709\n",
      "[1000]\tvalid's rmse: 1.55247 + 0.00483062\n",
      "[1100]\tvalid's rmse: 1.55227 + 0.00480783\n",
      "[1200]\tvalid's rmse: 1.55219 + 0.00474297\n",
      "[1300]\tvalid's rmse: 1.55216 + 0.00472828\n",
      "[1400]\tvalid's rmse: 1.55216 + 0.00475767\n",
      "[1500]\tvalid's rmse: 1.55211 + 0.00476619\n",
      "[1600]\tvalid's rmse: 1.55213 + 0.00474386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:06:42,683] Trial 47 finished with value: 1.5521140457935696 and parameters: {'num_leaves': 61, 'colsample_bytree': 0.1955885216920464, 'subsample': 0.6276350352835681, 'max_depth': 10, 'reg_alpha': 9.98304870460778, 'reg_lambda': 8.38592455734228, 'min_split_gain': 0.8219671068301144, 'min_child_weight': 15.937053303977134, 'min_data_in_leaf': 61}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\tvalid's rmse: 1.55217 + 0.00473967\n",
      "Early stopping, best iteration is:\n",
      "[1501]\tvalid's rmse: 1.55211 + 0.00476798\n",
      "Trial 47: Improved score: 1.55211 (Previous best: 1.55213)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60571 + 0.00684439\n",
      "[200]\tvalid's rmse: 1.5769 + 0.00594081\n",
      "[300]\tvalid's rmse: 1.5656 + 0.0054657\n",
      "[400]\tvalid's rmse: 1.56016 + 0.0052589\n",
      "[500]\tvalid's rmse: 1.55722 + 0.00509828\n",
      "[600]\tvalid's rmse: 1.55539 + 0.00498601\n",
      "[700]\tvalid's rmse: 1.55431 + 0.00489523\n",
      "[800]\tvalid's rmse: 1.55352 + 0.00483448\n",
      "[900]\tvalid's rmse: 1.55306 + 0.00482966\n",
      "[1000]\tvalid's rmse: 1.55277 + 0.00473863\n",
      "[1100]\tvalid's rmse: 1.55256 + 0.00471166\n",
      "[1200]\tvalid's rmse: 1.55244 + 0.00469864\n",
      "[1300]\tvalid's rmse: 1.55239 + 0.00464407\n",
      "[1400]\tvalid's rmse: 1.55234 + 0.00467058\n",
      "[1500]\tvalid's rmse: 1.55234 + 0.00467565\n",
      "[1600]\tvalid's rmse: 1.55236 + 0.00461661\n",
      "[1700]\tvalid's rmse: 1.5524 + 0.00463782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:07:08,761] Trial 48 finished with value: 1.5523176297970238 and parameters: {'num_leaves': 62, 'colsample_bytree': 0.20542722534939042, 'subsample': 0.6657962759377211, 'max_depth': 8, 'reg_alpha': 9.875393521390672, 'reg_lambda': 6.747950362055515, 'min_split_gain': 1.1229237024141836, 'min_child_weight': 15.285287365367731, 'min_data_in_leaf': 61}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1544]\tvalid's rmse: 1.55232 + 0.00465817\n",
      "Trial 48: No improvement. Counter = 1, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.59915 + 0.00652225\n",
      "[200]\tvalid's rmse: 1.57119 + 0.00557382\n",
      "[300]\tvalid's rmse: 1.56187 + 0.00498942\n",
      "[400]\tvalid's rmse: 1.55765 + 0.00472259\n",
      "[500]\tvalid's rmse: 1.55551 + 0.0045594\n",
      "[600]\tvalid's rmse: 1.55433 + 0.00449988\n",
      "[700]\tvalid's rmse: 1.55368 + 0.00449011\n",
      "[800]\tvalid's rmse: 1.55331 + 0.00446726\n",
      "[900]\tvalid's rmse: 1.5531 + 0.00440939\n",
      "[1000]\tvalid's rmse: 1.55303 + 0.00435872\n",
      "[1100]\tvalid's rmse: 1.553 + 0.0043505\n",
      "[1200]\tvalid's rmse: 1.55304 + 0.00435771\n",
      "[1300]\tvalid's rmse: 1.55314 + 0.00432656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:07:38,546] Trial 49 finished with value: 1.552987129047844 and parameters: {'num_leaves': 62, 'colsample_bytree': 0.6494446728977511, 'subsample': 0.8662491492081423, 'max_depth': 8, 'reg_alpha': 9.913111689193093, 'reg_lambda': 6.751002324949823, 'min_split_gain': 0.5052301334033034, 'min_child_weight': 10.280042901700503, 'min_data_in_leaf': 61}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1113]\tvalid's rmse: 1.55299 + 0.00434466\n",
      "Trial 49: No improvement. Counter = 2, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.62607 + 0.00698684\n",
      "[200]\tvalid's rmse: 1.59532 + 0.00596632\n",
      "[300]\tvalid's rmse: 1.58222 + 0.00551199\n",
      "[400]\tvalid's rmse: 1.57452 + 0.0052369\n",
      "[500]\tvalid's rmse: 1.56934 + 0.00515248\n",
      "[600]\tvalid's rmse: 1.56553 + 0.00504698\n",
      "[700]\tvalid's rmse: 1.56304 + 0.00500782\n",
      "[800]\tvalid's rmse: 1.56079 + 0.00496942\n",
      "[900]\tvalid's rmse: 1.55912 + 0.00489059\n",
      "[1000]\tvalid's rmse: 1.5579 + 0.00483616\n",
      "[1100]\tvalid's rmse: 1.55714 + 0.00480385\n",
      "[1200]\tvalid's rmse: 1.55634 + 0.00480262\n",
      "[1300]\tvalid's rmse: 1.55581 + 0.00482227\n",
      "[1400]\tvalid's rmse: 1.55529 + 0.00482987\n",
      "[1500]\tvalid's rmse: 1.55504 + 0.00479165\n",
      "[1600]\tvalid's rmse: 1.55473 + 0.00476476\n",
      "[1700]\tvalid's rmse: 1.5545 + 0.00476405\n",
      "[1800]\tvalid's rmse: 1.5543 + 0.004753\n",
      "[1900]\tvalid's rmse: 1.5542 + 0.00471981\n",
      "[2000]\tvalid's rmse: 1.55411 + 0.00469545\n",
      "[2100]\tvalid's rmse: 1.55401 + 0.00468292\n",
      "[2200]\tvalid's rmse: 1.55393 + 0.00467927\n",
      "[2300]\tvalid's rmse: 1.55385 + 0.00462499\n",
      "[2400]\tvalid's rmse: 1.55382 + 0.0046123\n",
      "[2500]\tvalid's rmse: 1.55378 + 0.00456893\n",
      "[2600]\tvalid's rmse: 1.5538 + 0.00452757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:08:06,962] Trial 50 finished with value: 1.5537718788423893 and parameters: {'num_leaves': 62, 'colsample_bytree': 0.055604320544208136, 'subsample': 0.6691978606769179, 'max_depth': 10, 'reg_alpha': 8.814377304429385, 'reg_lambda': 8.356041429722508, 'min_split_gain': 1.5274359033795648, 'min_child_weight': 15.40589928152767, 'min_data_in_leaf': 62}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2497]\tvalid's rmse: 1.55377 + 0.00457318\n",
      "Trial 50: No improvement. Counter = 3, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60502 + 0.00682413\n",
      "[200]\tvalid's rmse: 1.57654 + 0.00594651\n",
      "[300]\tvalid's rmse: 1.56543 + 0.005467\n",
      "[400]\tvalid's rmse: 1.56009 + 0.00517156\n",
      "[500]\tvalid's rmse: 1.55723 + 0.00501171\n",
      "[600]\tvalid's rmse: 1.55542 + 0.00493713\n",
      "[700]\tvalid's rmse: 1.55434 + 0.00485233\n",
      "[800]\tvalid's rmse: 1.55365 + 0.00481656\n",
      "[900]\tvalid's rmse: 1.5532 + 0.00481065\n",
      "[1000]\tvalid's rmse: 1.55288 + 0.00476285\n",
      "[1100]\tvalid's rmse: 1.55268 + 0.00470799\n",
      "[1200]\tvalid's rmse: 1.55256 + 0.00465528\n",
      "[1300]\tvalid's rmse: 1.55253 + 0.00461348\n",
      "[1400]\tvalid's rmse: 1.55252 + 0.00459329\n",
      "[1500]\tvalid's rmse: 1.5525 + 0.00459713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:08:31,044] Trial 51 finished with value: 1.552480579813418 and parameters: {'num_leaves': 61, 'colsample_bytree': 0.2149643215538041, 'subsample': 0.61359767823269, 'max_depth': 8, 'reg_alpha': 9.528972145151505, 'reg_lambda': 5.728502201917325, 'min_split_gain': 1.0072236490232016, 'min_child_weight': 17.89881325333313, 'min_data_in_leaf': 58}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1361]\tvalid's rmse: 1.55248 + 0.00458959\n",
      "Trial 51: No improvement. Counter = 4, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60825 + 0.0067944\n",
      "[200]\tvalid's rmse: 1.57923 + 0.00595726\n",
      "[300]\tvalid's rmse: 1.56807 + 0.00552221\n",
      "[400]\tvalid's rmse: 1.56205 + 0.00519161\n",
      "[500]\tvalid's rmse: 1.55871 + 0.00501408\n",
      "[600]\tvalid's rmse: 1.55673 + 0.00493634\n",
      "[700]\tvalid's rmse: 1.55536 + 0.00484849\n",
      "[800]\tvalid's rmse: 1.55443 + 0.00482633\n",
      "[900]\tvalid's rmse: 1.55378 + 0.00477592\n",
      "[1000]\tvalid's rmse: 1.55334 + 0.00474438\n",
      "[1100]\tvalid's rmse: 1.55302 + 0.00471234\n",
      "[1200]\tvalid's rmse: 1.55279 + 0.00466496\n",
      "[1300]\tvalid's rmse: 1.55265 + 0.00465765\n",
      "[1400]\tvalid's rmse: 1.5526 + 0.00459514\n",
      "[1500]\tvalid's rmse: 1.55255 + 0.00457619\n",
      "[1600]\tvalid's rmse: 1.55253 + 0.00456001\n",
      "[1700]\tvalid's rmse: 1.55248 + 0.00453771\n",
      "[1800]\tvalid's rmse: 1.55251 + 0.00453899\n",
      "[1900]\tvalid's rmse: 1.55254 + 0.00452679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:08:56,012] Trial 52 finished with value: 1.5524722757629377 and parameters: {'num_leaves': 58, 'colsample_bytree': 0.1394242956676966, 'subsample': 0.7063462341906099, 'max_depth': 9, 'reg_alpha': 9.408368838898038, 'reg_lambda': 7.873266527823606, 'min_split_gain': 1.1285311034070393, 'min_child_weight': 14.428680938149329, 'min_data_in_leaf': 53}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1726]\tvalid's rmse: 1.55247 + 0.00453628\n",
      "Trial 52: No improvement. Counter = 5, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60552 + 0.00685157\n",
      "[200]\tvalid's rmse: 1.57699 + 0.00596253\n",
      "[300]\tvalid's rmse: 1.56573 + 0.00555559\n",
      "[400]\tvalid's rmse: 1.56024 + 0.00529437\n",
      "[500]\tvalid's rmse: 1.5573 + 0.0051252\n",
      "[600]\tvalid's rmse: 1.5554 + 0.00500994\n",
      "[700]\tvalid's rmse: 1.5543 + 0.00498223\n",
      "[800]\tvalid's rmse: 1.55353 + 0.00492969\n",
      "[900]\tvalid's rmse: 1.5531 + 0.00492176\n",
      "[1000]\tvalid's rmse: 1.55278 + 0.00488213\n",
      "[1100]\tvalid's rmse: 1.55258 + 0.00480419\n",
      "[1200]\tvalid's rmse: 1.55251 + 0.00476052\n",
      "[1300]\tvalid's rmse: 1.55244 + 0.00469469\n",
      "[1400]\tvalid's rmse: 1.55245 + 0.00469732\n",
      "[1500]\tvalid's rmse: 1.55244 + 0.00466663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:09:16,146] Trial 53 finished with value: 1.5524261872079892 and parameters: {'num_leaves': 56, 'colsample_bytree': 0.21195298025475373, 'subsample': 0.5860848143742247, 'max_depth': 10, 'reg_alpha': 9.916621350482421, 'reg_lambda': 7.063257635386081, 'min_split_gain': 1.7209107324467565, 'min_child_weight': 23.32412110147247, 'min_data_in_leaf': 61}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1357]\tvalid's rmse: 1.55243 + 0.00468129\n",
      "Trial 53: No improvement. Counter = 6, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60273 + 0.00674875\n",
      "[200]\tvalid's rmse: 1.5744 + 0.00587808\n",
      "[300]\tvalid's rmse: 1.56381 + 0.00548557\n",
      "[400]\tvalid's rmse: 1.55896 + 0.00523836\n",
      "[500]\tvalid's rmse: 1.55631 + 0.00505805\n",
      "[600]\tvalid's rmse: 1.55467 + 0.00496595\n",
      "[700]\tvalid's rmse: 1.55375 + 0.00486125\n",
      "[800]\tvalid's rmse: 1.55323 + 0.0048383\n",
      "[900]\tvalid's rmse: 1.55287 + 0.00477819\n",
      "[1000]\tvalid's rmse: 1.55269 + 0.00475082\n",
      "[1100]\tvalid's rmse: 1.55256 + 0.00466826\n",
      "[1200]\tvalid's rmse: 1.55256 + 0.00460234\n",
      "[1300]\tvalid's rmse: 1.55253 + 0.00455729\n",
      "[1400]\tvalid's rmse: 1.55255 + 0.00452334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:09:38,920] Trial 54 finished with value: 1.5525163306454701 and parameters: {'num_leaves': 56, 'colsample_bytree': 0.32396092868011367, 'subsample': 0.5887463468936718, 'max_depth': 10, 'reg_alpha': 9.999732849596537, 'reg_lambda': 6.187646792536838, 'min_split_gain': 1.7517418422651088, 'min_child_weight': 23.264141947561413, 'min_data_in_leaf': 61}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1266]\tvalid's rmse: 1.55252 + 0.00455666\n",
      "Trial 54: No improvement. Counter = 7, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60969 + 0.00679423\n",
      "[200]\tvalid's rmse: 1.57979 + 0.00603859\n",
      "[300]\tvalid's rmse: 1.56835 + 0.0055489\n",
      "[400]\tvalid's rmse: 1.56242 + 0.00523705\n",
      "[500]\tvalid's rmse: 1.55894 + 0.00511714\n",
      "[600]\tvalid's rmse: 1.55699 + 0.00511979\n",
      "[700]\tvalid's rmse: 1.55571 + 0.0050512\n",
      "[800]\tvalid's rmse: 1.55491 + 0.00501694\n",
      "[900]\tvalid's rmse: 1.55432 + 0.00497296\n",
      "[1000]\tvalid's rmse: 1.55394 + 0.00499309\n",
      "[1100]\tvalid's rmse: 1.55372 + 0.00498668\n",
      "[1200]\tvalid's rmse: 1.55364 + 0.00497951\n",
      "[1300]\tvalid's rmse: 1.55356 + 0.00497598\n",
      "[1400]\tvalid's rmse: 1.55353 + 0.00498127\n",
      "[1500]\tvalid's rmse: 1.55351 + 0.00497792\n",
      "[1600]\tvalid's rmse: 1.55349 + 0.00497593\n",
      "[1700]\tvalid's rmse: 1.55347 + 0.00496908\n",
      "[1800]\tvalid's rmse: 1.55346 + 0.00496852\n",
      "[1900]\tvalid's rmse: 1.55345 + 0.0049651\n",
      "[2000]\tvalid's rmse: 1.55344 + 0.00495884\n",
      "[2100]\tvalid's rmse: 1.55343 + 0.00495668\n",
      "[2200]\tvalid's rmse: 1.55343 + 0.00495642\n",
      "[2300]\tvalid's rmse: 1.55343 + 0.00495765\n",
      "[2400]\tvalid's rmse: 1.55343 + 0.00495738\n",
      "[2500]\tvalid's rmse: 1.55343 + 0.0049574\n",
      "Early stopping, best iteration is:\n",
      "[2329]\tvalid's rmse: 1.55343 + 0.00495683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:09:57,715] Trial 55 finished with value: 1.553428918262057 and parameters: {'num_leaves': 64, 'colsample_bytree': 0.1316128182605928, 'subsample': 0.6533716648046879, 'max_depth': 8, 'reg_alpha': 9.979483995767099, 'reg_lambda': 7.003447629213857, 'min_split_gain': 5.561362899850459, 'min_child_weight': 0.17076630672950444, 'min_data_in_leaf': 57}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55: No improvement. Counter = 8, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.62155 + 0.0070255\n",
      "[200]\tvalid's rmse: 1.59422 + 0.00630365\n",
      "[300]\tvalid's rmse: 1.58166 + 0.0059387\n",
      "[400]\tvalid's rmse: 1.57455 + 0.00567829\n",
      "[500]\tvalid's rmse: 1.56986 + 0.00543311\n",
      "[600]\tvalid's rmse: 1.56645 + 0.00528849\n",
      "[700]\tvalid's rmse: 1.56399 + 0.00513482\n",
      "[800]\tvalid's rmse: 1.56209 + 0.00508313\n",
      "[900]\tvalid's rmse: 1.56066 + 0.00500954\n",
      "[1000]\tvalid's rmse: 1.55955 + 0.00493104\n",
      "[1100]\tvalid's rmse: 1.55865 + 0.00495887\n",
      "[1200]\tvalid's rmse: 1.55799 + 0.00492998\n",
      "[1300]\tvalid's rmse: 1.55745 + 0.00489752\n",
      "[1400]\tvalid's rmse: 1.55697 + 0.00492159\n",
      "[1500]\tvalid's rmse: 1.55662 + 0.00487037\n",
      "[1600]\tvalid's rmse: 1.55634 + 0.0048269\n",
      "[1700]\tvalid's rmse: 1.55612 + 0.00481538\n",
      "[1800]\tvalid's rmse: 1.55592 + 0.0048146\n",
      "[1900]\tvalid's rmse: 1.55576 + 0.00479023\n",
      "[2000]\tvalid's rmse: 1.55562 + 0.00481128\n",
      "[2100]\tvalid's rmse: 1.5555 + 0.00479539\n",
      "[2200]\tvalid's rmse: 1.55539 + 0.00477384\n",
      "[2300]\tvalid's rmse: 1.55529 + 0.00475042\n",
      "[2400]\tvalid's rmse: 1.55522 + 0.00475\n",
      "[2500]\tvalid's rmse: 1.55514 + 0.00473914\n",
      "[2600]\tvalid's rmse: 1.55509 + 0.00473127\n",
      "[2700]\tvalid's rmse: 1.55502 + 0.00471797\n",
      "[2800]\tvalid's rmse: 1.55496 + 0.00470126\n",
      "[2900]\tvalid's rmse: 1.5549 + 0.00471119\n",
      "[3000]\tvalid's rmse: 1.55487 + 0.00471087\n",
      "[3100]\tvalid's rmse: 1.55483 + 0.00471605\n",
      "[3200]\tvalid's rmse: 1.55483 + 0.00472001\n",
      "[3300]\tvalid's rmse: 1.55479 + 0.00471955\n",
      "[3400]\tvalid's rmse: 1.55479 + 0.00471688\n",
      "[3500]\tvalid's rmse: 1.55476 + 0.00469999\n",
      "[3600]\tvalid's rmse: 1.55474 + 0.00468377\n",
      "[3700]\tvalid's rmse: 1.55474 + 0.00467813\n",
      "[3800]\tvalid's rmse: 1.55471 + 0.0046984\n",
      "[3900]\tvalid's rmse: 1.5547 + 0.00471601\n",
      "[4000]\tvalid's rmse: 1.55468 + 0.00470117\n",
      "[4100]\tvalid's rmse: 1.55467 + 0.00469087\n",
      "[4200]\tvalid's rmse: 1.55468 + 0.00466757\n",
      "[4300]\tvalid's rmse: 1.55466 + 0.00466939\n",
      "[4400]\tvalid's rmse: 1.55467 + 0.00469304\n",
      "[4500]\tvalid's rmse: 1.55467 + 0.00469351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:10:26,563] Trial 56 finished with value: 1.55464880295139 and parameters: {'num_leaves': 59, 'colsample_bytree': 0.20772404536928954, 'subsample': 0.7478619619453718, 'max_depth': 4, 'reg_alpha': 1.0249920431905748, 'reg_lambda': 5.359469632118667, 'min_split_gain': 0.05590116923011601, 'min_child_weight': 6.547746017141252, 'min_data_in_leaf': 60}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4358]\tvalid's rmse: 1.55465 + 0.00467396\n",
      "Trial 56: No improvement. Counter = 9, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60395 + 0.00674773\n",
      "[200]\tvalid's rmse: 1.57549 + 0.00593203\n",
      "[300]\tvalid's rmse: 1.56462 + 0.00547708\n",
      "[400]\tvalid's rmse: 1.55968 + 0.0051853\n",
      "[500]\tvalid's rmse: 1.55706 + 0.0050049\n",
      "[600]\tvalid's rmse: 1.55552 + 0.00488511\n",
      "[700]\tvalid's rmse: 1.55462 + 0.00479336\n",
      "[800]\tvalid's rmse: 1.55415 + 0.00475951\n",
      "[900]\tvalid's rmse: 1.55392 + 0.00476586\n",
      "[1000]\tvalid's rmse: 1.55389 + 0.00476942\n",
      "[1100]\tvalid's rmse: 1.55389 + 0.00476891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:10:39,191] Trial 57 finished with value: 1.5538886568939667 and parameters: {'num_leaves': 62, 'colsample_bytree': 0.2727281601406696, 'subsample': 0.5629023399007383, 'max_depth': 7, 'reg_alpha': 8.875522266279347, 'reg_lambda': 7.4769256726731905, 'min_split_gain': 7.885426163427505, 'min_child_weight': 11.700110464473887, 'min_data_in_leaf': 64}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\tvalid's rmse: 1.55389 + 0.00476891\n",
      "Early stopping, best iteration is:\n",
      "[1015]\tvalid's rmse: 1.55389 + 0.0047685\n",
      "Trial 57: No improvement. Counter = 10, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.67194 + 0.00794595\n",
      "[200]\tvalid's rmse: 1.65128 + 0.00765196\n",
      "[300]\tvalid's rmse: 1.63839 + 0.00737106\n",
      "[400]\tvalid's rmse: 1.62972 + 0.00708571\n",
      "[500]\tvalid's rmse: 1.62335 + 0.00688076\n",
      "[600]\tvalid's rmse: 1.6185 + 0.00674019\n",
      "[700]\tvalid's rmse: 1.61475 + 0.00656942\n",
      "[800]\tvalid's rmse: 1.61158 + 0.00646317\n",
      "[900]\tvalid's rmse: 1.60887 + 0.00633609\n",
      "[1000]\tvalid's rmse: 1.6065 + 0.00625712\n",
      "[1100]\tvalid's rmse: 1.60438 + 0.00618607\n",
      "[1200]\tvalid's rmse: 1.60247 + 0.00610168\n",
      "[1300]\tvalid's rmse: 1.60081 + 0.00602022\n",
      "[1400]\tvalid's rmse: 1.59926 + 0.00595318\n",
      "[1500]\tvalid's rmse: 1.59786 + 0.00590613\n",
      "[1600]\tvalid's rmse: 1.59659 + 0.00586087\n",
      "[1700]\tvalid's rmse: 1.59543 + 0.00581384\n",
      "[1800]\tvalid's rmse: 1.59435 + 0.00577496\n",
      "[1900]\tvalid's rmse: 1.59331 + 0.00573618\n",
      "[2000]\tvalid's rmse: 1.59238 + 0.00569135\n",
      "[2100]\tvalid's rmse: 1.59151 + 0.00565981\n",
      "[2200]\tvalid's rmse: 1.59069 + 0.00562839\n",
      "[2300]\tvalid's rmse: 1.58994 + 0.00559857\n",
      "[2400]\tvalid's rmse: 1.58924 + 0.00556594\n",
      "[2500]\tvalid's rmse: 1.58856 + 0.00554835\n",
      "[2600]\tvalid's rmse: 1.58791 + 0.0055224\n",
      "[2700]\tvalid's rmse: 1.58731 + 0.00549952\n",
      "[2800]\tvalid's rmse: 1.58675 + 0.00547437\n",
      "[2900]\tvalid's rmse: 1.58623 + 0.00545081\n",
      "[3000]\tvalid's rmse: 1.58574 + 0.00543006\n",
      "[3100]\tvalid's rmse: 1.58527 + 0.00540649\n",
      "[3200]\tvalid's rmse: 1.58482 + 0.0053882\n",
      "[3300]\tvalid's rmse: 1.58439 + 0.0053677\n",
      "[3400]\tvalid's rmse: 1.58398 + 0.00534835\n",
      "[3500]\tvalid's rmse: 1.5836 + 0.00533285\n",
      "[3600]\tvalid's rmse: 1.58323 + 0.00531167\n",
      "[3700]\tvalid's rmse: 1.58287 + 0.00530152\n",
      "[3800]\tvalid's rmse: 1.58253 + 0.00528763\n",
      "[3900]\tvalid's rmse: 1.58222 + 0.00527781\n",
      "[4000]\tvalid's rmse: 1.58192 + 0.00526517\n",
      "[4100]\tvalid's rmse: 1.58163 + 0.00524769\n",
      "[4200]\tvalid's rmse: 1.58134 + 0.00523796\n",
      "[4300]\tvalid's rmse: 1.58108 + 0.00522239\n",
      "[4400]\tvalid's rmse: 1.58082 + 0.00521068\n",
      "[4500]\tvalid's rmse: 1.58058 + 0.00519321\n",
      "[4600]\tvalid's rmse: 1.58034 + 0.00518313\n",
      "[4700]\tvalid's rmse: 1.58011 + 0.00516859\n",
      "[4800]\tvalid's rmse: 1.5799 + 0.00515492\n",
      "[4900]\tvalid's rmse: 1.57969 + 0.00514524\n",
      "[5000]\tvalid's rmse: 1.57949 + 0.0051285\n",
      "[5100]\tvalid's rmse: 1.57929 + 0.00511277\n",
      "[5200]\tvalid's rmse: 1.57911 + 0.00510542\n",
      "[5300]\tvalid's rmse: 1.57893 + 0.00509488\n",
      "[5400]\tvalid's rmse: 1.57876 + 0.0050845\n",
      "[5500]\tvalid's rmse: 1.57859 + 0.00507761\n",
      "[5600]\tvalid's rmse: 1.57843 + 0.00506163\n",
      "[5700]\tvalid's rmse: 1.57828 + 0.00505269\n",
      "[5800]\tvalid's rmse: 1.57812 + 0.00504582\n",
      "[5900]\tvalid's rmse: 1.57798 + 0.00503611\n",
      "[6000]\tvalid's rmse: 1.57783 + 0.00502676\n",
      "[6100]\tvalid's rmse: 1.57769 + 0.00501824\n",
      "[6200]\tvalid's rmse: 1.57756 + 0.00501291\n",
      "[6300]\tvalid's rmse: 1.57743 + 0.0050047\n",
      "[6400]\tvalid's rmse: 1.5773 + 0.00499738\n",
      "[6500]\tvalid's rmse: 1.57717 + 0.004988\n",
      "[6600]\tvalid's rmse: 1.57705 + 0.00498081\n",
      "[6700]\tvalid's rmse: 1.57693 + 0.0049738\n",
      "[6800]\tvalid's rmse: 1.57682 + 0.00496604\n",
      "[6900]\tvalid's rmse: 1.57671 + 0.00495715\n",
      "[7000]\tvalid's rmse: 1.5766 + 0.00494955\n",
      "[7100]\tvalid's rmse: 1.57649 + 0.00493916\n",
      "[7200]\tvalid's rmse: 1.57639 + 0.00493264\n",
      "[7300]\tvalid's rmse: 1.57629 + 0.00492417\n",
      "[7400]\tvalid's rmse: 1.5762 + 0.00491466\n",
      "[7500]\tvalid's rmse: 1.5761 + 0.00491097\n",
      "[7600]\tvalid's rmse: 1.57601 + 0.00490177\n",
      "[7700]\tvalid's rmse: 1.57592 + 0.004896\n",
      "[7800]\tvalid's rmse: 1.57583 + 0.00489012\n",
      "[7900]\tvalid's rmse: 1.57575 + 0.00488255\n",
      "[8000]\tvalid's rmse: 1.57567 + 0.00487835\n",
      "[8100]\tvalid's rmse: 1.57558 + 0.00487168\n",
      "[8200]\tvalid's rmse: 1.57551 + 0.00486798\n",
      "[8300]\tvalid's rmse: 1.57543 + 0.00486339\n",
      "[8400]\tvalid's rmse: 1.57535 + 0.00486001\n",
      "[8500]\tvalid's rmse: 1.57528 + 0.00485549\n",
      "[8600]\tvalid's rmse: 1.57521 + 0.00485212\n",
      "[8700]\tvalid's rmse: 1.57514 + 0.00485141\n",
      "[8800]\tvalid's rmse: 1.57507 + 0.0048451\n",
      "[8900]\tvalid's rmse: 1.57501 + 0.00484448\n",
      "[9000]\tvalid's rmse: 1.57494 + 0.0048384\n",
      "[9100]\tvalid's rmse: 1.57488 + 0.00483456\n",
      "[9200]\tvalid's rmse: 1.57482 + 0.00483209\n",
      "[9300]\tvalid's rmse: 1.57476 + 0.00482917\n",
      "[9400]\tvalid's rmse: 1.5747 + 0.00482483\n",
      "[9500]\tvalid's rmse: 1.57464 + 0.00482437\n",
      "[9600]\tvalid's rmse: 1.57458 + 0.00482053\n",
      "[9700]\tvalid's rmse: 1.57453 + 0.00481701\n",
      "[9800]\tvalid's rmse: 1.57447 + 0.00481438\n",
      "[9900]\tvalid's rmse: 1.57442 + 0.00480939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:11:15,732] Trial 58 finished with value: 1.5743701356088955 and parameters: {'num_leaves': 56, 'colsample_bytree': 0.10484273104052952, 'subsample': 0.8039486783761307, 'max_depth': 1, 'reg_alpha': 9.572444865352933, 'reg_lambda': 8.359504951426146, 'min_split_gain': 0.5726858788008934, 'min_child_weight': 16.47813434649503, 'min_data_in_leaf': 62}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\tvalid's rmse: 1.57437 + 0.00480785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid's rmse: 1.57437 + 0.00480785\n",
      "Trial 58: No improvement. Counter = 11, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60893 + 0.0065909\n",
      "[200]\tvalid's rmse: 1.5791 + 0.00580358\n",
      "[300]\tvalid's rmse: 1.567 + 0.0054063\n",
      "[400]\tvalid's rmse: 1.56134 + 0.00514303\n",
      "[500]\tvalid's rmse: 1.55801 + 0.00497477\n",
      "[600]\tvalid's rmse: 1.55605 + 0.00486284\n",
      "[700]\tvalid's rmse: 1.55483 + 0.00480676\n",
      "[800]\tvalid's rmse: 1.55411 + 0.00470276\n",
      "[900]\tvalid's rmse: 1.55357 + 0.00467624\n",
      "[1000]\tvalid's rmse: 1.55319 + 0.00460604\n",
      "[1100]\tvalid's rmse: 1.55294 + 0.0045705\n",
      "[1200]\tvalid's rmse: 1.55276 + 0.00451243\n",
      "[1300]\tvalid's rmse: 1.55266 + 0.00450539\n",
      "[1400]\tvalid's rmse: 1.5526 + 0.00449921\n",
      "[1500]\tvalid's rmse: 1.55254 + 0.00446656\n",
      "[1600]\tvalid's rmse: 1.55254 + 0.00443122\n",
      "[1700]\tvalid's rmse: 1.55258 + 0.00442086\n",
      "[1800]\tvalid's rmse: 1.55264 + 0.00443339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:11:43,506] Trial 59 finished with value: 1.552522714669634 and parameters: {'num_leaves': 58, 'colsample_bytree': 0.1531887197789566, 'subsample': 0.8841396586282282, 'max_depth': 10, 'reg_alpha': 9.228784880020186, 'reg_lambda': 6.664717710103787, 'min_split_gain': 1.2700699150657453, 'min_child_weight': 29.926527983793495, 'min_data_in_leaf': 52}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1619]\tvalid's rmse: 1.55252 + 0.00443117\n",
      "Trial 59: No improvement. Counter = 12, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60459 + 0.00683852\n",
      "[200]\tvalid's rmse: 1.5764 + 0.00613491\n",
      "[300]\tvalid's rmse: 1.56578 + 0.00551857\n",
      "[400]\tvalid's rmse: 1.56081 + 0.00518648\n",
      "[500]\tvalid's rmse: 1.558 + 0.00499225\n",
      "[600]\tvalid's rmse: 1.55619 + 0.00481712\n",
      "[700]\tvalid's rmse: 1.55518 + 0.00471166\n",
      "[800]\tvalid's rmse: 1.55448 + 0.00463367\n",
      "[900]\tvalid's rmse: 1.554 + 0.00462802\n",
      "[1000]\tvalid's rmse: 1.55369 + 0.00456986\n",
      "[1100]\tvalid's rmse: 1.55346 + 0.00454223\n",
      "[1200]\tvalid's rmse: 1.55334 + 0.00450558\n",
      "[1300]\tvalid's rmse: 1.55328 + 0.00447571\n",
      "[1400]\tvalid's rmse: 1.55322 + 0.00445178\n",
      "[1500]\tvalid's rmse: 1.5532 + 0.00444287\n",
      "[1600]\tvalid's rmse: 1.55322 + 0.00444419\n",
      "[1700]\tvalid's rmse: 1.55317 + 0.00440821\n",
      "[1800]\tvalid's rmse: 1.55322 + 0.00440616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:12:07,112] Trial 60 finished with value: 1.5531659810700855 and parameters: {'num_leaves': 52, 'colsample_bytree': 0.35042055330970934, 'subsample': 0.6909206705015739, 'max_depth': 6, 'reg_alpha': 8.338499738649535, 'reg_lambda': 4.599557086165075, 'min_split_gain': 1.7324428834216243, 'min_child_weight': 23.511228117123398, 'min_data_in_leaf': 57}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\tvalid's rmse: 1.55325 + 0.00439361\n",
      "Early stopping, best iteration is:\n",
      "[1703]\tvalid's rmse: 1.55317 + 0.00440712\n",
      "Trial 60: No improvement. Counter = 13, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60559 + 0.00686086\n",
      "[200]\tvalid's rmse: 1.5768 + 0.00596854\n",
      "[300]\tvalid's rmse: 1.56542 + 0.00554832\n",
      "[400]\tvalid's rmse: 1.55995 + 0.00526575\n",
      "[500]\tvalid's rmse: 1.55706 + 0.00510194\n",
      "[600]\tvalid's rmse: 1.55518 + 0.00498852\n",
      "[700]\tvalid's rmse: 1.55409 + 0.0049045\n",
      "[800]\tvalid's rmse: 1.55338 + 0.00483383\n",
      "[900]\tvalid's rmse: 1.55298 + 0.00484987\n",
      "[1000]\tvalid's rmse: 1.55272 + 0.00479409\n",
      "[1100]\tvalid's rmse: 1.55255 + 0.0047521\n",
      "[1200]\tvalid's rmse: 1.55245 + 0.00473564\n",
      "[1300]\tvalid's rmse: 1.55245 + 0.00469157\n",
      "[1400]\tvalid's rmse: 1.55245 + 0.00464816\n",
      "[1500]\tvalid's rmse: 1.55242 + 0.0046419\n",
      "[1600]\tvalid's rmse: 1.55248 + 0.00459703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:12:40,536] Trial 61 finished with value: 1.5524089758331598 and parameters: {'num_leaves': 60, 'colsample_bytree': 0.20783052752216588, 'subsample': 0.6402093133729421, 'max_depth': 9, 'reg_alpha': 9.442299121507594, 'reg_lambda': 8.643203120005163, 'min_split_gain': 1.1171821362097631, 'min_child_weight': 20.114366747734614, 'min_data_in_leaf': 56}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1482]\tvalid's rmse: 1.55241 + 0.004656\n",
      "Trial 61: No improvement. Counter = 14, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60592 + 0.00690871\n",
      "[200]\tvalid's rmse: 1.57708 + 0.00597594\n",
      "[300]\tvalid's rmse: 1.56561 + 0.00548921\n",
      "[400]\tvalid's rmse: 1.56014 + 0.0052784\n",
      "[500]\tvalid's rmse: 1.55711 + 0.00516778\n",
      "[600]\tvalid's rmse: 1.55524 + 0.00508298\n",
      "[700]\tvalid's rmse: 1.55409 + 0.00498934\n",
      "[800]\tvalid's rmse: 1.55335 + 0.00490513\n",
      "[900]\tvalid's rmse: 1.5529 + 0.00487035\n",
      "[1000]\tvalid's rmse: 1.55255 + 0.00477751\n",
      "[1100]\tvalid's rmse: 1.55235 + 0.00475838\n",
      "[1200]\tvalid's rmse: 1.55226 + 0.00474876\n",
      "[1300]\tvalid's rmse: 1.55223 + 0.00471605\n",
      "[1400]\tvalid's rmse: 1.55219 + 0.00468086\n",
      "[1500]\tvalid's rmse: 1.55221 + 0.00463053\n",
      "[1600]\tvalid's rmse: 1.5522 + 0.00460825\n",
      "Early stopping, best iteration is:\n",
      "[1412]\tvalid's rmse: 1.55218 + 0.0046803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:13:00,318] Trial 62 finished with value: 1.5521783332623584 and parameters: {'num_leaves': 60, 'colsample_bytree': 0.2011687394602051, 'subsample': 0.6272871526100169, 'max_depth': 9, 'reg_alpha': 8.83011046027487, 'reg_lambda': 8.019479516989291, 'min_split_gain': 2.3865672904961523, 'min_child_weight': 18.318794685240846, 'min_data_in_leaf': 56}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62: No improvement. Counter = 15, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60593 + 0.00672674\n",
      "[200]\tvalid's rmse: 1.57731 + 0.00588004\n",
      "[300]\tvalid's rmse: 1.56575 + 0.00544582\n",
      "[400]\tvalid's rmse: 1.56027 + 0.0051833\n",
      "[500]\tvalid's rmse: 1.55733 + 0.00497938\n",
      "[600]\tvalid's rmse: 1.55549 + 0.00491855\n",
      "[700]\tvalid's rmse: 1.55434 + 0.00486083\n",
      "[800]\tvalid's rmse: 1.55363 + 0.00486192\n",
      "[900]\tvalid's rmse: 1.5531 + 0.0048598\n",
      "[1000]\tvalid's rmse: 1.55279 + 0.00485758\n",
      "[1100]\tvalid's rmse: 1.55263 + 0.00487952\n",
      "[1200]\tvalid's rmse: 1.55253 + 0.00483932\n",
      "[1300]\tvalid's rmse: 1.55245 + 0.00482116\n",
      "[1400]\tvalid's rmse: 1.55243 + 0.00477018\n",
      "[1500]\tvalid's rmse: 1.55245 + 0.00470108\n",
      "[1600]\tvalid's rmse: 1.55248 + 0.00469305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:13:23,914] Trial 63 finished with value: 1.5524204041752754 and parameters: {'num_leaves': 60, 'colsample_bytree': 0.1843151236340857, 'subsample': 0.6485096470868545, 'max_depth': 9, 'reg_alpha': 2.892706718610029, 'reg_lambda': 8.590996299301432, 'min_split_gain': 0.7278603618515704, 'min_child_weight': 18.36733903352865, 'min_data_in_leaf': 56}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1415]\tvalid's rmse: 1.55242 + 0.00476676\n",
      "Trial 63: No improvement. Counter = 16, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.60249 + 0.00673499\n",
      "[200]\tvalid's rmse: 1.57401 + 0.00579138\n",
      "[300]\tvalid's rmse: 1.5635 + 0.0053683\n",
      "[400]\tvalid's rmse: 1.55881 + 0.00502385\n",
      "[500]\tvalid's rmse: 1.55621 + 0.00483348\n",
      "[600]\tvalid's rmse: 1.55463 + 0.00466339\n",
      "[700]\tvalid's rmse: 1.55374 + 0.0046071\n",
      "[800]\tvalid's rmse: 1.55317 + 0.00454931\n",
      "[900]\tvalid's rmse: 1.55283 + 0.00451618\n",
      "[1000]\tvalid's rmse: 1.55266 + 0.00444713\n",
      "[1100]\tvalid's rmse: 1.55256 + 0.00439341\n",
      "[1200]\tvalid's rmse: 1.55252 + 0.00437152\n",
      "[1300]\tvalid's rmse: 1.55255 + 0.00436314\n",
      "[1400]\tvalid's rmse: 1.55256 + 0.00438461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:13:45,458] Trial 64 finished with value: 1.5524967667377163 and parameters: {'num_leaves': 64, 'colsample_bytree': 0.3002590471089538, 'subsample': 0.5393820791928206, 'max_depth': 8, 'reg_alpha': 8.961713148050647, 'reg_lambda': 8.085397619641295, 'min_split_gain': 2.4288183643269727, 'min_child_weight': 16.139312897108898, 'min_data_in_leaf': 50}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1228]\tvalid's rmse: 1.5525 + 0.00435042\n",
      "Trial 64: No improvement. Counter = 17, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.59887 + 0.00636332\n",
      "[200]\tvalid's rmse: 1.57114 + 0.00534105\n",
      "[300]\tvalid's rmse: 1.56174 + 0.00485098\n",
      "[400]\tvalid's rmse: 1.55747 + 0.00458168\n",
      "[500]\tvalid's rmse: 1.55541 + 0.00437959\n",
      "[600]\tvalid's rmse: 1.55443 + 0.00432627\n",
      "[700]\tvalid's rmse: 1.55387 + 0.00434162\n",
      "[800]\tvalid's rmse: 1.55353 + 0.00425451\n",
      "[900]\tvalid's rmse: 1.55337 + 0.00420718\n",
      "[1000]\tvalid's rmse: 1.55334 + 0.00417451\n",
      "[1100]\tvalid's rmse: 1.55331 + 0.00417644\n",
      "[1200]\tvalid's rmse: 1.55344 + 0.00411001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:14:20,801] Trial 65 finished with value: 1.5532975300618552 and parameters: {'num_leaves': 62, 'colsample_bytree': 0.8980953615309918, 'subsample': 0.4975525849505841, 'max_depth': 9, 'reg_alpha': 9.700381665741638, 'reg_lambda': 9.56944230191317, 'min_split_gain': 1.1989372831765197, 'min_child_weight': 20.647702991754993, 'min_data_in_leaf': 48}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1089]\tvalid's rmse: 1.5533 + 0.00417864\n",
      "Trial 65: No improvement. Counter = 18, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.61647 + 0.00685064\n",
      "[200]\tvalid's rmse: 1.58769 + 0.00590956\n",
      "[300]\tvalid's rmse: 1.57528 + 0.00540614\n",
      "[400]\tvalid's rmse: 1.5682 + 0.00522167\n",
      "[500]\tvalid's rmse: 1.5635 + 0.00503996\n",
      "[600]\tvalid's rmse: 1.56032 + 0.00488718\n",
      "[700]\tvalid's rmse: 1.55805 + 0.00482007\n",
      "[800]\tvalid's rmse: 1.55652 + 0.00481965\n",
      "[900]\tvalid's rmse: 1.55556 + 0.00479625\n",
      "[1000]\tvalid's rmse: 1.55485 + 0.00479622\n",
      "[1100]\tvalid's rmse: 1.55431 + 0.00479642\n",
      "[1200]\tvalid's rmse: 1.55398 + 0.00481847\n",
      "[1300]\tvalid's rmse: 1.55368 + 0.00477106\n",
      "[1400]\tvalid's rmse: 1.55345 + 0.00475489\n",
      "[1500]\tvalid's rmse: 1.55329 + 0.00471634\n",
      "[1600]\tvalid's rmse: 1.5532 + 0.00474086\n",
      "[1700]\tvalid's rmse: 1.55304 + 0.00472734\n",
      "[1800]\tvalid's rmse: 1.553 + 0.00468749\n",
      "[1900]\tvalid's rmse: 1.55302 + 0.00465422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:14:47,893] Trial 66 finished with value: 1.553000181020618 and parameters: {'num_leaves': 60, 'colsample_bytree': 0.08983799450079875, 'subsample': 0.7307537723741785, 'max_depth': 9, 'reg_alpha': 8.155556524971226, 'reg_lambda': 8.548453854440824, 'min_split_gain': 2.794850475600949, 'min_child_weight': 13.045581567645703, 'min_data_in_leaf': 57}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\tvalid's rmse: 1.55305 + 0.00459889\n",
      "Early stopping, best iteration is:\n",
      "[1800]\tvalid's rmse: 1.553 + 0.00468749\n",
      "Trial 66: No improvement. Counter = 19, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.59856 + 0.0064168\n",
      "[200]\tvalid's rmse: 1.57116 + 0.00545648\n",
      "[300]\tvalid's rmse: 1.56182 + 0.00490855\n",
      "[400]\tvalid's rmse: 1.55772 + 0.00463443\n",
      "[500]\tvalid's rmse: 1.55568 + 0.00440575\n",
      "[600]\tvalid's rmse: 1.55465 + 0.00427495\n",
      "[700]\tvalid's rmse: 1.55411 + 0.00431\n",
      "[800]\tvalid's rmse: 1.55389 + 0.00422998\n",
      "[900]\tvalid's rmse: 1.55383 + 0.00423809\n",
      "[1000]\tvalid's rmse: 1.55379 + 0.00422307\n",
      "[1100]\tvalid's rmse: 1.5538 + 0.00420138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:15:24,416] Trial 67 finished with value: 1.5537576995016005 and parameters: {'num_leaves': 63, 'colsample_bytree': 0.9734405438440862, 'subsample': 0.6179107372318936, 'max_depth': 10, 'reg_alpha': 8.711790690277446, 'reg_lambda': 7.752484504925828, 'min_split_gain': 0.37838611735513306, 'min_child_weight': 18.677339850759076, 'min_data_in_leaf': 59}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[964]\tvalid's rmse: 1.55376 + 0.00422581\n",
      "Trial 67: No improvement. Counter = 20, Best Score = 1.55211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 1.64392 + 0.00732627\n",
      "[200]\tvalid's rmse: 1.61866 + 0.00656214\n",
      "[300]\tvalid's rmse: 1.60306 + 0.00596495\n",
      "[400]\tvalid's rmse: 1.59416 + 0.00562081\n",
      "[500]\tvalid's rmse: 1.58656 + 0.00532637\n",
      "[600]\tvalid's rmse: 1.58197 + 0.00517673\n",
      "[700]\tvalid's rmse: 1.57776 + 0.00507638\n",
      "[800]\tvalid's rmse: 1.57457 + 0.00494464\n",
      "[900]\tvalid's rmse: 1.57166 + 0.00483598\n",
      "[1000]\tvalid's rmse: 1.56943 + 0.0048313\n",
      "[1100]\tvalid's rmse: 1.56787 + 0.00481767\n",
      "[1200]\tvalid's rmse: 1.56611 + 0.00476035\n",
      "[1300]\tvalid's rmse: 1.56501 + 0.00479084\n",
      "[1400]\tvalid's rmse: 1.56398 + 0.00476046\n",
      "[1500]\tvalid's rmse: 1.56299 + 0.00475298\n",
      "[1600]\tvalid's rmse: 1.56192 + 0.0047237\n",
      "[1700]\tvalid's rmse: 1.56123 + 0.00470463\n",
      "[1800]\tvalid's rmse: 1.56054 + 0.00469565\n",
      "[1900]\tvalid's rmse: 1.55991 + 0.00470569\n",
      "[2000]\tvalid's rmse: 1.55931 + 0.00467493\n",
      "[2100]\tvalid's rmse: 1.55865 + 0.00468284\n",
      "[2200]\tvalid's rmse: 1.55827 + 0.00468837\n",
      "[2300]\tvalid's rmse: 1.55796 + 0.00470023\n",
      "[2400]\tvalid's rmse: 1.55763 + 0.00471463\n",
      "[2500]\tvalid's rmse: 1.55744 + 0.00470511\n",
      "[2600]\tvalid's rmse: 1.55718 + 0.00470237\n",
      "[2700]\tvalid's rmse: 1.55695 + 0.00468765\n",
      "[2800]\tvalid's rmse: 1.55673 + 0.00470561\n",
      "[2900]\tvalid's rmse: 1.55653 + 0.00466781\n",
      "[3000]\tvalid's rmse: 1.55635 + 0.00466439\n",
      "[3100]\tvalid's rmse: 1.55621 + 0.0046596\n",
      "[3200]\tvalid's rmse: 1.55611 + 0.00466479\n",
      "[3300]\tvalid's rmse: 1.55599 + 0.00464449\n",
      "[3400]\tvalid's rmse: 1.5559 + 0.00462236\n",
      "[3500]\tvalid's rmse: 1.55579 + 0.00465049\n",
      "[3600]\tvalid's rmse: 1.55574 + 0.00463075\n",
      "[3700]\tvalid's rmse: 1.55567 + 0.00462735\n",
      "[3800]\tvalid's rmse: 1.55558 + 0.00461073\n",
      "[3900]\tvalid's rmse: 1.55554 + 0.00461831\n",
      "[4000]\tvalid's rmse: 1.55551 + 0.00462986\n",
      "[4100]\tvalid's rmse: 1.55545 + 0.00462102\n",
      "[4200]\tvalid's rmse: 1.55542 + 0.00461466\n",
      "[4300]\tvalid's rmse: 1.55539 + 0.00460342\n",
      "[4400]\tvalid's rmse: 1.55535 + 0.00460149\n",
      "[4500]\tvalid's rmse: 1.55534 + 0.00459484\n",
      "[4600]\tvalid's rmse: 1.55535 + 0.00457064\n",
      "[4700]\tvalid's rmse: 1.55534 + 0.00457061\n",
      "Early stopping, best iteration is:\n",
      "[4535]\tvalid's rmse: 1.55532 + 0.00457477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:15:52,756] Trial 68 finished with value: 1.555320843109077 and parameters: {'num_leaves': 25, 'colsample_bytree': 0.03407032475159549, 'subsample': 0.6418907163395001, 'max_depth': 8, 'reg_alpha': 9.318745076226863, 'reg_lambda': 8.187643841314499, 'min_split_gain': 1.5182149173511392, 'min_child_weight': 25.034212226963643, 'min_data_in_leaf': 63}. Best is trial 47 with value: 1.5521140457935696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68: No improvement. Counter = 21, Best Score = 1.55211\n",
      "Early stopping threshold reached. Terminating optimization.\n",
      "Early stopping triggered for LightGBM optimization.\n",
      "\n",
      " Best hyperparameters for LightGBM:\n",
      "    num_leaves: 61\n",
      "    colsample_bytree: 0.1955885216920464\n",
      "    subsample: 0.6276350352835681\n",
      "    max_depth: 10\n",
      "    reg_alpha: 9.98304870460778\n",
      "    reg_lambda: 8.38592455734228\n",
      "    min_split_gain: 0.8219671068301144\n",
      "    min_child_weight: 15.937053303977134\n",
      "    min_data_in_leaf: 61\n"
     ]
    }
   ],
   "source": [
    "# === MODEL 5 - PART 2: LIGHTGBM TUNING EXECUTION (with early stopping and logging) ===\n",
    "\n",
    "class LGB_EarlyStoppingExceeded(optuna.exceptions.OptunaError):\n",
    "    early_stop = 20  # Number of trials without improvement before stopping\n",
    "    early_stop_count = 0\n",
    "    best_score = None\n",
    "\n",
    "def lgb_early_stopping_opt(study, trial):\n",
    "    current_score = study.best_value\n",
    "\n",
    "    # First trial initialization\n",
    "    if LGB_EarlyStoppingExceeded.best_score is None:\n",
    "        LGB_EarlyStoppingExceeded.best_score = current_score\n",
    "        print(f\"Trial {trial.number}: Initial best score set to {current_score:.5f}\")\n",
    "        return\n",
    "\n",
    "    # Improved score\n",
    "    if current_score < LGB_EarlyStoppingExceeded.best_score:\n",
    "        print(f\"Trial {trial.number}: Improved score: {current_score:.5f} (Previous best: {LGB_EarlyStoppingExceeded.best_score:.5f})\")\n",
    "        LGB_EarlyStoppingExceeded.best_score = current_score\n",
    "        LGB_EarlyStoppingExceeded.early_stop_count = 0\n",
    "\n",
    "    # No improvement\n",
    "    else:\n",
    "        LGB_EarlyStoppingExceeded.early_stop_count += 1\n",
    "        print(f\"Trial {trial.number}: No improvement. Counter = {LGB_EarlyStoppingExceeded.early_stop_count}, Best Score = {LGB_EarlyStoppingExceeded.best_score:.5f}\")\n",
    "        \n",
    "        if LGB_EarlyStoppingExceeded.early_stop_count > LGB_EarlyStoppingExceeded.early_stop:\n",
    "            print(\"Early stopping threshold reached. Terminating optimization.\")\n",
    "            raise LGB_EarlyStoppingExceeded()\n",
    "\n",
    "# === Run the Optuna Study ===\n",
    "lgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "try:\n",
    "    lgb_study.optimize(lgb_objective, n_trials=100, callbacks=[lgb_early_stopping_opt])\n",
    "except LGB_EarlyStoppingExceeded:\n",
    "    print(\"Early stopping triggered for LightGBM optimization.\")\n",
    "\n",
    "# === Log Best Parameters ===\n",
    "print(\"\\n Best hyperparameters for LightGBM:\")\n",
    "for k, v in lgb_study.best_trial.params.items():\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL 5 - PART 3: LIGHTGBM TRAINING FUNCTION (MODIFIED to return model) ===\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def lgb_train_and_predict(best_params, n_splits, X_train, y_train, test, num_round=10000):\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    pred_y_train = np.zeros(len(X_train))\n",
    "    pred_y_test = np.zeros(len(test))\n",
    "    best_model = None\n",
    "\n",
    "    for fold_, (train_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "        print(f\" LightGBM Fold {fold_ + 1}\")\n",
    "\n",
    "        train_data = lgb.Dataset(X_train.iloc[train_idx], label=y_train.iloc[train_idx])\n",
    "        val_data = lgb.Dataset(X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n",
    "\n",
    "        model = lgb.train(\n",
    "            best_params,\n",
    "            train_data,\n",
    "            num_boost_round=num_round,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=150),\n",
    "                lgb.log_evaluation(period=200)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        best_model = model  # Save the last trained model (or change logic to save best fold)\n",
    "        pred_y_train[val_idx] = model.predict(X_train.iloc[val_idx], num_iteration=model.best_iteration)\n",
    "        pred_y_test += model.predict(test, num_iteration=model.best_iteration) / folds.n_splits\n",
    "\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_train, pred_y_train))\n",
    "    print(f\"\\n Overall Validation RMSE (LightGBM): {val_rmse:.5f}\")\n",
    "    return pred_y_test, val_rmse, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LightGBM Fold 1\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.56394\tvalid_1's rmse: 1.56148\n",
      "[400]\ttraining's rmse: 1.53351\tvalid_1's rmse: 1.54546\n",
      "[600]\ttraining's rmse: 1.51555\tvalid_1's rmse: 1.54049\n",
      "[800]\ttraining's rmse: 1.50153\tvalid_1's rmse: 1.5385\n",
      "[1000]\ttraining's rmse: 1.48964\tvalid_1's rmse: 1.53748\n",
      "[1200]\ttraining's rmse: 1.47901\tvalid_1's rmse: 1.53701\n",
      "[1400]\ttraining's rmse: 1.46889\tvalid_1's rmse: 1.53687\n",
      "[1600]\ttraining's rmse: 1.45942\tvalid_1's rmse: 1.53681\n",
      "[1800]\ttraining's rmse: 1.45005\tvalid_1's rmse: 1.53665\n",
      "[2000]\ttraining's rmse: 1.44084\tvalid_1's rmse: 1.53662\n",
      "Early stopping, best iteration is:\n",
      "[1942]\ttraining's rmse: 1.44349\tvalid_1's rmse: 1.53656\n",
      " LightGBM Fold 2\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.56026\tvalid_1's rmse: 1.59238\n",
      "[400]\ttraining's rmse: 1.52967\tvalid_1's rmse: 1.57559\n",
      "[600]\ttraining's rmse: 1.5118\tvalid_1's rmse: 1.57069\n",
      "[800]\ttraining's rmse: 1.49781\tvalid_1's rmse: 1.56902\n",
      "[1000]\ttraining's rmse: 1.4859\tvalid_1's rmse: 1.56848\n",
      "[1200]\ttraining's rmse: 1.47503\tvalid_1's rmse: 1.56826\n",
      "[1400]\ttraining's rmse: 1.46482\tvalid_1's rmse: 1.56809\n",
      "[1600]\ttraining's rmse: 1.45531\tvalid_1's rmse: 1.56805\n",
      "Early stopping, best iteration is:\n",
      "[1530]\ttraining's rmse: 1.45857\tvalid_1's rmse: 1.56796\n",
      " LightGBM Fold 3\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.56234\tvalid_1's rmse: 1.57703\n",
      "[400]\ttraining's rmse: 1.53197\tvalid_1's rmse: 1.55876\n",
      "[600]\ttraining's rmse: 1.51418\tvalid_1's rmse: 1.55349\n",
      "[800]\ttraining's rmse: 1.50049\tvalid_1's rmse: 1.55138\n",
      "[1000]\ttraining's rmse: 1.48883\tvalid_1's rmse: 1.55035\n",
      "[1200]\ttraining's rmse: 1.47839\tvalid_1's rmse: 1.54992\n",
      "[1400]\ttraining's rmse: 1.46854\tvalid_1's rmse: 1.54957\n",
      "Early stopping, best iteration is:\n",
      "[1442]\ttraining's rmse: 1.4666\tvalid_1's rmse: 1.54947\n",
      " LightGBM Fold 4\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.56435\tvalid_1's rmse: 1.55674\n",
      "[400]\ttraining's rmse: 1.53373\tvalid_1's rmse: 1.5418\n",
      "[600]\ttraining's rmse: 1.51595\tvalid_1's rmse: 1.53764\n",
      "[800]\ttraining's rmse: 1.50208\tvalid_1's rmse: 1.53595\n",
      "[1000]\ttraining's rmse: 1.49026\tvalid_1's rmse: 1.53528\n",
      "[1200]\ttraining's rmse: 1.47972\tvalid_1's rmse: 1.53492\n",
      "[1400]\ttraining's rmse: 1.46966\tvalid_1's rmse: 1.53484\n",
      "Early stopping, best iteration is:\n",
      "[1383]\ttraining's rmse: 1.47046\tvalid_1's rmse: 1.53483\n",
      " LightGBM Fold 5\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.56377\tvalid_1's rmse: 1.56366\n",
      "[400]\ttraining's rmse: 1.53336\tvalid_1's rmse: 1.54647\n",
      "[600]\ttraining's rmse: 1.51554\tvalid_1's rmse: 1.54119\n",
      "[800]\ttraining's rmse: 1.5016\tvalid_1's rmse: 1.53921\n",
      "[1000]\ttraining's rmse: 1.4896\tvalid_1's rmse: 1.53833\n",
      "[1200]\ttraining's rmse: 1.47888\tvalid_1's rmse: 1.53804\n",
      "[1400]\ttraining's rmse: 1.46866\tvalid_1's rmse: 1.5378\n",
      "Early stopping, best iteration is:\n",
      "[1433]\ttraining's rmse: 1.46704\tvalid_1's rmse: 1.53772\n",
      " LightGBM Fold 6\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.56216\tvalid_1's rmse: 1.57513\n",
      "[400]\ttraining's rmse: 1.53165\tvalid_1's rmse: 1.55931\n",
      "[600]\ttraining's rmse: 1.5139\tvalid_1's rmse: 1.55452\n",
      "[800]\ttraining's rmse: 1.49999\tvalid_1's rmse: 1.55267\n",
      "[1000]\ttraining's rmse: 1.48813\tvalid_1's rmse: 1.55187\n",
      "[1200]\ttraining's rmse: 1.47741\tvalid_1's rmse: 1.55142\n",
      "[1400]\ttraining's rmse: 1.46744\tvalid_1's rmse: 1.55128\n",
      "Early stopping, best iteration is:\n",
      "[1346]\ttraining's rmse: 1.47011\tvalid_1's rmse: 1.55125\n",
      " LightGBM Fold 7\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.56026\tvalid_1's rmse: 1.59239\n",
      "[400]\ttraining's rmse: 1.52982\tvalid_1's rmse: 1.57538\n",
      "[600]\ttraining's rmse: 1.5119\tvalid_1's rmse: 1.57031\n",
      "[800]\ttraining's rmse: 1.49785\tvalid_1's rmse: 1.56861\n",
      "[1000]\ttraining's rmse: 1.48604\tvalid_1's rmse: 1.56808\n",
      "[1200]\ttraining's rmse: 1.47549\tvalid_1's rmse: 1.56765\n",
      "[1400]\ttraining's rmse: 1.4657\tvalid_1's rmse: 1.56753\n",
      "[1600]\ttraining's rmse: 1.45637\tvalid_1's rmse: 1.56726\n",
      "[1800]\ttraining's rmse: 1.44719\tvalid_1's rmse: 1.56725\n",
      "Early stopping, best iteration is:\n",
      "[1703]\ttraining's rmse: 1.4515\tvalid_1's rmse: 1.5672\n",
      " LightGBM Fold 8\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.55929\tvalid_1's rmse: 1.60035\n",
      "[400]\ttraining's rmse: 1.52909\tvalid_1's rmse: 1.58251\n",
      "[600]\ttraining's rmse: 1.51131\tvalid_1's rmse: 1.57682\n",
      "[800]\ttraining's rmse: 1.49736\tvalid_1's rmse: 1.57449\n",
      "[1000]\ttraining's rmse: 1.48558\tvalid_1's rmse: 1.57342\n",
      "[1200]\ttraining's rmse: 1.47503\tvalid_1's rmse: 1.57302\n",
      "[1400]\ttraining's rmse: 1.46504\tvalid_1's rmse: 1.57275\n",
      "[1600]\ttraining's rmse: 1.45563\tvalid_1's rmse: 1.57261\n",
      "Early stopping, best iteration is:\n",
      "[1582]\ttraining's rmse: 1.45647\tvalid_1's rmse: 1.57256\n",
      " LightGBM Fold 9\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 1.56302\tvalid_1's rmse: 1.56984\n",
      "[400]\ttraining's rmse: 1.53245\tvalid_1's rmse: 1.5529\n",
      "[600]\ttraining's rmse: 1.51443\tvalid_1's rmse: 1.548\n",
      "[800]\ttraining's rmse: 1.50025\tvalid_1's rmse: 1.54616\n",
      "[1000]\ttraining's rmse: 1.4883\tvalid_1's rmse: 1.54523\n",
      "[1200]\ttraining's rmse: 1.47761\tvalid_1's rmse: 1.54481\n",
      "[1400]\ttraining's rmse: 1.46776\tvalid_1's rmse: 1.54449\n",
      "[1600]\ttraining's rmse: 1.45803\tvalid_1's rmse: 1.54441\n",
      "[1800]\ttraining's rmse: 1.44865\tvalid_1's rmse: 1.54452\n",
      "Early stopping, best iteration is:\n",
      "[1718]\ttraining's rmse: 1.45247\tvalid_1's rmse: 1.54431\n",
      "\n",
      " Overall Validation RMSE (LightGBM): 1.55138\n",
      "Nulls in submission: 0\n",
      "           card_id    target\n",
      "0  C_ID_0ab67a22ab -0.370143\n",
      "1  C_ID_130fd0cbdd -0.073096\n",
      "2  C_ID_b709037bc5 -0.433413\n",
      "3  C_ID_d27d835a9f -0.113392\n",
      "4  C_ID_2b5e3df5c2 -1.604033\n",
      "Submission saved to 'data/lgb_latest_ou.csv'\n",
      " LightGBM model saved as 'lgb_model_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "# === MODEL 5 - PART 4: LIGHTGBM FINAL SUBMISSION (MODIFIED to save model) ===\n",
    "\n",
    "# Apply best parameters\n",
    "lgb_best_params = lgb_study.best_trial.params\n",
    "lgb_best_params.update({\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'nthread': 8\n",
    "})\n",
    "\n",
    "# Prepare aligned columns\n",
    "df_train_columns_lgb = [col for col in df_train_columns_clf if col in X_train_all.columns and col in test.columns]\n",
    "\n",
    "# Predict and get model\n",
    "lgb_test_preds, val_rmse_lgb, lgb_model_final = lgb_train_and_predict(\n",
    "    best_params=lgb_best_params,\n",
    "    n_splits=9,\n",
    "    X_train=X_train_all[df_train_columns_lgb],\n",
    "    y_train=y_train_all,\n",
    "    test=test_features_for_reg[df_train_columns_lgb]\n",
    ")\n",
    "\n",
    "# Create clean submission\n",
    "submission_lgb = test_result.copy()\n",
    "submission_lgb.loc[submission_lgb['outlier'] == 0, 'target'] = lgb_test_preds\n",
    "\n",
    "final_submission_lgb = submission_lgb[['card_id', 'target']].copy()\n",
    "print(\"Nulls in submission:\", final_submission_lgb.isnull().sum().sum())\n",
    "print(final_submission_lgb.head())\n",
    "\n",
    "# Save submission\n",
    "final_submission_lgb.to_csv(\"lgb_latest_ou.csv\", index=False)\n",
    "print(\"Submission saved to 'data/lgb_latest_ou.csv'\")\n",
    "\n",
    "#  Save model to .pkl\n",
    "with open(\"lgb_model_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lgb_model_final, f)\n",
    "print(\" LightGBM model saved as 'lgb_model_final.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4ecfc",
   "metadata": {},
   "source": [
    "## Model 6: Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL 6 - PART 1: XGBOOST OPTUNA OBJECTIVE ===\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    xgb_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.01,\n",
    "        'tree_method': 'auto',\n",
    "        'nthread': -1,\n",
    "        'seed': 326,\n",
    "\n",
    "        # Tunable hyperparameters\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 12),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0, 45),\n",
    "        'subsample': trial.suggest_float('subsample', 0.001, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.001, 1),\n",
    "        'lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'gamma': trial.suggest_float('min_split_gain', 0, 10),\n",
    "    }\n",
    "\n",
    "    dtrain_xgb = xgb.DMatrix(X_train_all, label=y_train_all)\n",
    "\n",
    "    cv_result = xgb.cv(\n",
    "        xgb_params,\n",
    "        dtrain_xgb,\n",
    "        num_boost_round=10000,\n",
    "        nfold=3,\n",
    "        seed=47,\n",
    "        early_stopping_rounds=200,\n",
    "        verbose_eval=100,\n",
    "        as_pandas=True\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    if 'test-rmse-mean' in cv_result.columns:\n",
    "        return cv_result['test-rmse-mean'].iloc[-1]\n",
    "\n",
    "    raise KeyError(\"Expected 'test-rmse-mean' in cv_result.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0b307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:24:54,710] A new study created in memory with name: no-name-ff684dad-1b6a-437b-9725-21c1fc112c32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.71229+0.00409\ttest-rmse:1.71236+0.00830\n",
      "[100]\ttrain-rmse:1.59903+0.00306\ttest-rmse:1.61027+0.00668\n",
      "[200]\ttrain-rmse:1.55902+0.00266\ttest-rmse:1.58107+0.00588\n",
      "[300]\ttrain-rmse:1.53792+0.00242\ttest-rmse:1.56933+0.00537\n",
      "[400]\ttrain-rmse:1.52413+0.00234\ttest-rmse:1.56394+0.00505\n",
      "[500]\ttrain-rmse:1.51301+0.00228\ttest-rmse:1.56090+0.00487\n",
      "[600]\ttrain-rmse:1.50370+0.00222\ttest-rmse:1.55911+0.00468\n",
      "[700]\ttrain-rmse:1.49469+0.00209\ttest-rmse:1.55795+0.00462\n",
      "[800]\ttrain-rmse:1.48623+0.00213\ttest-rmse:1.55729+0.00452\n",
      "[900]\ttrain-rmse:1.47802+0.00217\ttest-rmse:1.55681+0.00461\n",
      "[1000]\ttrain-rmse:1.47015+0.00205\ttest-rmse:1.55649+0.00453\n",
      "[1100]\ttrain-rmse:1.46255+0.00205\ttest-rmse:1.55630+0.00465\n",
      "[1200]\ttrain-rmse:1.45522+0.00200\ttest-rmse:1.55609+0.00452\n",
      "[1300]\ttrain-rmse:1.44814+0.00203\ttest-rmse:1.55607+0.00455\n",
      "[1400]\ttrain-rmse:1.44088+0.00208\ttest-rmse:1.55606+0.00460\n",
      "[1500]\ttrain-rmse:1.43379+0.00219\ttest-rmse:1.55609+0.00454\n",
      "[1600]\ttrain-rmse:1.42684+0.00201\ttest-rmse:1.55614+0.00452\n",
      "[1611]\ttrain-rmse:1.42608+0.00202\ttest-rmse:1.55619+0.00451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:26:21,835] Trial 0 finished with value: 1.556025623596111 and parameters: {'max_depth': 8, 'min_child_weight': 8.70427025304442, 'subsample': 0.13418725805234694, 'colsample_bytree': 0.14925977214865696, 'reg_lambda': 6.797277857606744, 'reg_alpha': 7.959362667195574, 'min_split_gain': 1.4881373826300637}. Best is trial 0 with value: 1.556025623596111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 0: Initial best score set to 1.55603\n",
      "[0]\ttrain-rmse:1.71247+0.00413\ttest-rmse:1.71271+0.00828\n",
      "[100]\ttrain-rmse:1.59013+0.00279\ttest-rmse:1.61363+0.00685\n",
      "[200]\ttrain-rmse:1.53810+0.00237\ttest-rmse:1.58331+0.00594\n",
      "[300]\ttrain-rmse:1.50636+0.00227\ttest-rmse:1.57080+0.00551\n",
      "[400]\ttrain-rmse:1.48428+0.00227\ttest-rmse:1.56460+0.00522\n",
      "[500]\ttrain-rmse:1.46704+0.00231\ttest-rmse:1.56099+0.00507\n",
      "[600]\ttrain-rmse:1.45243+0.00229\ttest-rmse:1.55852+0.00492\n",
      "[700]\ttrain-rmse:1.43949+0.00228\ttest-rmse:1.55692+0.00484\n",
      "[800]\ttrain-rmse:1.42887+0.00218\ttest-rmse:1.55588+0.00483\n",
      "[900]\ttrain-rmse:1.41976+0.00207\ttest-rmse:1.55513+0.00481\n",
      "[1000]\ttrain-rmse:1.41245+0.00173\ttest-rmse:1.55464+0.00483\n",
      "[1100]\ttrain-rmse:1.40613+0.00157\ttest-rmse:1.55426+0.00478\n",
      "[1200]\ttrain-rmse:1.40197+0.00158\ttest-rmse:1.55405+0.00474\n",
      "[1300]\ttrain-rmse:1.39875+0.00134\ttest-rmse:1.55389+0.00474\n",
      "[1400]\ttrain-rmse:1.39645+0.00137\ttest-rmse:1.55374+0.00473\n",
      "[1500]\ttrain-rmse:1.39528+0.00136\ttest-rmse:1.55366+0.00474\n",
      "[1600]\ttrain-rmse:1.39469+0.00138\ttest-rmse:1.55362+0.00474\n",
      "[1700]\ttrain-rmse:1.39298+0.00155\ttest-rmse:1.55354+0.00472\n",
      "[1800]\ttrain-rmse:1.39255+0.00160\ttest-rmse:1.55352+0.00472\n",
      "[1900]\ttrain-rmse:1.39193+0.00155\ttest-rmse:1.55348+0.00471\n",
      "[2000]\ttrain-rmse:1.39098+0.00160\ttest-rmse:1.55341+0.00469\n",
      "[2100]\ttrain-rmse:1.39069+0.00165\ttest-rmse:1.55340+0.00469\n",
      "[2200]\ttrain-rmse:1.39020+0.00164\ttest-rmse:1.55337+0.00468\n",
      "[2300]\ttrain-rmse:1.38990+0.00163\ttest-rmse:1.55336+0.00468\n",
      "[2400]\ttrain-rmse:1.38948+0.00187\ttest-rmse:1.55334+0.00466\n",
      "[2500]\ttrain-rmse:1.38904+0.00219\ttest-rmse:1.55333+0.00465\n",
      "[2600]\ttrain-rmse:1.38900+0.00217\ttest-rmse:1.55333+0.00465\n",
      "[2700]\ttrain-rmse:1.38900+0.00217\ttest-rmse:1.55333+0.00465\n",
      "[2713]\ttrain-rmse:1.38900+0.00217\ttest-rmse:1.55333+0.00465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:28:00,225] Trial 1 finished with value: 1.5533286894424974 and parameters: {'max_depth': 9, 'min_child_weight': 38.98979462815416, 'subsample': 0.9999854167875533, 'colsample_bytree': 0.08216496734418356, 'reg_lambda': 9.442655254809898, 'reg_alpha': 4.1272701026746255, 'min_split_gain': 7.787747707395736}. Best is trial 1 with value: 1.5533286894424974.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 1: Improved score: 1.55333 (Previous best: 1.55603)\n",
      "[0]\ttrain-rmse:1.71174+0.00408\ttest-rmse:1.71209+0.00830\n",
      "[100]\ttrain-rmse:1.56286+0.00316\ttest-rmse:1.59734+0.00633\n",
      "[200]\ttrain-rmse:1.50628+0.00272\ttest-rmse:1.56952+0.00564\n",
      "[300]\ttrain-rmse:1.47385+0.00291\ttest-rmse:1.56044+0.00531\n",
      "[400]\ttrain-rmse:1.45194+0.00300\ttest-rmse:1.55710+0.00511\n",
      "[500]\ttrain-rmse:1.43374+0.00310\ttest-rmse:1.55565+0.00487\n",
      "[600]\ttrain-rmse:1.41752+0.00307\ttest-rmse:1.55498+0.00492\n",
      "[700]\ttrain-rmse:1.40215+0.00290\ttest-rmse:1.55468+0.00468\n",
      "[800]\ttrain-rmse:1.38788+0.00278\ttest-rmse:1.55452+0.00460\n",
      "[900]\ttrain-rmse:1.37378+0.00276\ttest-rmse:1.55463+0.00466\n",
      "[1000]\ttrain-rmse:1.36015+0.00260\ttest-rmse:1.55484+0.00456\n",
      "[1016]\ttrain-rmse:1.35798+0.00262\ttest-rmse:1.55485+0.00454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:29:09,875] Trial 2 finished with value: 1.5544621782064765 and parameters: {'max_depth': 11, 'min_child_weight': 44.51611677811523, 'subsample': 0.31610083478474543, 'colsample_bytree': 0.20758552789027818, 'reg_lambda': 2.9931695261884848, 'reg_alpha': 2.154118979337384, 'min_split_gain': 0.7586022584398144}. Best is trial 1 with value: 1.5533286894424974.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 2: No improvement. Counter = 1, Best Score = 1.55333\n",
      "[0]\ttrain-rmse:1.71153+0.00411\ttest-rmse:1.71205+0.00828\n",
      "[100]\ttrain-rmse:1.54267+0.00261\ttest-rmse:1.59415+0.00650\n",
      "[200]\ttrain-rmse:1.47423+0.00188\ttest-rmse:1.56728+0.00566\n",
      "[300]\ttrain-rmse:1.43333+0.00195\ttest-rmse:1.55911+0.00515\n",
      "[400]\ttrain-rmse:1.40427+0.00135\ttest-rmse:1.55628+0.00483\n",
      "[500]\ttrain-rmse:1.38047+0.00135\ttest-rmse:1.55492+0.00475\n",
      "[600]\ttrain-rmse:1.35931+0.00151\ttest-rmse:1.55438+0.00461\n",
      "[700]\ttrain-rmse:1.33891+0.00122\ttest-rmse:1.55430+0.00446\n",
      "[800]\ttrain-rmse:1.32015+0.00130\ttest-rmse:1.55430+0.00454\n",
      "[844]\ttrain-rmse:1.31211+0.00114\ttest-rmse:1.55431+0.00446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:30:12,984] Trial 3 finished with value: 1.5542513219128937 and parameters: {'max_depth': 10, 'min_child_weight': 11.390993576049143, 'subsample': 0.3847635336127652, 'colsample_bytree': 0.30744129343815746, 'reg_lambda': 3.2491447425110254, 'reg_alpha': 1.396388136840938, 'min_split_gain': 6.215849674589496}. Best is trial 1 with value: 1.5533286894424974.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 3: No improvement. Counter = 2, Best Score = 1.55333\n",
      "[0]\ttrain-rmse:1.71166+0.00413\ttest-rmse:1.71216+0.00825\n",
      "[100]\ttrain-rmse:1.55047+0.00260\ttest-rmse:1.59707+0.00670\n",
      "[200]\ttrain-rmse:1.48373+0.00191\ttest-rmse:1.56946+0.00573\n",
      "[300]\ttrain-rmse:1.44329+0.00131\ttest-rmse:1.56025+0.00535\n",
      "[400]\ttrain-rmse:1.41559+0.00118\ttest-rmse:1.55682+0.00514\n",
      "[500]\ttrain-rmse:1.39483+0.00090\ttest-rmse:1.55520+0.00498\n",
      "[600]\ttrain-rmse:1.37786+0.00061\ttest-rmse:1.55430+0.00486\n",
      "[700]\ttrain-rmse:1.36470+0.00090\ttest-rmse:1.55392+0.00488\n",
      "[800]\ttrain-rmse:1.35428+0.00080\ttest-rmse:1.55372+0.00482\n",
      "[900]\ttrain-rmse:1.34686+0.00069\ttest-rmse:1.55362+0.00476\n",
      "[1000]\ttrain-rmse:1.34124+0.00063\ttest-rmse:1.55356+0.00475\n",
      "[1100]\ttrain-rmse:1.33716+0.00061\ttest-rmse:1.55357+0.00475\n",
      "[1200]\ttrain-rmse:1.33341+0.00075\ttest-rmse:1.55358+0.00476\n",
      "[1207]\ttrain-rmse:1.33315+0.00063\ttest-rmse:1.55357+0.00476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:31:23,193] Trial 4 finished with value: 1.5535441924691966 and parameters: {'max_depth': 11, 'min_child_weight': 20.923596111911777, 'subsample': 0.688580380820874, 'colsample_bytree': 0.22046197817391514, 'reg_lambda': 3.9713162881847874, 'reg_alpha': 7.673368386670132, 'min_split_gain': 9.609857833674324}. Best is trial 1 with value: 1.5533286894424974.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 4: No improvement. Counter = 3, Best Score = 1.55333\n",
      "[0]\ttrain-rmse:1.71175+0.00412\ttest-rmse:1.71209+0.00826\n",
      "[100]\ttrain-rmse:1.55972+0.00258\ttest-rmse:1.59255+0.00653\n",
      "[200]\ttrain-rmse:1.50560+0.00239\ttest-rmse:1.56578+0.00560\n",
      "[300]\ttrain-rmse:1.47594+0.00231\ttest-rmse:1.55800+0.00519\n",
      "[400]\ttrain-rmse:1.45533+0.00237\ttest-rmse:1.55528+0.00498\n",
      "[500]\ttrain-rmse:1.43879+0.00225\ttest-rmse:1.55406+0.00489\n",
      "[600]\ttrain-rmse:1.42451+0.00218\ttest-rmse:1.55355+0.00475\n",
      "[700]\ttrain-rmse:1.41034+0.00205\ttest-rmse:1.55337+0.00471\n",
      "[800]\ttrain-rmse:1.39674+0.00231\ttest-rmse:1.55337+0.00479\n",
      "[900]\ttrain-rmse:1.38392+0.00252\ttest-rmse:1.55339+0.00482\n",
      "[934]\ttrain-rmse:1.37982+0.00233\ttest-rmse:1.55339+0.00482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:32:22,476] Trial 5 finished with value: 1.5532965715891616 and parameters: {'max_depth': 9, 'min_child_weight': 26.582811394428475, 'subsample': 0.4970761616136848, 'colsample_bytree': 0.7192008269427965, 'reg_lambda': 5.864931628777762, 'reg_alpha': 6.729544120366866, 'min_split_gain': 9.949444602921293}. Best is trial 5 with value: 1.5532965715891616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 5: Improved score: 1.55330 (Previous best: 1.55333)\n",
      "[0]\ttrain-rmse:1.71270+0.00410\ttest-rmse:1.71276+0.00829\n",
      "[100]\ttrain-rmse:1.61087+0.00275\ttest-rmse:1.61555+0.00734\n",
      "[200]\ttrain-rmse:1.57754+0.00263\ttest-rmse:1.58660+0.00637\n",
      "[300]\ttrain-rmse:1.56157+0.00251\ttest-rmse:1.57466+0.00596\n",
      "[400]\ttrain-rmse:1.55211+0.00263\ttest-rmse:1.56883+0.00556\n",
      "[500]\ttrain-rmse:1.54536+0.00247\ttest-rmse:1.56587+0.00549\n",
      "[600]\ttrain-rmse:1.53981+0.00252\ttest-rmse:1.56388+0.00537\n",
      "[700]\ttrain-rmse:1.53480+0.00256\ttest-rmse:1.56258+0.00516\n",
      "[800]\ttrain-rmse:1.53068+0.00257\ttest-rmse:1.56170+0.00515\n",
      "[900]\ttrain-rmse:1.52686+0.00247\ttest-rmse:1.56124+0.00524\n",
      "[1000]\ttrain-rmse:1.52303+0.00252\ttest-rmse:1.56100+0.00503\n",
      "[1100]\ttrain-rmse:1.51948+0.00242\ttest-rmse:1.56073+0.00505\n",
      "[1200]\ttrain-rmse:1.51625+0.00233\ttest-rmse:1.56063+0.00510\n",
      "[1300]\ttrain-rmse:1.51295+0.00238\ttest-rmse:1.56066+0.00530\n",
      "[1400]\ttrain-rmse:1.50983+0.00244\ttest-rmse:1.56064+0.00551\n",
      "[1500]\ttrain-rmse:1.50669+0.00246\ttest-rmse:1.56080+0.00538\n",
      "[1576]\ttrain-rmse:1.50430+0.00250\ttest-rmse:1.56084+0.00546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:33:32,035] Trial 6 finished with value: 1.5605492024181722 and parameters: {'max_depth': 9, 'min_child_weight': 17.570412036721315, 'subsample': 0.031232066606360496, 'colsample_bytree': 0.2367345547522657, 'reg_lambda': 7.012874809301273, 'reg_alpha': 5.793104287031152, 'min_split_gain': 7.38523578697503}. Best is trial 5 with value: 1.5532965715891616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 6: No improvement. Counter = 1, Best Score = 1.55330\n",
      "[0]\ttrain-rmse:1.71141+0.00412\ttest-rmse:1.71203+0.00829\n",
      "[100]\ttrain-rmse:1.55073+0.00280\ttest-rmse:1.60538+0.00681\n",
      "[200]\ttrain-rmse:1.47723+0.00205\ttest-rmse:1.57610+0.00604\n",
      "[300]\ttrain-rmse:1.43245+0.00170\ttest-rmse:1.56553+0.00569\n",
      "[400]\ttrain-rmse:1.40245+0.00154\ttest-rmse:1.56069+0.00545\n",
      "[500]\ttrain-rmse:1.38017+0.00154\ttest-rmse:1.55821+0.00528\n",
      "[600]\ttrain-rmse:1.36326+0.00120\ttest-rmse:1.55671+0.00515\n",
      "[700]\ttrain-rmse:1.35065+0.00079\ttest-rmse:1.55578+0.00510\n",
      "[800]\ttrain-rmse:1.34195+0.00071\ttest-rmse:1.55518+0.00504\n",
      "[900]\ttrain-rmse:1.33636+0.00052\ttest-rmse:1.55485+0.00502\n",
      "[1000]\ttrain-rmse:1.33198+0.00019\ttest-rmse:1.55462+0.00498\n",
      "[1100]\ttrain-rmse:1.32894+0.00028\ttest-rmse:1.55445+0.00498\n",
      "[1200]\ttrain-rmse:1.32706+0.00058\ttest-rmse:1.55433+0.00496\n",
      "[1300]\ttrain-rmse:1.32572+0.00046\ttest-rmse:1.55427+0.00495\n",
      "[1400]\ttrain-rmse:1.32456+0.00048\ttest-rmse:1.55420+0.00493\n",
      "[1500]\ttrain-rmse:1.32323+0.00048\ttest-rmse:1.55416+0.00495\n",
      "[1600]\ttrain-rmse:1.32227+0.00060\ttest-rmse:1.55410+0.00498\n",
      "[1700]\ttrain-rmse:1.32102+0.00068\ttest-rmse:1.55406+0.00495\n",
      "[1800]\ttrain-rmse:1.32055+0.00065\ttest-rmse:1.55403+0.00495\n",
      "[1900]\ttrain-rmse:1.32002+0.00070\ttest-rmse:1.55402+0.00495\n",
      "[2000]\ttrain-rmse:1.31938+0.00072\ttest-rmse:1.55398+0.00497\n",
      "[2100]\ttrain-rmse:1.31905+0.00081\ttest-rmse:1.55395+0.00496\n",
      "[2200]\ttrain-rmse:1.31878+0.00086\ttest-rmse:1.55393+0.00495\n",
      "[2300]\ttrain-rmse:1.31864+0.00079\ttest-rmse:1.55393+0.00495\n",
      "[2400]\ttrain-rmse:1.31849+0.00082\ttest-rmse:1.55393+0.00496\n",
      "[2500]\ttrain-rmse:1.31808+0.00077\ttest-rmse:1.55392+0.00496\n",
      "[2600]\ttrain-rmse:1.31780+0.00082\ttest-rmse:1.55391+0.00495\n",
      "[2700]\ttrain-rmse:1.31762+0.00093\ttest-rmse:1.55390+0.00496\n",
      "[2800]\ttrain-rmse:1.31753+0.00095\ttest-rmse:1.55390+0.00496\n",
      "[2900]\ttrain-rmse:1.31731+0.00093\ttest-rmse:1.55391+0.00496\n",
      "[2972]\ttrain-rmse:1.31718+0.00097\ttest-rmse:1.55390+0.00495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:35:17,768] Trial 7 finished with value: 1.5538986243698727 and parameters: {'max_depth': 11, 'min_child_weight': 27.574557262229305, 'subsample': 0.9365089932916977, 'colsample_bytree': 0.1011130628595686, 'reg_lambda': 0.5048399133456039, 'reg_alpha': 2.7342075928274054, 'min_split_gain': 9.61145643024404}. Best is trial 5 with value: 1.5532965715891616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 7: No improvement. Counter = 2, Best Score = 1.55330\n",
      "[0]\ttrain-rmse:1.71272+0.00413\ttest-rmse:1.71273+0.00828\n",
      "[100]\ttrain-rmse:1.62612+0.00315\ttest-rmse:1.62716+0.00713\n",
      "[200]\ttrain-rmse:1.59859+0.00287\ttest-rmse:1.60072+0.00634\n",
      "[300]\ttrain-rmse:1.58513+0.00277\ttest-rmse:1.58836+0.00593\n",
      "[400]\ttrain-rmse:1.57659+0.00271\ttest-rmse:1.58089+0.00568\n",
      "[500]\ttrain-rmse:1.57024+0.00264\ttest-rmse:1.57549+0.00541\n",
      "[600]\ttrain-rmse:1.56543+0.00254\ttest-rmse:1.57172+0.00533\n",
      "[700]\ttrain-rmse:1.56154+0.00249\ttest-rmse:1.56886+0.00515\n",
      "[800]\ttrain-rmse:1.55835+0.00247\ttest-rmse:1.56664+0.00505\n",
      "[900]\ttrain-rmse:1.55564+0.00246\ttest-rmse:1.56497+0.00498\n",
      "[1000]\ttrain-rmse:1.55335+0.00246\ttest-rmse:1.56361+0.00492\n",
      "[1100]\ttrain-rmse:1.55133+0.00244\ttest-rmse:1.56254+0.00486\n",
      "[1200]\ttrain-rmse:1.54947+0.00244\ttest-rmse:1.56167+0.00481\n",
      "[1300]\ttrain-rmse:1.54779+0.00245\ttest-rmse:1.56093+0.00474\n",
      "[1400]\ttrain-rmse:1.54624+0.00242\ttest-rmse:1.56027+0.00475\n",
      "[1500]\ttrain-rmse:1.54477+0.00245\ttest-rmse:1.55973+0.00468\n",
      "[1600]\ttrain-rmse:1.54335+0.00245\ttest-rmse:1.55924+0.00463\n",
      "[1700]\ttrain-rmse:1.54201+0.00236\ttest-rmse:1.55891+0.00465\n",
      "[1800]\ttrain-rmse:1.54075+0.00233\ttest-rmse:1.55858+0.00471\n",
      "[1900]\ttrain-rmse:1.53953+0.00231\ttest-rmse:1.55828+0.00475\n",
      "[2000]\ttrain-rmse:1.53833+0.00231\ttest-rmse:1.55800+0.00473\n",
      "[2100]\ttrain-rmse:1.53719+0.00233\ttest-rmse:1.55778+0.00471\n",
      "[2200]\ttrain-rmse:1.53609+0.00234\ttest-rmse:1.55758+0.00476\n",
      "[2300]\ttrain-rmse:1.53501+0.00236\ttest-rmse:1.55739+0.00474\n",
      "[2400]\ttrain-rmse:1.53395+0.00240\ttest-rmse:1.55716+0.00473\n",
      "[2500]\ttrain-rmse:1.53293+0.00239\ttest-rmse:1.55697+0.00474\n",
      "[2600]\ttrain-rmse:1.53187+0.00240\ttest-rmse:1.55681+0.00473\n",
      "[2700]\ttrain-rmse:1.53085+0.00241\ttest-rmse:1.55673+0.00475\n",
      "[2800]\ttrain-rmse:1.52985+0.00239\ttest-rmse:1.55664+0.00471\n",
      "[2900]\ttrain-rmse:1.52888+0.00240\ttest-rmse:1.55651+0.00468\n",
      "[3000]\ttrain-rmse:1.52793+0.00239\ttest-rmse:1.55639+0.00466\n",
      "[3100]\ttrain-rmse:1.52701+0.00240\ttest-rmse:1.55630+0.00464\n",
      "[3200]\ttrain-rmse:1.52602+0.00242\ttest-rmse:1.55620+0.00469\n",
      "[3300]\ttrain-rmse:1.52509+0.00241\ttest-rmse:1.55610+0.00474\n",
      "[3400]\ttrain-rmse:1.52419+0.00239\ttest-rmse:1.55607+0.00476\n",
      "[3500]\ttrain-rmse:1.52328+0.00235\ttest-rmse:1.55602+0.00480\n",
      "[3600]\ttrain-rmse:1.52239+0.00236\ttest-rmse:1.55596+0.00479\n",
      "[3700]\ttrain-rmse:1.52148+0.00238\ttest-rmse:1.55590+0.00479\n",
      "[3800]\ttrain-rmse:1.52060+0.00235\ttest-rmse:1.55588+0.00485\n",
      "[3900]\ttrain-rmse:1.51971+0.00235\ttest-rmse:1.55579+0.00485\n",
      "[4000]\ttrain-rmse:1.51882+0.00235\ttest-rmse:1.55576+0.00490\n",
      "[4100]\ttrain-rmse:1.51798+0.00238\ttest-rmse:1.55569+0.00487\n",
      "[4200]\ttrain-rmse:1.51714+0.00236\ttest-rmse:1.55567+0.00491\n",
      "[4300]\ttrain-rmse:1.51628+0.00233\ttest-rmse:1.55562+0.00495\n",
      "[4400]\ttrain-rmse:1.51546+0.00234\ttest-rmse:1.55559+0.00491\n",
      "[4500]\ttrain-rmse:1.51464+0.00232\ttest-rmse:1.55560+0.00489\n",
      "[4600]\ttrain-rmse:1.51384+0.00231\ttest-rmse:1.55562+0.00495\n",
      "[4607]\ttrain-rmse:1.51378+0.00231\ttest-rmse:1.55561+0.00495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:37:15,407] Trial 8 finished with value: 1.555589780859988 and parameters: {'max_depth': 3, 'min_child_weight': 16.42033240976282, 'subsample': 0.27957494134701266, 'colsample_bytree': 0.5698615202388735, 'reg_lambda': 1.7428666272403526, 'reg_alpha': 3.3560203269896682, 'min_split_gain': 5.917308596371965}. Best is trial 5 with value: 1.5532965715891616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 8: No improvement. Counter = 3, Best Score = 1.55330\n",
      "[0]\ttrain-rmse:1.71270+0.00409\ttest-rmse:1.71271+0.00831\n",
      "[100]\ttrain-rmse:1.62185+0.00293\ttest-rmse:1.62352+0.00705\n",
      "[200]\ttrain-rmse:1.59287+0.00259\ttest-rmse:1.59615+0.00651\n",
      "[300]\ttrain-rmse:1.57839+0.00265\ttest-rmse:1.58328+0.00581\n",
      "[400]\ttrain-rmse:1.56946+0.00262\ttest-rmse:1.57593+0.00546\n",
      "[500]\ttrain-rmse:1.56300+0.00259\ttest-rmse:1.57085+0.00527\n",
      "[600]\ttrain-rmse:1.55805+0.00256\ttest-rmse:1.56735+0.00508\n",
      "[700]\ttrain-rmse:1.55402+0.00257\ttest-rmse:1.56474+0.00496\n",
      "[800]\ttrain-rmse:1.55072+0.00245\ttest-rmse:1.56278+0.00494\n",
      "[900]\ttrain-rmse:1.54792+0.00245\ttest-rmse:1.56137+0.00493\n",
      "[1000]\ttrain-rmse:1.54548+0.00244\ttest-rmse:1.56028+0.00488\n",
      "[1100]\ttrain-rmse:1.54323+0.00241\ttest-rmse:1.55929+0.00485\n",
      "[1200]\ttrain-rmse:1.54113+0.00241\ttest-rmse:1.55858+0.00483\n",
      "[1300]\ttrain-rmse:1.53925+0.00237\ttest-rmse:1.55800+0.00483\n",
      "[1400]\ttrain-rmse:1.53738+0.00240\ttest-rmse:1.55744+0.00479\n",
      "[1500]\ttrain-rmse:1.53569+0.00239\ttest-rmse:1.55701+0.00476\n",
      "[1600]\ttrain-rmse:1.53406+0.00234\ttest-rmse:1.55668+0.00476\n",
      "[1700]\ttrain-rmse:1.53246+0.00233\ttest-rmse:1.55636+0.00473\n",
      "[1800]\ttrain-rmse:1.53088+0.00234\ttest-rmse:1.55606+0.00475\n",
      "[1900]\ttrain-rmse:1.52935+0.00233\ttest-rmse:1.55575+0.00478\n",
      "[2000]\ttrain-rmse:1.52787+0.00231\ttest-rmse:1.55550+0.00477\n",
      "[2100]\ttrain-rmse:1.52647+0.00230\ttest-rmse:1.55531+0.00481\n",
      "[2200]\ttrain-rmse:1.52503+0.00228\ttest-rmse:1.55509+0.00485\n",
      "[2300]\ttrain-rmse:1.52364+0.00229\ttest-rmse:1.55496+0.00484\n",
      "[2400]\ttrain-rmse:1.52226+0.00228\ttest-rmse:1.55487+0.00484\n",
      "[2500]\ttrain-rmse:1.52091+0.00232\ttest-rmse:1.55473+0.00482\n",
      "[2600]\ttrain-rmse:1.51956+0.00232\ttest-rmse:1.55458+0.00486\n",
      "[2700]\ttrain-rmse:1.51827+0.00229\ttest-rmse:1.55449+0.00489\n",
      "[2800]\ttrain-rmse:1.51698+0.00228\ttest-rmse:1.55443+0.00490\n",
      "[2900]\ttrain-rmse:1.51570+0.00226\ttest-rmse:1.55437+0.00485\n",
      "[3000]\ttrain-rmse:1.51440+0.00219\ttest-rmse:1.55430+0.00484\n",
      "[3100]\ttrain-rmse:1.51317+0.00219\ttest-rmse:1.55423+0.00484\n",
      "[3200]\ttrain-rmse:1.51197+0.00220\ttest-rmse:1.55421+0.00484\n",
      "[3300]\ttrain-rmse:1.51081+0.00216\ttest-rmse:1.55422+0.00484\n",
      "[3335]\ttrain-rmse:1.51041+0.00217\ttest-rmse:1.55422+0.00487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:38:48,284] Trial 9 finished with value: 1.5541987850515724 and parameters: {'max_depth': 4, 'min_child_weight': 10.415222316421223, 'subsample': 0.2413642285553229, 'colsample_bytree': 0.16148765841046292, 'reg_lambda': 8.883514473110845, 'reg_alpha': 8.379992266606665, 'min_split_gain': 8.997022568993264}. Best is trial 5 with value: 1.5532965715891616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 9: No improvement. Counter = 4, Best Score = 1.55330\n",
      "[0]\ttrain-rmse:1.71205+0.00410\ttest-rmse:1.71215+0.00828\n",
      "[100]\ttrain-rmse:1.59103+0.00256\ttest-rmse:1.60032+0.00679\n",
      "[200]\ttrain-rmse:1.55472+0.00230\ttest-rmse:1.57270+0.00575\n",
      "[300]\ttrain-rmse:1.53711+0.00237\ttest-rmse:1.56314+0.00513\n",
      "[400]\ttrain-rmse:1.52549+0.00235\ttest-rmse:1.55890+0.00485\n",
      "[500]\ttrain-rmse:1.51623+0.00233\ttest-rmse:1.55663+0.00467\n",
      "[600]\ttrain-rmse:1.50840+0.00236\ttest-rmse:1.55521+0.00459\n",
      "[700]\ttrain-rmse:1.50126+0.00230\ttest-rmse:1.55433+0.00458\n",
      "[800]\ttrain-rmse:1.49484+0.00241\ttest-rmse:1.55371+0.00450\n",
      "[900]\ttrain-rmse:1.48853+0.00244\ttest-rmse:1.55327+0.00441\n",
      "[1000]\ttrain-rmse:1.48254+0.00246\ttest-rmse:1.55301+0.00440\n",
      "[1100]\ttrain-rmse:1.47658+0.00250\ttest-rmse:1.55280+0.00443\n",
      "[1200]\ttrain-rmse:1.47082+0.00251\ttest-rmse:1.55269+0.00447\n",
      "[1300]\ttrain-rmse:1.46509+0.00252\ttest-rmse:1.55265+0.00449\n",
      "[1400]\ttrain-rmse:1.45931+0.00252\ttest-rmse:1.55265+0.00451\n",
      "[1500]\ttrain-rmse:1.45369+0.00260\ttest-rmse:1.55266+0.00447\n",
      "[1600]\ttrain-rmse:1.44827+0.00266\ttest-rmse:1.55263+0.00445\n",
      "[1700]\ttrain-rmse:1.44278+0.00255\ttest-rmse:1.55272+0.00443\n",
      "[1795]\ttrain-rmse:1.43761+0.00270\ttest-rmse:1.55279+0.00443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:39:57,321] Trial 10 finished with value: 1.5526216749528154 and parameters: {'max_depth': 6, 'min_child_weight': 30.453470025111102, 'subsample': 0.5978969238185174, 'colsample_bytree': 0.8915256462533131, 'reg_lambda': 5.869429531266187, 'reg_alpha': 5.767462837988923, 'min_split_gain': 3.178236800449556}. Best is trial 10 with value: 1.5526216749528154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 10: Improved score: 1.55262 (Previous best: 1.55330)\n",
      "[0]\ttrain-rmse:1.71203+0.00413\ttest-rmse:1.71212+0.00826\n",
      "[100]\ttrain-rmse:1.59086+0.00251\ttest-rmse:1.60039+0.00668\n",
      "[200]\ttrain-rmse:1.55445+0.00228\ttest-rmse:1.57286+0.00567\n",
      "[300]\ttrain-rmse:1.53665+0.00233\ttest-rmse:1.56332+0.00509\n",
      "[400]\ttrain-rmse:1.52481+0.00232\ttest-rmse:1.55902+0.00490\n",
      "[500]\ttrain-rmse:1.51538+0.00235\ttest-rmse:1.55674+0.00478\n",
      "[600]\ttrain-rmse:1.50737+0.00226\ttest-rmse:1.55535+0.00467\n",
      "[700]\ttrain-rmse:1.50016+0.00236\ttest-rmse:1.55439+0.00461\n",
      "[800]\ttrain-rmse:1.49348+0.00255\ttest-rmse:1.55379+0.00460\n",
      "[900]\ttrain-rmse:1.48723+0.00267\ttest-rmse:1.55342+0.00460\n",
      "[1000]\ttrain-rmse:1.48115+0.00284\ttest-rmse:1.55315+0.00458\n",
      "[1100]\ttrain-rmse:1.47530+0.00271\ttest-rmse:1.55292+0.00458\n",
      "[1200]\ttrain-rmse:1.46956+0.00258\ttest-rmse:1.55281+0.00462\n",
      "[1300]\ttrain-rmse:1.46398+0.00253\ttest-rmse:1.55276+0.00465\n",
      "[1400]\ttrain-rmse:1.45812+0.00253\ttest-rmse:1.55277+0.00470\n",
      "[1500]\ttrain-rmse:1.45234+0.00251\ttest-rmse:1.55276+0.00475\n",
      "[1600]\ttrain-rmse:1.44675+0.00254\ttest-rmse:1.55275+0.00474\n",
      "[1700]\ttrain-rmse:1.44126+0.00236\ttest-rmse:1.55275+0.00472\n",
      "[1800]\ttrain-rmse:1.43595+0.00238\ttest-rmse:1.55287+0.00471\n",
      "[1875]\ttrain-rmse:1.43192+0.00242\ttest-rmse:1.55292+0.00472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:41:10,647] Trial 11 finished with value: 1.5527230758966628 and parameters: {'max_depth': 6, 'min_child_weight': 31.119129678647308, 'subsample': 0.679462679973374, 'colsample_bytree': 0.9103062599553802, 'reg_lambda': 5.682106785698001, 'reg_alpha': 5.753439109782828, 'min_split_gain': 3.3348871815202434}. Best is trial 10 with value: 1.5526216749528154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 11: No improvement. Counter = 1, Best Score = 1.55262\n",
      "[0]\ttrain-rmse:1.71203+0.00413\ttest-rmse:1.71212+0.00826\n",
      "[100]\ttrain-rmse:1.59093+0.00243\ttest-rmse:1.60049+0.00671\n",
      "[200]\ttrain-rmse:1.55445+0.00224\ttest-rmse:1.57297+0.00560\n",
      "[300]\ttrain-rmse:1.53667+0.00222\ttest-rmse:1.56347+0.00505\n",
      "[400]\ttrain-rmse:1.52482+0.00224\ttest-rmse:1.55914+0.00479\n",
      "[500]\ttrain-rmse:1.51544+0.00207\ttest-rmse:1.55676+0.00467\n",
      "[600]\ttrain-rmse:1.50745+0.00213\ttest-rmse:1.55535+0.00454\n",
      "[700]\ttrain-rmse:1.50030+0.00219\ttest-rmse:1.55443+0.00456\n",
      "[800]\ttrain-rmse:1.49370+0.00229\ttest-rmse:1.55385+0.00456\n",
      "[900]\ttrain-rmse:1.48739+0.00245\ttest-rmse:1.55341+0.00452\n",
      "[1000]\ttrain-rmse:1.48140+0.00259\ttest-rmse:1.55318+0.00456\n",
      "[1100]\ttrain-rmse:1.47561+0.00264\ttest-rmse:1.55296+0.00450\n",
      "[1200]\ttrain-rmse:1.46980+0.00265\ttest-rmse:1.55285+0.00446\n",
      "[1300]\ttrain-rmse:1.46408+0.00271\ttest-rmse:1.55277+0.00446\n",
      "[1400]\ttrain-rmse:1.45834+0.00263\ttest-rmse:1.55281+0.00447\n",
      "[1493]\ttrain-rmse:1.45314+0.00276\ttest-rmse:1.55279+0.00451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:42:10,240] Trial 12 finished with value: 1.5527623766614063 and parameters: {'max_depth': 6, 'min_child_weight': 34.33930800753375, 'subsample': 0.6931284689047308, 'colsample_bytree': 0.9328413802267653, 'reg_lambda': 5.19790944754314, 'reg_alpha': 5.9484277829282854, 'min_split_gain': 3.09810829077543}. Best is trial 10 with value: 1.5526216749528154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 12: No improvement. Counter = 2, Best Score = 1.55262\n",
      "[0]\ttrain-rmse:1.71347+0.00414\ttest-rmse:1.71346+0.00829\n",
      "[100]\ttrain-rmse:1.66654+0.00377\ttest-rmse:1.66670+0.00798\n",
      "[200]\ttrain-rmse:1.64646+0.00345\ttest-rmse:1.64680+0.00765\n",
      "[300]\ttrain-rmse:1.63388+0.00321\ttest-rmse:1.63432+0.00735\n",
      "[400]\ttrain-rmse:1.62567+0.00302\ttest-rmse:1.62621+0.00710\n",
      "[500]\ttrain-rmse:1.61987+0.00291\ttest-rmse:1.62055+0.00684\n",
      "[600]\ttrain-rmse:1.61532+0.00285\ttest-rmse:1.61617+0.00667\n",
      "[700]\ttrain-rmse:1.61150+0.00281\ttest-rmse:1.61239+0.00656\n",
      "[800]\ttrain-rmse:1.60822+0.00278\ttest-rmse:1.60920+0.00644\n",
      "[900]\ttrain-rmse:1.60542+0.00274\ttest-rmse:1.60648+0.00634\n",
      "[1000]\ttrain-rmse:1.60297+0.00271\ttest-rmse:1.60416+0.00626\n",
      "[1100]\ttrain-rmse:1.60080+0.00269\ttest-rmse:1.60208+0.00616\n",
      "[1200]\ttrain-rmse:1.59887+0.00266\ttest-rmse:1.60023+0.00612\n",
      "[1300]\ttrain-rmse:1.59711+0.00264\ttest-rmse:1.59858+0.00603\n",
      "[1400]\ttrain-rmse:1.59551+0.00262\ttest-rmse:1.59704+0.00598\n",
      "[1500]\ttrain-rmse:1.59404+0.00260\ttest-rmse:1.59567+0.00593\n",
      "[1600]\ttrain-rmse:1.59269+0.00258\ttest-rmse:1.59439+0.00588\n",
      "[1700]\ttrain-rmse:1.59143+0.00257\ttest-rmse:1.59321+0.00581\n",
      "[1800]\ttrain-rmse:1.59027+0.00255\ttest-rmse:1.59213+0.00578\n",
      "[1900]\ttrain-rmse:1.58920+0.00254\ttest-rmse:1.59112+0.00573\n",
      "[2000]\ttrain-rmse:1.58821+0.00252\ttest-rmse:1.59019+0.00568\n",
      "[2100]\ttrain-rmse:1.58728+0.00251\ttest-rmse:1.58935+0.00565\n",
      "[2200]\ttrain-rmse:1.58641+0.00249\ttest-rmse:1.58853+0.00562\n",
      "[2300]\ttrain-rmse:1.58560+0.00248\ttest-rmse:1.58779+0.00558\n",
      "[2400]\ttrain-rmse:1.58483+0.00247\ttest-rmse:1.58709+0.00555\n",
      "[2500]\ttrain-rmse:1.58412+0.00246\ttest-rmse:1.58642+0.00552\n",
      "[2600]\ttrain-rmse:1.58344+0.00245\ttest-rmse:1.58581+0.00548\n",
      "[2700]\ttrain-rmse:1.58280+0.00244\ttest-rmse:1.58524+0.00545\n",
      "[2800]\ttrain-rmse:1.58219+0.00243\ttest-rmse:1.58469+0.00543\n",
      "[2900]\ttrain-rmse:1.58162+0.00242\ttest-rmse:1.58418+0.00541\n",
      "[3000]\ttrain-rmse:1.58107+0.00241\ttest-rmse:1.58369+0.00537\n",
      "[3100]\ttrain-rmse:1.58056+0.00240\ttest-rmse:1.58325+0.00534\n",
      "[3200]\ttrain-rmse:1.58007+0.00240\ttest-rmse:1.58281+0.00531\n",
      "[3300]\ttrain-rmse:1.57960+0.00240\ttest-rmse:1.58238+0.00531\n",
      "[3400]\ttrain-rmse:1.57914+0.00239\ttest-rmse:1.58198+0.00529\n",
      "[3500]\ttrain-rmse:1.57871+0.00238\ttest-rmse:1.58162+0.00529\n",
      "[3600]\ttrain-rmse:1.57830+0.00238\ttest-rmse:1.58126+0.00526\n",
      "[3700]\ttrain-rmse:1.57791+0.00237\ttest-rmse:1.58093+0.00523\n",
      "[3800]\ttrain-rmse:1.57753+0.00237\ttest-rmse:1.58061+0.00520\n",
      "[3900]\ttrain-rmse:1.57716+0.00237\ttest-rmse:1.58030+0.00518\n",
      "[4000]\ttrain-rmse:1.57681+0.00237\ttest-rmse:1.57999+0.00516\n",
      "[4100]\ttrain-rmse:1.57648+0.00236\ttest-rmse:1.57972+0.00515\n",
      "[4200]\ttrain-rmse:1.57615+0.00236\ttest-rmse:1.57945+0.00515\n",
      "[4300]\ttrain-rmse:1.57584+0.00236\ttest-rmse:1.57920+0.00512\n",
      "[4400]\ttrain-rmse:1.57554+0.00236\ttest-rmse:1.57896+0.00510\n",
      "[4500]\ttrain-rmse:1.57526+0.00236\ttest-rmse:1.57873+0.00508\n",
      "[4600]\ttrain-rmse:1.57498+0.00235\ttest-rmse:1.57850+0.00506\n",
      "[4700]\ttrain-rmse:1.57470+0.00235\ttest-rmse:1.57829+0.00504\n",
      "[4800]\ttrain-rmse:1.57444+0.00235\ttest-rmse:1.57808+0.00504\n",
      "[4900]\ttrain-rmse:1.57419+0.00235\ttest-rmse:1.57789+0.00502\n",
      "[5000]\ttrain-rmse:1.57394+0.00235\ttest-rmse:1.57770+0.00500\n",
      "[5100]\ttrain-rmse:1.57371+0.00235\ttest-rmse:1.57752+0.00497\n",
      "[5200]\ttrain-rmse:1.57348+0.00234\ttest-rmse:1.57734+0.00496\n",
      "[5300]\ttrain-rmse:1.57325+0.00234\ttest-rmse:1.57717+0.00495\n",
      "[5400]\ttrain-rmse:1.57303+0.00234\ttest-rmse:1.57700+0.00493\n",
      "[5500]\ttrain-rmse:1.57282+0.00234\ttest-rmse:1.57685+0.00493\n",
      "[5600]\ttrain-rmse:1.57262+0.00234\ttest-rmse:1.57670+0.00491\n",
      "[5700]\ttrain-rmse:1.57242+0.00234\ttest-rmse:1.57655+0.00491\n",
      "[5800]\ttrain-rmse:1.57222+0.00234\ttest-rmse:1.57641+0.00490\n",
      "[5900]\ttrain-rmse:1.57203+0.00233\ttest-rmse:1.57627+0.00490\n",
      "[6000]\ttrain-rmse:1.57185+0.00233\ttest-rmse:1.57613+0.00489\n",
      "[6100]\ttrain-rmse:1.57167+0.00233\ttest-rmse:1.57601+0.00488\n",
      "[6200]\ttrain-rmse:1.57149+0.00233\ttest-rmse:1.57588+0.00486\n",
      "[6300]\ttrain-rmse:1.57132+0.00233\ttest-rmse:1.57577+0.00486\n",
      "[6400]\ttrain-rmse:1.57115+0.00233\ttest-rmse:1.57564+0.00485\n",
      "[6500]\ttrain-rmse:1.57099+0.00233\ttest-rmse:1.57553+0.00484\n",
      "[6600]\ttrain-rmse:1.57083+0.00233\ttest-rmse:1.57543+0.00484\n",
      "[6700]\ttrain-rmse:1.57067+0.00233\ttest-rmse:1.57532+0.00482\n",
      "[6800]\ttrain-rmse:1.57052+0.00233\ttest-rmse:1.57523+0.00482\n",
      "[6900]\ttrain-rmse:1.57037+0.00232\ttest-rmse:1.57513+0.00482\n",
      "[7000]\ttrain-rmse:1.57023+0.00233\ttest-rmse:1.57504+0.00481\n",
      "[7100]\ttrain-rmse:1.57009+0.00233\ttest-rmse:1.57495+0.00480\n",
      "[7200]\ttrain-rmse:1.56995+0.00233\ttest-rmse:1.57485+0.00479\n",
      "[7300]\ttrain-rmse:1.56981+0.00233\ttest-rmse:1.57477+0.00479\n",
      "[7400]\ttrain-rmse:1.56968+0.00233\ttest-rmse:1.57469+0.00478\n",
      "[7500]\ttrain-rmse:1.56955+0.00233\ttest-rmse:1.57460+0.00478\n",
      "[7600]\ttrain-rmse:1.56942+0.00233\ttest-rmse:1.57452+0.00478\n",
      "[7700]\ttrain-rmse:1.56930+0.00233\ttest-rmse:1.57445+0.00478\n",
      "[7800]\ttrain-rmse:1.56917+0.00233\ttest-rmse:1.57438+0.00478\n",
      "[7900]\ttrain-rmse:1.56905+0.00233\ttest-rmse:1.57431+0.00478\n",
      "[8000]\ttrain-rmse:1.56894+0.00233\ttest-rmse:1.57424+0.00477\n",
      "[8100]\ttrain-rmse:1.56882+0.00233\ttest-rmse:1.57418+0.00477\n",
      "[8200]\ttrain-rmse:1.56871+0.00233\ttest-rmse:1.57411+0.00477\n",
      "[8300]\ttrain-rmse:1.56860+0.00233\ttest-rmse:1.57406+0.00476\n",
      "[8400]\ttrain-rmse:1.56848+0.00233\ttest-rmse:1.57399+0.00475\n",
      "[8500]\ttrain-rmse:1.56838+0.00233\ttest-rmse:1.57395+0.00475\n",
      "[8600]\ttrain-rmse:1.56827+0.00233\ttest-rmse:1.57390+0.00475\n",
      "[8700]\ttrain-rmse:1.56817+0.00233\ttest-rmse:1.57384+0.00476\n",
      "[8800]\ttrain-rmse:1.56807+0.00233\ttest-rmse:1.57380+0.00475\n",
      "[8900]\ttrain-rmse:1.56796+0.00233\ttest-rmse:1.57375+0.00474\n",
      "[9000]\ttrain-rmse:1.56786+0.00233\ttest-rmse:1.57370+0.00474\n",
      "[9100]\ttrain-rmse:1.56777+0.00233\ttest-rmse:1.57366+0.00473\n",
      "[9200]\ttrain-rmse:1.56767+0.00233\ttest-rmse:1.57362+0.00472\n",
      "[9300]\ttrain-rmse:1.56757+0.00234\ttest-rmse:1.57358+0.00472\n",
      "[9400]\ttrain-rmse:1.56748+0.00234\ttest-rmse:1.57352+0.00472\n",
      "[9500]\ttrain-rmse:1.56738+0.00234\ttest-rmse:1.57348+0.00471\n",
      "[9600]\ttrain-rmse:1.56729+0.00234\ttest-rmse:1.57343+0.00471\n",
      "[9700]\ttrain-rmse:1.56720+0.00234\ttest-rmse:1.57339+0.00471\n",
      "[9800]\ttrain-rmse:1.56711+0.00234\ttest-rmse:1.57335+0.00472\n",
      "[9900]\ttrain-rmse:1.56702+0.00234\ttest-rmse:1.57332+0.00471\n",
      "[9999]\ttrain-rmse:1.56694+0.00234\ttest-rmse:1.57326+0.00470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:45:34,686] Trial 13 finished with value: 1.5732602953658572 and parameters: {'max_depth': 1, 'min_child_weight': 33.88556497552564, 'subsample': 0.7020402928438605, 'colsample_bytree': 0.9981685541662777, 'reg_lambda': 7.710836140133366, 'reg_alpha': 9.526789681683276, 'min_split_gain': 4.131822653585373}. Best is trial 10 with value: 1.5526216749528154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 13: No improvement. Counter = 3, Best Score = 1.55262\n",
      "[0]\ttrain-rmse:1.71202+0.00410\ttest-rmse:1.71211+0.00828\n",
      "[100]\ttrain-rmse:1.59004+0.00266\ttest-rmse:1.60028+0.00672\n",
      "[200]\ttrain-rmse:1.55333+0.00234\ttest-rmse:1.57303+0.00582\n",
      "[300]\ttrain-rmse:1.53504+0.00239\ttest-rmse:1.56370+0.00524\n",
      "[400]\ttrain-rmse:1.52258+0.00244\ttest-rmse:1.55942+0.00489\n",
      "[500]\ttrain-rmse:1.51280+0.00243\ttest-rmse:1.55704+0.00479\n",
      "[600]\ttrain-rmse:1.50458+0.00241\ttest-rmse:1.55563+0.00479\n",
      "[700]\ttrain-rmse:1.49734+0.00237\ttest-rmse:1.55474+0.00477\n",
      "[800]\ttrain-rmse:1.49081+0.00240\ttest-rmse:1.55418+0.00474\n",
      "[900]\ttrain-rmse:1.48465+0.00244\ttest-rmse:1.55379+0.00476\n",
      "[1000]\ttrain-rmse:1.47867+0.00255\ttest-rmse:1.55355+0.00472\n",
      "[1100]\ttrain-rmse:1.47315+0.00261\ttest-rmse:1.55341+0.00471\n",
      "[1200]\ttrain-rmse:1.46760+0.00265\ttest-rmse:1.55329+0.00466\n",
      "[1300]\ttrain-rmse:1.46222+0.00263\ttest-rmse:1.55323+0.00471\n",
      "[1400]\ttrain-rmse:1.45684+0.00267\ttest-rmse:1.55316+0.00467\n",
      "[1500]\ttrain-rmse:1.45142+0.00271\ttest-rmse:1.55320+0.00473\n",
      "[1588]\ttrain-rmse:1.44670+0.00277\ttest-rmse:1.55320+0.00474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:46:35,099] Trial 14 finished with value: 1.5531524113560549 and parameters: {'max_depth': 6, 'min_child_weight': 28.721885375930054, 'subsample': 0.8117060078127215, 'colsample_bytree': 0.8171713366090931, 'reg_lambda': 4.863423788081939, 'reg_alpha': 0.29697633284211733, 'min_split_gain': 2.583782528441155}. Best is trial 10 with value: 1.5526216749528154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 14: No improvement. Counter = 4, Best Score = 1.55262\n",
      "[0]\ttrain-rmse:1.71252+0.00411\ttest-rmse:1.71254+0.00829\n",
      "[100]\ttrain-rmse:1.61324+0.00289\ttest-rmse:1.61563+0.00707\n",
      "[200]\ttrain-rmse:1.58377+0.00267\ttest-rmse:1.58847+0.00629\n",
      "[300]\ttrain-rmse:1.56998+0.00260\ttest-rmse:1.57702+0.00570\n",
      "[400]\ttrain-rmse:1.56131+0.00249\ttest-rmse:1.57052+0.00547\n",
      "[500]\ttrain-rmse:1.55499+0.00238\ttest-rmse:1.56629+0.00536\n",
      "[600]\ttrain-rmse:1.55016+0.00233\ttest-rmse:1.56353+0.00522\n",
      "[700]\ttrain-rmse:1.54603+0.00232\ttest-rmse:1.56147+0.00507\n",
      "[800]\ttrain-rmse:1.54253+0.00231\ttest-rmse:1.55991+0.00501\n",
      "[900]\ttrain-rmse:1.53946+0.00234\ttest-rmse:1.55873+0.00493\n",
      "[1000]\ttrain-rmse:1.53666+0.00240\ttest-rmse:1.55780+0.00486\n",
      "[1100]\ttrain-rmse:1.53411+0.00233\ttest-rmse:1.55714+0.00486\n",
      "[1200]\ttrain-rmse:1.53168+0.00235\ttest-rmse:1.55659+0.00481\n",
      "[1300]\ttrain-rmse:1.52938+0.00232\ttest-rmse:1.55615+0.00482\n",
      "[1400]\ttrain-rmse:1.52714+0.00232\ttest-rmse:1.55582+0.00477\n",
      "[1500]\ttrain-rmse:1.52497+0.00235\ttest-rmse:1.55548+0.00477\n",
      "[1600]\ttrain-rmse:1.52297+0.00238\ttest-rmse:1.55523+0.00471\n",
      "[1700]\ttrain-rmse:1.52095+0.00238\ttest-rmse:1.55501+0.00468\n",
      "[1800]\ttrain-rmse:1.51893+0.00240\ttest-rmse:1.55481+0.00473\n",
      "[1900]\ttrain-rmse:1.51699+0.00246\ttest-rmse:1.55465+0.00469\n",
      "[2000]\ttrain-rmse:1.51508+0.00242\ttest-rmse:1.55450+0.00470\n",
      "[2100]\ttrain-rmse:1.51321+0.00241\ttest-rmse:1.55438+0.00471\n",
      "[2200]\ttrain-rmse:1.51137+0.00242\ttest-rmse:1.55423+0.00472\n",
      "[2300]\ttrain-rmse:1.50954+0.00241\ttest-rmse:1.55415+0.00475\n",
      "[2400]\ttrain-rmse:1.50775+0.00233\ttest-rmse:1.55406+0.00480\n",
      "[2500]\ttrain-rmse:1.50591+0.00230\ttest-rmse:1.55395+0.00480\n",
      "[2600]\ttrain-rmse:1.50413+0.00227\ttest-rmse:1.55395+0.00479\n",
      "[2700]\ttrain-rmse:1.50235+0.00223\ttest-rmse:1.55389+0.00481\n",
      "[2800]\ttrain-rmse:1.50057+0.00221\ttest-rmse:1.55388+0.00481\n",
      "[2900]\ttrain-rmse:1.49881+0.00216\ttest-rmse:1.55385+0.00486\n",
      "[3000]\ttrain-rmse:1.49710+0.00215\ttest-rmse:1.55383+0.00484\n",
      "[3100]\ttrain-rmse:1.49540+0.00216\ttest-rmse:1.55381+0.00487\n",
      "[3200]\ttrain-rmse:1.49372+0.00212\ttest-rmse:1.55382+0.00489\n",
      "[3300]\ttrain-rmse:1.49201+0.00212\ttest-rmse:1.55378+0.00493\n",
      "[3400]\ttrain-rmse:1.49033+0.00214\ttest-rmse:1.55373+0.00494\n",
      "[3500]\ttrain-rmse:1.48867+0.00213\ttest-rmse:1.55377+0.00498\n",
      "[3583]\ttrain-rmse:1.48728+0.00213\ttest-rmse:1.55376+0.00496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:48:15,986] Trial 15 finished with value: 1.5537289240121446 and parameters: {'max_depth': 4, 'min_child_weight': 35.13174044681155, 'subsample': 0.5224329759790411, 'colsample_bytree': 0.648342709955922, 'reg_lambda': 6.158314571232207, 'reg_alpha': 5.0570060185007, 'min_split_gain': 4.412181520216187}. Best is trial 10 with value: 1.5526216749528154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 15: No improvement. Counter = 5, Best Score = 1.55262\n",
      "[0]\ttrain-rmse:1.71204+0.00412\ttest-rmse:1.71219+0.00828\n",
      "[100]\ttrain-rmse:1.58424+0.00295\ttest-rmse:1.59876+0.00666\n",
      "[200]\ttrain-rmse:1.54363+0.00253\ttest-rmse:1.57088+0.00572\n",
      "[300]\ttrain-rmse:1.52263+0.00243\ttest-rmse:1.56124+0.00519\n",
      "[400]\ttrain-rmse:1.50915+0.00233\ttest-rmse:1.55727+0.00500\n",
      "[500]\ttrain-rmse:1.49821+0.00243\ttest-rmse:1.55513+0.00491\n",
      "[600]\ttrain-rmse:1.48930+0.00257\ttest-rmse:1.55407+0.00468\n",
      "[700]\ttrain-rmse:1.48087+0.00242\ttest-rmse:1.55337+0.00469\n",
      "[800]\ttrain-rmse:1.47307+0.00264\ttest-rmse:1.55296+0.00468\n",
      "[900]\ttrain-rmse:1.46545+0.00267\ttest-rmse:1.55257+0.00462\n",
      "[1000]\ttrain-rmse:1.45817+0.00268\ttest-rmse:1.55241+0.00457\n",
      "[1100]\ttrain-rmse:1.45132+0.00273\ttest-rmse:1.55230+0.00458\n",
      "[1200]\ttrain-rmse:1.44431+0.00275\ttest-rmse:1.55232+0.00459\n",
      "[1300]\ttrain-rmse:1.43769+0.00266\ttest-rmse:1.55237+0.00463\n",
      "[1322]\ttrain-rmse:1.43621+0.00273\ttest-rmse:1.55241+0.00464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:49:12,503] Trial 16 finished with value: 1.5522957865331242 and parameters: {'max_depth': 7, 'min_child_weight': 42.98697417939779, 'subsample': 0.5386265776076169, 'colsample_bytree': 0.43830151929810635, 'reg_lambda': 8.333399896014102, 'reg_alpha': 4.3279446811271125, 'min_split_gain': 2.7008957670944342}. Best is trial 16 with value: 1.5522957865331242.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 16: Improved score: 1.55230 (Previous best: 1.55262)\n",
      "[0]\ttrain-rmse:1.71206+0.00412\ttest-rmse:1.71220+0.00826\n",
      "[100]\ttrain-rmse:1.58489+0.00282\ttest-rmse:1.59902+0.00670\n",
      "[200]\ttrain-rmse:1.54470+0.00260\ttest-rmse:1.57120+0.00579\n",
      "[300]\ttrain-rmse:1.52392+0.00248\ttest-rmse:1.56156+0.00536\n",
      "[400]\ttrain-rmse:1.51063+0.00251\ttest-rmse:1.55750+0.00519\n",
      "[500]\ttrain-rmse:1.49997+0.00271\ttest-rmse:1.55527+0.00508\n",
      "[600]\ttrain-rmse:1.49116+0.00270\ttest-rmse:1.55402+0.00506\n",
      "[700]\ttrain-rmse:1.48283+0.00252\ttest-rmse:1.55325+0.00505\n",
      "[800]\ttrain-rmse:1.47526+0.00264\ttest-rmse:1.55276+0.00497\n",
      "[900]\ttrain-rmse:1.46793+0.00262\ttest-rmse:1.55242+0.00503\n",
      "[1000]\ttrain-rmse:1.46081+0.00267\ttest-rmse:1.55224+0.00498\n",
      "[1100]\ttrain-rmse:1.45414+0.00249\ttest-rmse:1.55214+0.00510\n",
      "[1200]\ttrain-rmse:1.44739+0.00259\ttest-rmse:1.55213+0.00509\n",
      "[1300]\ttrain-rmse:1.44081+0.00253\ttest-rmse:1.55214+0.00508\n",
      "[1400]\ttrain-rmse:1.43421+0.00258\ttest-rmse:1.55217+0.00508\n",
      "[1433]\ttrain-rmse:1.43202+0.00261\ttest-rmse:1.55218+0.00505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:50:12,430] Trial 17 finished with value: 1.5521044007944447 and parameters: {'max_depth': 7, 'min_child_weight': 44.76841804021024, 'subsample': 0.5142659659303197, 'colsample_bytree': 0.4074275275515026, 'reg_lambda': 8.360294049385999, 'reg_alpha': 4.0552633917620176, 'min_split_gain': 1.8343819854563466}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 17: Improved score: 1.55210 (Previous best: 1.55230)\n",
      "[0]\ttrain-rmse:1.71207+0.00414\ttest-rmse:1.71220+0.00826\n",
      "[100]\ttrain-rmse:1.58595+0.00294\ttest-rmse:1.59951+0.00656\n",
      "[200]\ttrain-rmse:1.54606+0.00247\ttest-rmse:1.57150+0.00569\n",
      "[300]\ttrain-rmse:1.52588+0.00233\ttest-rmse:1.56185+0.00523\n",
      "[400]\ttrain-rmse:1.51288+0.00250\ttest-rmse:1.55776+0.00487\n",
      "[500]\ttrain-rmse:1.50287+0.00238\ttest-rmse:1.55562+0.00477\n",
      "[600]\ttrain-rmse:1.49430+0.00249\ttest-rmse:1.55441+0.00468\n",
      "[700]\ttrain-rmse:1.48639+0.00243\ttest-rmse:1.55367+0.00460\n",
      "[800]\ttrain-rmse:1.47914+0.00253\ttest-rmse:1.55319+0.00463\n",
      "[900]\ttrain-rmse:1.47201+0.00253\ttest-rmse:1.55287+0.00462\n",
      "[1000]\ttrain-rmse:1.46517+0.00257\ttest-rmse:1.55268+0.00456\n",
      "[1100]\ttrain-rmse:1.45838+0.00250\ttest-rmse:1.55256+0.00454\n",
      "[1200]\ttrain-rmse:1.45195+0.00261\ttest-rmse:1.55251+0.00451\n",
      "[1300]\ttrain-rmse:1.44563+0.00261\ttest-rmse:1.55250+0.00448\n",
      "[1400]\ttrain-rmse:1.43924+0.00271\ttest-rmse:1.55258+0.00449\n",
      "[1482]\ttrain-rmse:1.43409+0.00289\ttest-rmse:1.55258+0.00448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:51:15,035] Trial 18 finished with value: 1.552457693550141 and parameters: {'max_depth': 7, 'min_child_weight': 44.920463733029614, 'subsample': 0.4382869097123995, 'colsample_bytree': 0.4005054956145977, 'reg_lambda': 8.341995228093808, 'reg_alpha': 4.079666769620679, 'min_split_gain': 0.12834322184106184}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 18: No improvement. Counter = 1, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71253+0.00412\ttest-rmse:1.71255+0.00828\n",
      "[100]\ttrain-rmse:1.61491+0.00293\ttest-rmse:1.61714+0.00708\n",
      "[200]\ttrain-rmse:1.58567+0.00273\ttest-rmse:1.59005+0.00629\n",
      "[300]\ttrain-rmse:1.57142+0.00257\ttest-rmse:1.57810+0.00579\n",
      "[400]\ttrain-rmse:1.56265+0.00248\ttest-rmse:1.57144+0.00553\n",
      "[500]\ttrain-rmse:1.55613+0.00240\ttest-rmse:1.56707+0.00531\n",
      "[600]\ttrain-rmse:1.55112+0.00244\ttest-rmse:1.56412+0.00513\n",
      "[700]\ttrain-rmse:1.54691+0.00244\ttest-rmse:1.56192+0.00504\n",
      "[800]\ttrain-rmse:1.54331+0.00248\ttest-rmse:1.56028+0.00494\n",
      "[900]\ttrain-rmse:1.54014+0.00250\ttest-rmse:1.55904+0.00487\n",
      "[1000]\ttrain-rmse:1.53726+0.00247\ttest-rmse:1.55803+0.00486\n",
      "[1100]\ttrain-rmse:1.53465+0.00246\ttest-rmse:1.55729+0.00478\n",
      "[1200]\ttrain-rmse:1.53219+0.00247\ttest-rmse:1.55669+0.00472\n",
      "[1300]\ttrain-rmse:1.52988+0.00244\ttest-rmse:1.55624+0.00475\n",
      "[1400]\ttrain-rmse:1.52763+0.00244\ttest-rmse:1.55582+0.00473\n",
      "[1500]\ttrain-rmse:1.52544+0.00244\ttest-rmse:1.55549+0.00474\n",
      "[1600]\ttrain-rmse:1.52332+0.00238\ttest-rmse:1.55521+0.00473\n",
      "[1700]\ttrain-rmse:1.52124+0.00237\ttest-rmse:1.55496+0.00471\n",
      "[1800]\ttrain-rmse:1.51919+0.00233\ttest-rmse:1.55474+0.00475\n",
      "[1900]\ttrain-rmse:1.51721+0.00232\ttest-rmse:1.55456+0.00474\n",
      "[2000]\ttrain-rmse:1.51524+0.00223\ttest-rmse:1.55440+0.00476\n",
      "[2100]\ttrain-rmse:1.51333+0.00220\ttest-rmse:1.55428+0.00475\n",
      "[2200]\ttrain-rmse:1.51145+0.00217\ttest-rmse:1.55414+0.00480\n",
      "[2300]\ttrain-rmse:1.50959+0.00218\ttest-rmse:1.55407+0.00479\n",
      "[2400]\ttrain-rmse:1.50777+0.00214\ttest-rmse:1.55398+0.00482\n",
      "[2500]\ttrain-rmse:1.50593+0.00210\ttest-rmse:1.55389+0.00483\n",
      "[2600]\ttrain-rmse:1.50414+0.00208\ttest-rmse:1.55383+0.00483\n",
      "[2700]\ttrain-rmse:1.50233+0.00205\ttest-rmse:1.55375+0.00487\n",
      "[2800]\ttrain-rmse:1.50056+0.00201\ttest-rmse:1.55370+0.00487\n",
      "[2900]\ttrain-rmse:1.49877+0.00198\ttest-rmse:1.55366+0.00487\n",
      "[3000]\ttrain-rmse:1.49701+0.00199\ttest-rmse:1.55363+0.00484\n",
      "[3100]\ttrain-rmse:1.49530+0.00198\ttest-rmse:1.55361+0.00486\n",
      "[3200]\ttrain-rmse:1.49359+0.00197\ttest-rmse:1.55361+0.00487\n",
      "[3300]\ttrain-rmse:1.49185+0.00195\ttest-rmse:1.55356+0.00485\n",
      "[3400]\ttrain-rmse:1.49016+0.00195\ttest-rmse:1.55355+0.00483\n",
      "[3500]\ttrain-rmse:1.48849+0.00194\ttest-rmse:1.55355+0.00484\n",
      "[3600]\ttrain-rmse:1.48681+0.00190\ttest-rmse:1.55355+0.00486\n",
      "[3700]\ttrain-rmse:1.48517+0.00189\ttest-rmse:1.55356+0.00484\n",
      "[3723]\ttrain-rmse:1.48481+0.00189\ttest-rmse:1.55357+0.00482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:52:59,046] Trial 19 finished with value: 1.5535230523644572 and parameters: {'max_depth': 4, 'min_child_weight': 0.470147277677853, 'subsample': 0.5387720568388968, 'colsample_bytree': 0.44452424597181267, 'reg_lambda': 9.550847392214049, 'reg_alpha': 4.310490416302996, 'min_split_gain': 2.187841009049106}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 19: No improvement. Counter = 2, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71178+0.00412\ttest-rmse:1.71209+0.00827\n",
      "[100]\ttrain-rmse:1.56550+0.00281\ttest-rmse:1.59360+0.00651\n",
      "[200]\ttrain-rmse:1.51490+0.00229\ttest-rmse:1.56706+0.00580\n",
      "[300]\ttrain-rmse:1.48652+0.00223\ttest-rmse:1.55865+0.00535\n",
      "[400]\ttrain-rmse:1.46737+0.00236\ttest-rmse:1.55547+0.00507\n",
      "[500]\ttrain-rmse:1.45231+0.00235\ttest-rmse:1.55394+0.00494\n",
      "[600]\ttrain-rmse:1.43994+0.00239\ttest-rmse:1.55314+0.00479\n",
      "[700]\ttrain-rmse:1.42873+0.00263\ttest-rmse:1.55272+0.00482\n",
      "[800]\ttrain-rmse:1.41807+0.00306\ttest-rmse:1.55243+0.00486\n",
      "[900]\ttrain-rmse:1.40787+0.00310\ttest-rmse:1.55241+0.00484\n",
      "[1000]\ttrain-rmse:1.39790+0.00345\ttest-rmse:1.55241+0.00484\n",
      "[1100]\ttrain-rmse:1.38825+0.00352\ttest-rmse:1.55247+0.00486\n",
      "[1150]\ttrain-rmse:1.38355+0.00345\ttest-rmse:1.55248+0.00481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:53:59,100] Trial 20 finished with value: 1.552363982071452 and parameters: {'max_depth': 8, 'min_child_weight': 39.29932271466753, 'subsample': 0.8200463446493249, 'colsample_bytree': 0.524206779157832, 'reg_lambda': 8.134575513426363, 'reg_alpha': 1.3222680152473911, 'min_split_gain': 1.4692465024340775}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 20: No improvement. Counter = 3, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71177+0.00411\ttest-rmse:1.71207+0.00828\n",
      "[100]\ttrain-rmse:1.56476+0.00274\ttest-rmse:1.59348+0.00653\n",
      "[200]\ttrain-rmse:1.51381+0.00229\ttest-rmse:1.56702+0.00573\n",
      "[300]\ttrain-rmse:1.48528+0.00208\ttest-rmse:1.55878+0.00526\n",
      "[400]\ttrain-rmse:1.46615+0.00236\ttest-rmse:1.55570+0.00498\n",
      "[500]\ttrain-rmse:1.45149+0.00238\ttest-rmse:1.55431+0.00492\n",
      "[600]\ttrain-rmse:1.43907+0.00239\ttest-rmse:1.55348+0.00487\n",
      "[700]\ttrain-rmse:1.42791+0.00275\ttest-rmse:1.55307+0.00480\n",
      "[800]\ttrain-rmse:1.41753+0.00294\ttest-rmse:1.55283+0.00481\n",
      "[900]\ttrain-rmse:1.40766+0.00292\ttest-rmse:1.55277+0.00479\n",
      "[1000]\ttrain-rmse:1.39774+0.00332\ttest-rmse:1.55272+0.00478\n",
      "[1100]\ttrain-rmse:1.38842+0.00340\ttest-rmse:1.55282+0.00475\n",
      "[1200]\ttrain-rmse:1.37922+0.00352\ttest-rmse:1.55290+0.00472\n",
      "[1201]\ttrain-rmse:1.37914+0.00350\ttest-rmse:1.55290+0.00472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:55:00,656] Trial 21 finished with value: 1.5527101831739083 and parameters: {'max_depth': 8, 'min_child_weight': 40.18040371380097, 'subsample': 0.8391501513228741, 'colsample_bytree': 0.5319692206204878, 'reg_lambda': 7.903702306490856, 'reg_alpha': 0.12687336790414339, 'min_split_gain': 1.1665872806351785}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 21: No improvement. Counter = 4, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71206+0.00412\ttest-rmse:1.71220+0.00828\n",
      "[100]\ttrain-rmse:1.58407+0.00297\ttest-rmse:1.59975+0.00677\n",
      "[200]\ttrain-rmse:1.54202+0.00238\ttest-rmse:1.57200+0.00616\n",
      "[300]\ttrain-rmse:1.51930+0.00240\ttest-rmse:1.56207+0.00563\n",
      "[400]\ttrain-rmse:1.50396+0.00249\ttest-rmse:1.55779+0.00537\n",
      "[500]\ttrain-rmse:1.49209+0.00235\ttest-rmse:1.55556+0.00519\n",
      "[600]\ttrain-rmse:1.48183+0.00229\ttest-rmse:1.55427+0.00505\n",
      "[700]\ttrain-rmse:1.47313+0.00223\ttest-rmse:1.55356+0.00501\n",
      "[800]\ttrain-rmse:1.46523+0.00241\ttest-rmse:1.55304+0.00494\n",
      "[900]\ttrain-rmse:1.45782+0.00237\ttest-rmse:1.55271+0.00492\n",
      "[1000]\ttrain-rmse:1.45076+0.00254\ttest-rmse:1.55256+0.00490\n",
      "[1100]\ttrain-rmse:1.44393+0.00257\ttest-rmse:1.55242+0.00483\n",
      "[1200]\ttrain-rmse:1.43719+0.00252\ttest-rmse:1.55239+0.00488\n",
      "[1300]\ttrain-rmse:1.43058+0.00256\ttest-rmse:1.55239+0.00489\n",
      "[1400]\ttrain-rmse:1.42402+0.00264\ttest-rmse:1.55237+0.00481\n",
      "[1500]\ttrain-rmse:1.41744+0.00255\ttest-rmse:1.55236+0.00477\n",
      "[1600]\ttrain-rmse:1.41075+0.00263\ttest-rmse:1.55241+0.00476\n",
      "[1700]\ttrain-rmse:1.40453+0.00266\ttest-rmse:1.55252+0.00476\n",
      "[1705]\ttrain-rmse:1.40423+0.00266\ttest-rmse:1.55253+0.00475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:56:09,844] Trial 22 finished with value: 1.5523503566531813 and parameters: {'max_depth': 7, 'min_child_weight': 39.412812870136456, 'subsample': 0.8120202843382262, 'colsample_bytree': 0.3322044589845622, 'reg_lambda': 7.331966067211036, 'reg_alpha': 1.171350719287736, 'min_split_gain': 1.9422750704978577}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 22: No improvement. Counter = 5, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71209+0.00412\ttest-rmse:1.71222+0.00828\n",
      "[100]\ttrain-rmse:1.58501+0.00283\ttest-rmse:1.59975+0.00668\n",
      "[200]\ttrain-rmse:1.54391+0.00247\ttest-rmse:1.57195+0.00591\n",
      "[300]\ttrain-rmse:1.52223+0.00243\ttest-rmse:1.56205+0.00528\n",
      "[400]\ttrain-rmse:1.50792+0.00235\ttest-rmse:1.55778+0.00509\n",
      "[500]\ttrain-rmse:1.49669+0.00230\ttest-rmse:1.55557+0.00485\n",
      "[600]\ttrain-rmse:1.48734+0.00240\ttest-rmse:1.55424+0.00483\n",
      "[700]\ttrain-rmse:1.47896+0.00221\ttest-rmse:1.55352+0.00474\n",
      "[800]\ttrain-rmse:1.47105+0.00227\ttest-rmse:1.55300+0.00472\n",
      "[900]\ttrain-rmse:1.46379+0.00227\ttest-rmse:1.55259+0.00472\n",
      "[1000]\ttrain-rmse:1.45662+0.00242\ttest-rmse:1.55245+0.00469\n",
      "[1100]\ttrain-rmse:1.44983+0.00256\ttest-rmse:1.55240+0.00476\n",
      "[1200]\ttrain-rmse:1.44291+0.00258\ttest-rmse:1.55235+0.00472\n",
      "[1300]\ttrain-rmse:1.43630+0.00254\ttest-rmse:1.55234+0.00473\n",
      "[1400]\ttrain-rmse:1.42966+0.00253\ttest-rmse:1.55235+0.00470\n",
      "[1493]\ttrain-rmse:1.42340+0.00272\ttest-rmse:1.55238+0.00472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:57:11,742] Trial 23 finished with value: 1.552328756636185 and parameters: {'max_depth': 7, 'min_child_weight': 41.758799503371364, 'subsample': 0.6180858111629124, 'colsample_bytree': 0.3547430912687002, 'reg_lambda': 7.055728207728372, 'reg_alpha': 3.3099089470288963, 'min_split_gain': 2.1565595100905126}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 23: No improvement. Counter = 6, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71233+0.00412\ttest-rmse:1.71238+0.00828\n",
      "[100]\ttrain-rmse:1.60490+0.00286\ttest-rmse:1.60935+0.00696\n",
      "[200]\ttrain-rmse:1.57295+0.00263\ttest-rmse:1.58164+0.00605\n",
      "[300]\ttrain-rmse:1.55736+0.00247\ttest-rmse:1.57022+0.00560\n",
      "[400]\ttrain-rmse:1.54772+0.00235\ttest-rmse:1.56449+0.00543\n",
      "[500]\ttrain-rmse:1.54057+0.00234\ttest-rmse:1.56097+0.00518\n",
      "[600]\ttrain-rmse:1.53487+0.00241\ttest-rmse:1.55876+0.00497\n",
      "[700]\ttrain-rmse:1.53005+0.00229\ttest-rmse:1.55720+0.00489\n",
      "[800]\ttrain-rmse:1.52581+0.00236\ttest-rmse:1.55611+0.00487\n",
      "[900]\ttrain-rmse:1.52183+0.00238\ttest-rmse:1.55529+0.00483\n",
      "[1000]\ttrain-rmse:1.51817+0.00245\ttest-rmse:1.55469+0.00480\n",
      "[1100]\ttrain-rmse:1.51473+0.00243\ttest-rmse:1.55429+0.00478\n",
      "[1200]\ttrain-rmse:1.51136+0.00244\ttest-rmse:1.55396+0.00473\n",
      "[1300]\ttrain-rmse:1.50818+0.00241\ttest-rmse:1.55369+0.00480\n",
      "[1400]\ttrain-rmse:1.50512+0.00243\ttest-rmse:1.55349+0.00477\n",
      "[1500]\ttrain-rmse:1.50194+0.00251\ttest-rmse:1.55333+0.00482\n",
      "[1600]\ttrain-rmse:1.49893+0.00253\ttest-rmse:1.55321+0.00476\n",
      "[1700]\ttrain-rmse:1.49589+0.00258\ttest-rmse:1.55314+0.00477\n",
      "[1800]\ttrain-rmse:1.49305+0.00259\ttest-rmse:1.55305+0.00480\n",
      "[1900]\ttrain-rmse:1.49020+0.00265\ttest-rmse:1.55295+0.00480\n",
      "[2000]\ttrain-rmse:1.48730+0.00261\ttest-rmse:1.55293+0.00480\n",
      "[2100]\ttrain-rmse:1.48446+0.00256\ttest-rmse:1.55287+0.00479\n",
      "[2200]\ttrain-rmse:1.48162+0.00257\ttest-rmse:1.55283+0.00480\n",
      "[2300]\ttrain-rmse:1.47887+0.00258\ttest-rmse:1.55284+0.00480\n",
      "[2400]\ttrain-rmse:1.47616+0.00257\ttest-rmse:1.55283+0.00482\n",
      "[2446]\ttrain-rmse:1.47487+0.00259\ttest-rmse:1.55283+0.00482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:58:27,798] Trial 24 finished with value: 1.5528238296260293 and parameters: {'max_depth': 5, 'min_child_weight': 42.42962099308215, 'subsample': 0.6018771163488431, 'colsample_bytree': 0.4096311815121144, 'reg_lambda': 9.91319607575519, 'reg_alpha': 2.906984565623053, 'min_split_gain': 0.14503826943823261}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 24: No improvement. Counter = 7, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71211+0.00411\ttest-rmse:1.71223+0.00827\n",
      "[100]\ttrain-rmse:1.58852+0.00284\ttest-rmse:1.60118+0.00668\n",
      "[200]\ttrain-rmse:1.54901+0.00243\ttest-rmse:1.57305+0.00580\n",
      "[300]\ttrain-rmse:1.52884+0.00224\ttest-rmse:1.56299+0.00528\n",
      "[400]\ttrain-rmse:1.51582+0.00215\ttest-rmse:1.55858+0.00503\n",
      "[500]\ttrain-rmse:1.50576+0.00210\ttest-rmse:1.55620+0.00493\n",
      "[600]\ttrain-rmse:1.49717+0.00214\ttest-rmse:1.55490+0.00484\n",
      "[700]\ttrain-rmse:1.48918+0.00198\ttest-rmse:1.55409+0.00468\n",
      "[800]\ttrain-rmse:1.48201+0.00215\ttest-rmse:1.55355+0.00466\n",
      "[900]\ttrain-rmse:1.47491+0.00211\ttest-rmse:1.55326+0.00465\n",
      "[1000]\ttrain-rmse:1.46809+0.00216\ttest-rmse:1.55296+0.00463\n",
      "[1100]\ttrain-rmse:1.46153+0.00224\ttest-rmse:1.55284+0.00460\n",
      "[1200]\ttrain-rmse:1.45498+0.00226\ttest-rmse:1.55275+0.00454\n",
      "[1300]\ttrain-rmse:1.44879+0.00230\ttest-rmse:1.55276+0.00450\n",
      "[1374]\ttrain-rmse:1.44404+0.00244\ttest-rmse:1.55278+0.00448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 03:59:24,264] Trial 25 finished with value: 1.552718835667159 and parameters: {'max_depth': 7, 'min_child_weight': 37.17352107805313, 'subsample': 0.41316905152089645, 'colsample_bytree': 0.32378627901456275, 'reg_lambda': 8.925016179700034, 'reg_alpha': 4.829935717677127, 'min_split_gain': 3.8161608890037497}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 25: No improvement. Counter = 8, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71233+0.00411\ttest-rmse:1.71238+0.00828\n",
      "[100]\ttrain-rmse:1.60287+0.00272\ttest-rmse:1.60758+0.00693\n",
      "[200]\ttrain-rmse:1.57073+0.00243\ttest-rmse:1.57988+0.00611\n",
      "[300]\ttrain-rmse:1.55556+0.00231\ttest-rmse:1.56911+0.00566\n",
      "[400]\ttrain-rmse:1.54597+0.00229\ttest-rmse:1.56365+0.00532\n",
      "[500]\ttrain-rmse:1.53892+0.00225\ttest-rmse:1.56037+0.00511\n",
      "[600]\ttrain-rmse:1.53319+0.00220\ttest-rmse:1.55828+0.00496\n",
      "[700]\ttrain-rmse:1.52818+0.00214\ttest-rmse:1.55679+0.00486\n",
      "[800]\ttrain-rmse:1.52386+0.00227\ttest-rmse:1.55576+0.00480\n",
      "[900]\ttrain-rmse:1.51984+0.00228\ttest-rmse:1.55505+0.00476\n",
      "[1000]\ttrain-rmse:1.51609+0.00230\ttest-rmse:1.55452+0.00475\n",
      "[1100]\ttrain-rmse:1.51257+0.00229\ttest-rmse:1.55416+0.00473\n",
      "[1200]\ttrain-rmse:1.50915+0.00228\ttest-rmse:1.55388+0.00473\n",
      "[1300]\ttrain-rmse:1.50585+0.00231\ttest-rmse:1.55363+0.00477\n",
      "[1400]\ttrain-rmse:1.50254+0.00231\ttest-rmse:1.55343+0.00472\n",
      "[1500]\ttrain-rmse:1.49918+0.00231\ttest-rmse:1.55330+0.00479\n",
      "[1600]\ttrain-rmse:1.49606+0.00231\ttest-rmse:1.55316+0.00476\n",
      "[1700]\ttrain-rmse:1.49294+0.00231\ttest-rmse:1.55309+0.00478\n",
      "[1800]\ttrain-rmse:1.48990+0.00239\ttest-rmse:1.55300+0.00482\n",
      "[1900]\ttrain-rmse:1.48684+0.00244\ttest-rmse:1.55290+0.00479\n",
      "[2000]\ttrain-rmse:1.48383+0.00238\ttest-rmse:1.55291+0.00481\n",
      "[2100]\ttrain-rmse:1.48089+0.00233\ttest-rmse:1.55288+0.00478\n",
      "[2200]\ttrain-rmse:1.47790+0.00238\ttest-rmse:1.55284+0.00478\n",
      "[2300]\ttrain-rmse:1.47495+0.00240\ttest-rmse:1.55288+0.00474\n",
      "[2372]\ttrain-rmse:1.47291+0.00244\ttest-rmse:1.55289+0.00477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:00:39,731] Trial 26 finished with value: 1.5528283571193453 and parameters: {'max_depth': 5, 'min_child_weight': 42.19809048910017, 'subsample': 0.5980302514251536, 'colsample_bytree': 0.6043148414349394, 'reg_lambda': 8.71478724545849, 'reg_alpha': 3.4177851905071313, 'min_split_gain': 5.474420589518607}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 26: No improvement. Counter = 9, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71306+0.00414\ttest-rmse:1.71306+0.00828\n",
      "[100]\ttrain-rmse:1.64237+0.00330\ttest-rmse:1.64274+0.00742\n",
      "[200]\ttrain-rmse:1.61833+0.00288\ttest-rmse:1.61921+0.00685\n",
      "[300]\ttrain-rmse:1.60542+0.00275\ttest-rmse:1.60675+0.00648\n",
      "[400]\ttrain-rmse:1.59696+0.00278\ttest-rmse:1.59871+0.00608\n",
      "[500]\ttrain-rmse:1.59059+0.00272\ttest-rmse:1.59277+0.00586\n",
      "[600]\ttrain-rmse:1.58559+0.00256\ttest-rmse:1.58813+0.00575\n",
      "[700]\ttrain-rmse:1.58142+0.00258\ttest-rmse:1.58436+0.00556\n",
      "[800]\ttrain-rmse:1.57795+0.00254\ttest-rmse:1.58124+0.00545\n",
      "[900]\ttrain-rmse:1.57505+0.00259\ttest-rmse:1.57869+0.00526\n",
      "[1000]\ttrain-rmse:1.57251+0.00261\ttest-rmse:1.57651+0.00513\n",
      "[1100]\ttrain-rmse:1.57035+0.00257\ttest-rmse:1.57463+0.00512\n",
      "[1200]\ttrain-rmse:1.56844+0.00256\ttest-rmse:1.57307+0.00503\n",
      "[1300]\ttrain-rmse:1.56676+0.00255\ttest-rmse:1.57175+0.00497\n",
      "[1400]\ttrain-rmse:1.56525+0.00255\ttest-rmse:1.57058+0.00490\n",
      "[1500]\ttrain-rmse:1.56388+0.00258\ttest-rmse:1.56950+0.00486\n",
      "[1600]\ttrain-rmse:1.56261+0.00261\ttest-rmse:1.56854+0.00478\n",
      "[1700]\ttrain-rmse:1.56145+0.00261\ttest-rmse:1.56767+0.00477\n",
      "[1800]\ttrain-rmse:1.56043+0.00260\ttest-rmse:1.56699+0.00473\n",
      "[1900]\ttrain-rmse:1.55948+0.00259\ttest-rmse:1.56636+0.00469\n",
      "[2000]\ttrain-rmse:1.55858+0.00259\ttest-rmse:1.56581+0.00466\n",
      "[2100]\ttrain-rmse:1.55780+0.00259\ttest-rmse:1.56534+0.00465\n",
      "[2200]\ttrain-rmse:1.55698+0.00258\ttest-rmse:1.56486+0.00468\n",
      "[2300]\ttrain-rmse:1.55622+0.00257\ttest-rmse:1.56444+0.00463\n",
      "[2400]\ttrain-rmse:1.55553+0.00258\ttest-rmse:1.56407+0.00463\n",
      "[2500]\ttrain-rmse:1.55487+0.00257\ttest-rmse:1.56370+0.00461\n",
      "[2600]\ttrain-rmse:1.55418+0.00260\ttest-rmse:1.56337+0.00459\n",
      "[2700]\ttrain-rmse:1.55359+0.00260\ttest-rmse:1.56310+0.00460\n",
      "[2800]\ttrain-rmse:1.55302+0.00261\ttest-rmse:1.56286+0.00461\n",
      "[2900]\ttrain-rmse:1.55246+0.00263\ttest-rmse:1.56263+0.00459\n",
      "[3000]\ttrain-rmse:1.55190+0.00267\ttest-rmse:1.56240+0.00455\n",
      "[3100]\ttrain-rmse:1.55134+0.00269\ttest-rmse:1.56216+0.00454\n",
      "[3200]\ttrain-rmse:1.55083+0.00269\ttest-rmse:1.56198+0.00456\n",
      "[3300]\ttrain-rmse:1.55033+0.00269\ttest-rmse:1.56178+0.00459\n",
      "[3400]\ttrain-rmse:1.54981+0.00269\ttest-rmse:1.56158+0.00458\n",
      "[3500]\ttrain-rmse:1.54931+0.00269\ttest-rmse:1.56141+0.00458\n",
      "[3600]\ttrain-rmse:1.54882+0.00269\ttest-rmse:1.56123+0.00457\n",
      "[3700]\ttrain-rmse:1.54833+0.00268\ttest-rmse:1.56103+0.00459\n",
      "[3800]\ttrain-rmse:1.54786+0.00268\ttest-rmse:1.56088+0.00461\n",
      "[3900]\ttrain-rmse:1.54741+0.00267\ttest-rmse:1.56074+0.00461\n",
      "[4000]\ttrain-rmse:1.54697+0.00266\ttest-rmse:1.56060+0.00462\n",
      "[4100]\ttrain-rmse:1.54654+0.00267\ttest-rmse:1.56048+0.00462\n",
      "[4200]\ttrain-rmse:1.54611+0.00267\ttest-rmse:1.56035+0.00461\n",
      "[4300]\ttrain-rmse:1.54567+0.00266\ttest-rmse:1.56022+0.00464\n",
      "[4400]\ttrain-rmse:1.54526+0.00266\ttest-rmse:1.56012+0.00463\n",
      "[4500]\ttrain-rmse:1.54487+0.00267\ttest-rmse:1.56006+0.00462\n",
      "[4600]\ttrain-rmse:1.54446+0.00268\ttest-rmse:1.55998+0.00462\n",
      "[4700]\ttrain-rmse:1.54406+0.00268\ttest-rmse:1.55989+0.00466\n",
      "[4800]\ttrain-rmse:1.54367+0.00267\ttest-rmse:1.55979+0.00464\n",
      "[4900]\ttrain-rmse:1.54328+0.00265\ttest-rmse:1.55970+0.00465\n",
      "[5000]\ttrain-rmse:1.54289+0.00265\ttest-rmse:1.55960+0.00466\n",
      "[5100]\ttrain-rmse:1.54252+0.00264\ttest-rmse:1.55952+0.00469\n",
      "[5200]\ttrain-rmse:1.54215+0.00263\ttest-rmse:1.55942+0.00472\n",
      "[5300]\ttrain-rmse:1.54177+0.00263\ttest-rmse:1.55933+0.00473\n",
      "[5400]\ttrain-rmse:1.54140+0.00263\ttest-rmse:1.55926+0.00472\n",
      "[5500]\ttrain-rmse:1.54104+0.00264\ttest-rmse:1.55921+0.00473\n",
      "[5600]\ttrain-rmse:1.54067+0.00264\ttest-rmse:1.55913+0.00476\n",
      "[5700]\ttrain-rmse:1.54030+0.00263\ttest-rmse:1.55909+0.00475\n",
      "[5800]\ttrain-rmse:1.53995+0.00262\ttest-rmse:1.55903+0.00477\n",
      "[5900]\ttrain-rmse:1.53960+0.00260\ttest-rmse:1.55897+0.00481\n",
      "[6000]\ttrain-rmse:1.53926+0.00260\ttest-rmse:1.55890+0.00482\n",
      "[6100]\ttrain-rmse:1.53893+0.00259\ttest-rmse:1.55884+0.00483\n",
      "[6200]\ttrain-rmse:1.53859+0.00259\ttest-rmse:1.55879+0.00483\n",
      "[6300]\ttrain-rmse:1.53825+0.00258\ttest-rmse:1.55872+0.00487\n",
      "[6400]\ttrain-rmse:1.53793+0.00258\ttest-rmse:1.55869+0.00490\n",
      "[6500]\ttrain-rmse:1.53759+0.00258\ttest-rmse:1.55862+0.00490\n",
      "[6600]\ttrain-rmse:1.53726+0.00258\ttest-rmse:1.55862+0.00491\n",
      "[6700]\ttrain-rmse:1.53693+0.00257\ttest-rmse:1.55861+0.00491\n",
      "[6800]\ttrain-rmse:1.53660+0.00256\ttest-rmse:1.55854+0.00490\n",
      "[6900]\ttrain-rmse:1.53629+0.00256\ttest-rmse:1.55850+0.00490\n",
      "[7000]\ttrain-rmse:1.53598+0.00255\ttest-rmse:1.55849+0.00492\n",
      "[7100]\ttrain-rmse:1.53567+0.00256\ttest-rmse:1.55845+0.00494\n",
      "[7200]\ttrain-rmse:1.53536+0.00255\ttest-rmse:1.55839+0.00495\n",
      "[7300]\ttrain-rmse:1.53506+0.00253\ttest-rmse:1.55836+0.00496\n",
      "[7400]\ttrain-rmse:1.53473+0.00254\ttest-rmse:1.55832+0.00495\n",
      "[7500]\ttrain-rmse:1.53443+0.00254\ttest-rmse:1.55827+0.00494\n",
      "[7600]\ttrain-rmse:1.53413+0.00254\ttest-rmse:1.55821+0.00493\n",
      "[7700]\ttrain-rmse:1.53382+0.00253\ttest-rmse:1.55819+0.00494\n",
      "[7800]\ttrain-rmse:1.53353+0.00254\ttest-rmse:1.55818+0.00495\n",
      "[7900]\ttrain-rmse:1.53323+0.00254\ttest-rmse:1.55817+0.00494\n",
      "[8000]\ttrain-rmse:1.53295+0.00253\ttest-rmse:1.55814+0.00494\n",
      "[8100]\ttrain-rmse:1.53265+0.00251\ttest-rmse:1.55813+0.00492\n",
      "[8200]\ttrain-rmse:1.53236+0.00251\ttest-rmse:1.55812+0.00491\n",
      "[8300]\ttrain-rmse:1.53207+0.00250\ttest-rmse:1.55807+0.00492\n",
      "[8400]\ttrain-rmse:1.53179+0.00249\ttest-rmse:1.55804+0.00492\n",
      "[8500]\ttrain-rmse:1.53151+0.00248\ttest-rmse:1.55802+0.00493\n",
      "[8600]\ttrain-rmse:1.53122+0.00248\ttest-rmse:1.55801+0.00492\n",
      "[8700]\ttrain-rmse:1.53093+0.00248\ttest-rmse:1.55797+0.00492\n",
      "[8800]\ttrain-rmse:1.53065+0.00247\ttest-rmse:1.55796+0.00492\n",
      "[8900]\ttrain-rmse:1.53035+0.00247\ttest-rmse:1.55795+0.00490\n",
      "[9000]\ttrain-rmse:1.53007+0.00246\ttest-rmse:1.55792+0.00489\n",
      "[9100]\ttrain-rmse:1.52979+0.00246\ttest-rmse:1.55792+0.00488\n",
      "[9200]\ttrain-rmse:1.52951+0.00246\ttest-rmse:1.55793+0.00487\n",
      "[9300]\ttrain-rmse:1.52925+0.00246\ttest-rmse:1.55790+0.00487\n",
      "[9400]\ttrain-rmse:1.52898+0.00245\ttest-rmse:1.55788+0.00488\n",
      "[9500]\ttrain-rmse:1.52871+0.00245\ttest-rmse:1.55787+0.00489\n",
      "[9600]\ttrain-rmse:1.52844+0.00244\ttest-rmse:1.55785+0.00490\n",
      "[9700]\ttrain-rmse:1.52817+0.00244\ttest-rmse:1.55781+0.00488\n",
      "[9800]\ttrain-rmse:1.52792+0.00244\ttest-rmse:1.55780+0.00490\n",
      "[9900]\ttrain-rmse:1.52765+0.00243\ttest-rmse:1.55781+0.00490\n",
      "[9999]\ttrain-rmse:1.52738+0.00242\ttest-rmse:1.55777+0.00490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:04:20,818] Trial 27 finished with value: 1.5577708755175335 and parameters: {'max_depth': 2, 'min_child_weight': 23.700256362315056, 'subsample': 0.3516463771678519, 'colsample_bytree': 0.45794921927800925, 'reg_lambda': 6.576776281977468, 'reg_alpha': 2.469297605135697, 'min_split_gain': 2.6046395341119677}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 27: No improvement. Counter = 10, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71151+0.00412\ttest-rmse:1.71206+0.00824\n",
      "[100]\ttrain-rmse:1.53462+0.00278\ttest-rmse:1.59168+0.00653\n",
      "[200]\ttrain-rmse:1.46008+0.00221\ttest-rmse:1.56476+0.00549\n",
      "[300]\ttrain-rmse:1.41531+0.00237\ttest-rmse:1.55749+0.00479\n",
      "[400]\ttrain-rmse:1.38400+0.00275\ttest-rmse:1.55527+0.00461\n",
      "[500]\ttrain-rmse:1.35886+0.00274\ttest-rmse:1.55449+0.00460\n",
      "[600]\ttrain-rmse:1.33618+0.00318\ttest-rmse:1.55416+0.00442\n",
      "[700]\ttrain-rmse:1.31443+0.00336\ttest-rmse:1.55428+0.00441\n",
      "[800]\ttrain-rmse:1.29233+0.00357\ttest-rmse:1.55467+0.00431\n",
      "[805]\ttrain-rmse:1.29133+0.00348\ttest-rmse:1.55469+0.00429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:05:41,119] Trial 28 finished with value: 1.5541466870509681 and parameters: {'max_depth': 12, 'min_child_weight': 44.967228287436875, 'subsample': 0.46273331881165697, 'colsample_bytree': 0.6782428970267484, 'reg_lambda': 7.521781370255961, 'reg_alpha': 3.647436407466755, 'min_split_gain': 4.739213117820357}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 28: No improvement. Counter = 11, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71209+0.00412\ttest-rmse:1.71225+0.00825\n",
      "[100]\ttrain-rmse:1.58402+0.00306\ttest-rmse:1.59989+0.00663\n",
      "[200]\ttrain-rmse:1.54187+0.00245\ttest-rmse:1.57141+0.00584\n",
      "[300]\ttrain-rmse:1.52115+0.00250\ttest-rmse:1.56198+0.00521\n",
      "[400]\ttrain-rmse:1.50770+0.00233\ttest-rmse:1.55807+0.00490\n",
      "[500]\ttrain-rmse:1.49675+0.00283\ttest-rmse:1.55618+0.00474\n",
      "[600]\ttrain-rmse:1.48740+0.00291\ttest-rmse:1.55516+0.00467\n",
      "[700]\ttrain-rmse:1.47858+0.00270\ttest-rmse:1.55450+0.00456\n",
      "[800]\ttrain-rmse:1.47033+0.00282\ttest-rmse:1.55411+0.00440\n",
      "[900]\ttrain-rmse:1.46200+0.00298\ttest-rmse:1.55383+0.00448\n",
      "[1000]\ttrain-rmse:1.45379+0.00293\ttest-rmse:1.55366+0.00441\n",
      "[1100]\ttrain-rmse:1.44595+0.00297\ttest-rmse:1.55369+0.00445\n",
      "[1200]\ttrain-rmse:1.43816+0.00290\ttest-rmse:1.55377+0.00444\n",
      "[1257]\ttrain-rmse:1.43401+0.00284\ttest-rmse:1.55386+0.00452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:06:43,010] Trial 29 finished with value: 1.5536386135860925 and parameters: {'max_depth': 8, 'min_child_weight': 35.973474861229704, 'subsample': 0.22434755854482147, 'colsample_bytree': 0.3570157044896897, 'reg_lambda': 6.820023166796713, 'reg_alpha': 5.017061953234091, 'min_split_gain': 0.856608145162375}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 29: No improvement. Counter = 12, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71443+0.00415\ttest-rmse:1.71443+0.00829\n",
      "[100]\ttrain-rmse:1.69687+0.00391\ttest-rmse:1.69723+0.00823\n",
      "[200]\ttrain-rmse:1.68171+0.00365\ttest-rmse:1.68251+0.00806\n",
      "[300]\ttrain-rmse:1.67124+0.00352\ttest-rmse:1.67249+0.00792\n",
      "[400]\ttrain-rmse:1.65974+0.00328\ttest-rmse:1.66139+0.00774\n",
      "[500]\ttrain-rmse:1.65225+0.00317\ttest-rmse:1.65423+0.00755\n",
      "[600]\ttrain-rmse:1.64628+0.00309\ttest-rmse:1.64862+0.00740\n",
      "[700]\ttrain-rmse:1.64147+0.00301\ttest-rmse:1.64419+0.00730\n",
      "[800]\ttrain-rmse:1.63661+0.00292\ttest-rmse:1.63968+0.00717\n",
      "[900]\ttrain-rmse:1.63128+0.00280\ttest-rmse:1.63469+0.00700\n",
      "[1000]\ttrain-rmse:1.62835+0.00277\ttest-rmse:1.63211+0.00689\n",
      "[1100]\ttrain-rmse:1.62468+0.00272\ttest-rmse:1.62880+0.00677\n",
      "[1200]\ttrain-rmse:1.62303+0.00270\ttest-rmse:1.62749+0.00670\n",
      "[1300]\ttrain-rmse:1.62080+0.00265\ttest-rmse:1.62561+0.00660\n",
      "[1400]\ttrain-rmse:1.61732+0.00257\ttest-rmse:1.62248+0.00652\n",
      "[1500]\ttrain-rmse:1.61508+0.00253\ttest-rmse:1.62057+0.00640\n",
      "[1600]\ttrain-rmse:1.61334+0.00250\ttest-rmse:1.61918+0.00632\n",
      "[1700]\ttrain-rmse:1.61154+0.00249\ttest-rmse:1.61772+0.00624\n",
      "[1800]\ttrain-rmse:1.60973+0.00244\ttest-rmse:1.61624+0.00617\n",
      "[1900]\ttrain-rmse:1.60801+0.00242\ttest-rmse:1.61485+0.00607\n",
      "[2000]\ttrain-rmse:1.60658+0.00241\ttest-rmse:1.61370+0.00598\n",
      "[2100]\ttrain-rmse:1.60529+0.00237\ttest-rmse:1.61268+0.00592\n",
      "[2200]\ttrain-rmse:1.60370+0.00236\ttest-rmse:1.61141+0.00585\n",
      "[2300]\ttrain-rmse:1.60219+0.00232\ttest-rmse:1.61021+0.00581\n",
      "[2400]\ttrain-rmse:1.60078+0.00230\ttest-rmse:1.60909+0.00574\n",
      "[2500]\ttrain-rmse:1.59946+0.00229\ttest-rmse:1.60803+0.00568\n",
      "[2600]\ttrain-rmse:1.59812+0.00229\ttest-rmse:1.60696+0.00562\n",
      "[2700]\ttrain-rmse:1.59696+0.00228\ttest-rmse:1.60611+0.00556\n",
      "[2800]\ttrain-rmse:1.59596+0.00227\ttest-rmse:1.60541+0.00552\n",
      "[2900]\ttrain-rmse:1.59460+0.00225\ttest-rmse:1.60435+0.00547\n",
      "[3000]\ttrain-rmse:1.59334+0.00223\ttest-rmse:1.60339+0.00541\n",
      "[3100]\ttrain-rmse:1.59218+0.00221\ttest-rmse:1.60248+0.00538\n",
      "[3200]\ttrain-rmse:1.59111+0.00221\ttest-rmse:1.60174+0.00534\n",
      "[3300]\ttrain-rmse:1.59012+0.00221\ttest-rmse:1.60102+0.00532\n",
      "[3400]\ttrain-rmse:1.58882+0.00221\ttest-rmse:1.59998+0.00526\n",
      "[3500]\ttrain-rmse:1.58799+0.00220\ttest-rmse:1.59942+0.00522\n",
      "[3600]\ttrain-rmse:1.58731+0.00219\ttest-rmse:1.59901+0.00519\n",
      "[3700]\ttrain-rmse:1.58630+0.00220\ttest-rmse:1.59828+0.00514\n",
      "[3800]\ttrain-rmse:1.58535+0.00219\ttest-rmse:1.59761+0.00512\n",
      "[3900]\ttrain-rmse:1.58435+0.00218\ttest-rmse:1.59688+0.00508\n",
      "[4000]\ttrain-rmse:1.58357+0.00218\ttest-rmse:1.59637+0.00507\n",
      "[4100]\ttrain-rmse:1.58273+0.00216\ttest-rmse:1.59584+0.00505\n",
      "[4200]\ttrain-rmse:1.58202+0.00217\ttest-rmse:1.59538+0.00502\n",
      "[4300]\ttrain-rmse:1.58136+0.00217\ttest-rmse:1.59500+0.00500\n",
      "[4400]\ttrain-rmse:1.58072+0.00216\ttest-rmse:1.59462+0.00497\n",
      "[4500]\ttrain-rmse:1.57997+0.00214\ttest-rmse:1.59417+0.00495\n",
      "[4600]\ttrain-rmse:1.57908+0.00215\ttest-rmse:1.59350+0.00492\n",
      "[4700]\ttrain-rmse:1.57846+0.00216\ttest-rmse:1.59313+0.00490\n",
      "[4800]\ttrain-rmse:1.57785+0.00215\ttest-rmse:1.59279+0.00488\n",
      "[4900]\ttrain-rmse:1.57727+0.00214\ttest-rmse:1.59246+0.00484\n",
      "[5000]\ttrain-rmse:1.57670+0.00213\ttest-rmse:1.59217+0.00484\n",
      "[5100]\ttrain-rmse:1.57611+0.00211\ttest-rmse:1.59187+0.00481\n",
      "[5200]\ttrain-rmse:1.57560+0.00211\ttest-rmse:1.59157+0.00481\n",
      "[5300]\ttrain-rmse:1.57512+0.00210\ttest-rmse:1.59133+0.00476\n",
      "[5400]\ttrain-rmse:1.57461+0.00212\ttest-rmse:1.59103+0.00474\n",
      "[5500]\ttrain-rmse:1.57387+0.00213\ttest-rmse:1.59054+0.00471\n",
      "[5600]\ttrain-rmse:1.57335+0.00214\ttest-rmse:1.59026+0.00471\n",
      "[5700]\ttrain-rmse:1.57281+0.00212\ttest-rmse:1.58998+0.00470\n",
      "[5800]\ttrain-rmse:1.57208+0.00211\ttest-rmse:1.58951+0.00468\n",
      "[5900]\ttrain-rmse:1.57146+0.00212\ttest-rmse:1.58915+0.00468\n",
      "[6000]\ttrain-rmse:1.57102+0.00212\ttest-rmse:1.58894+0.00465\n",
      "[6100]\ttrain-rmse:1.57050+0.00212\ttest-rmse:1.58868+0.00463\n",
      "[6200]\ttrain-rmse:1.57005+0.00212\ttest-rmse:1.58846+0.00462\n",
      "[6300]\ttrain-rmse:1.56959+0.00210\ttest-rmse:1.58822+0.00460\n",
      "[6400]\ttrain-rmse:1.56913+0.00211\ttest-rmse:1.58802+0.00460\n",
      "[6500]\ttrain-rmse:1.56858+0.00210\ttest-rmse:1.58770+0.00458\n",
      "[6600]\ttrain-rmse:1.56824+0.00210\ttest-rmse:1.58757+0.00458\n",
      "[6700]\ttrain-rmse:1.56773+0.00210\ttest-rmse:1.58729+0.00458\n",
      "[6800]\ttrain-rmse:1.56720+0.00209\ttest-rmse:1.58703+0.00456\n",
      "[6900]\ttrain-rmse:1.56667+0.00208\ttest-rmse:1.58670+0.00455\n",
      "[7000]\ttrain-rmse:1.56617+0.00207\ttest-rmse:1.58642+0.00453\n",
      "[7100]\ttrain-rmse:1.56580+0.00207\ttest-rmse:1.58627+0.00453\n",
      "[7200]\ttrain-rmse:1.56542+0.00207\ttest-rmse:1.58612+0.00452\n",
      "[7300]\ttrain-rmse:1.56502+0.00207\ttest-rmse:1.58592+0.00450\n",
      "[7400]\ttrain-rmse:1.56455+0.00206\ttest-rmse:1.58572+0.00449\n",
      "[7500]\ttrain-rmse:1.56418+0.00208\ttest-rmse:1.58558+0.00448\n",
      "[7600]\ttrain-rmse:1.56378+0.00208\ttest-rmse:1.58538+0.00448\n",
      "[7700]\ttrain-rmse:1.56337+0.00208\ttest-rmse:1.58520+0.00448\n",
      "[7800]\ttrain-rmse:1.56304+0.00207\ttest-rmse:1.58509+0.00447\n",
      "[7900]\ttrain-rmse:1.56280+0.00207\ttest-rmse:1.58503+0.00446\n",
      "[8000]\ttrain-rmse:1.56249+0.00207\ttest-rmse:1.58491+0.00445\n",
      "[8100]\ttrain-rmse:1.56205+0.00206\ttest-rmse:1.58470+0.00444\n",
      "[8200]\ttrain-rmse:1.56167+0.00205\ttest-rmse:1.58452+0.00442\n",
      "[8300]\ttrain-rmse:1.56127+0.00204\ttest-rmse:1.58438+0.00440\n",
      "[8400]\ttrain-rmse:1.56098+0.00204\ttest-rmse:1.58429+0.00440\n",
      "[8500]\ttrain-rmse:1.56064+0.00203\ttest-rmse:1.58419+0.00439\n",
      "[8600]\ttrain-rmse:1.56030+0.00204\ttest-rmse:1.58402+0.00438\n",
      "[8700]\ttrain-rmse:1.55997+0.00204\ttest-rmse:1.58389+0.00437\n",
      "[8800]\ttrain-rmse:1.55964+0.00204\ttest-rmse:1.58375+0.00437\n",
      "[8900]\ttrain-rmse:1.55928+0.00204\ttest-rmse:1.58365+0.00436\n",
      "[9000]\ttrain-rmse:1.55891+0.00204\ttest-rmse:1.58349+0.00435\n",
      "[9100]\ttrain-rmse:1.55862+0.00204\ttest-rmse:1.58340+0.00435\n",
      "[9200]\ttrain-rmse:1.55825+0.00203\ttest-rmse:1.58323+0.00434\n",
      "[9300]\ttrain-rmse:1.55789+0.00202\ttest-rmse:1.58313+0.00433\n",
      "[9400]\ttrain-rmse:1.55759+0.00202\ttest-rmse:1.58303+0.00433\n",
      "[9500]\ttrain-rmse:1.55734+0.00202\ttest-rmse:1.58297+0.00432\n",
      "[9600]\ttrain-rmse:1.55708+0.00202\ttest-rmse:1.58290+0.00432\n",
      "[9700]\ttrain-rmse:1.55679+0.00202\ttest-rmse:1.58281+0.00433\n",
      "[9800]\ttrain-rmse:1.55655+0.00202\ttest-rmse:1.58277+0.00433\n",
      "[9900]\ttrain-rmse:1.55625+0.00201\ttest-rmse:1.58268+0.00433\n",
      "[9999]\ttrain-rmse:1.55600+0.00202\ttest-rmse:1.58261+0.00431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:11:04,810] Trial 30 finished with value: 1.5826058392414415 and parameters: {'max_depth': 5, 'min_child_weight': 41.5179388082869, 'subsample': 0.5695720561097383, 'colsample_bytree': 0.002770678885179678, 'reg_lambda': 4.607874270736586, 'reg_alpha': 6.716181757896647, 'min_split_gain': 1.7782028489733992}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 30: No improvement. Counter = 13, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71206+0.00413\ttest-rmse:1.71221+0.00826\n",
      "[100]\ttrain-rmse:1.58462+0.00286\ttest-rmse:1.59998+0.00672\n",
      "[200]\ttrain-rmse:1.54310+0.00247\ttest-rmse:1.57239+0.00597\n",
      "[300]\ttrain-rmse:1.52057+0.00249\ttest-rmse:1.56226+0.00543\n",
      "[400]\ttrain-rmse:1.50528+0.00248\ttest-rmse:1.55790+0.00511\n",
      "[500]\ttrain-rmse:1.49342+0.00225\ttest-rmse:1.55565+0.00490\n",
      "[600]\ttrain-rmse:1.48324+0.00211\ttest-rmse:1.55427+0.00481\n",
      "[700]\ttrain-rmse:1.47467+0.00221\ttest-rmse:1.55359+0.00477\n",
      "[800]\ttrain-rmse:1.46676+0.00233\ttest-rmse:1.55309+0.00476\n",
      "[900]\ttrain-rmse:1.45927+0.00231\ttest-rmse:1.55279+0.00472\n",
      "[1000]\ttrain-rmse:1.45224+0.00222\ttest-rmse:1.55254+0.00467\n",
      "[1100]\ttrain-rmse:1.44534+0.00230\ttest-rmse:1.55241+0.00462\n",
      "[1200]\ttrain-rmse:1.43851+0.00232\ttest-rmse:1.55236+0.00459\n",
      "[1300]\ttrain-rmse:1.43195+0.00227\ttest-rmse:1.55235+0.00462\n",
      "[1400]\ttrain-rmse:1.42548+0.00244\ttest-rmse:1.55237+0.00463\n",
      "[1454]\ttrain-rmse:1.42188+0.00247\ttest-rmse:1.55236+0.00465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:12:02,682] Trial 31 finished with value: 1.552319110271507 and parameters: {'max_depth': 7, 'min_child_weight': 38.293222385149285, 'subsample': 0.7714855400142813, 'colsample_bytree': 0.30811247993537183, 'reg_lambda': 7.659332386360353, 'reg_alpha': 1.5528237960668398, 'min_split_gain': 1.8659477371809023}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 31: No improvement. Counter = 14, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71211+0.00412\ttest-rmse:1.71224+0.00826\n",
      "[100]\ttrain-rmse:1.58639+0.00285\ttest-rmse:1.60105+0.00675\n",
      "[200]\ttrain-rmse:1.54517+0.00246\ttest-rmse:1.57315+0.00592\n",
      "[300]\ttrain-rmse:1.52281+0.00242\ttest-rmse:1.56284+0.00549\n",
      "[400]\ttrain-rmse:1.50768+0.00237\ttest-rmse:1.55826+0.00525\n",
      "[500]\ttrain-rmse:1.49607+0.00246\ttest-rmse:1.55588+0.00507\n",
      "[600]\ttrain-rmse:1.48612+0.00234\ttest-rmse:1.55441+0.00497\n",
      "[700]\ttrain-rmse:1.47762+0.00233\ttest-rmse:1.55364+0.00489\n",
      "[800]\ttrain-rmse:1.46981+0.00264\ttest-rmse:1.55314+0.00479\n",
      "[900]\ttrain-rmse:1.46241+0.00262\ttest-rmse:1.55279+0.00476\n",
      "[1000]\ttrain-rmse:1.45549+0.00263\ttest-rmse:1.55253+0.00475\n",
      "[1100]\ttrain-rmse:1.44874+0.00268\ttest-rmse:1.55236+0.00477\n",
      "[1200]\ttrain-rmse:1.44192+0.00243\ttest-rmse:1.55232+0.00471\n",
      "[1300]\ttrain-rmse:1.43540+0.00244\ttest-rmse:1.55227+0.00468\n",
      "[1400]\ttrain-rmse:1.42891+0.00269\ttest-rmse:1.55224+0.00471\n",
      "[1500]\ttrain-rmse:1.42239+0.00283\ttest-rmse:1.55228+0.00473\n",
      "[1570]\ttrain-rmse:1.41800+0.00288\ttest-rmse:1.55229+0.00475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:13:04,216] Trial 32 finished with value: 1.5522366322598942 and parameters: {'max_depth': 7, 'min_child_weight': 37.43579564659678, 'subsample': 0.7296307058480898, 'colsample_bytree': 0.27081899651115127, 'reg_lambda': 9.128840245725797, 'reg_alpha': 1.6896140873778058, 'min_split_gain': 2.5819575527626073}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 32: No improvement. Counter = 15, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71174+0.00413\ttest-rmse:1.71213+0.00825\n",
      "[100]\ttrain-rmse:1.55918+0.00283\ttest-rmse:1.59617+0.00671\n",
      "[200]\ttrain-rmse:1.50035+0.00207\ttest-rmse:1.56858+0.00594\n",
      "[300]\ttrain-rmse:1.46496+0.00209\ttest-rmse:1.55963+0.00560\n",
      "[400]\ttrain-rmse:1.44036+0.00214\ttest-rmse:1.55610+0.00534\n",
      "[500]\ttrain-rmse:1.42069+0.00196\ttest-rmse:1.55438+0.00522\n",
      "[600]\ttrain-rmse:1.40375+0.00179\ttest-rmse:1.55346+0.00519\n",
      "[700]\ttrain-rmse:1.38876+0.00191\ttest-rmse:1.55302+0.00512\n",
      "[800]\ttrain-rmse:1.37456+0.00225\ttest-rmse:1.55277+0.00513\n",
      "[900]\ttrain-rmse:1.36141+0.00234\ttest-rmse:1.55277+0.00507\n",
      "[1000]\ttrain-rmse:1.34875+0.00230\ttest-rmse:1.55277+0.00505\n",
      "[1061]\ttrain-rmse:1.34130+0.00246\ttest-rmse:1.55281+0.00508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:14:06,739] Trial 33 finished with value: 1.5527356752280934 and parameters: {'max_depth': 9, 'min_child_weight': 31.436542631419158, 'subsample': 0.7427245602338567, 'colsample_bytree': 0.27266662327523244, 'reg_lambda': 9.2474751821756, 'reg_alpha': 2.137681045171297, 'min_split_gain': 3.6146717213292328}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 33: No improvement. Counter = 16, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71182+0.00412\ttest-rmse:1.71211+0.00827\n",
      "[100]\ttrain-rmse:1.56771+0.00273\ttest-rmse:1.59451+0.00666\n",
      "[200]\ttrain-rmse:1.51759+0.00228\ttest-rmse:1.56754+0.00566\n",
      "[300]\ttrain-rmse:1.48985+0.00223\ttest-rmse:1.55901+0.00525\n",
      "[400]\ttrain-rmse:1.47081+0.00217\ttest-rmse:1.55582+0.00506\n",
      "[500]\ttrain-rmse:1.45574+0.00207\ttest-rmse:1.55420+0.00486\n",
      "[600]\ttrain-rmse:1.44300+0.00212\ttest-rmse:1.55342+0.00483\n",
      "[700]\ttrain-rmse:1.43188+0.00230\ttest-rmse:1.55297+0.00475\n",
      "[800]\ttrain-rmse:1.42129+0.00251\ttest-rmse:1.55268+0.00471\n",
      "[900]\ttrain-rmse:1.41106+0.00281\ttest-rmse:1.55261+0.00476\n",
      "[1000]\ttrain-rmse:1.40068+0.00314\ttest-rmse:1.55262+0.00478\n",
      "[1100]\ttrain-rmse:1.39110+0.00344\ttest-rmse:1.55262+0.00480\n",
      "[1200]\ttrain-rmse:1.38113+0.00332\ttest-rmse:1.55276+0.00475\n",
      "[1243]\ttrain-rmse:1.37706+0.00315\ttest-rmse:1.55282+0.00474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:15:07,860] Trial 34 finished with value: 1.552581426967911 and parameters: {'max_depth': 8, 'min_child_weight': 37.50946222189153, 'subsample': 0.7410048381034976, 'colsample_bytree': 0.47050262345853244, 'reg_lambda': 8.377566298234216, 'reg_alpha': 1.698011200790864, 'min_split_gain': 2.6742522041789503}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 34: No improvement. Counter = 17, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71165+0.00412\ttest-rmse:1.71215+0.00828\n",
      "[100]\ttrain-rmse:1.54779+0.00284\ttest-rmse:1.59851+0.00668\n",
      "[200]\ttrain-rmse:1.47600+0.00196\ttest-rmse:1.57042+0.00574\n",
      "[300]\ttrain-rmse:1.43110+0.00185\ttest-rmse:1.56105+0.00539\n",
      "[400]\ttrain-rmse:1.39925+0.00171\ttest-rmse:1.55726+0.00510\n",
      "[500]\ttrain-rmse:1.37421+0.00204\ttest-rmse:1.55537+0.00504\n",
      "[600]\ttrain-rmse:1.35307+0.00226\ttest-rmse:1.55446+0.00488\n",
      "[700]\ttrain-rmse:1.33390+0.00200\ttest-rmse:1.55390+0.00482\n",
      "[800]\ttrain-rmse:1.31688+0.00209\ttest-rmse:1.55354+0.00481\n",
      "[900]\ttrain-rmse:1.30107+0.00181\ttest-rmse:1.55349+0.00476\n",
      "[1000]\ttrain-rmse:1.28667+0.00182\ttest-rmse:1.55346+0.00474\n",
      "[1100]\ttrain-rmse:1.27301+0.00207\ttest-rmse:1.55346+0.00471\n",
      "[1153]\ttrain-rmse:1.26583+0.00194\ttest-rmse:1.55351+0.00472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:16:29,229] Trial 35 finished with value: 1.5534270302117206 and parameters: {'max_depth': 10, 'min_child_weight': 33.310038234019544, 'subsample': 0.9039096287348977, 'colsample_bytree': 0.17123421993181295, 'reg_lambda': 9.949371007762412, 'reg_alpha': 0.7113325456161107, 'min_split_gain': 0.7668582182287011}. Best is trial 17 with value: 1.5521044007944447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 35: No improvement. Counter = 18, Best Score = 1.55210\n",
      "[0]\ttrain-rmse:1.71212+0.00412\ttest-rmse:1.71225+0.00827\n",
      "[100]\ttrain-rmse:1.58750+0.00287\ttest-rmse:1.60162+0.00682\n",
      "[200]\ttrain-rmse:1.54652+0.00254\ttest-rmse:1.57346+0.00601\n",
      "[300]\ttrain-rmse:1.52449+0.00250\ttest-rmse:1.56296+0.00552\n",
      "[400]\ttrain-rmse:1.51012+0.00243\ttest-rmse:1.55835+0.00535\n",
      "[500]\ttrain-rmse:1.49887+0.00242\ttest-rmse:1.55599+0.00520\n",
      "[600]\ttrain-rmse:1.48916+0.00220\ttest-rmse:1.55454+0.00514\n",
      "[700]\ttrain-rmse:1.48073+0.00198\ttest-rmse:1.55365+0.00516\n",
      "[800]\ttrain-rmse:1.47299+0.00222\ttest-rmse:1.55307+0.00508\n",
      "[900]\ttrain-rmse:1.46587+0.00244\ttest-rmse:1.55271+0.00503\n",
      "[1000]\ttrain-rmse:1.45890+0.00269\ttest-rmse:1.55244+0.00503\n",
      "[1100]\ttrain-rmse:1.45223+0.00268\ttest-rmse:1.55224+0.00501\n",
      "[1200]\ttrain-rmse:1.44560+0.00261\ttest-rmse:1.55216+0.00499\n",
      "[1300]\ttrain-rmse:1.43917+0.00264\ttest-rmse:1.55208+0.00493\n",
      "[1400]\ttrain-rmse:1.43282+0.00271\ttest-rmse:1.55213+0.00491\n",
      "[1500]\ttrain-rmse:1.42638+0.00267\ttest-rmse:1.55216+0.00488\n",
      "[1527]\ttrain-rmse:1.42476+0.00273\ttest-rmse:1.55217+0.00487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:17:29,901] Trial 36 finished with value: 1.5520636386618045 and parameters: {'max_depth': 7, 'min_child_weight': 38.18414290403634, 'subsample': 0.6486182004695331, 'colsample_bytree': 0.26466558766149234, 'reg_lambda': 9.477892847589064, 'reg_alpha': 2.178769479196936, 'min_split_gain': 1.1558812717327778}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 36: Improved score: 1.55206 (Previous best: 1.55210)\n",
      "[0]\ttrain-rmse:1.71187+0.00413\ttest-rmse:1.71219+0.00828\n",
      "[100]\ttrain-rmse:1.56517+0.00286\ttest-rmse:1.59747+0.00675\n",
      "[200]\ttrain-rmse:1.50972+0.00243\ttest-rmse:1.56933+0.00581\n",
      "[300]\ttrain-rmse:1.47761+0.00228\ttest-rmse:1.55993+0.00539\n",
      "[400]\ttrain-rmse:1.45590+0.00221\ttest-rmse:1.55631+0.00516\n",
      "[500]\ttrain-rmse:1.43874+0.00222\ttest-rmse:1.55459+0.00507\n",
      "[600]\ttrain-rmse:1.42390+0.00208\ttest-rmse:1.55369+0.00487\n",
      "[700]\ttrain-rmse:1.41034+0.00152\ttest-rmse:1.55323+0.00483\n",
      "[800]\ttrain-rmse:1.39788+0.00174\ttest-rmse:1.55293+0.00480\n",
      "[900]\ttrain-rmse:1.38622+0.00168\ttest-rmse:1.55276+0.00482\n",
      "[1000]\ttrain-rmse:1.37499+0.00184\ttest-rmse:1.55265+0.00469\n",
      "[1100]\ttrain-rmse:1.36386+0.00190\ttest-rmse:1.55265+0.00466\n",
      "[1200]\ttrain-rmse:1.35277+0.00210\ttest-rmse:1.55277+0.00476\n",
      "[1241]\ttrain-rmse:1.34851+0.00204\ttest-rmse:1.55283+0.00477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:18:38,458] Trial 37 finished with value: 1.5526330868282747 and parameters: {'max_depth': 9, 'min_child_weight': 44.03275704074295, 'subsample': 0.6474420215648189, 'colsample_bytree': 0.2479453092933225, 'reg_lambda': 9.277407552974577, 'reg_alpha': 2.0045632178491806, 'min_split_gain': 1.2759245610627121}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 37: No improvement. Counter = 1, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71237+0.00412\ttest-rmse:1.71241+0.00828\n",
      "[100]\ttrain-rmse:1.60527+0.00291\ttest-rmse:1.60960+0.00698\n",
      "[200]\ttrain-rmse:1.57316+0.00256\ttest-rmse:1.58169+0.00613\n",
      "[300]\ttrain-rmse:1.55749+0.00247\ttest-rmse:1.57033+0.00564\n",
      "[400]\ttrain-rmse:1.54760+0.00236\ttest-rmse:1.56448+0.00533\n",
      "[500]\ttrain-rmse:1.54008+0.00237\ttest-rmse:1.56098+0.00509\n",
      "[600]\ttrain-rmse:1.53406+0.00232\ttest-rmse:1.55866+0.00495\n",
      "[700]\ttrain-rmse:1.52878+0.00229\ttest-rmse:1.55719+0.00493\n",
      "[800]\ttrain-rmse:1.52406+0.00227\ttest-rmse:1.55607+0.00488\n",
      "[900]\ttrain-rmse:1.51980+0.00224\ttest-rmse:1.55528+0.00491\n",
      "[1000]\ttrain-rmse:1.51576+0.00225\ttest-rmse:1.55473+0.00486\n",
      "[1100]\ttrain-rmse:1.51192+0.00223\ttest-rmse:1.55430+0.00485\n",
      "[1200]\ttrain-rmse:1.50825+0.00228\ttest-rmse:1.55403+0.00484\n",
      "[1300]\ttrain-rmse:1.50463+0.00221\ttest-rmse:1.55375+0.00481\n",
      "[1400]\ttrain-rmse:1.50111+0.00216\ttest-rmse:1.55361+0.00480\n",
      "[1500]\ttrain-rmse:1.49757+0.00223\ttest-rmse:1.55340+0.00481\n",
      "[1600]\ttrain-rmse:1.49406+0.00214\ttest-rmse:1.55330+0.00479\n",
      "[1700]\ttrain-rmse:1.49061+0.00207\ttest-rmse:1.55315+0.00479\n",
      "[1800]\ttrain-rmse:1.48730+0.00209\ttest-rmse:1.55302+0.00479\n",
      "[1900]\ttrain-rmse:1.48404+0.00207\ttest-rmse:1.55296+0.00479\n",
      "[2000]\ttrain-rmse:1.48075+0.00201\ttest-rmse:1.55291+0.00477\n",
      "[2100]\ttrain-rmse:1.47750+0.00207\ttest-rmse:1.55290+0.00480\n",
      "[2200]\ttrain-rmse:1.47434+0.00205\ttest-rmse:1.55283+0.00481\n",
      "[2300]\ttrain-rmse:1.47116+0.00207\ttest-rmse:1.55288+0.00487\n",
      "[2400]\ttrain-rmse:1.46808+0.00201\ttest-rmse:1.55287+0.00491\n",
      "[2402]\ttrain-rmse:1.46802+0.00201\ttest-rmse:1.55287+0.00491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:19:53,328] Trial 38 finished with value: 1.5528241816458743 and parameters: {'max_depth': 5, 'min_child_weight': 4.762914979194331, 'subsample': 0.4821556159259631, 'colsample_bytree': 0.3845349683569029, 'reg_lambda': 8.399990924953402, 'reg_alpha': 4.081507964019137, 'min_split_gain': 0.5241860420218069}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 38: No improvement. Counter = 2, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71180+0.00410\ttest-rmse:1.71218+0.00827\n",
      "[100]\ttrain-rmse:1.55948+0.00294\ttest-rmse:1.59913+0.00667\n",
      "[200]\ttrain-rmse:1.49690+0.00234\ttest-rmse:1.57096+0.00573\n",
      "[300]\ttrain-rmse:1.45849+0.00230\ttest-rmse:1.56131+0.00519\n",
      "[400]\ttrain-rmse:1.43192+0.00208\ttest-rmse:1.55734+0.00502\n",
      "[500]\ttrain-rmse:1.41008+0.00210\ttest-rmse:1.55555+0.00497\n",
      "[600]\ttrain-rmse:1.39151+0.00240\ttest-rmse:1.55459+0.00472\n",
      "[700]\ttrain-rmse:1.37327+0.00259\ttest-rmse:1.55411+0.00466\n",
      "[800]\ttrain-rmse:1.35680+0.00246\ttest-rmse:1.55394+0.00446\n",
      "[900]\ttrain-rmse:1.34163+0.00225\ttest-rmse:1.55386+0.00452\n",
      "[1000]\ttrain-rmse:1.32684+0.00204\ttest-rmse:1.55388+0.00452\n",
      "[1100]\ttrain-rmse:1.31250+0.00183\ttest-rmse:1.55398+0.00454\n",
      "[1160]\ttrain-rmse:1.30380+0.00195\ttest-rmse:1.55409+0.00452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:21:10,112] Trial 39 finished with value: 1.5538019246678967 and parameters: {'max_depth': 10, 'min_child_weight': 25.36928079811701, 'subsample': 0.5355758781214551, 'colsample_bytree': 0.19311722689096514, 'reg_lambda': 9.573770241652237, 'reg_alpha': 2.708411165038739, 'min_split_gain': 5.137524966941409}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 39: No improvement. Counter = 3, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71225+0.00413\ttest-rmse:1.71236+0.00826\n",
      "[100]\ttrain-rmse:1.59911+0.00292\ttest-rmse:1.60968+0.00671\n",
      "[200]\ttrain-rmse:1.56078+0.00270\ttest-rmse:1.58074+0.00587\n",
      "[300]\ttrain-rmse:1.54192+0.00252\ttest-rmse:1.56955+0.00547\n",
      "[400]\ttrain-rmse:1.53031+0.00229\ttest-rmse:1.56475+0.00539\n",
      "[500]\ttrain-rmse:1.52145+0.00210\ttest-rmse:1.56189+0.00518\n",
      "[600]\ttrain-rmse:1.51376+0.00193\ttest-rmse:1.56014+0.00496\n",
      "[700]\ttrain-rmse:1.50660+0.00180\ttest-rmse:1.55909+0.00483\n",
      "[800]\ttrain-rmse:1.50003+0.00183\ttest-rmse:1.55832+0.00467\n",
      "[900]\ttrain-rmse:1.49388+0.00172\ttest-rmse:1.55794+0.00467\n",
      "[1000]\ttrain-rmse:1.48805+0.00154\ttest-rmse:1.55771+0.00467\n",
      "[1100]\ttrain-rmse:1.48211+0.00176\ttest-rmse:1.55752+0.00477\n",
      "[1200]\ttrain-rmse:1.47650+0.00157\ttest-rmse:1.55739+0.00477\n",
      "[1300]\ttrain-rmse:1.47113+0.00154\ttest-rmse:1.55717+0.00461\n",
      "[1400]\ttrain-rmse:1.46565+0.00153\ttest-rmse:1.55705+0.00465\n",
      "[1500]\ttrain-rmse:1.46035+0.00161\ttest-rmse:1.55728+0.00455\n",
      "[1600]\ttrain-rmse:1.45530+0.00172\ttest-rmse:1.55746+0.00451\n",
      "[1601]\ttrain-rmse:1.45526+0.00171\ttest-rmse:1.55747+0.00451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:22:15,232] Trial 40 finished with value: 1.5570427692160171 and parameters: {'max_depth': 8, 'min_child_weight': 17.1565354939164, 'subsample': 0.08898222126792765, 'colsample_bytree': 0.1374264051552787, 'reg_lambda': 3.42417238228786, 'reg_alpha': 0.786720659603412, 'min_split_gain': 6.451444696531613}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 40: No improvement. Counter = 4, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71210+0.00413\ttest-rmse:1.71224+0.00826\n",
      "[100]\ttrain-rmse:1.58546+0.00290\ttest-rmse:1.60051+0.00670\n",
      "[200]\ttrain-rmse:1.54431+0.00238\ttest-rmse:1.57293+0.00601\n",
      "[300]\ttrain-rmse:1.52186+0.00238\ttest-rmse:1.56271+0.00547\n",
      "[400]\ttrain-rmse:1.50672+0.00240\ttest-rmse:1.55824+0.00518\n",
      "[500]\ttrain-rmse:1.49492+0.00219\ttest-rmse:1.55594+0.00507\n",
      "[600]\ttrain-rmse:1.48475+0.00209\ttest-rmse:1.55447+0.00502\n",
      "[700]\ttrain-rmse:1.47587+0.00219\ttest-rmse:1.55369+0.00493\n",
      "[800]\ttrain-rmse:1.46792+0.00244\ttest-rmse:1.55313+0.00489\n",
      "[900]\ttrain-rmse:1.46036+0.00243\ttest-rmse:1.55281+0.00485\n",
      "[1000]\ttrain-rmse:1.45321+0.00247\ttest-rmse:1.55261+0.00476\n",
      "[1100]\ttrain-rmse:1.44631+0.00246\ttest-rmse:1.55246+0.00477\n",
      "[1200]\ttrain-rmse:1.43959+0.00247\ttest-rmse:1.55242+0.00478\n",
      "[1300]\ttrain-rmse:1.43305+0.00235\ttest-rmse:1.55235+0.00477\n",
      "[1400]\ttrain-rmse:1.42660+0.00248\ttest-rmse:1.55233+0.00473\n",
      "[1500]\ttrain-rmse:1.42003+0.00261\ttest-rmse:1.55230+0.00477\n",
      "[1600]\ttrain-rmse:1.41369+0.00270\ttest-rmse:1.55231+0.00479\n",
      "[1700]\ttrain-rmse:1.40731+0.00262\ttest-rmse:1.55232+0.00481\n",
      "[1774]\ttrain-rmse:1.40268+0.00259\ttest-rmse:1.55237+0.00479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:23:24,237] Trial 41 finished with value: 1.5522784753549512 and parameters: {'max_depth': 7, 'min_child_weight': 37.72812115611397, 'subsample': 0.7649841356740501, 'colsample_bytree': 0.28840080059739925, 'reg_lambda': 8.920136724388781, 'reg_alpha': 1.7798332220875523, 'min_split_gain': 1.5468668406208212}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 41: No improvement. Counter = 5, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71227+0.00413\ttest-rmse:1.71234+0.00827\n",
      "[100]\ttrain-rmse:1.59642+0.00286\ttest-rmse:1.60494+0.00686\n",
      "[200]\ttrain-rmse:1.56078+0.00248\ttest-rmse:1.57739+0.00612\n",
      "[300]\ttrain-rmse:1.54198+0.00235\ttest-rmse:1.56624+0.00569\n",
      "[400]\ttrain-rmse:1.52977+0.00243\ttest-rmse:1.56099+0.00533\n",
      "[500]\ttrain-rmse:1.52059+0.00234\ttest-rmse:1.55805+0.00518\n",
      "[600]\ttrain-rmse:1.51281+0.00245\ttest-rmse:1.55623+0.00496\n",
      "[700]\ttrain-rmse:1.50624+0.00253\ttest-rmse:1.55505+0.00487\n",
      "[800]\ttrain-rmse:1.50040+0.00273\ttest-rmse:1.55431+0.00479\n",
      "[900]\ttrain-rmse:1.49510+0.00279\ttest-rmse:1.55382+0.00474\n",
      "[1000]\ttrain-rmse:1.49003+0.00286\ttest-rmse:1.55345+0.00473\n",
      "[1100]\ttrain-rmse:1.48526+0.00297\ttest-rmse:1.55317+0.00470\n",
      "[1200]\ttrain-rmse:1.48063+0.00300\ttest-rmse:1.55300+0.00468\n",
      "[1300]\ttrain-rmse:1.47615+0.00292\ttest-rmse:1.55287+0.00464\n",
      "[1400]\ttrain-rmse:1.47166+0.00290\ttest-rmse:1.55280+0.00464\n",
      "[1500]\ttrain-rmse:1.46727+0.00279\ttest-rmse:1.55274+0.00462\n",
      "[1600]\ttrain-rmse:1.46308+0.00279\ttest-rmse:1.55269+0.00464\n",
      "[1700]\ttrain-rmse:1.45873+0.00273\ttest-rmse:1.55265+0.00468\n",
      "[1800]\ttrain-rmse:1.45446+0.00273\ttest-rmse:1.55260+0.00465\n",
      "[1900]\ttrain-rmse:1.45022+0.00263\ttest-rmse:1.55261+0.00466\n",
      "[2000]\ttrain-rmse:1.44608+0.00257\ttest-rmse:1.55258+0.00465\n",
      "[2100]\ttrain-rmse:1.44200+0.00251\ttest-rmse:1.55260+0.00471\n",
      "[2157]\ttrain-rmse:1.43964+0.00244\ttest-rmse:1.55260+0.00471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:24:37,130] Trial 42 finished with value: 1.5525715850779933 and parameters: {'max_depth': 6, 'min_child_weight': 41.20160012983571, 'subsample': 0.8826626260453874, 'colsample_bytree': 0.2890965809109233, 'reg_lambda': 8.926836823993707, 'reg_alpha': 2.2691790553894635, 'min_split_gain': 1.3228967010821773}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 42: No improvement. Counter = 6, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71284+0.00413\ttest-rmse:1.71293+0.00827\n",
      "[100]\ttrain-rmse:1.60874+0.00286\ttest-rmse:1.61948+0.00691\n",
      "[200]\ttrain-rmse:1.56863+0.00249\ttest-rmse:1.58993+0.00601\n",
      "[300]\ttrain-rmse:1.54560+0.00236\ttest-rmse:1.57666+0.00554\n",
      "[400]\ttrain-rmse:1.52944+0.00225\ttest-rmse:1.56940+0.00529\n",
      "[500]\ttrain-rmse:1.51687+0.00226\ttest-rmse:1.56490+0.00508\n",
      "[600]\ttrain-rmse:1.50613+0.00214\ttest-rmse:1.56183+0.00503\n",
      "[700]\ttrain-rmse:1.49646+0.00214\ttest-rmse:1.55956+0.00494\n",
      "[800]\ttrain-rmse:1.48802+0.00224\ttest-rmse:1.55799+0.00489\n",
      "[900]\ttrain-rmse:1.48046+0.00219\ttest-rmse:1.55683+0.00482\n",
      "[1000]\ttrain-rmse:1.47357+0.00218\ttest-rmse:1.55605+0.00478\n",
      "[1100]\ttrain-rmse:1.46677+0.00213\ttest-rmse:1.55542+0.00475\n",
      "[1200]\ttrain-rmse:1.46040+0.00220\ttest-rmse:1.55490+0.00476\n",
      "[1300]\ttrain-rmse:1.45450+0.00235\ttest-rmse:1.55448+0.00476\n",
      "[1400]\ttrain-rmse:1.44878+0.00249\ttest-rmse:1.55420+0.00476\n",
      "[1500]\ttrain-rmse:1.44323+0.00243\ttest-rmse:1.55400+0.00476\n",
      "[1600]\ttrain-rmse:1.43784+0.00257\ttest-rmse:1.55377+0.00478\n",
      "[1700]\ttrain-rmse:1.43234+0.00262\ttest-rmse:1.55361+0.00478\n",
      "[1800]\ttrain-rmse:1.42723+0.00248\ttest-rmse:1.55352+0.00472\n",
      "[1900]\ttrain-rmse:1.42238+0.00239\ttest-rmse:1.55343+0.00464\n",
      "[2000]\ttrain-rmse:1.41757+0.00237\ttest-rmse:1.55335+0.00461\n",
      "[2100]\ttrain-rmse:1.41300+0.00235\ttest-rmse:1.55330+0.00460\n",
      "[2200]\ttrain-rmse:1.40835+0.00228\ttest-rmse:1.55320+0.00458\n",
      "[2300]\ttrain-rmse:1.40361+0.00231\ttest-rmse:1.55319+0.00456\n",
      "[2400]\ttrain-rmse:1.39903+0.00231\ttest-rmse:1.55320+0.00456\n",
      "[2500]\ttrain-rmse:1.39437+0.00227\ttest-rmse:1.55323+0.00452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:26:11,475] Trial 43 finished with value: 1.5531833749716828 and parameters: {'max_depth': 7, 'min_child_weight': 36.86343623718768, 'subsample': 0.9636151960518603, 'colsample_bytree': 0.07575144956222646, 'reg_lambda': 8.665810944805036, 'reg_alpha': 3.0645275685519544, 'min_split_gain': 2.927006441762956}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 43: No improvement. Counter = 7, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71206+0.00412\ttest-rmse:1.71225+0.00827\n",
      "[100]\ttrain-rmse:1.57918+0.00297\ttest-rmse:1.60007+0.00670\n",
      "[200]\ttrain-rmse:1.53245+0.00259\ttest-rmse:1.57171+0.00590\n",
      "[300]\ttrain-rmse:1.50617+0.00253\ttest-rmse:1.56161+0.00545\n",
      "[400]\ttrain-rmse:1.48856+0.00266\ttest-rmse:1.55745+0.00513\n",
      "[500]\ttrain-rmse:1.47456+0.00273\ttest-rmse:1.55537+0.00499\n",
      "[600]\ttrain-rmse:1.46260+0.00259\ttest-rmse:1.55414+0.00498\n",
      "[700]\ttrain-rmse:1.45186+0.00240\ttest-rmse:1.55351+0.00489\n",
      "[800]\ttrain-rmse:1.44169+0.00241\ttest-rmse:1.55306+0.00483\n",
      "[900]\ttrain-rmse:1.43224+0.00267\ttest-rmse:1.55277+0.00479\n",
      "[1000]\ttrain-rmse:1.42311+0.00271\ttest-rmse:1.55262+0.00481\n",
      "[1100]\ttrain-rmse:1.41425+0.00288\ttest-rmse:1.55255+0.00483\n",
      "[1200]\ttrain-rmse:1.40532+0.00302\ttest-rmse:1.55255+0.00473\n",
      "[1300]\ttrain-rmse:1.39688+0.00309\ttest-rmse:1.55253+0.00470\n",
      "[1336]\ttrain-rmse:1.39386+0.00338\ttest-rmse:1.55256+0.00467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:27:14,556] Trial 44 finished with value: 1.5524933898980435 and parameters: {'max_depth': 8, 'min_child_weight': 43.72747028570302, 'subsample': 0.6359087998077732, 'colsample_bytree': 0.2377688444911666, 'reg_lambda': 9.339066018120368, 'reg_alpha': 4.542826651768341, 'min_split_gain': 2.298323552819297}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 44: No improvement. Counter = 8, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71215+0.00412\ttest-rmse:1.71225+0.00828\n",
      "[100]\ttrain-rmse:1.59386+0.00278\ttest-rmse:1.60288+0.00682\n",
      "[200]\ttrain-rmse:1.55753+0.00241\ttest-rmse:1.57508+0.00602\n",
      "[300]\ttrain-rmse:1.53902+0.00228\ttest-rmse:1.56460+0.00556\n",
      "[400]\ttrain-rmse:1.52667+0.00228\ttest-rmse:1.55984+0.00527\n",
      "[500]\ttrain-rmse:1.51714+0.00216\ttest-rmse:1.55719+0.00515\n",
      "[600]\ttrain-rmse:1.50896+0.00224\ttest-rmse:1.55553+0.00504\n",
      "[700]\ttrain-rmse:1.50190+0.00222\ttest-rmse:1.55459+0.00501\n",
      "[800]\ttrain-rmse:1.49531+0.00241\ttest-rmse:1.55392+0.00494\n",
      "[900]\ttrain-rmse:1.48926+0.00235\ttest-rmse:1.55344+0.00499\n",
      "[1000]\ttrain-rmse:1.48338+0.00223\ttest-rmse:1.55310+0.00498\n",
      "[1100]\ttrain-rmse:1.47779+0.00241\ttest-rmse:1.55293+0.00498\n",
      "[1200]\ttrain-rmse:1.47237+0.00232\ttest-rmse:1.55281+0.00498\n",
      "[1300]\ttrain-rmse:1.46696+0.00226\ttest-rmse:1.55270+0.00501\n",
      "[1400]\ttrain-rmse:1.46167+0.00243\ttest-rmse:1.55263+0.00493\n",
      "[1500]\ttrain-rmse:1.45626+0.00254\ttest-rmse:1.55258+0.00491\n",
      "[1600]\ttrain-rmse:1.45105+0.00253\ttest-rmse:1.55249+0.00487\n",
      "[1700]\ttrain-rmse:1.44579+0.00247\ttest-rmse:1.55246+0.00488\n",
      "[1800]\ttrain-rmse:1.44071+0.00228\ttest-rmse:1.55248+0.00491\n",
      "[1900]\ttrain-rmse:1.43559+0.00229\ttest-rmse:1.55249+0.00494\n",
      "[1903]\ttrain-rmse:1.43542+0.00229\ttest-rmse:1.55249+0.00496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:28:22,192] Trial 45 finished with value: 1.552445544374334 and parameters: {'max_depth': 6, 'min_child_weight': 20.494652951414853, 'subsample': 0.7571315668448116, 'colsample_bytree': 0.43785682433178796, 'reg_lambda': 8.049434258066706, 'reg_alpha': 3.7110979016298833, 'min_split_gain': 1.7078103756032967}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 45: No improvement. Counter = 9, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71163+0.00413\ttest-rmse:1.71209+0.00827\n",
      "[100]\ttrain-rmse:1.56067+0.00286\ttest-rmse:1.60238+0.00676\n",
      "[200]\ttrain-rmse:1.49620+0.00251\ttest-rmse:1.57340+0.00597\n",
      "[300]\ttrain-rmse:1.45731+0.00233\ttest-rmse:1.56329+0.00561\n",
      "[400]\ttrain-rmse:1.43001+0.00239\ttest-rmse:1.55909+0.00542\n",
      "[500]\ttrain-rmse:1.40763+0.00256\ttest-rmse:1.55674+0.00534\n",
      "[600]\ttrain-rmse:1.38861+0.00263\ttest-rmse:1.55557+0.00533\n",
      "[700]\ttrain-rmse:1.37121+0.00227\ttest-rmse:1.55480+0.00522\n",
      "[800]\ttrain-rmse:1.35509+0.00249\ttest-rmse:1.55445+0.00518\n",
      "[900]\ttrain-rmse:1.33962+0.00250\ttest-rmse:1.55421+0.00516\n",
      "[1000]\ttrain-rmse:1.32533+0.00257\ttest-rmse:1.55408+0.00513\n",
      "[1100]\ttrain-rmse:1.31179+0.00275\ttest-rmse:1.55411+0.00512\n",
      "[1200]\ttrain-rmse:1.29824+0.00277\ttest-rmse:1.55428+0.00509\n",
      "[1272]\ttrain-rmse:1.28895+0.00277\ttest-rmse:1.55430+0.00504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:29:43,689] Trial 46 finished with value: 1.5540324392607943 and parameters: {'max_depth': 10, 'min_child_weight': 39.34747152929512, 'subsample': 0.6794643184794574, 'colsample_bytree': 0.12224792010585026, 'reg_lambda': 2.302463463016693, 'reg_alpha': 0.8799054104771692, 'min_split_gain': 0.9077796447434339}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 46: No improvement. Counter = 10, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71213+0.00412\ttest-rmse:1.71226+0.00827\n",
      "[100]\ttrain-rmse:1.58930+0.00291\ttest-rmse:1.60191+0.00672\n",
      "[200]\ttrain-rmse:1.55006+0.00252\ttest-rmse:1.57383+0.00590\n",
      "[300]\ttrain-rmse:1.52995+0.00254\ttest-rmse:1.56357+0.00550\n",
      "[400]\ttrain-rmse:1.51715+0.00256\ttest-rmse:1.55908+0.00527\n",
      "[500]\ttrain-rmse:1.50702+0.00246\ttest-rmse:1.55661+0.00512\n",
      "[600]\ttrain-rmse:1.49857+0.00251\ttest-rmse:1.55513+0.00490\n",
      "[700]\ttrain-rmse:1.49082+0.00233\ttest-rmse:1.55436+0.00484\n",
      "[800]\ttrain-rmse:1.48388+0.00232\ttest-rmse:1.55382+0.00481\n",
      "[900]\ttrain-rmse:1.47727+0.00225\ttest-rmse:1.55339+0.00485\n",
      "[1000]\ttrain-rmse:1.47079+0.00237\ttest-rmse:1.55313+0.00480\n",
      "[1100]\ttrain-rmse:1.46444+0.00241\ttest-rmse:1.55291+0.00483\n",
      "[1200]\ttrain-rmse:1.45819+0.00231\ttest-rmse:1.55283+0.00480\n",
      "[1300]\ttrain-rmse:1.45218+0.00242\ttest-rmse:1.55281+0.00480\n",
      "[1400]\ttrain-rmse:1.44624+0.00245\ttest-rmse:1.55276+0.00483\n",
      "[1500]\ttrain-rmse:1.44008+0.00254\ttest-rmse:1.55276+0.00485\n",
      "[1600]\ttrain-rmse:1.43416+0.00271\ttest-rmse:1.55283+0.00483\n",
      "[1644]\ttrain-rmse:1.43153+0.00266\ttest-rmse:1.55286+0.00483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:30:48,011] Trial 47 finished with value: 1.55274125160635 and parameters: {'max_depth': 7, 'min_child_weight': 32.89629939412624, 'subsample': 0.3605787359448904, 'colsample_bytree': 0.2772163308569434, 'reg_lambda': 9.918586684704426, 'reg_alpha': 1.808518693954937, 'min_split_gain': 0.3425979202007037}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 47: No improvement. Counter = 11, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71216+0.00411\ttest-rmse:1.71226+0.00827\n",
      "[100]\ttrain-rmse:1.59244+0.00272\ttest-rmse:1.60177+0.00673\n",
      "[200]\ttrain-rmse:1.55627+0.00234\ttest-rmse:1.57423+0.00575\n",
      "[300]\ttrain-rmse:1.53773+0.00221\ttest-rmse:1.56407+0.00528\n",
      "[400]\ttrain-rmse:1.52546+0.00207\ttest-rmse:1.55948+0.00507\n",
      "[500]\ttrain-rmse:1.51580+0.00198\ttest-rmse:1.55696+0.00492\n",
      "[600]\ttrain-rmse:1.50765+0.00190\ttest-rmse:1.55547+0.00474\n",
      "[700]\ttrain-rmse:1.50032+0.00175\ttest-rmse:1.55452+0.00472\n",
      "[800]\ttrain-rmse:1.49369+0.00195\ttest-rmse:1.55393+0.00469\n",
      "[900]\ttrain-rmse:1.48725+0.00186\ttest-rmse:1.55352+0.00467\n",
      "[1000]\ttrain-rmse:1.48110+0.00189\ttest-rmse:1.55319+0.00468\n",
      "[1100]\ttrain-rmse:1.47523+0.00192\ttest-rmse:1.55299+0.00465\n",
      "[1200]\ttrain-rmse:1.46934+0.00193\ttest-rmse:1.55292+0.00466\n",
      "[1300]\ttrain-rmse:1.46363+0.00194\ttest-rmse:1.55286+0.00469\n",
      "[1400]\ttrain-rmse:1.45789+0.00201\ttest-rmse:1.55279+0.00468\n",
      "[1500]\ttrain-rmse:1.45216+0.00199\ttest-rmse:1.55277+0.00467\n",
      "[1600]\ttrain-rmse:1.44669+0.00189\ttest-rmse:1.55279+0.00463\n",
      "[1700]\ttrain-rmse:1.44126+0.00189\ttest-rmse:1.55281+0.00462\n",
      "[1769]\ttrain-rmse:1.43762+0.00196\ttest-rmse:1.55284+0.00463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:31:52,650] Trial 48 finished with value: 1.5527618499486016 and parameters: {'max_depth': 6, 'min_child_weight': 14.27434922559334, 'subsample': 0.5668886851761625, 'colsample_bytree': 0.4958498593275241, 'reg_lambda': 0.6977709331772299, 'reg_alpha': 6.448611381657026, 'min_split_gain': 8.395618706471112}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 48: No improvement. Counter = 12, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71188+0.00413\ttest-rmse:1.71219+0.00828\n",
      "[100]\ttrain-rmse:1.56624+0.00282\ttest-rmse:1.59885+0.00686\n",
      "[200]\ttrain-rmse:1.50983+0.00232\ttest-rmse:1.57066+0.00586\n",
      "[300]\ttrain-rmse:1.47539+0.00201\ttest-rmse:1.56078+0.00545\n",
      "[400]\ttrain-rmse:1.45184+0.00207\ttest-rmse:1.55674+0.00524\n",
      "[500]\ttrain-rmse:1.43289+0.00209\ttest-rmse:1.55488+0.00511\n",
      "[600]\ttrain-rmse:1.41599+0.00187\ttest-rmse:1.55393+0.00509\n",
      "[700]\ttrain-rmse:1.40106+0.00186\ttest-rmse:1.55340+0.00510\n",
      "[800]\ttrain-rmse:1.38719+0.00247\ttest-rmse:1.55307+0.00514\n",
      "[900]\ttrain-rmse:1.37386+0.00275\ttest-rmse:1.55294+0.00509\n",
      "[1000]\ttrain-rmse:1.36127+0.00294\ttest-rmse:1.55288+0.00506\n",
      "[1100]\ttrain-rmse:1.34923+0.00279\ttest-rmse:1.55293+0.00505\n",
      "[1200]\ttrain-rmse:1.33715+0.00267\ttest-rmse:1.55301+0.00506\n",
      "[1206]\ttrain-rmse:1.33649+0.00269\ttest-rmse:1.55301+0.00506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:33:01,639] Trial 49 finished with value: 1.5528669447192225 and parameters: {'max_depth': 9, 'min_child_weight': 35.65184942310789, 'subsample': 0.7136242309639447, 'colsample_bytree': 0.2129268211504555, 'reg_lambda': 6.398548469747918, 'reg_alpha': 5.352158633709981, 'min_split_gain': 3.075402436613869}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 49: No improvement. Counter = 13, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71239+0.00412\ttest-rmse:1.71242+0.00828\n",
      "[100]\ttrain-rmse:1.60578+0.00289\ttest-rmse:1.61014+0.00687\n",
      "[200]\ttrain-rmse:1.57387+0.00256\ttest-rmse:1.58241+0.00611\n",
      "[300]\ttrain-rmse:1.55821+0.00243\ttest-rmse:1.57085+0.00559\n",
      "[400]\ttrain-rmse:1.54842+0.00241\ttest-rmse:1.56493+0.00526\n",
      "[500]\ttrain-rmse:1.54119+0.00232\ttest-rmse:1.56142+0.00511\n",
      "[600]\ttrain-rmse:1.53531+0.00228\ttest-rmse:1.55904+0.00499\n",
      "[700]\ttrain-rmse:1.53039+0.00221\ttest-rmse:1.55748+0.00498\n",
      "[800]\ttrain-rmse:1.52599+0.00237\ttest-rmse:1.55636+0.00492\n",
      "[900]\ttrain-rmse:1.52201+0.00236\ttest-rmse:1.55550+0.00491\n",
      "[1000]\ttrain-rmse:1.51827+0.00237\ttest-rmse:1.55488+0.00486\n",
      "[1100]\ttrain-rmse:1.51481+0.00234\ttest-rmse:1.55445+0.00488\n",
      "[1200]\ttrain-rmse:1.51141+0.00233\ttest-rmse:1.55409+0.00486\n",
      "[1300]\ttrain-rmse:1.50812+0.00233\ttest-rmse:1.55375+0.00488\n",
      "[1400]\ttrain-rmse:1.50486+0.00235\ttest-rmse:1.55355+0.00488\n",
      "[1500]\ttrain-rmse:1.50162+0.00236\ttest-rmse:1.55335+0.00488\n",
      "[1600]\ttrain-rmse:1.49852+0.00239\ttest-rmse:1.55315+0.00481\n",
      "[1700]\ttrain-rmse:1.49540+0.00237\ttest-rmse:1.55301+0.00482\n",
      "[1800]\ttrain-rmse:1.49245+0.00237\ttest-rmse:1.55292+0.00481\n",
      "[1900]\ttrain-rmse:1.48948+0.00238\ttest-rmse:1.55282+0.00485\n",
      "[2000]\ttrain-rmse:1.48650+0.00231\ttest-rmse:1.55277+0.00486\n",
      "[2100]\ttrain-rmse:1.48349+0.00231\ttest-rmse:1.55271+0.00488\n",
      "[2200]\ttrain-rmse:1.48050+0.00227\ttest-rmse:1.55266+0.00487\n",
      "[2300]\ttrain-rmse:1.47763+0.00227\ttest-rmse:1.55266+0.00487\n",
      "[2400]\ttrain-rmse:1.47476+0.00222\ttest-rmse:1.55264+0.00488\n",
      "[2500]\ttrain-rmse:1.47186+0.00212\ttest-rmse:1.55263+0.00490\n",
      "[2600]\ttrain-rmse:1.46902+0.00215\ttest-rmse:1.55262+0.00491\n",
      "[2700]\ttrain-rmse:1.46624+0.00215\ttest-rmse:1.55264+0.00493\n",
      "[2736]\ttrain-rmse:1.46519+0.00214\ttest-rmse:1.55266+0.00493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:34:25,553] Trial 50 finished with value: 1.552616305324098 and parameters: {'max_depth': 5, 'min_child_weight': 30.051660017179405, 'subsample': 0.6507211493567899, 'colsample_bytree': 0.3722877452420791, 'reg_lambda': 9.029801594983097, 'reg_alpha': 7.61533767305511, 'min_split_gain': 2.612465344263435}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 50: No improvement. Counter = 14, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71207+0.00413\ttest-rmse:1.71221+0.00827\n",
      "[100]\ttrain-rmse:1.58450+0.00281\ttest-rmse:1.60003+0.00676\n",
      "[200]\ttrain-rmse:1.54278+0.00224\ttest-rmse:1.57228+0.00599\n",
      "[300]\ttrain-rmse:1.52024+0.00228\ttest-rmse:1.56228+0.00537\n",
      "[400]\ttrain-rmse:1.50490+0.00227\ttest-rmse:1.55796+0.00510\n",
      "[500]\ttrain-rmse:1.49306+0.00216\ttest-rmse:1.55566+0.00491\n",
      "[600]\ttrain-rmse:1.48280+0.00199\ttest-rmse:1.55431+0.00481\n",
      "[700]\ttrain-rmse:1.47418+0.00196\ttest-rmse:1.55359+0.00478\n",
      "[800]\ttrain-rmse:1.46621+0.00209\ttest-rmse:1.55304+0.00470\n",
      "[900]\ttrain-rmse:1.45868+0.00219\ttest-rmse:1.55277+0.00462\n",
      "[1000]\ttrain-rmse:1.45133+0.00197\ttest-rmse:1.55250+0.00460\n",
      "[1100]\ttrain-rmse:1.44437+0.00218\ttest-rmse:1.55241+0.00457\n",
      "[1200]\ttrain-rmse:1.43748+0.00215\ttest-rmse:1.55241+0.00454\n",
      "[1300]\ttrain-rmse:1.43091+0.00205\ttest-rmse:1.55241+0.00454\n",
      "[1342]\ttrain-rmse:1.42823+0.00205\ttest-rmse:1.55242+0.00453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:35:19,907] Trial 51 finished with value: 1.5523660000072284 and parameters: {'max_depth': 7, 'min_child_weight': 38.253688345170964, 'subsample': 0.7754381535035781, 'colsample_bytree': 0.3222302720109352, 'reg_lambda': 7.582707356072615, 'reg_alpha': 1.7901974455620602, 'min_split_gain': 1.7222274747214183}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 51: No improvement. Counter = 15, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71189+0.00413\ttest-rmse:1.71214+0.00826\n",
      "[100]\ttrain-rmse:1.57121+0.00294\ttest-rmse:1.59673+0.00658\n",
      "[200]\ttrain-rmse:1.52187+0.00226\ttest-rmse:1.56958+0.00585\n",
      "[300]\ttrain-rmse:1.49375+0.00221\ttest-rmse:1.56035+0.00544\n",
      "[400]\ttrain-rmse:1.47421+0.00236\ttest-rmse:1.55658+0.00512\n",
      "[500]\ttrain-rmse:1.45928+0.00236\ttest-rmse:1.55478+0.00489\n",
      "[600]\ttrain-rmse:1.44635+0.00219\ttest-rmse:1.55377+0.00478\n",
      "[700]\ttrain-rmse:1.43551+0.00215\ttest-rmse:1.55327+0.00469\n",
      "[800]\ttrain-rmse:1.42555+0.00218\ttest-rmse:1.55291+0.00464\n",
      "[900]\ttrain-rmse:1.41616+0.00231\ttest-rmse:1.55269+0.00460\n",
      "[1000]\ttrain-rmse:1.40680+0.00256\ttest-rmse:1.55254+0.00449\n",
      "[1100]\ttrain-rmse:1.39791+0.00267\ttest-rmse:1.55249+0.00448\n",
      "[1200]\ttrain-rmse:1.38879+0.00295\ttest-rmse:1.55253+0.00447\n",
      "[1300]\ttrain-rmse:1.38024+0.00256\ttest-rmse:1.55254+0.00442\n",
      "[1312]\ttrain-rmse:1.37927+0.00260\ttest-rmse:1.55256+0.00443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:36:23,490] Trial 52 finished with value: 1.552470045074765 and parameters: {'max_depth': 8, 'min_child_weight': 43.11596845310388, 'subsample': 0.8601310284586887, 'colsample_bytree': 0.307073944411299, 'reg_lambda': 8.52653985204765, 'reg_alpha': 1.333818194628209, 'min_split_gain': 2.082718645460214}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 52: No improvement. Counter = 16, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71197+0.00412\ttest-rmse:1.71215+0.00828\n",
      "[100]\ttrain-rmse:1.58171+0.00282\ttest-rmse:1.59802+0.00669\n",
      "[200]\ttrain-rmse:1.53955+0.00211\ttest-rmse:1.57068+0.00595\n",
      "[300]\ttrain-rmse:1.51722+0.00208\ttest-rmse:1.56120+0.00539\n",
      "[400]\ttrain-rmse:1.50207+0.00221\ttest-rmse:1.55725+0.00518\n",
      "[500]\ttrain-rmse:1.49031+0.00214\ttest-rmse:1.55516+0.00496\n",
      "[600]\ttrain-rmse:1.48058+0.00206\ttest-rmse:1.55396+0.00484\n",
      "[700]\ttrain-rmse:1.47211+0.00228\ttest-rmse:1.55330+0.00479\n",
      "[800]\ttrain-rmse:1.46426+0.00237\ttest-rmse:1.55288+0.00470\n",
      "[900]\ttrain-rmse:1.45684+0.00237\ttest-rmse:1.55266+0.00464\n",
      "[1000]\ttrain-rmse:1.44958+0.00229\ttest-rmse:1.55250+0.00453\n",
      "[1100]\ttrain-rmse:1.44270+0.00259\ttest-rmse:1.55240+0.00447\n",
      "[1200]\ttrain-rmse:1.43592+0.00250\ttest-rmse:1.55241+0.00443\n",
      "[1300]\ttrain-rmse:1.42919+0.00231\ttest-rmse:1.55242+0.00436\n",
      "[1354]\ttrain-rmse:1.42557+0.00218\ttest-rmse:1.55240+0.00434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:37:19,615] Trial 53 finished with value: 1.5523826285601097 and parameters: {'max_depth': 7, 'min_child_weight': 40.50976478797267, 'subsample': 0.789686448716283, 'colsample_bytree': 0.41407879598560154, 'reg_lambda': 7.260380243164761, 'reg_alpha': 0.48601546963276854, 'min_split_gain': 1.129832688850405}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 53: No improvement. Counter = 17, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71227+0.00412\ttest-rmse:1.71235+0.00827\n",
      "[100]\ttrain-rmse:1.59799+0.00290\ttest-rmse:1.60609+0.00685\n",
      "[200]\ttrain-rmse:1.56212+0.00258\ttest-rmse:1.57787+0.00613\n",
      "[300]\ttrain-rmse:1.54360+0.00258\ttest-rmse:1.56659+0.00562\n",
      "[400]\ttrain-rmse:1.53165+0.00252\ttest-rmse:1.56119+0.00537\n",
      "[500]\ttrain-rmse:1.52263+0.00261\ttest-rmse:1.55819+0.00515\n",
      "[600]\ttrain-rmse:1.51500+0.00246\ttest-rmse:1.55629+0.00512\n",
      "[700]\ttrain-rmse:1.50852+0.00243\ttest-rmse:1.55515+0.00505\n",
      "[800]\ttrain-rmse:1.50263+0.00257\ttest-rmse:1.55433+0.00503\n",
      "[900]\ttrain-rmse:1.49722+0.00252\ttest-rmse:1.55372+0.00498\n",
      "[1000]\ttrain-rmse:1.49216+0.00264\ttest-rmse:1.55334+0.00492\n",
      "[1100]\ttrain-rmse:1.48734+0.00265\ttest-rmse:1.55304+0.00497\n",
      "[1200]\ttrain-rmse:1.48260+0.00258\ttest-rmse:1.55285+0.00495\n",
      "[1300]\ttrain-rmse:1.47809+0.00260\ttest-rmse:1.55269+0.00498\n",
      "[1400]\ttrain-rmse:1.47351+0.00276\ttest-rmse:1.55255+0.00494\n",
      "[1500]\ttrain-rmse:1.46895+0.00286\ttest-rmse:1.55244+0.00493\n",
      "[1600]\ttrain-rmse:1.46464+0.00292\ttest-rmse:1.55240+0.00490\n",
      "[1700]\ttrain-rmse:1.46025+0.00286\ttest-rmse:1.55236+0.00493\n",
      "[1800]\ttrain-rmse:1.45592+0.00273\ttest-rmse:1.55235+0.00488\n",
      "[1900]\ttrain-rmse:1.45157+0.00261\ttest-rmse:1.55230+0.00490\n",
      "[2000]\ttrain-rmse:1.44729+0.00243\ttest-rmse:1.55229+0.00486\n",
      "[2100]\ttrain-rmse:1.44316+0.00238\ttest-rmse:1.55234+0.00488\n",
      "[2193]\ttrain-rmse:1.43912+0.00239\ttest-rmse:1.55234+0.00491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:38:33,286] Trial 54 finished with value: 1.5522805842007286 and parameters: {'max_depth': 6, 'min_child_weight': 38.07640586638926, 'subsample': 0.713731532081471, 'colsample_bytree': 0.2546017899988036, 'reg_lambda': 7.872116895680317, 'reg_alpha': 2.544908658210492, 'min_split_gain': 3.405328416880643}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 54: No improvement. Counter = 18, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71295+0.00413\ttest-rmse:1.71299+0.00827\n",
      "[100]\ttrain-rmse:1.61689+0.00293\ttest-rmse:1.62288+0.00693\n",
      "[200]\ttrain-rmse:1.58197+0.00262\ttest-rmse:1.59386+0.00598\n",
      "[300]\ttrain-rmse:1.56284+0.00248\ttest-rmse:1.58040+0.00550\n",
      "[400]\ttrain-rmse:1.54986+0.00252\ttest-rmse:1.57271+0.00523\n",
      "[500]\ttrain-rmse:1.54014+0.00249\ttest-rmse:1.56777+0.00506\n",
      "[600]\ttrain-rmse:1.53216+0.00243\ttest-rmse:1.56435+0.00495\n",
      "[700]\ttrain-rmse:1.52501+0.00243\ttest-rmse:1.56183+0.00483\n",
      "[800]\ttrain-rmse:1.51885+0.00242\ttest-rmse:1.55995+0.00478\n",
      "[900]\ttrain-rmse:1.51336+0.00244\ttest-rmse:1.55864+0.00469\n",
      "[1000]\ttrain-rmse:1.50838+0.00244\ttest-rmse:1.55756+0.00469\n",
      "[1100]\ttrain-rmse:1.50362+0.00232\ttest-rmse:1.55671+0.00468\n",
      "[1200]\ttrain-rmse:1.49914+0.00227\ttest-rmse:1.55610+0.00466\n",
      "[1300]\ttrain-rmse:1.49496+0.00238\ttest-rmse:1.55555+0.00463\n",
      "[1400]\ttrain-rmse:1.49083+0.00241\ttest-rmse:1.55512+0.00464\n",
      "[1500]\ttrain-rmse:1.48697+0.00240\ttest-rmse:1.55484+0.00463\n",
      "[1600]\ttrain-rmse:1.48312+0.00245\ttest-rmse:1.55455+0.00463\n",
      "[1700]\ttrain-rmse:1.47917+0.00245\ttest-rmse:1.55425+0.00458\n",
      "[1800]\ttrain-rmse:1.47557+0.00242\ttest-rmse:1.55410+0.00455\n",
      "[1900]\ttrain-rmse:1.47183+0.00242\ttest-rmse:1.55392+0.00455\n",
      "[2000]\ttrain-rmse:1.46832+0.00244\ttest-rmse:1.55380+0.00452\n",
      "[2100]\ttrain-rmse:1.46486+0.00246\ttest-rmse:1.55366+0.00452\n",
      "[2200]\ttrain-rmse:1.46136+0.00245\ttest-rmse:1.55352+0.00449\n",
      "[2300]\ttrain-rmse:1.45798+0.00247\ttest-rmse:1.55346+0.00447\n",
      "[2400]\ttrain-rmse:1.45457+0.00237\ttest-rmse:1.55340+0.00447\n",
      "[2500]\ttrain-rmse:1.45114+0.00235\ttest-rmse:1.55335+0.00449\n",
      "[2600]\ttrain-rmse:1.44787+0.00244\ttest-rmse:1.55336+0.00452\n",
      "[2700]\ttrain-rmse:1.44464+0.00244\ttest-rmse:1.55330+0.00452\n",
      "[2800]\ttrain-rmse:1.44140+0.00237\ttest-rmse:1.55326+0.00449\n",
      "[2900]\ttrain-rmse:1.43816+0.00234\ttest-rmse:1.55325+0.00446\n",
      "[3000]\ttrain-rmse:1.43497+0.00228\ttest-rmse:1.55328+0.00448\n",
      "[3053]\ttrain-rmse:1.43335+0.00229\ttest-rmse:1.55328+0.00448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:40:14,260] Trial 55 finished with value: 1.5532283518654835 and parameters: {'max_depth': 6, 'min_child_weight': 32.189476162580114, 'subsample': 0.7170055746926882, 'colsample_bytree': 0.07456621593079552, 'reg_lambda': 8.053151896391832, 'reg_alpha': 2.517747022174963, 'min_split_gain': 3.5866868690453737}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 55: No improvement. Counter = 19, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71218+0.00411\ttest-rmse:1.71228+0.00827\n",
      "[100]\ttrain-rmse:1.59300+0.00292\ttest-rmse:1.60172+0.00675\n",
      "[200]\ttrain-rmse:1.55730+0.00262\ttest-rmse:1.57393+0.00593\n",
      "[300]\ttrain-rmse:1.53977+0.00247\ttest-rmse:1.56386+0.00541\n",
      "[400]\ttrain-rmse:1.52866+0.00248\ttest-rmse:1.55935+0.00513\n",
      "[500]\ttrain-rmse:1.52007+0.00246\ttest-rmse:1.55683+0.00496\n",
      "[600]\ttrain-rmse:1.51292+0.00247\ttest-rmse:1.55535+0.00488\n",
      "[700]\ttrain-rmse:1.50630+0.00240\ttest-rmse:1.55440+0.00486\n",
      "[800]\ttrain-rmse:1.50043+0.00248\ttest-rmse:1.55381+0.00477\n",
      "[900]\ttrain-rmse:1.49479+0.00251\ttest-rmse:1.55333+0.00472\n",
      "[1000]\ttrain-rmse:1.48939+0.00261\ttest-rmse:1.55298+0.00475\n",
      "[1100]\ttrain-rmse:1.48424+0.00260\ttest-rmse:1.55282+0.00478\n",
      "[1200]\ttrain-rmse:1.47911+0.00268\ttest-rmse:1.55272+0.00480\n",
      "[1300]\ttrain-rmse:1.47412+0.00264\ttest-rmse:1.55264+0.00485\n",
      "[1400]\ttrain-rmse:1.46913+0.00263\ttest-rmse:1.55262+0.00488\n",
      "[1500]\ttrain-rmse:1.46423+0.00275\ttest-rmse:1.55263+0.00485\n",
      "[1600]\ttrain-rmse:1.45930+0.00276\ttest-rmse:1.55260+0.00480\n",
      "[1665]\ttrain-rmse:1.45613+0.00280\ttest-rmse:1.55259+0.00478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:41:14,411] Trial 56 finished with value: 1.5525622340726963 and parameters: {'max_depth': 6, 'min_child_weight': 34.216432368835896, 'subsample': 0.5084636134317624, 'colsample_bytree': 0.5639529034859379, 'reg_lambda': 9.631667879712339, 'reg_alpha': 3.128651881022757, 'min_split_gain': 3.455992723540622}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 56: No improvement. Counter = 20, Best Score = 1.55206\n",
      "[0]\ttrain-rmse:1.71269+0.00413\ttest-rmse:1.71271+0.00827\n",
      "[100]\ttrain-rmse:1.61766+0.00295\ttest-rmse:1.61971+0.00706\n",
      "[200]\ttrain-rmse:1.58853+0.00268\ttest-rmse:1.59264+0.00646\n",
      "[300]\ttrain-rmse:1.57399+0.00261\ttest-rmse:1.58024+0.00589\n",
      "[400]\ttrain-rmse:1.56496+0.00254\ttest-rmse:1.57322+0.00560\n",
      "[500]\ttrain-rmse:1.55846+0.00249\ttest-rmse:1.56863+0.00536\n",
      "[600]\ttrain-rmse:1.55327+0.00251\ttest-rmse:1.56531+0.00518\n",
      "[700]\ttrain-rmse:1.54913+0.00248\ttest-rmse:1.56300+0.00501\n",
      "[800]\ttrain-rmse:1.54556+0.00257\ttest-rmse:1.56118+0.00490\n",
      "[900]\ttrain-rmse:1.54247+0.00250\ttest-rmse:1.55974+0.00486\n",
      "[1000]\ttrain-rmse:1.53969+0.00251\ttest-rmse:1.55865+0.00480\n",
      "[1100]\ttrain-rmse:1.53717+0.00251\ttest-rmse:1.55783+0.00478\n",
      "[1200]\ttrain-rmse:1.53490+0.00251\ttest-rmse:1.55719+0.00474\n",
      "[1300]\ttrain-rmse:1.53275+0.00252\ttest-rmse:1.55664+0.00474\n",
      "[1400]\ttrain-rmse:1.53064+0.00255\ttest-rmse:1.55617+0.00472\n",
      "[1500]\ttrain-rmse:1.52863+0.00250\ttest-rmse:1.55578+0.00473\n",
      "[1600]\ttrain-rmse:1.52672+0.00250\ttest-rmse:1.55545+0.00471\n",
      "[1700]\ttrain-rmse:1.52483+0.00249\ttest-rmse:1.55518+0.00472\n",
      "[1800]\ttrain-rmse:1.52304+0.00248\ttest-rmse:1.55494+0.00470\n",
      "[1900]\ttrain-rmse:1.52127+0.00246\ttest-rmse:1.55471+0.00469\n",
      "[2000]\ttrain-rmse:1.51952+0.00246\ttest-rmse:1.55453+0.00467\n",
      "[2100]\ttrain-rmse:1.51781+0.00246\ttest-rmse:1.55439+0.00469\n",
      "[2200]\ttrain-rmse:1.51613+0.00245\ttest-rmse:1.55424+0.00472\n",
      "[2300]\ttrain-rmse:1.51445+0.00246\ttest-rmse:1.55411+0.00472\n",
      "[2400]\ttrain-rmse:1.51281+0.00245\ttest-rmse:1.55400+0.00472\n",
      "[2500]\ttrain-rmse:1.51113+0.00243\ttest-rmse:1.55387+0.00472\n",
      "[2600]\ttrain-rmse:1.50947+0.00244\ttest-rmse:1.55383+0.00474\n",
      "[2700]\ttrain-rmse:1.50783+0.00240\ttest-rmse:1.55377+0.00474\n",
      "[2800]\ttrain-rmse:1.50625+0.00240\ttest-rmse:1.55372+0.00473\n",
      "[2900]\ttrain-rmse:1.50470+0.00238\ttest-rmse:1.55363+0.00473\n",
      "[3000]\ttrain-rmse:1.50314+0.00236\ttest-rmse:1.55358+0.00476\n",
      "[3100]\ttrain-rmse:1.50158+0.00234\ttest-rmse:1.55353+0.00474\n",
      "[3200]\ttrain-rmse:1.50001+0.00234\ttest-rmse:1.55349+0.00476\n",
      "[3300]\ttrain-rmse:1.49847+0.00232\ttest-rmse:1.55345+0.00475\n",
      "[3400]\ttrain-rmse:1.49693+0.00232\ttest-rmse:1.55344+0.00475\n",
      "[3500]\ttrain-rmse:1.49542+0.00232\ttest-rmse:1.55341+0.00476\n",
      "[3600]\ttrain-rmse:1.49390+0.00230\ttest-rmse:1.55339+0.00476\n",
      "[3700]\ttrain-rmse:1.49241+0.00225\ttest-rmse:1.55340+0.00476\n",
      "[3800]\ttrain-rmse:1.49090+0.00225\ttest-rmse:1.55339+0.00475\n",
      "[3900]\ttrain-rmse:1.48938+0.00225\ttest-rmse:1.55337+0.00473\n",
      "[4000]\ttrain-rmse:1.48790+0.00224\ttest-rmse:1.55337+0.00472\n",
      "[4100]\ttrain-rmse:1.48642+0.00220\ttest-rmse:1.55338+0.00476\n",
      "[4138]\ttrain-rmse:1.48588+0.00220\ttest-rmse:1.55340+0.00477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:43:06,003] Trial 57 finished with value: 1.553344655828419 and parameters: {'max_depth': 4, 'min_child_weight': 29.026719766599435, 'subsample': 0.6740140463194438, 'colsample_bytree': 0.26586273521038717, 'reg_lambda': 9.081855327372333, 'reg_alpha': 3.739693471475238, 'min_split_gain': 4.002283408481057}. Best is trial 36 with value: 1.5520636386618045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 57: No improvement. Counter = 21, Best Score = 1.55206\n",
      " Early stopping threshold reached. Terminating optimization.\n",
      " Early stopping triggered for XGBoost optimization.\n",
      "\n",
      " Best hyperparameters for XGBoost:\n",
      "    max_depth: 7\n",
      "    min_child_weight: 38.18414290403634\n",
      "    subsample: 0.6486182004695331\n",
      "    colsample_bytree: 0.26466558766149234\n",
      "    reg_lambda: 9.477892847589064\n",
      "    reg_alpha: 2.178769479196936\n",
      "    min_split_gain: 1.1558812717327778\n"
     ]
    }
   ],
   "source": [
    "# === MODEL 6 - PART 2: XGBOOST TUNING EXECUTION (with logging and early stopping counter) ===\n",
    "\n",
    "class XGB_EarlyStoppingExceeded(optuna.exceptions.OptunaError):\n",
    "    early_stop = 20\n",
    "    early_stop_count = 0\n",
    "    best_score = None\n",
    "\n",
    "def xgb_early_stopping_opt(study, trial):\n",
    "    current_score = study.best_value\n",
    "\n",
    "    if XGB_EarlyStoppingExceeded.best_score is None:\n",
    "        XGB_EarlyStoppingExceeded.best_score = current_score\n",
    "        print(f\" Trial {trial.number}: Initial best score set to {current_score:.5f}\")\n",
    "        return\n",
    "\n",
    "    if current_score < XGB_EarlyStoppingExceeded.best_score:\n",
    "        print(f\" Trial {trial.number}: Improved score: {current_score:.5f} (Previous best: {XGB_EarlyStoppingExceeded.best_score:.5f})\")\n",
    "        XGB_EarlyStoppingExceeded.best_score = current_score\n",
    "        XGB_EarlyStoppingExceeded.early_stop_count = 0\n",
    "    else:\n",
    "        XGB_EarlyStoppingExceeded.early_stop_count += 1\n",
    "        print(f\" Trial {trial.number}: No improvement. Counter = {XGB_EarlyStoppingExceeded.early_stop_count}, Best Score = {XGB_EarlyStoppingExceeded.best_score:.5f}\")\n",
    "        if XGB_EarlyStoppingExceeded.early_stop_count > XGB_EarlyStoppingExceeded.early_stop:\n",
    "            print(\" Early stopping threshold reached. Terminating optimization.\")\n",
    "            raise XGB_EarlyStoppingExceeded()\n",
    "\n",
    "# === Run the Optuna Study for XGBoost ===\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "try:\n",
    "    xgb_study.optimize(xgb_objective, n_trials=100, callbacks=[xgb_early_stopping_opt])\n",
    "except XGB_EarlyStoppingExceeded:\n",
    "    print(\" Early stopping triggered for XGBoost optimization.\")\n",
    "\n",
    "# === Log Best Parameters ===\n",
    "print(\"\\n Best hyperparameters for XGBoost:\")\n",
    "for k, v in xgb_study.best_trial.params.items():\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ab9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle  # for saving the model\n",
    "\n",
    "def xgb_train_and_predict(best_params, n_splits, X_train, y_train, test, num_round=10000):\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    pred_y_train = np.zeros(len(X_train))\n",
    "    pred_y_test = np.zeros(len(test))\n",
    "    final_model = None\n",
    "\n",
    "    for fold_, (train_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "        print(f\" XGBoost Fold {fold_ + 1}\")\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest = xgb.DMatrix(test)\n",
    "\n",
    "        model = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_round,\n",
    "            evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "            early_stopping_rounds=150,\n",
    "            verbose_eval=200\n",
    "        )\n",
    "\n",
    "        final_model = model  # Save the last fold's model (or modify logic to save best fold)\n",
    "        val_preds = model.predict(dval, iteration_range=(0, model.best_iteration + 1))\n",
    "        pred_y_train[val_idx] = val_preds\n",
    "        pred_y_test += model.predict(dtest, iteration_range=(0, model.best_iteration + 1)) / folds.n_splits\n",
    "\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_train, pred_y_train))\n",
    "    print(f\"\\n Overall Validation RMSE (XGBoost): {val_rmse:.5f}\")\n",
    "    return pred_y_test, val_rmse, final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c5771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGBoost Fold 1\n",
      "[0]\ttrain-rmse:1.71421\tvalid-rmse:1.69447\n",
      "[200]\ttrain-rmse:1.55186\tvalid-rmse:1.55727\n",
      "[400]\ttrain-rmse:1.51973\tvalid-rmse:1.54374\n",
      "[600]\ttrain-rmse:1.50139\tvalid-rmse:1.54021\n",
      "[800]\ttrain-rmse:1.48753\tvalid-rmse:1.53846\n",
      "[1000]\ttrain-rmse:1.47541\tvalid-rmse:1.53796\n",
      "[1200]\ttrain-rmse:1.46434\tvalid-rmse:1.53741\n",
      "[1400]\ttrain-rmse:1.45375\tvalid-rmse:1.53730\n",
      "[1600]\ttrain-rmse:1.44336\tvalid-rmse:1.53689\n",
      "[1800]\ttrain-rmse:1.43330\tvalid-rmse:1.53691\n",
      "[1824]\ttrain-rmse:1.43215\tvalid-rmse:1.53691\n",
      " XGBoost Fold 2\n",
      "[0]\ttrain-rmse:1.70979\tvalid-rmse:1.73077\n",
      "[200]\ttrain-rmse:1.54851\tvalid-rmse:1.58746\n",
      "[400]\ttrain-rmse:1.51627\tvalid-rmse:1.57316\n",
      "[600]\ttrain-rmse:1.49760\tvalid-rmse:1.56955\n",
      "[800]\ttrain-rmse:1.48399\tvalid-rmse:1.56827\n",
      "[1000]\ttrain-rmse:1.47185\tvalid-rmse:1.56785\n",
      "[1200]\ttrain-rmse:1.46096\tvalid-rmse:1.56755\n",
      "[1400]\ttrain-rmse:1.45016\tvalid-rmse:1.56753\n",
      "[1493]\ttrain-rmse:1.44535\tvalid-rmse:1.56764\n",
      " XGBoost Fold 3\n",
      "[0]\ttrain-rmse:1.71115\tvalid-rmse:1.71991\n",
      "[200]\ttrain-rmse:1.55078\tvalid-rmse:1.57259\n",
      "[400]\ttrain-rmse:1.51880\tvalid-rmse:1.55675\n",
      "[600]\ttrain-rmse:1.50024\tvalid-rmse:1.55250\n",
      "[800]\ttrain-rmse:1.48701\tvalid-rmse:1.55084\n",
      "[1000]\ttrain-rmse:1.47484\tvalid-rmse:1.54989\n",
      "[1200]\ttrain-rmse:1.46369\tvalid-rmse:1.54943\n",
      "[1400]\ttrain-rmse:1.45287\tvalid-rmse:1.54928\n",
      "[1600]\ttrain-rmse:1.44228\tvalid-rmse:1.54905\n",
      "[1800]\ttrain-rmse:1.43224\tvalid-rmse:1.54881\n",
      "[1951]\ttrain-rmse:1.42422\tvalid-rmse:1.54889\n",
      " XGBoost Fold 4\n",
      "[0]\ttrain-rmse:1.71534\tvalid-rmse:1.68535\n",
      "[200]\ttrain-rmse:1.55261\tvalid-rmse:1.55247\n",
      "[400]\ttrain-rmse:1.52012\tvalid-rmse:1.53999\n",
      "[600]\ttrain-rmse:1.50163\tvalid-rmse:1.53675\n",
      "[800]\ttrain-rmse:1.48762\tvalid-rmse:1.53547\n",
      "[1000]\ttrain-rmse:1.47545\tvalid-rmse:1.53474\n",
      "[1200]\ttrain-rmse:1.46433\tvalid-rmse:1.53447\n",
      "[1296]\ttrain-rmse:1.45898\tvalid-rmse:1.53452\n",
      " XGBoost Fold 5\n",
      "[0]\ttrain-rmse:1.71364\tvalid-rmse:1.69912\n",
      "[200]\ttrain-rmse:1.55203\tvalid-rmse:1.55964\n",
      "[400]\ttrain-rmse:1.51978\tvalid-rmse:1.54482\n",
      "[600]\ttrain-rmse:1.50134\tvalid-rmse:1.54089\n",
      "[800]\ttrain-rmse:1.48745\tvalid-rmse:1.53914\n",
      "[1000]\ttrain-rmse:1.47578\tvalid-rmse:1.53856\n",
      "[1200]\ttrain-rmse:1.46485\tvalid-rmse:1.53828\n",
      "[1400]\ttrain-rmse:1.45382\tvalid-rmse:1.53833\n",
      "[1406]\ttrain-rmse:1.45348\tvalid-rmse:1.53837\n",
      " XGBoost Fold 6\n",
      "[0]\ttrain-rmse:1.71256\tvalid-rmse:1.70808\n",
      "[200]\ttrain-rmse:1.55042\tvalid-rmse:1.57087\n",
      "[400]\ttrain-rmse:1.51831\tvalid-rmse:1.55705\n",
      "[600]\ttrain-rmse:1.50022\tvalid-rmse:1.55349\n",
      "[800]\ttrain-rmse:1.48643\tvalid-rmse:1.55189\n",
      "[1000]\ttrain-rmse:1.47459\tvalid-rmse:1.55098\n",
      "[1200]\ttrain-rmse:1.46354\tvalid-rmse:1.55050\n",
      "[1400]\ttrain-rmse:1.45270\tvalid-rmse:1.55026\n",
      "[1598]\ttrain-rmse:1.44203\tvalid-rmse:1.55027\n",
      " XGBoost Fold 7\n",
      "[0]\ttrain-rmse:1.70986\tvalid-rmse:1.73008\n",
      "[200]\ttrain-rmse:1.54875\tvalid-rmse:1.58778\n",
      "[400]\ttrain-rmse:1.51677\tvalid-rmse:1.57303\n",
      "[600]\ttrain-rmse:1.49808\tvalid-rmse:1.56899\n",
      "[800]\ttrain-rmse:1.48424\tvalid-rmse:1.56756\n",
      "[1000]\ttrain-rmse:1.47228\tvalid-rmse:1.56723\n",
      "[1200]\ttrain-rmse:1.46113\tvalid-rmse:1.56685\n",
      "[1400]\ttrain-rmse:1.45018\tvalid-rmse:1.56654\n",
      "[1534]\ttrain-rmse:1.44273\tvalid-rmse:1.56657\n",
      " XGBoost Fold 8\n",
      "[0]\ttrain-rmse:1.70941\tvalid-rmse:1.73323\n",
      "[200]\ttrain-rmse:1.54827\tvalid-rmse:1.59601\n",
      "[400]\ttrain-rmse:1.51612\tvalid-rmse:1.58092\n",
      "[600]\ttrain-rmse:1.49776\tvalid-rmse:1.57613\n",
      "[800]\ttrain-rmse:1.48389\tvalid-rmse:1.57391\n",
      "[1000]\ttrain-rmse:1.47192\tvalid-rmse:1.57296\n",
      "[1200]\ttrain-rmse:1.46102\tvalid-rmse:1.57237\n",
      "[1400]\ttrain-rmse:1.45025\tvalid-rmse:1.57222\n",
      "[1600]\ttrain-rmse:1.43953\tvalid-rmse:1.57206\n",
      "[1674]\ttrain-rmse:1.43557\tvalid-rmse:1.57217\n",
      " XGBoost Fold 9\n",
      "[0]\ttrain-rmse:1.71256\tvalid-rmse:1.70808\n",
      "[200]\ttrain-rmse:1.55139\tvalid-rmse:1.56510\n",
      "[400]\ttrain-rmse:1.51926\tvalid-rmse:1.55065\n",
      "[600]\ttrain-rmse:1.50047\tvalid-rmse:1.54677\n",
      "[800]\ttrain-rmse:1.48649\tvalid-rmse:1.54553\n",
      "[1000]\ttrain-rmse:1.47375\tvalid-rmse:1.54479\n",
      "[1200]\ttrain-rmse:1.46257\tvalid-rmse:1.54468\n",
      "[1400]\ttrain-rmse:1.45160\tvalid-rmse:1.54449\n",
      "[1551]\ttrain-rmse:1.44353\tvalid-rmse:1.54456\n",
      "\n",
      " Overall Validation RMSE (XGBoost): 1.55104\n",
      " Nulls in submission: 0\n",
      "           card_id    target\n",
      "0  C_ID_0ab67a22ab -0.377804\n",
      "1  C_ID_130fd0cbdd -0.064557\n",
      "2  C_ID_b709037bc5 -0.333415\n",
      "3  C_ID_d27d835a9f -0.068611\n",
      "4  C_ID_2b5e3df5c2 -1.462076\n",
      " Submission saved to 'data/xgb_latest_ou.csv'\n",
      " XGBoost model saved as 'xgb_model_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Apply best parameters\n",
    "xgb_best_params = xgb_study.best_trial.params\n",
    "xgb_best_params.update({\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'verbosity': 0,\n",
    "    'tree_method': 'auto',\n",
    "    'seed': 42\n",
    "})\n",
    "\n",
    "# Align columns\n",
    "df_train_columns_xgb = [col for col in df_train_columns_clf if col in X_train_all.columns and col in test.columns]\n",
    "\n",
    "# Run training and prediction\n",
    "xgb_test_preds, val_rmse_xgb, xgb_model_final = xgb_train_and_predict(\n",
    "    best_params=xgb_best_params,\n",
    "    n_splits=9,\n",
    "    X_train=X_train_all[df_train_columns_xgb],\n",
    "    y_train=y_train_all,\n",
    "    test=test_features_for_reg[df_train_columns_xgb]\n",
    ")\n",
    "\n",
    "# Build submission\n",
    "submission_xgb = test_result.copy()\n",
    "submission_xgb.loc[submission_xgb['outlier'] == 0, 'target'] = xgb_test_preds\n",
    "\n",
    "final_submission_xgb = submission_xgb[['card_id', 'target']].copy()\n",
    "print(\" Nulls in submission:\", final_submission_xgb.isnull().sum().sum())\n",
    "print(final_submission_xgb.head())\n",
    "\n",
    "# Save submission\n",
    "final_submission_xgb.to_csv(\"xgb_latest_ou.csv\", index=False)\n",
    "print(\" Submission saved to 'data/xgb_latest_ou.csv'\")\n",
    "\n",
    "# ‚úÖ Save model to .pkl\n",
    "with open(\"xgb_model_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_model_final, f)\n",
    "print(\" XGBoost model saved as 'xgb_model_final.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116a613",
   "metadata": {},
   "source": [
    "## Model 7: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e64aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL 7 - PART 1: CATBOOST OPTUNA OBJECTIVE ===\n",
    "from catboost import Pool, cv\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "def cb_objective(trial):\n",
    "    cb_params = {\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'RMSE',\n",
    "        'learning_rate': 0.01,\n",
    "        'iterations': 10000,\n",
    "        'random_seed': 326,\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 200,\n",
    "\n",
    "        # Hyperparameters to tune\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.0, 1.0),\n",
    "        'rsm': trial.suggest_float('rsm', 0.001, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255)\n",
    "    }\n",
    "\n",
    "    cb_pool = Pool(X_train_all, label=y_train_all)\n",
    "\n",
    "    cv_result = cv(\n",
    "        params=cb_params,\n",
    "        pool=cb_pool,\n",
    "        fold_count=3,\n",
    "        partition_random_seed=47,\n",
    "        early_stopping_rounds=cb_params['early_stopping_rounds'],\n",
    "        verbose=False,\n",
    "        plot=False\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    if 'test-RMSE-mean' in cv_result.columns:\n",
    "        return cv_result['test-RMSE-mean'].iloc[-1]\n",
    "\n",
    "    raise KeyError(\"Expected 'test-RMSE-mean' not found in CatBoost CV results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d72d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:46:31,901] A new study created in memory with name: no-name-332811d4-b22c-4e1e-8f23-e97c83b47a5f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.557361764\n",
      "bestIteration = 4010\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552848861\n",
      "bestIteration = 4418\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:54:53,903] Trial 0 finished with value: 1.5541669542639969 and parameters: {'depth': 6, 'l2_leaf_reg': 0.0444275155070382, 'bagging_temperature': 0.1589507095417878, 'random_strength': 0.5658296613019782, 'rsm': 0.5309253217042641, 'border_count': 136}. Best is trial 0 with value: 1.5541669542639969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552172349\n",
      "bestIteration = 4779\n",
      "\n",
      "Trial 0: Initial best score set to 1.55417\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556295767\n",
      "bestIteration = 3873\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.55229181\n",
      "bestIteration = 3693\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 04:58:31,314] Trial 1 finished with value: 1.5537023262845784 and parameters: {'depth': 7, 'l2_leaf_reg': 0.05560812766271702, 'bagging_temperature': 0.7658898607412754, 'random_strength': 0.5463064076223892, 'rsm': 0.1230143474287879, 'border_count': 165}. Best is trial 1 with value: 1.5537023262845784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552427153\n",
      "bestIteration = 3978\n",
      "\n",
      "Trial 1: Improved score: 1.55370 (Previous best: 1.55417)\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556944158\n",
      "bestIteration = 4254\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553015588\n",
      "bestIteration = 5294\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:03:04,020] Trial 2 finished with value: 1.5542050334853725 and parameters: {'depth': 6, 'l2_leaf_reg': 0.03782501014837518, 'bagging_temperature': 0.012947743767179776, 'random_strength': 0.09233327660181745, 'rsm': 0.098564967302581, 'border_count': 185}. Best is trial 1 with value: 1.5537023262845784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552497706\n",
      "bestIteration = 5277\n",
      "\n",
      "Trial 2: No improvement. Counter = 1, Best Score = 1.55370\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556670504\n",
      "bestIteration = 2254\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553541943\n",
      "bestIteration = 1739\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:07:08,841] Trial 3 finished with value: 1.5541422708495913 and parameters: {'depth': 10, 'l2_leaf_reg': 0.18887435923235485, 'bagging_temperature': 0.3498094263022691, 'random_strength': 0.21510915372741868, 'rsm': 0.2717408657111057, 'border_count': 185}. Best is trial 1 with value: 1.5537023262845784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.551971428\n",
      "bestIteration = 1970\n",
      "\n",
      "Trial 3: No improvement. Counter = 2, Best Score = 1.55370\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.560844772\n",
      "bestIteration = 6344\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.555185243\n",
      "bestIteration = 9501\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:10:07,467] Trial 4 finished with value: 1.5569080543377343 and parameters: {'depth': 3, 'l2_leaf_reg': 0.6972540317034704, 'bagging_temperature': 0.2809015422021236, 'random_strength': 0.08545422637359779, 'rsm': 0.8571082162228807, 'border_count': 38}. Best is trial 1 with value: 1.5537023262845784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.554637109\n",
      "bestIteration = 9691\n",
      "\n",
      "Trial 4: No improvement. Counter = 3, Best Score = 1.55370\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556963051\n",
      "bestIteration = 4426\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.551959327\n",
      "bestIteration = 5295\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:12:55,650] Trial 5 finished with value: 1.5536734510082557 and parameters: {'depth': 6, 'l2_leaf_reg': 0.022229789490885263, 'bagging_temperature': 0.4618903374417369, 'random_strength': 0.6397936290559484, 'rsm': 0.09982912329977724, 'border_count': 64}. Best is trial 5 with value: 1.5536734510082557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552062938\n",
      "bestIteration = 4691\n",
      "\n",
      "Trial 5: Improved score: 1.55367 (Previous best: 1.55370)\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556301325\n",
      "bestIteration = 3334\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552529701\n",
      "bestIteration = 4451\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:23:55,725] Trial 6 finished with value: 1.5537030358724364 and parameters: {'depth': 8, 'l2_leaf_reg': 4.387721267498002, 'bagging_temperature': 0.3616764149200272, 'random_strength': 0.6948115379564989, 'rsm': 0.6298275115190773, 'border_count': 246}. Best is trial 5 with value: 1.5536734510082557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552135647\n",
      "bestIteration = 3858\n",
      "\n",
      "Trial 6: No improvement. Counter = 1, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.557805738\n",
      "bestIteration = 2830\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553393705\n",
      "bestIteration = 4455\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:31:17,019] Trial 7 finished with value: 1.554789945951125 and parameters: {'depth': 6, 'l2_leaf_reg': 0.1309743099121978, 'bagging_temperature': 0.9684302258779105, 'random_strength': 0.09516037362900132, 'rsm': 0.598567527250321, 'border_count': 120}. Best is trial 5 with value: 1.5536734510082557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.553037431\n",
      "bestIteration = 4236\n",
      "\n",
      "Trial 7: No improvement. Counter = 2, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.557175187\n",
      "bestIteration = 3109\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552324074\n",
      "bestIteration = 3417\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:33:46,380] Trial 8 finished with value: 1.5542265094382 and parameters: {'depth': 10, 'l2_leaf_reg': 0.84843944932673, 'bagging_temperature': 0.3871095602309872, 'random_strength': 0.5954529818671707, 'rsm': 0.03557097473149036, 'border_count': 239}. Best is trial 5 with value: 1.5536734510082557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552907825\n",
      "bestIteration = 2889\n",
      "\n",
      "Trial 8: No improvement. Counter = 3, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.560182004\n",
      "bestIteration = 7925\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.555560226\n",
      "bestIteration = 9238\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:36:46,074] Trial 9 finished with value: 1.5569709618320566 and parameters: {'depth': 3, 'l2_leaf_reg': 0.3770762088829178, 'bagging_temperature': 0.22424964161238903, 'random_strength': 0.8266672399404768, 'rsm': 0.9711604584738514, 'border_count': 48}. Best is trial 5 with value: 1.5536734510082557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.555100368\n",
      "bestIteration = 9943\n",
      "\n",
      "Trial 9: No improvement. Counter = 4, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.55822416\n",
      "bestIteration = 6751\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553776512\n",
      "bestIteration = 7877\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:39:37,097] Trial 10 finished with value: 1.5551085619872962 and parameters: {'depth': 4, 'l2_leaf_reg': 0.012216137629976254, 'bagging_temperature': 0.5950563363105351, 'random_strength': 0.9905759287225882, 'rsm': 0.32115357926253785, 'border_count': 87}. Best is trial 5 with value: 1.5536734510082557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.553190916\n",
      "bestIteration = 8044\n",
      "\n",
      "Trial 10: No improvement. Counter = 5, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556574424\n",
      "bestIteration = 2251\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553013503\n",
      "bestIteration = 2652\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:45:30,886] Trial 11 finished with value: 1.5540789300153142 and parameters: {'depth': 8, 'l2_leaf_reg': 0.023207543581246964, 'bagging_temperature': 0.6725432364438356, 'random_strength': 0.34950480476281354, 'rsm': 0.2383484846842187, 'border_count': 179}. Best is trial 5 with value: 1.5536734510082557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552477637\n",
      "bestIteration = 3722\n",
      "\n",
      "Trial 11: No improvement. Counter = 6, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556302608\n",
      "bestIteration = 2759\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552295921\n",
      "bestIteration = 3416\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:51:09,382] Trial 12 finished with value: 1.5536664109914657 and parameters: {'depth': 8, 'l2_leaf_reg': 0.08726335382712298, 'bagging_temperature': 0.7806149614579784, 'random_strength': 0.41793936819346916, 'rsm': 0.16101113804311123, 'border_count': 85}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552270147\n",
      "bestIteration = 2493\n",
      "\n",
      "Trial 12: Improved score: 1.55367 (Previous best: 1.55367)\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556547624\n",
      "bestIteration = 2504\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552206354\n",
      "bestIteration = 3332\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 05:56:51,064] Trial 13 finished with value: 1.5537498595460226 and parameters: {'depth': 8, 'l2_leaf_reg': 0.012029176037023883, 'bagging_temperature': 0.8721804792331748, 'random_strength': 0.3715885107966474, 'rsm': 0.3146279872028811, 'border_count': 81}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552227399\n",
      "bestIteration = 2866\n",
      "\n",
      "Trial 13: No improvement. Counter = 1, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.55773019\n",
      "bestIteration = 3792\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553592756\n",
      "bestIteration = 6072\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:00:12,766] Trial 14 finished with value: 1.5548653940408697 and parameters: {'depth': 5, 'l2_leaf_reg': 0.09957656955439516, 'bagging_temperature': 0.5584804875600153, 'random_strength': 0.37938767789250427, 'rsm': 0.397000953161525, 'border_count': 91}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.553128107\n",
      "bestIteration = 5389\n",
      "\n",
      "Trial 14: No improvement. Counter = 2, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556932552\n",
      "bestIteration = 2340\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552227335\n",
      "bestIteration = 2406\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:04:42,703] Trial 15 finished with value: 1.5539665920521866 and parameters: {'depth': 9, 'l2_leaf_reg': 0.07314986647120404, 'bagging_temperature': 0.7532663523764404, 'random_strength': 0.7954898964173689, 'rsm': 0.16599330413440128, 'border_count': 65}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552597508\n",
      "bestIteration = 2599\n",
      "\n",
      "Trial 15: No improvement. Counter = 3, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.557350502\n",
      "bestIteration = 4829\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552448623\n",
      "bestIteration = 6137\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:09:12,013] Trial 16 finished with value: 1.5541260739202174 and parameters: {'depth': 7, 'l2_leaf_reg': 7.216795592751072, 'bagging_temperature': 0.5403299983824119, 'random_strength': 0.4347190012652466, 'rsm': 0.01950638936669208, 'border_count': 112}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552495531\n",
      "bestIteration = 6239\n",
      "\n",
      "Trial 16: No improvement. Counter = 4, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.557702913\n",
      "bestIteration = 4539\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553273293\n",
      "bestIteration = 5342\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:12:40,258] Trial 17 finished with value: 1.5545341393895555 and parameters: {'depth': 5, 'l2_leaf_reg': 0.022648077711422427, 'bagging_temperature': 0.46040253915491935, 'random_strength': 0.7028772608967317, 'rsm': 0.4241485877687274, 'border_count': 61}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552542591\n",
      "bestIteration = 5341\n",
      "\n",
      "Trial 17: No improvement. Counter = 5, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556833779\n",
      "bestIteration = 2267\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553174027\n",
      "bestIteration = 2188\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:19:20,455] Trial 18 finished with value: 1.554167696803504 and parameters: {'depth': 9, 'l2_leaf_reg': 0.23093927987561766, 'bagging_temperature': 0.8506014886505009, 'random_strength': 0.2680036887985694, 'rsm': 0.7380103218326206, 'border_count': 34}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552368226\n",
      "bestIteration = 2408\n",
      "\n",
      "Trial 18: No improvement. Counter = 6, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.557200184\n",
      "bestIteration = 5529\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552966724\n",
      "bestIteration = 5687\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:22:57,138] Trial 19 finished with value: 1.5542649181258341 and parameters: {'depth': 5, 'l2_leaf_reg': 2.110223890921373, 'bagging_temperature': 0.988916457027048, 'random_strength': 0.4882411902737436, 'rsm': 0.18993976459378947, 'border_count': 108}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.5525692\n",
      "bestIteration = 6181\n",
      "\n",
      "Trial 19: No improvement. Counter = 7, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.557873029\n",
      "bestIteration = 6785\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553265564\n",
      "bestIteration = 6850\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:27:32,672] Trial 20 finished with value: 1.5548983680386919 and parameters: {'depth': 7, 'l2_leaf_reg': 0.02406269418880626, 'bagging_temperature': 0.6643171103507381, 'random_strength': 0.6786438784470685, 'rsm': 0.013092087608163175, 'border_count': 148}. Best is trial 12 with value: 1.5536664109914657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.553464204\n",
      "bestIteration = 6842\n",
      "\n",
      "Trial 20: No improvement. Counter = 8, Best Score = 1.55367\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556359251\n",
      "bestIteration = 3545\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.551841044\n",
      "bestIteration = 4410\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:31:25,882] Trial 21 finished with value: 1.5534904133184044 and parameters: {'depth': 7, 'l2_leaf_reg': 0.059439927756140334, 'bagging_temperature': 0.776391714709271, 'random_strength': 0.5447803267109745, 'rsm': 0.11442949894018659, 'border_count': 160}. Best is trial 21 with value: 1.5534904133184044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552096752\n",
      "bestIteration = 4202\n",
      "\n",
      "Trial 21: Improved score: 1.55349 (Previous best: 1.55367)\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556082559\n",
      "bestIteration = 2738\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552316186\n",
      "bestIteration = 2951\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:35:43,142] Trial 22 finished with value: 1.553723172643861 and parameters: {'depth': 8, 'l2_leaf_reg': 0.10199037191353201, 'bagging_temperature': 0.8261225775545856, 'random_strength': 0.4795252698208959, 'rsm': 0.14158929796239855, 'border_count': 204}. Best is trial 21 with value: 1.5534904133184044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552626167\n",
      "bestIteration = 2989\n",
      "\n",
      "Trial 22: No improvement. Counter = 1, Best Score = 1.55349\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556429236\n",
      "bestIteration = 2330\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552707877\n",
      "bestIteration = 2932\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:43:34,735] Trial 23 finished with value: 1.5538327404556045 and parameters: {'depth': 9, 'l2_leaf_reg': 0.41177351146009683, 'bagging_temperature': 0.6583320684268745, 'random_strength': 0.6428557080725682, 'rsm': 0.38835398593228326, 'border_count': 142}. Best is trial 21 with value: 1.5534904133184044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.5520628\n",
      "bestIteration = 2830\n",
      "\n",
      "Trial 23: No improvement. Counter = 2, Best Score = 1.55349\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556759776\n",
      "bestIteration = 3360\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552816943\n",
      "bestIteration = 4647\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:48:47,272] Trial 24 finished with value: 1.5540443975129392 and parameters: {'depth': 7, 'l2_leaf_reg': 0.0336956751892226, 'bagging_temperature': 0.4676264890155275, 'random_strength': 0.8176548980407448, 'rsm': 0.21058843702585292, 'border_count': 217}. Best is trial 21 with value: 1.5534904133184044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552455009\n",
      "bestIteration = 4398\n",
      "\n",
      "Trial 24: No improvement. Counter = 3, Best Score = 1.55349\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.557374737\n",
      "bestIteration = 3092\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.552388709\n",
      "bestIteration = 4723\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:51:19,173] Trial 25 finished with value: 1.5540186444072537 and parameters: {'depth': 6, 'l2_leaf_reg': 0.06513549362212326, 'bagging_temperature': 0.7589196676619188, 'random_strength': 0.24440846366217098, 'rsm': 0.09532903031588123, 'border_count': 67}. Best is trial 21 with value: 1.5534904133184044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.552145272\n",
      "bestIteration = 5128\n",
      "\n",
      "Trial 25: No improvement. Counter = 4, Best Score = 1.55349\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.558177497\n",
      "bestIteration = 5528\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.553780971\n",
      "bestIteration = 8431\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:54:54,316] Trial 26 finished with value: 1.5550319417624399 and parameters: {'depth': 4, 'l2_leaf_reg': 0.15193173423328363, 'bagging_temperature': 0.9222932817825279, 'random_strength': 0.7636124439668126, 'rsm': 0.295165493049487, 'border_count': 99}. Best is trial 21 with value: 1.5534904133184044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.553045586\n",
      "bestIteration = 8296\n",
      "\n",
      "Trial 26: No improvement. Counter = 5, Best Score = 1.55349\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.556477549\n",
      "bestIteration = 4587\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 1.551732248\n",
      "bestIteration = 4657\n",
      "\n",
      "Training on fold [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 06:59:08,541] Trial 27 finished with value: 1.5533953158874727 and parameters: {'depth': 7, 'l2_leaf_reg': 0.015513967881211782, 'bagging_temperature': 0.6160393410853552, 'random_strength': 0.9085183414130871, 'rsm': 0.07784840594915488, 'border_count': 124}. Best is trial 27 with value: 1.5533953158874727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.55175875\n",
      "bestIteration = 4871\n",
      "\n",
      "Trial 27: Improved score: 1.55340 (Previous best: 1.55349)\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 1.55629095\n",
      "bestIteration = 3399\n",
      "\n",
      "Training on fold [1/3]\n"
     ]
    }
   ],
   "source": [
    "# === MODEL 7 - PART 2: CATBOOST TUNING EXECUTION (with verbose early stopping logs) ===\n",
    "\n",
    "class CB_EarlyStoppingExceeded(optuna.exceptions.OptunaError):\n",
    "    early_stop = 20\n",
    "    early_stop_count = 0\n",
    "    best_score = None\n",
    "\n",
    "def cb_early_stopping_opt(study, trial):\n",
    "    current_score = study.best_value\n",
    "\n",
    "    if CB_EarlyStoppingExceeded.best_score is None:\n",
    "        CB_EarlyStoppingExceeded.best_score = current_score\n",
    "        print(f\"Trial {trial.number}: Initial best score set to {current_score:.5f}\")\n",
    "        return\n",
    "\n",
    "    if current_score < CB_EarlyStoppingExceeded.best_score:\n",
    "        print(f\"Trial {trial.number}: Improved score: {current_score:.5f} (Previous best: {CB_EarlyStoppingExceeded.best_score:.5f})\")\n",
    "        CB_EarlyStoppingExceeded.best_score = current_score\n",
    "        CB_EarlyStoppingExceeded.early_stop_count = 0\n",
    "    else:\n",
    "        CB_EarlyStoppingExceeded.early_stop_count += 1\n",
    "        print(f\"Trial {trial.number}: No improvement. Counter = {CB_EarlyStoppingExceeded.early_stop_count}, Best Score = {CB_EarlyStoppingExceeded.best_score:.5f}\")\n",
    "        if CB_EarlyStoppingExceeded.early_stop_count > CB_EarlyStoppingExceeded.early_stop:\n",
    "            print(\"Early stopping threshold reached. Terminating optimization.\")\n",
    "            raise CB_EarlyStoppingExceeded()\n",
    "\n",
    "# === Run the Optuna study for CatBoost ===\n",
    "cb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "try:\n",
    "    cb_study.optimize(cb_objective, n_trials=100, callbacks=[cb_early_stopping_opt])\n",
    "except CB_EarlyStoppingExceeded:\n",
    "    print(\" Early stopping triggered for CatBoost.\")\n",
    "\n",
    "# === Log Best Parameters ===\n",
    "print(\"\\n Best hyperparameters for CatBoost:\")\n",
    "for k, v in cb_study.best_trial.params.items():\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe68dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle  #  Add this\n",
    "\n",
    "def cb_train_and_predict(best_params, n_splits, X_train, y_train, test, num_round=10000):\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    pred_y_train = np.zeros(len(X_train))\n",
    "    pred_y_test = np.zeros(len(test))\n",
    "    final_model = None  #  We'll save the last (or best) model\n",
    "\n",
    "    for fold_, (train_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "        print(f\" CatBoost Fold {fold_ + 1}\")\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr)\n",
    "        val_pool = Pool(X_val, y_val)\n",
    "        test_pool = Pool(test)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            iterations=num_round,\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            depth=best_params['depth'],\n",
    "            l2_leaf_reg=best_params['l2_leaf_reg'],\n",
    "            bagging_temperature=best_params['bagging_temperature'],\n",
    "            random_strength=best_params['random_strength'],\n",
    "            rsm=best_params['rsm'],\n",
    "            border_count=best_params['border_count'],\n",
    "            loss_function='RMSE',\n",
    "            eval_metric='RMSE',\n",
    "            random_seed=42,\n",
    "            early_stopping_rounds=150,\n",
    "            verbose=200\n",
    "        )\n",
    "\n",
    "        model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "        final_model = model  # Save last fold‚Äôs model\n",
    "        pred_y_train[val_idx] = model.predict(val_pool)\n",
    "        pred_y_test += model.predict(test_pool) / folds.n_splits\n",
    "\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_train, pred_y_train))\n",
    "    print(f\"\\n Overall Validation RMSE (CatBoost): {val_rmse:.5f}\")\n",
    "    return pred_y_test, val_rmse, final_model  #  Return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af252e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CatBoost Fold 1\n",
      "0:\tlearn: 1.7210333\ttest: 1.7160517\tbest: 1.7160517 (0)\ttotal: 39.1ms\tremaining: 6m 30s\n",
      "200:\tlearn: 1.5742562\ttest: 1.5846752\tbest: 1.5846752 (200)\ttotal: 6.1s\tremaining: 4m 57s\n",
      "400:\tlearn: 1.5362720\ttest: 1.5704040\tbest: 1.5704040 (400)\ttotal: 12.2s\tremaining: 4m 51s\n",
      "600:\tlearn: 1.5108636\ttest: 1.5663787\tbest: 1.5663787 (600)\ttotal: 18.8s\tremaining: 4m 54s\n",
      "800:\tlearn: 1.4892676\ttest: 1.5640193\tbest: 1.5640077 (797)\ttotal: 25.4s\tremaining: 4m 51s\n",
      "1000:\tlearn: 1.4694726\ttest: 1.5623554\tbest: 1.5623554 (1000)\ttotal: 32s\tremaining: 4m 47s\n",
      "1200:\tlearn: 1.4510739\ttest: 1.5619018\tbest: 1.5618421 (1169)\ttotal: 38.4s\tremaining: 4m 41s\n",
      "1400:\tlearn: 1.4336544\ttest: 1.5615789\tbest: 1.5615719 (1322)\ttotal: 45.1s\tremaining: 4m 36s\n",
      "1600:\tlearn: 1.4167433\ttest: 1.5615647\tbest: 1.5614601 (1525)\ttotal: 51.7s\tremaining: 4m 31s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.56146014\n",
      "bestIteration = 1525\n",
      "\n",
      "Shrink model to first 1526 iterations.\n",
      " CatBoost Fold 2\n",
      "0:\tlearn: 1.7202495\ttest: 1.7226050\tbest: 1.7226050 (0)\ttotal: 40.1ms\tremaining: 6m 41s\n",
      "200:\tlearn: 1.5734057\ttest: 1.5904729\tbest: 1.5904729 (200)\ttotal: 6.5s\tremaining: 5m 16s\n",
      "400:\tlearn: 1.5364692\ttest: 1.5762608\tbest: 1.5762608 (400)\ttotal: 13.1s\tremaining: 5m 13s\n",
      "600:\tlearn: 1.5113869\ttest: 1.5717615\tbest: 1.5717446 (593)\ttotal: 19.9s\tremaining: 5m 10s\n",
      "800:\tlearn: 1.4897053\ttest: 1.5696033\tbest: 1.5695975 (799)\ttotal: 26.2s\tremaining: 5m 1s\n",
      "1000:\tlearn: 1.4705477\ttest: 1.5685707\tbest: 1.5684932 (994)\ttotal: 32.7s\tremaining: 4m 54s\n",
      "1200:\tlearn: 1.4523483\ttest: 1.5677088\tbest: 1.5676961 (1192)\ttotal: 39.2s\tremaining: 4m 47s\n",
      "1400:\tlearn: 1.4341799\ttest: 1.5673659\tbest: 1.5673572 (1384)\ttotal: 45.5s\tremaining: 4m 39s\n",
      "1600:\tlearn: 1.4161757\ttest: 1.5670797\tbest: 1.5670693 (1596)\ttotal: 51.7s\tremaining: 4m 31s\n",
      "1800:\tlearn: 1.3990180\ttest: 1.5666132\tbest: 1.5665809 (1793)\ttotal: 58.1s\tremaining: 4m 24s\n",
      "2000:\tlearn: 1.3822367\ttest: 1.5664197\tbest: 1.5663795 (1994)\ttotal: 1m 4s\tremaining: 4m 17s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.566379518\n",
      "bestIteration = 1994\n",
      "\n",
      "Shrink model to first 1995 iterations.\n",
      " CatBoost Fold 3\n",
      "0:\tlearn: 1.7215118\ttest: 1.7127100\tbest: 1.7127100 (0)\ttotal: 25.5ms\tremaining: 4m 14s\n",
      "200:\tlearn: 1.5737598\ttest: 1.5864527\tbest: 1.5864527 (200)\ttotal: 6.36s\tremaining: 5m 10s\n",
      "400:\tlearn: 1.5369964\ttest: 1.5720049\tbest: 1.5720049 (400)\ttotal: 12.5s\tremaining: 4m 59s\n",
      "600:\tlearn: 1.5111233\ttest: 1.5672481\tbest: 1.5672481 (600)\ttotal: 18.8s\tremaining: 4m 53s\n",
      "800:\tlearn: 1.4896605\ttest: 1.5645975\tbest: 1.5645968 (797)\ttotal: 25.1s\tremaining: 4m 48s\n",
      "1000:\tlearn: 1.4694132\ttest: 1.5632064\tbest: 1.5632064 (1000)\ttotal: 31.3s\tremaining: 4m 41s\n",
      "1200:\tlearn: 1.4515928\ttest: 1.5619516\tbest: 1.5619516 (1200)\ttotal: 37.6s\tremaining: 4m 35s\n",
      "1400:\tlearn: 1.4334894\ttest: 1.5613109\tbest: 1.5612767 (1392)\ttotal: 43.7s\tremaining: 4m 28s\n",
      "1600:\tlearn: 1.4159424\ttest: 1.5612147\tbest: 1.5611213 (1561)\ttotal: 49.6s\tremaining: 4m 20s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.56112128\n",
      "bestIteration = 1561\n",
      "\n",
      "Shrink model to first 1562 iterations.\n",
      " CatBoost Fold 4\n",
      "0:\tlearn: 1.7156749\ttest: 1.7589136\tbest: 1.7589136 (0)\ttotal: 22.9ms\tremaining: 3m 48s\n",
      "200:\tlearn: 1.5672046\ttest: 1.6345169\tbest: 1.6345169 (200)\ttotal: 6.32s\tremaining: 5m 8s\n",
      "400:\tlearn: 1.5292658\ttest: 1.6222411\tbest: 1.6222411 (400)\ttotal: 12.8s\tremaining: 5m 5s\n",
      "600:\tlearn: 1.5040285\ttest: 1.6183486\tbest: 1.6183442 (599)\ttotal: 19.7s\tremaining: 5m 8s\n",
      "800:\tlearn: 1.4824334\ttest: 1.6168476\tbest: 1.6168476 (800)\ttotal: 26.4s\tremaining: 5m 3s\n",
      "1000:\tlearn: 1.4625865\ttest: 1.6161542\tbest: 1.6160552 (959)\ttotal: 32.6s\tremaining: 4m 53s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.616055216\n",
      "bestIteration = 959\n",
      "\n",
      "Shrink model to first 960 iterations.\n",
      " CatBoost Fold 5\n",
      "0:\tlearn: 1.7172122\ttest: 1.7467516\tbest: 1.7467516 (0)\ttotal: 24.1ms\tremaining: 4m 1s\n",
      "200:\tlearn: 1.5693881\ttest: 1.6272530\tbest: 1.6272530 (200)\ttotal: 6.72s\tremaining: 5m 27s\n",
      "400:\tlearn: 1.5330501\ttest: 1.6139507\tbest: 1.6139109 (399)\ttotal: 13.4s\tremaining: 5m 20s\n",
      "600:\tlearn: 1.5086515\ttest: 1.6094984\tbest: 1.6094984 (600)\ttotal: 19.9s\tremaining: 5m 10s\n",
      "800:\tlearn: 1.4875611\ttest: 1.6075465\tbest: 1.6074950 (795)\ttotal: 26.2s\tremaining: 5m\n",
      "1000:\tlearn: 1.4680185\ttest: 1.6062306\tbest: 1.6062306 (1000)\ttotal: 32.3s\tremaining: 4m 50s\n",
      "1200:\tlearn: 1.4499201\ttest: 1.6057260\tbest: 1.6056757 (1179)\ttotal: 38.5s\tremaining: 4m 42s\n",
      "1400:\tlearn: 1.4321008\ttest: 1.6052258\tbest: 1.6052258 (1400)\ttotal: 44.8s\tremaining: 4m 35s\n",
      "1600:\tlearn: 1.4149984\ttest: 1.6044450\tbest: 1.6043698 (1586)\ttotal: 51.1s\tremaining: 4m 27s\n",
      "1800:\tlearn: 1.3985322\ttest: 1.6040054\tbest: 1.6039394 (1795)\ttotal: 57.2s\tremaining: 4m 20s\n",
      "2000:\tlearn: 1.3819354\ttest: 1.6035918\tbest: 1.6035493 (1996)\ttotal: 1m 3s\tremaining: 4m 12s\n",
      "2200:\tlearn: 1.3658961\ttest: 1.6033568\tbest: 1.6033512 (2160)\ttotal: 1m 9s\tremaining: 4m 5s\n",
      "2400:\tlearn: 1.3503812\ttest: 1.6031868\tbest: 1.6031661 (2398)\ttotal: 1m 15s\tremaining: 3m 58s\n",
      "2600:\tlearn: 1.3354120\ttest: 1.6029571\tbest: 1.6029381 (2572)\ttotal: 1m 21s\tremaining: 3m 52s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.602938083\n",
      "bestIteration = 2572\n",
      "\n",
      "Shrink model to first 2573 iterations.\n",
      " CatBoost Fold 6\n",
      "0:\tlearn: 1.7221313\ttest: 1.7081645\tbest: 1.7081645 (0)\ttotal: 25.7ms\tremaining: 4m 17s\n",
      "200:\tlearn: 1.5769865\ttest: 1.5688194\tbest: 1.5688194 (200)\ttotal: 5.97s\tremaining: 4m 51s\n",
      "400:\tlearn: 1.5407274\ttest: 1.5518700\tbest: 1.5518700 (400)\ttotal: 12.1s\tremaining: 4m 48s\n",
      "600:\tlearn: 1.5156035\ttest: 1.5463878\tbest: 1.5463878 (600)\ttotal: 18s\tremaining: 4m 41s\n",
      "800:\tlearn: 1.4935625\ttest: 1.5430078\tbest: 1.5430078 (800)\ttotal: 24s\tremaining: 4m 35s\n",
      "1000:\tlearn: 1.4742956\ttest: 1.5411847\tbest: 1.5411834 (999)\ttotal: 30s\tremaining: 4m 30s\n",
      "1200:\tlearn: 1.4558954\ttest: 1.5402010\tbest: 1.5401452 (1195)\ttotal: 35.9s\tremaining: 4m 23s\n",
      "1400:\tlearn: 1.4369622\ttest: 1.5396798\tbest: 1.5396798 (1400)\ttotal: 42s\tremaining: 4m 17s\n",
      "1600:\tlearn: 1.4191901\ttest: 1.5392957\tbest: 1.5392957 (1600)\ttotal: 47.9s\tremaining: 4m 11s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.539185953\n",
      "bestIteration = 1632\n",
      "\n",
      "Shrink model to first 1633 iterations.\n",
      " CatBoost Fold 7\n",
      "0:\tlearn: 1.7192771\ttest: 1.7301869\tbest: 1.7301869 (0)\ttotal: 21.9ms\tremaining: 3m 38s\n",
      "200:\tlearn: 1.5696952\ttest: 1.6167871\tbest: 1.6167871 (200)\ttotal: 6.02s\tremaining: 4m 53s\n",
      "400:\tlearn: 1.5324752\ttest: 1.6059875\tbest: 1.6059875 (400)\ttotal: 12s\tremaining: 4m 46s\n",
      "600:\tlearn: 1.5069901\ttest: 1.6021746\tbest: 1.6021746 (600)\ttotal: 17.8s\tremaining: 4m 38s\n",
      "800:\tlearn: 1.4854613\ttest: 1.6004292\tbest: 1.6004248 (779)\ttotal: 23.7s\tremaining: 4m 32s\n",
      "1000:\tlearn: 1.4653509\ttest: 1.5996822\tbest: 1.5996575 (996)\ttotal: 29.7s\tremaining: 4m 26s\n",
      "1200:\tlearn: 1.4468091\ttest: 1.5991327\tbest: 1.5991327 (1200)\ttotal: 35.5s\tremaining: 4m 20s\n",
      "1400:\tlearn: 1.4282210\ttest: 1.5992875\tbest: 1.5989141 (1263)\ttotal: 41.5s\tremaining: 4m 14s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.598914136\n",
      "bestIteration = 1263\n",
      "\n",
      "Shrink model to first 1264 iterations.\n",
      " CatBoost Fold 8\n",
      "0:\tlearn: 1.7218335\ttest: 1.7103513\tbest: 1.7103513 (0)\ttotal: 23.3ms\tremaining: 3m 53s\n",
      "200:\tlearn: 1.5731958\ttest: 1.5875527\tbest: 1.5875527 (200)\ttotal: 6.27s\tremaining: 5m 5s\n",
      "400:\tlearn: 1.5363022\ttest: 1.5737501\tbest: 1.5737501 (400)\ttotal: 12.4s\tremaining: 4m 57s\n",
      "600:\tlearn: 1.5105936\ttest: 1.5686866\tbest: 1.5686866 (600)\ttotal: 18.5s\tremaining: 4m 48s\n",
      "800:\tlearn: 1.4888318\ttest: 1.5658155\tbest: 1.5658155 (800)\ttotal: 24.7s\tremaining: 4m 43s\n",
      "1000:\tlearn: 1.4688409\ttest: 1.5643907\tbest: 1.5643907 (1000)\ttotal: 30.9s\tremaining: 4m 38s\n",
      "1200:\tlearn: 1.4502459\ttest: 1.5634614\tbest: 1.5634381 (1186)\ttotal: 37.6s\tremaining: 4m 35s\n",
      "1400:\tlearn: 1.4321743\ttest: 1.5628027\tbest: 1.5627911 (1384)\ttotal: 43.9s\tremaining: 4m 29s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.562790467\n",
      "bestIteration = 1402\n",
      "\n",
      "Shrink model to first 1403 iterations.\n",
      " CatBoost Fold 9\n",
      "0:\tlearn: 1.7257500\ttest: 1.6785415\tbest: 1.6785415 (0)\ttotal: 24.6ms\tremaining: 4m 5s\n",
      "200:\tlearn: 1.5774769\ttest: 1.5582347\tbest: 1.5582347 (200)\ttotal: 6.31s\tremaining: 5m 7s\n",
      "400:\tlearn: 1.5405852\ttest: 1.5457322\tbest: 1.5457322 (400)\ttotal: 12.5s\tremaining: 4m 58s\n",
      "600:\tlearn: 1.5149834\ttest: 1.5416162\tbest: 1.5416162 (600)\ttotal: 18.6s\tremaining: 4m 51s\n",
      "800:\tlearn: 1.4934612\ttest: 1.5393251\tbest: 1.5393184 (797)\ttotal: 25.1s\tremaining: 4m 48s\n",
      "1000:\tlearn: 1.4736519\ttest: 1.5380895\tbest: 1.5380807 (999)\ttotal: 31.3s\tremaining: 4m 41s\n",
      "1200:\tlearn: 1.4550403\ttest: 1.5374136\tbest: 1.5373877 (1192)\ttotal: 37.8s\tremaining: 4m 36s\n",
      "1400:\tlearn: 1.4384224\ttest: 1.5370282\tbest: 1.5369490 (1385)\ttotal: 43.9s\tremaining: 4m 29s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.536885857\n",
      "bestIteration = 1413\n",
      "\n",
      "Shrink model to first 1414 iterations.\n",
      "\n",
      " Overall Validation RMSE (CatBoost): 1.57197\n",
      " Nulls in submission: 0\n",
      "           card_id    target\n",
      "0  C_ID_0ab67a22ab -0.388394\n",
      "1  C_ID_130fd0cbdd -0.216571\n",
      "2  C_ID_b709037bc5 -0.451742\n",
      "3  C_ID_d27d835a9f -0.013335\n",
      "4  C_ID_2b5e3df5c2 -1.879206\n",
      " Submission saved to 'data/cb_latest_ou.csv'\n",
      " CatBoost model saved as 'cb_model_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Use best params\n",
    "cb_best_params = cb_study.best_trial.params\n",
    "cb_best_params.update({\n",
    "    'learning_rate': 0.01  # ensure consistent learning rate\n",
    "})\n",
    "\n",
    "# Align columns\n",
    "df_train_columns_cb = [col for col in df_train_columns_clf if col in X_train_all.columns and col in test.columns]\n",
    "\n",
    "# Predict on non-outlier rows\n",
    "cb_test_preds, val_rmse_cb, cb_model_final = cb_train_and_predict(\n",
    "    best_params=cb_best_params,\n",
    "    n_splits=9,\n",
    "    X_train=X_train_all[df_train_columns_cb],\n",
    "    y_train=y_train_all,\n",
    "    test=test_features_for_reg[df_train_columns_cb]\n",
    ")\n",
    "\n",
    "# Apply predictions\n",
    "submission_cb = test_result.copy()\n",
    "submission_cb.loc[submission_cb['outlier'] == 0, 'target'] = cb_test_preds\n",
    "\n",
    "final_submission_cb = submission_cb[['card_id', 'target']].copy()\n",
    "print(\" Nulls in submission:\", final_submission_cb.isnull().sum().sum())\n",
    "print(final_submission_cb.head())\n",
    "\n",
    "# Save submission\n",
    "final_submission_cb.to_csv(\"cb_latest_ou.csv\", index=False)\n",
    "print(\" Submission saved to 'data/cb_latest_ou.csv'\")\n",
    "\n",
    "# Save the CatBoost model\n",
    "with open(\"cb_model_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cb_model_final, f)\n",
    "print(\" CatBoost model saved as 'cb_model_final.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c5feaf",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/77537 \n",
    "\n",
    "https://www.kaggle.com/code/ar2017/basics-of-feature-selection-with-python\n",
    "\n",
    "\n",
    "There are three main types of feature selection methods:\n",
    "\n",
    "1. **Filter Methods** ‚Äì Use statistical techniques to evaluate the relevance of features independent of any machine learning model.\n",
    "2. **Wrapper Methods** ‚Äì Evaluate feature subsets by training and validating models iteratively, which can be computationally expensive.\n",
    "3. **Embedded Methods** ‚Äì Perform feature selection as part of the model training process (e.g., using feature importance scores).\n",
    "\n",
    "In this workflow, we choose **embedded methods** due to their simplicity and integration with model training. Feature selection will be performed **both prior to** and **after** model training to enhance model performance and reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:04<00:00, 49.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "list_importance_value =[]\n",
    "\n",
    "for i in tqdm(df_train_columns):\n",
    "    list_importance_value.append(ks_2samp(test[i] , X_train[i])[1])\n",
    "\n",
    "Se = pd.Series(list_importance_value, index = df_train_columns).sort_values() \n",
    "list_discarded = list(Se[Se < .1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_hist_purchase_amount_var',\n",
       " 'new_hist_purchase_recency',\n",
       " 'new_hist_purchase_amount_quantiles_var',\n",
       " 'purchase_amount_total',\n",
       " 'new_hist_purchase_date_min',\n",
       " 'new_hist_purchase_date_max',\n",
       " 'new_hist_of_new_hist_purchase_date_average',\n",
       " 'new_hist_purchase_count_ratio',\n",
       " 'new_hist_purchase_amount_diff',\n",
       " 'new_hist_purchase_amount_min',\n",
       " 'new_hist_purchase_amount_max',\n",
       " 'new_hist_purchase_amount_sum',\n",
       " 'new_hist_weekofyear_mean',\n",
       " 'new_hist_purchase_amount_mean',\n",
       " 'hist_amount_month_ratio_mean',\n",
       " 'hist_purchase_amount_sum',\n",
       " 'hist_ChristmasDay_2017_sum',\n",
       " 'hist_BlackFriday_2017_mean',\n",
       " 'hist_purchase_amount_quantiles_skew',\n",
       " 'hist_amount_month_ratio_max']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the features with significantly different distributions\n",
    "df_train_filtered = X_train.drop(columns=list_discarded)\n",
    "df_test_filtered = test.drop(columns=list_discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feature_percentile(model_fn, feature_df, X_train, y_train, test_df, param, model_name=\"model\", num_round=10000, n_splits=9):\n",
    "    results = []\n",
    "    \n",
    "    # Compute average importance per feature\n",
    "    avg_importance = (\n",
    "        feature_df.groupby(\"Feature\")[\"importance\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    for percentile in [90, 80, 70, 60]:\n",
    "        # Calculate the cutoff index for the given percentile\n",
    "        cutoff_index = int(len(avg_importance) * (percentile / 100.0))\n",
    "        selected_features = avg_importance.iloc[:cutoff_index].index.tolist()\n",
    "        importance_threshold = avg_importance.iloc[cutoff_index - 1]\n",
    "\n",
    "        print(f\"[{model_name}] Top {percentile}% ‚Üí {len(selected_features)} features (threshold ‚âà {importance_threshold:.4f})\")\n",
    "\n",
    "        model, oof_preds, test_preds, _, rmse = model_fn(\n",
    "            best_params=param,\n",
    "            n_splits=n_splits,\n",
    "            X_train=X_train[selected_features],\n",
    "            y_train=y_train,\n",
    "            test_df=test_df[selected_features],\n",
    "            num_round=num_round\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"percentile\": percentile,\n",
    "            \"threshold_value\": importance_threshold,\n",
    "            \"num_features\": len(selected_features),\n",
    "            \"rmse\": rmse\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    best_row = results_df.loc[results_df[\"rmse\"].idxmin()]\n",
    "\n",
    "    print(\"\\nBest Percentile Threshold Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    print(best_row)\n",
    "\n",
    "    return best_row, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] Top 90% ‚Üí 213 features (threshold ‚âà 8.5556)\n",
      "Starting 9-Fold CV with LightGBM...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.6181\tvalid_1's rmse: 3.78947\n",
      "[400]\ttraining's rmse: 3.56212\tvalid_1's rmse: 3.77023\n",
      "[600]\ttraining's rmse: 3.52768\tvalid_1's rmse: 3.76487\n",
      "[800]\ttraining's rmse: 3.49903\tvalid_1's rmse: 3.76345\n",
      "[1000]\ttraining's rmse: 3.47424\tvalid_1's rmse: 3.7631\n",
      "[1200]\ttraining's rmse: 3.45283\tvalid_1's rmse: 3.76297\n",
      "Early stopping, best iteration is:\n",
      "[1183]\ttraining's rmse: 3.45474\tvalid_1's rmse: 3.76275\n",
      "Fold 1 RMSE: 3.76275\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.64679\tvalid_1's rmse: 3.54275\n",
      "[400]\ttraining's rmse: 3.59053\tvalid_1's rmse: 3.52319\n",
      "[600]\ttraining's rmse: 3.55593\tvalid_1's rmse: 3.51745\n",
      "[800]\ttraining's rmse: 3.52857\tvalid_1's rmse: 3.5152\n",
      "[1000]\ttraining's rmse: 3.50376\tvalid_1's rmse: 3.51416\n",
      "[1200]\ttraining's rmse: 3.48141\tvalid_1's rmse: 3.51366\n",
      "Early stopping, best iteration is:\n",
      "[1199]\ttraining's rmse: 3.48152\tvalid_1's rmse: 3.51364\n",
      "Fold 2 RMSE: 3.51364\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62675\tvalid_1's rmse: 3.71363\n",
      "[400]\ttraining's rmse: 3.57003\tvalid_1's rmse: 3.6989\n",
      "[600]\ttraining's rmse: 3.53485\tvalid_1's rmse: 3.6966\n",
      "Early stopping, best iteration is:\n",
      "[579]\ttraining's rmse: 3.5382\tvalid_1's rmse: 3.69644\n",
      "Fold 3 RMSE: 3.69644\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62662\tvalid_1's rmse: 3.70442\n",
      "[400]\ttraining's rmse: 3.56971\tvalid_1's rmse: 3.69005\n",
      "[600]\ttraining's rmse: 3.53454\tvalid_1's rmse: 3.68618\n",
      "[800]\ttraining's rmse: 3.50605\tvalid_1's rmse: 3.6851\n",
      "Early stopping, best iteration is:\n",
      "[848]\ttraining's rmse: 3.4998\tvalid_1's rmse: 3.68489\n",
      "Fold 4 RMSE: 3.68489\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62706\tvalid_1's rmse: 3.71186\n",
      "[400]\ttraining's rmse: 3.57155\tvalid_1's rmse: 3.69143\n",
      "[600]\ttraining's rmse: 3.53731\tvalid_1's rmse: 3.68649\n",
      "[800]\ttraining's rmse: 3.51021\tvalid_1's rmse: 3.68494\n",
      "Early stopping, best iteration is:\n",
      "[797]\ttraining's rmse: 3.5106\tvalid_1's rmse: 3.68485\n",
      "Fold 5 RMSE: 3.68485\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.626\tvalid_1's rmse: 3.72276\n",
      "[400]\ttraining's rmse: 3.57018\tvalid_1's rmse: 3.69493\n",
      "[600]\ttraining's rmse: 3.53548\tvalid_1's rmse: 3.68406\n",
      "[800]\ttraining's rmse: 3.50838\tvalid_1's rmse: 3.67842\n",
      "[1000]\ttraining's rmse: 3.48464\tvalid_1's rmse: 3.67549\n",
      "[1200]\ttraining's rmse: 3.46284\tvalid_1's rmse: 3.67339\n",
      "[1400]\ttraining's rmse: 3.44182\tvalid_1's rmse: 3.67139\n",
      "[1600]\ttraining's rmse: 3.42216\tvalid_1's rmse: 3.67057\n",
      "[1800]\ttraining's rmse: 3.40242\tvalid_1's rmse: 3.67014\n",
      "[2000]\ttraining's rmse: 3.3841\tvalid_1's rmse: 3.6696\n",
      "[2200]\ttraining's rmse: 3.36687\tvalid_1's rmse: 3.66956\n",
      "Early stopping, best iteration is:\n",
      "[2101]\ttraining's rmse: 3.37492\tvalid_1's rmse: 3.66907\n",
      "Fold 6 RMSE: 3.66907\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61859\tvalid_1's rmse: 3.78489\n",
      "[400]\ttraining's rmse: 3.5631\tvalid_1's rmse: 3.76154\n",
      "[600]\ttraining's rmse: 3.52933\tvalid_1's rmse: 3.75307\n",
      "[800]\ttraining's rmse: 3.5022\tvalid_1's rmse: 3.7493\n",
      "[1000]\ttraining's rmse: 3.47865\tvalid_1's rmse: 3.74779\n",
      "[1200]\ttraining's rmse: 3.45682\tvalid_1's rmse: 3.74769\n",
      "Early stopping, best iteration is:\n",
      "[1084]\ttraining's rmse: 3.46911\tvalid_1's rmse: 3.7474\n",
      "Fold 7 RMSE: 3.74740\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.63739\tvalid_1's rmse: 3.63506\n",
      "[400]\ttraining's rmse: 3.5813\tvalid_1's rmse: 3.61425\n",
      "[600]\ttraining's rmse: 3.54613\tvalid_1's rmse: 3.60847\n",
      "[800]\ttraining's rmse: 3.51735\tvalid_1's rmse: 3.60566\n",
      "[1000]\ttraining's rmse: 3.49358\tvalid_1's rmse: 3.60493\n",
      "[1200]\ttraining's rmse: 3.47196\tvalid_1's rmse: 3.60423\n",
      "[1400]\ttraining's rmse: 3.45075\tvalid_1's rmse: 3.60403\n",
      "Early stopping, best iteration is:\n",
      "[1306]\ttraining's rmse: 3.4607\tvalid_1's rmse: 3.60372\n",
      "Fold 8 RMSE: 3.60372\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.6554\tvalid_1's rmse: 3.46463\n",
      "[400]\ttraining's rmse: 3.59813\tvalid_1's rmse: 3.45436\n",
      "[600]\ttraining's rmse: 3.56377\tvalid_1's rmse: 3.45111\n",
      "[800]\ttraining's rmse: 3.53562\tvalid_1's rmse: 3.45133\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's rmse: 3.54885\tvalid_1's rmse: 3.45089\n",
      "Fold 9 RMSE: 3.45089\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64729\n",
      "===================================\n",
      "[LightGBM] Top 80% ‚Üí 189 features (threshold ‚âà 33.2222)\n",
      "Starting 9-Fold CV with LightGBM...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61863\tvalid_1's rmse: 3.78973\n",
      "[400]\ttraining's rmse: 3.56147\tvalid_1's rmse: 3.76866\n",
      "[600]\ttraining's rmse: 3.52696\tvalid_1's rmse: 3.76268\n",
      "[800]\ttraining's rmse: 3.49849\tvalid_1's rmse: 3.76132\n",
      "[1000]\ttraining's rmse: 3.47362\tvalid_1's rmse: 3.76033\n",
      "[1200]\ttraining's rmse: 3.45132\tvalid_1's rmse: 3.76043\n",
      "Early stopping, best iteration is:\n",
      "[1054]\ttraining's rmse: 3.46755\tvalid_1's rmse: 3.76018\n",
      "Fold 1 RMSE: 3.76018\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.64716\tvalid_1's rmse: 3.54309\n",
      "[400]\ttraining's rmse: 3.59138\tvalid_1's rmse: 3.52386\n",
      "[600]\ttraining's rmse: 3.55605\tvalid_1's rmse: 3.51762\n",
      "[800]\ttraining's rmse: 3.52772\tvalid_1's rmse: 3.51527\n",
      "[1000]\ttraining's rmse: 3.50367\tvalid_1's rmse: 3.51431\n",
      "[1200]\ttraining's rmse: 3.48114\tvalid_1's rmse: 3.5135\n",
      "[1400]\ttraining's rmse: 3.46027\tvalid_1's rmse: 3.51342\n",
      "Early stopping, best iteration is:\n",
      "[1319]\ttraining's rmse: 3.46881\tvalid_1's rmse: 3.51306\n",
      "Fold 2 RMSE: 3.51306\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62751\tvalid_1's rmse: 3.71271\n",
      "[400]\ttraining's rmse: 3.57083\tvalid_1's rmse: 3.69771\n",
      "[600]\ttraining's rmse: 3.53496\tvalid_1's rmse: 3.69548\n",
      "[800]\ttraining's rmse: 3.50516\tvalid_1's rmse: 3.69441\n",
      "[1000]\ttraining's rmse: 3.48064\tvalid_1's rmse: 3.69402\n",
      "[1200]\ttraining's rmse: 3.45805\tvalid_1's rmse: 3.69374\n",
      "Early stopping, best iteration is:\n",
      "[1181]\ttraining's rmse: 3.46033\tvalid_1's rmse: 3.69364\n",
      "Fold 3 RMSE: 3.69364\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62771\tvalid_1's rmse: 3.70641\n",
      "[400]\ttraining's rmse: 3.57052\tvalid_1's rmse: 3.69137\n",
      "[600]\ttraining's rmse: 3.53584\tvalid_1's rmse: 3.68802\n",
      "[800]\ttraining's rmse: 3.50678\tvalid_1's rmse: 3.68731\n",
      "[1000]\ttraining's rmse: 3.48236\tvalid_1's rmse: 3.68664\n",
      "[1200]\ttraining's rmse: 3.45886\tvalid_1's rmse: 3.68638\n",
      "Early stopping, best iteration is:\n",
      "[1118]\ttraining's rmse: 3.46829\tvalid_1's rmse: 3.68613\n",
      "Fold 4 RMSE: 3.68613\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62709\tvalid_1's rmse: 3.71311\n",
      "[400]\ttraining's rmse: 3.57159\tvalid_1's rmse: 3.69251\n",
      "[600]\ttraining's rmse: 3.53712\tvalid_1's rmse: 3.68736\n",
      "[800]\ttraining's rmse: 3.50979\tvalid_1's rmse: 3.68592\n",
      "[1000]\ttraining's rmse: 3.48636\tvalid_1's rmse: 3.68603\n",
      "Early stopping, best iteration is:\n",
      "[871]\ttraining's rmse: 3.50094\tvalid_1's rmse: 3.68566\n",
      "Fold 5 RMSE: 3.68566\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62721\tvalid_1's rmse: 3.72329\n",
      "[400]\ttraining's rmse: 3.57107\tvalid_1's rmse: 3.69419\n",
      "[600]\ttraining's rmse: 3.53607\tvalid_1's rmse: 3.68256\n",
      "[800]\ttraining's rmse: 3.50823\tvalid_1's rmse: 3.67739\n",
      "[1000]\ttraining's rmse: 3.48449\tvalid_1's rmse: 3.6744\n",
      "[1200]\ttraining's rmse: 3.46209\tvalid_1's rmse: 3.67289\n",
      "[1400]\ttraining's rmse: 3.44164\tvalid_1's rmse: 3.67185\n",
      "[1600]\ttraining's rmse: 3.42195\tvalid_1's rmse: 3.67126\n",
      "[1800]\ttraining's rmse: 3.40188\tvalid_1's rmse: 3.6711\n",
      "[2000]\ttraining's rmse: 3.38258\tvalid_1's rmse: 3.67082\n",
      "Early stopping, best iteration is:\n",
      "[1925]\ttraining's rmse: 3.38962\tvalid_1's rmse: 3.67068\n",
      "Fold 6 RMSE: 3.67068\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61875\tvalid_1's rmse: 3.7853\n",
      "[400]\ttraining's rmse: 3.56326\tvalid_1's rmse: 3.76021\n",
      "[600]\ttraining's rmse: 3.52955\tvalid_1's rmse: 3.75214\n",
      "[800]\ttraining's rmse: 3.50198\tvalid_1's rmse: 3.74838\n",
      "[1000]\ttraining's rmse: 3.47754\tvalid_1's rmse: 3.7462\n",
      "[1200]\ttraining's rmse: 3.45599\tvalid_1's rmse: 3.74537\n",
      "[1400]\ttraining's rmse: 3.43557\tvalid_1's rmse: 3.74456\n",
      "Early stopping, best iteration is:\n",
      "[1449]\ttraining's rmse: 3.43051\tvalid_1's rmse: 3.74435\n",
      "Fold 7 RMSE: 3.74435\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.63845\tvalid_1's rmse: 3.63673\n",
      "[400]\ttraining's rmse: 3.58186\tvalid_1's rmse: 3.61484\n",
      "[600]\ttraining's rmse: 3.54649\tvalid_1's rmse: 3.60989\n",
      "[800]\ttraining's rmse: 3.51764\tvalid_1's rmse: 3.60774\n",
      "[1000]\ttraining's rmse: 3.49328\tvalid_1's rmse: 3.60667\n",
      "[1200]\ttraining's rmse: 3.47106\tvalid_1's rmse: 3.6057\n",
      "Early stopping, best iteration is:\n",
      "[1168]\ttraining's rmse: 3.47433\tvalid_1's rmse: 3.60551\n",
      "Fold 8 RMSE: 3.60551\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.65611\tvalid_1's rmse: 3.46583\n",
      "[400]\ttraining's rmse: 3.59917\tvalid_1's rmse: 3.45567\n",
      "[600]\ttraining's rmse: 3.56451\tvalid_1's rmse: 3.45331\n",
      "[800]\ttraining's rmse: 3.53569\tvalid_1's rmse: 3.45329\n",
      "Early stopping, best iteration is:\n",
      "[770]\ttraining's rmse: 3.53954\tvalid_1's rmse: 3.4531\n",
      "Fold 9 RMSE: 3.45310\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64711\n",
      "===================================\n",
      "[LightGBM] Top 70% ‚Üí 165 features (threshold ‚âà 60.0000)\n",
      "Starting 9-Fold CV with LightGBM...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61859\tvalid_1's rmse: 3.7908\n",
      "[400]\ttraining's rmse: 3.56253\tvalid_1's rmse: 3.77111\n",
      "[600]\ttraining's rmse: 3.5285\tvalid_1's rmse: 3.76534\n",
      "[800]\ttraining's rmse: 3.49975\tvalid_1's rmse: 3.76284\n",
      "[1000]\ttraining's rmse: 3.47543\tvalid_1's rmse: 3.76243\n",
      "[1200]\ttraining's rmse: 3.45403\tvalid_1's rmse: 3.76218\n",
      "[1400]\ttraining's rmse: 3.43349\tvalid_1's rmse: 3.76209\n",
      "Early stopping, best iteration is:\n",
      "[1325]\ttraining's rmse: 3.44124\tvalid_1's rmse: 3.76181\n",
      "Fold 1 RMSE: 3.76181\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.64723\tvalid_1's rmse: 3.54174\n",
      "[400]\ttraining's rmse: 3.59144\tvalid_1's rmse: 3.52242\n",
      "[600]\ttraining's rmse: 3.55778\tvalid_1's rmse: 3.51762\n",
      "[800]\ttraining's rmse: 3.52967\tvalid_1's rmse: 3.51511\n",
      "[1000]\ttraining's rmse: 3.50542\tvalid_1's rmse: 3.5146\n",
      "[1200]\ttraining's rmse: 3.48298\tvalid_1's rmse: 3.51397\n",
      "Early stopping, best iteration is:\n",
      "[1208]\ttraining's rmse: 3.48224\tvalid_1's rmse: 3.51394\n",
      "Fold 2 RMSE: 3.51394\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62774\tvalid_1's rmse: 3.71304\n",
      "[400]\ttraining's rmse: 3.57055\tvalid_1's rmse: 3.69842\n",
      "[600]\ttraining's rmse: 3.5349\tvalid_1's rmse: 3.69561\n",
      "[800]\ttraining's rmse: 3.50578\tvalid_1's rmse: 3.69424\n",
      "[1000]\ttraining's rmse: 3.48115\tvalid_1's rmse: 3.69354\n",
      "Early stopping, best iteration is:\n",
      "[1048]\ttraining's rmse: 3.47612\tvalid_1's rmse: 3.69319\n",
      "Fold 3 RMSE: 3.69319\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62726\tvalid_1's rmse: 3.70525\n",
      "[400]\ttraining's rmse: 3.57123\tvalid_1's rmse: 3.68994\n",
      "[600]\ttraining's rmse: 3.53678\tvalid_1's rmse: 3.68634\n",
      "[800]\ttraining's rmse: 3.50878\tvalid_1's rmse: 3.68472\n",
      "[1000]\ttraining's rmse: 3.48406\tvalid_1's rmse: 3.68464\n",
      "Early stopping, best iteration is:\n",
      "[881]\ttraining's rmse: 3.4987\tvalid_1's rmse: 3.68407\n",
      "Fold 4 RMSE: 3.68407\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62728\tvalid_1's rmse: 3.71317\n",
      "[400]\ttraining's rmse: 3.57157\tvalid_1's rmse: 3.69214\n",
      "[600]\ttraining's rmse: 3.53717\tvalid_1's rmse: 3.68719\n",
      "[800]\ttraining's rmse: 3.50993\tvalid_1's rmse: 3.68579\n",
      "Early stopping, best iteration is:\n",
      "[781]\ttraining's rmse: 3.51212\tvalid_1's rmse: 3.68563\n",
      "Fold 5 RMSE: 3.68563\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62688\tvalid_1's rmse: 3.724\n",
      "[400]\ttraining's rmse: 3.57137\tvalid_1's rmse: 3.69615\n",
      "[600]\ttraining's rmse: 3.53651\tvalid_1's rmse: 3.68469\n",
      "[800]\ttraining's rmse: 3.50901\tvalid_1's rmse: 3.6797\n",
      "[1000]\ttraining's rmse: 3.48484\tvalid_1's rmse: 3.6769\n",
      "[1200]\ttraining's rmse: 3.46321\tvalid_1's rmse: 3.67513\n",
      "[1400]\ttraining's rmse: 3.44276\tvalid_1's rmse: 3.67409\n",
      "[1600]\ttraining's rmse: 3.42265\tvalid_1's rmse: 3.67335\n",
      "[1800]\ttraining's rmse: 3.40325\tvalid_1's rmse: 3.67285\n",
      "[2000]\ttraining's rmse: 3.38449\tvalid_1's rmse: 3.67256\n",
      "[2200]\ttraining's rmse: 3.36667\tvalid_1's rmse: 3.67249\n",
      "Early stopping, best iteration is:\n",
      "[2071]\ttraining's rmse: 3.37818\tvalid_1's rmse: 3.67232\n",
      "Fold 6 RMSE: 3.67232\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61917\tvalid_1's rmse: 3.7853\n",
      "[400]\ttraining's rmse: 3.56328\tvalid_1's rmse: 3.76077\n",
      "[600]\ttraining's rmse: 3.52924\tvalid_1's rmse: 3.75313\n",
      "[800]\ttraining's rmse: 3.50359\tvalid_1's rmse: 3.74962\n",
      "[1000]\ttraining's rmse: 3.47984\tvalid_1's rmse: 3.74805\n",
      "[1200]\ttraining's rmse: 3.45758\tvalid_1's rmse: 3.74662\n",
      "[1400]\ttraining's rmse: 3.43692\tvalid_1's rmse: 3.74576\n",
      "Early stopping, best iteration is:\n",
      "[1404]\ttraining's rmse: 3.43653\tvalid_1's rmse: 3.74572\n",
      "Fold 7 RMSE: 3.74572\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.63801\tvalid_1's rmse: 3.63501\n",
      "[400]\ttraining's rmse: 3.58222\tvalid_1's rmse: 3.61315\n",
      "[600]\ttraining's rmse: 3.54663\tvalid_1's rmse: 3.60735\n",
      "[800]\ttraining's rmse: 3.51893\tvalid_1's rmse: 3.60488\n",
      "[1000]\ttraining's rmse: 3.49434\tvalid_1's rmse: 3.60419\n",
      "[1200]\ttraining's rmse: 3.4721\tvalid_1's rmse: 3.60354\n",
      "Early stopping, best iteration is:\n",
      "[1209]\ttraining's rmse: 3.47113\tvalid_1's rmse: 3.60352\n",
      "Fold 8 RMSE: 3.60352\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.65637\tvalid_1's rmse: 3.46523\n",
      "[400]\ttraining's rmse: 3.59942\tvalid_1's rmse: 3.45478\n",
      "[600]\ttraining's rmse: 3.56535\tvalid_1's rmse: 3.45243\n",
      "[800]\ttraining's rmse: 3.53728\tvalid_1's rmse: 3.45202\n",
      "Early stopping, best iteration is:\n",
      "[737]\ttraining's rmse: 3.54523\tvalid_1's rmse: 3.45176\n",
      "Fold 9 RMSE: 3.45176\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64709\n",
      "===================================\n",
      "[LightGBM] Top 60% ‚Üí 142 features (threshold ‚âà 107.7778)\n",
      "Starting 9-Fold CV with LightGBM...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61985\tvalid_1's rmse: 3.79131\n",
      "[400]\ttraining's rmse: 3.56427\tvalid_1's rmse: 3.77086\n",
      "[600]\ttraining's rmse: 3.52949\tvalid_1's rmse: 3.76446\n",
      "[800]\ttraining's rmse: 3.50166\tvalid_1's rmse: 3.76231\n",
      "[1000]\ttraining's rmse: 3.47732\tvalid_1's rmse: 3.76148\n",
      "Early stopping, best iteration is:\n",
      "[948]\ttraining's rmse: 3.48351\tvalid_1's rmse: 3.76109\n",
      "Fold 1 RMSE: 3.76109\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.64736\tvalid_1's rmse: 3.5431\n",
      "[400]\ttraining's rmse: 3.59188\tvalid_1's rmse: 3.52363\n",
      "[600]\ttraining's rmse: 3.55707\tvalid_1's rmse: 3.51777\n",
      "[800]\ttraining's rmse: 3.53032\tvalid_1's rmse: 3.51587\n",
      "[1000]\ttraining's rmse: 3.5059\tvalid_1's rmse: 3.51466\n",
      "[1200]\ttraining's rmse: 3.48266\tvalid_1's rmse: 3.51395\n",
      "[1400]\ttraining's rmse: 3.46146\tvalid_1's rmse: 3.51413\n",
      "Early stopping, best iteration is:\n",
      "[1309]\ttraining's rmse: 3.47112\tvalid_1's rmse: 3.51378\n",
      "Fold 2 RMSE: 3.51378\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62768\tvalid_1's rmse: 3.7141\n",
      "[400]\ttraining's rmse: 3.57142\tvalid_1's rmse: 3.70017\n",
      "[600]\ttraining's rmse: 3.53578\tvalid_1's rmse: 3.69624\n",
      "[800]\ttraining's rmse: 3.50753\tvalid_1's rmse: 3.69446\n",
      "[1000]\ttraining's rmse: 3.48295\tvalid_1's rmse: 3.69439\n",
      "Early stopping, best iteration is:\n",
      "[915]\ttraining's rmse: 3.49315\tvalid_1's rmse: 3.69409\n",
      "Fold 3 RMSE: 3.69409\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62803\tvalid_1's rmse: 3.70353\n",
      "[400]\ttraining's rmse: 3.5715\tvalid_1's rmse: 3.68919\n",
      "[600]\ttraining's rmse: 3.53642\tvalid_1's rmse: 3.68557\n",
      "[800]\ttraining's rmse: 3.50871\tvalid_1's rmse: 3.68484\n",
      "[1000]\ttraining's rmse: 3.48356\tvalid_1's rmse: 3.68435\n",
      "[1200]\ttraining's rmse: 3.46007\tvalid_1's rmse: 3.68415\n",
      "Early stopping, best iteration is:\n",
      "[1222]\ttraining's rmse: 3.45777\tvalid_1's rmse: 3.68399\n",
      "Fold 4 RMSE: 3.68399\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62824\tvalid_1's rmse: 3.71184\n",
      "[400]\ttraining's rmse: 3.57315\tvalid_1's rmse: 3.69123\n",
      "[600]\ttraining's rmse: 3.53892\tvalid_1's rmse: 3.68688\n",
      "[800]\ttraining's rmse: 3.51206\tvalid_1's rmse: 3.6858\n",
      "Early stopping, best iteration is:\n",
      "[734]\ttraining's rmse: 3.52028\tvalid_1's rmse: 3.68566\n",
      "Fold 5 RMSE: 3.68566\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62737\tvalid_1's rmse: 3.72366\n",
      "[400]\ttraining's rmse: 3.57163\tvalid_1's rmse: 3.69473\n",
      "[600]\ttraining's rmse: 3.53682\tvalid_1's rmse: 3.68391\n",
      "[800]\ttraining's rmse: 3.50956\tvalid_1's rmse: 3.67743\n",
      "[1000]\ttraining's rmse: 3.48595\tvalid_1's rmse: 3.67412\n",
      "[1200]\ttraining's rmse: 3.46487\tvalid_1's rmse: 3.67237\n",
      "[1400]\ttraining's rmse: 3.44406\tvalid_1's rmse: 3.67121\n",
      "[1600]\ttraining's rmse: 3.42362\tvalid_1's rmse: 3.67011\n",
      "[1800]\ttraining's rmse: 3.40404\tvalid_1's rmse: 3.66925\n",
      "[2000]\ttraining's rmse: 3.38585\tvalid_1's rmse: 3.66893\n",
      "Early stopping, best iteration is:\n",
      "[1985]\ttraining's rmse: 3.38709\tvalid_1's rmse: 3.66881\n",
      "Fold 6 RMSE: 3.66881\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61915\tvalid_1's rmse: 3.78606\n",
      "[400]\ttraining's rmse: 3.56436\tvalid_1's rmse: 3.76175\n",
      "[600]\ttraining's rmse: 3.5309\tvalid_1's rmse: 3.7537\n",
      "[800]\ttraining's rmse: 3.50466\tvalid_1's rmse: 3.74939\n",
      "[1000]\ttraining's rmse: 3.48055\tvalid_1's rmse: 3.74738\n",
      "Early stopping, best iteration is:\n",
      "[990]\ttraining's rmse: 3.48186\tvalid_1's rmse: 3.74723\n",
      "Fold 7 RMSE: 3.74723\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.63836\tvalid_1's rmse: 3.63309\n",
      "[400]\ttraining's rmse: 3.58341\tvalid_1's rmse: 3.61212\n",
      "[600]\ttraining's rmse: 3.54729\tvalid_1's rmse: 3.60619\n",
      "[800]\ttraining's rmse: 3.51913\tvalid_1's rmse: 3.60411\n",
      "[1000]\ttraining's rmse: 3.49584\tvalid_1's rmse: 3.60299\n",
      "[1200]\ttraining's rmse: 3.47252\tvalid_1's rmse: 3.60246\n",
      "[1400]\ttraining's rmse: 3.45057\tvalid_1's rmse: 3.60144\n",
      "[1600]\ttraining's rmse: 3.43001\tvalid_1's rmse: 3.60129\n",
      "Early stopping, best iteration is:\n",
      "[1490]\ttraining's rmse: 3.44153\tvalid_1's rmse: 3.60107\n",
      "Fold 8 RMSE: 3.60107\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.65636\tvalid_1's rmse: 3.46456\n",
      "[400]\ttraining's rmse: 3.59999\tvalid_1's rmse: 3.45423\n",
      "[600]\ttraining's rmse: 3.56584\tvalid_1's rmse: 3.45215\n",
      "Early stopping, best iteration is:\n",
      "[626]\ttraining's rmse: 3.56159\tvalid_1's rmse: 3.45178\n",
      "Fold 9 RMSE: 3.45178\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64660\n",
      "===================================\n",
      "\n",
      "Best Percentile Threshold Summary\n",
      "========================================\n",
      "percentile          60.000000\n",
      "threshold_value    107.777778\n",
      "num_features       142.000000\n",
      "rmse                 3.646598\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective'         : 'regression',\n",
    "    'boosting_type'     : 'gbdt',\n",
    "    'metric'            : 'rmse',\n",
    "    'learning_rate'     : 0.01,\n",
    "    'num_leaves': 43,\n",
    "    'colsample_bytree': 0.37833128023384316,\n",
    "    'subsample': 0.020581374607877696,\n",
    "    'max_depth': 11,\n",
    "    'reg_alpha': 4.926058053299857,\n",
    "    'reg_lambda': 8.077177812556824,\n",
    "    'min_split_gain': 4.326677551210331,\n",
    "    'min_child_weight': 441.95211148401055,\n",
    "    'min_data_in_leaf': 16,\n",
    "    'nthread'           : 8\n",
    "    \n",
    "} \n",
    "best_lgb_percentile, lgb_percentile_results = find_best_feature_percentile(\n",
    "    model_fn=prediction_with_best_parameters,\n",
    "    feature_df=feature_importance_df_lgb,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    test_df=test,\n",
    "    param=param,\n",
    "    model_name=\"LightGBM\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retaining 200 features. Dropping 37.\n",
      "Starting 9-Fold CV with LightGBM...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.6185\tvalid_1's rmse: 3.7903\n",
      "[400]\ttraining's rmse: 3.56272\tvalid_1's rmse: 3.76918\n",
      "[600]\ttraining's rmse: 3.528\tvalid_1's rmse: 3.76333\n",
      "[800]\ttraining's rmse: 3.49987\tvalid_1's rmse: 3.76152\n",
      "[1000]\ttraining's rmse: 3.47583\tvalid_1's rmse: 3.76085\n",
      "Early stopping, best iteration is:\n",
      "[990]\ttraining's rmse: 3.4769\tvalid_1's rmse: 3.76076\n",
      "Fold 1 RMSE: 3.76076\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.64655\tvalid_1's rmse: 3.54211\n",
      "[400]\ttraining's rmse: 3.5906\tvalid_1's rmse: 3.52338\n",
      "[600]\ttraining's rmse: 3.55674\tvalid_1's rmse: 3.51777\n",
      "[800]\ttraining's rmse: 3.52951\tvalid_1's rmse: 3.51546\n",
      "[1000]\ttraining's rmse: 3.50493\tvalid_1's rmse: 3.51446\n",
      "[1200]\ttraining's rmse: 3.48209\tvalid_1's rmse: 3.51341\n",
      "Early stopping, best iteration is:\n",
      "[1218]\ttraining's rmse: 3.48014\tvalid_1's rmse: 3.51338\n",
      "Fold 2 RMSE: 3.51338\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62726\tvalid_1's rmse: 3.71249\n",
      "[400]\ttraining's rmse: 3.57055\tvalid_1's rmse: 3.69733\n",
      "[600]\ttraining's rmse: 3.53464\tvalid_1's rmse: 3.69533\n",
      "[800]\ttraining's rmse: 3.50573\tvalid_1's rmse: 3.69354\n",
      "[1000]\ttraining's rmse: 3.48181\tvalid_1's rmse: 3.69329\n",
      "[1200]\ttraining's rmse: 3.45977\tvalid_1's rmse: 3.69327\n",
      "Early stopping, best iteration is:\n",
      "[1136]\ttraining's rmse: 3.46667\tvalid_1's rmse: 3.69299\n",
      "Fold 3 RMSE: 3.69299\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.6271\tvalid_1's rmse: 3.70609\n",
      "[400]\ttraining's rmse: 3.56997\tvalid_1's rmse: 3.69071\n",
      "[600]\ttraining's rmse: 3.53535\tvalid_1's rmse: 3.68783\n",
      "[800]\ttraining's rmse: 3.5065\tvalid_1's rmse: 3.68689\n",
      "Early stopping, best iteration is:\n",
      "[848]\ttraining's rmse: 3.50049\tvalid_1's rmse: 3.68636\n",
      "Fold 4 RMSE: 3.68636\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62728\tvalid_1's rmse: 3.71169\n",
      "[400]\ttraining's rmse: 3.57183\tvalid_1's rmse: 3.68936\n",
      "[600]\ttraining's rmse: 3.53752\tvalid_1's rmse: 3.68511\n",
      "[800]\ttraining's rmse: 3.50999\tvalid_1's rmse: 3.68352\n",
      "[1000]\ttraining's rmse: 3.48637\tvalid_1's rmse: 3.68347\n",
      "Early stopping, best iteration is:\n",
      "[861]\ttraining's rmse: 3.50297\tvalid_1's rmse: 3.68325\n",
      "Fold 5 RMSE: 3.68325\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.62669\tvalid_1's rmse: 3.72325\n",
      "[400]\ttraining's rmse: 3.57092\tvalid_1's rmse: 3.69495\n",
      "[600]\ttraining's rmse: 3.53598\tvalid_1's rmse: 3.68311\n",
      "[800]\ttraining's rmse: 3.50858\tvalid_1's rmse: 3.67734\n",
      "[1000]\ttraining's rmse: 3.48506\tvalid_1's rmse: 3.6748\n",
      "[1200]\ttraining's rmse: 3.46316\tvalid_1's rmse: 3.6729\n",
      "[1400]\ttraining's rmse: 3.44162\tvalid_1's rmse: 3.67158\n",
      "[1600]\ttraining's rmse: 3.42228\tvalid_1's rmse: 3.67138\n",
      "[1800]\ttraining's rmse: 3.40288\tvalid_1's rmse: 3.6708\n",
      "[2000]\ttraining's rmse: 3.38373\tvalid_1's rmse: 3.67036\n",
      "[2200]\ttraining's rmse: 3.364\tvalid_1's rmse: 3.66996\n",
      "[2400]\ttraining's rmse: 3.34669\tvalid_1's rmse: 3.66967\n",
      "[2600]\ttraining's rmse: 3.32862\tvalid_1's rmse: 3.66905\n",
      "Early stopping, best iteration is:\n",
      "[2602]\ttraining's rmse: 3.3284\tvalid_1's rmse: 3.66901\n",
      "Fold 6 RMSE: 3.66901\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.61885\tvalid_1's rmse: 3.78518\n",
      "[400]\ttraining's rmse: 3.56277\tvalid_1's rmse: 3.75983\n",
      "[600]\ttraining's rmse: 3.52854\tvalid_1's rmse: 3.75248\n",
      "[800]\ttraining's rmse: 3.50191\tvalid_1's rmse: 3.74945\n",
      "[1000]\ttraining's rmse: 3.47835\tvalid_1's rmse: 3.74847\n",
      "[1200]\ttraining's rmse: 3.45715\tvalid_1's rmse: 3.74811\n",
      "Early stopping, best iteration is:\n",
      "[1119]\ttraining's rmse: 3.46548\tvalid_1's rmse: 3.74779\n",
      "Fold 7 RMSE: 3.74779\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.63751\tvalid_1's rmse: 3.63439\n",
      "[400]\ttraining's rmse: 3.58172\tvalid_1's rmse: 3.61434\n",
      "[600]\ttraining's rmse: 3.54658\tvalid_1's rmse: 3.60832\n",
      "[800]\ttraining's rmse: 3.51751\tvalid_1's rmse: 3.60647\n",
      "[1000]\ttraining's rmse: 3.49332\tvalid_1's rmse: 3.60505\n",
      "[1200]\ttraining's rmse: 3.47124\tvalid_1's rmse: 3.60411\n",
      "[1400]\ttraining's rmse: 3.45066\tvalid_1's rmse: 3.60286\n",
      "[1600]\ttraining's rmse: 3.42852\tvalid_1's rmse: 3.60294\n",
      "Early stopping, best iteration is:\n",
      "[1476]\ttraining's rmse: 3.44192\tvalid_1's rmse: 3.60268\n",
      "Fold 8 RMSE: 3.60268\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's rmse: 3.65619\tvalid_1's rmse: 3.46484\n",
      "[400]\ttraining's rmse: 3.59883\tvalid_1's rmse: 3.45496\n",
      "[600]\ttraining's rmse: 3.56437\tvalid_1's rmse: 3.45282\n",
      "[800]\ttraining's rmse: 3.53567\tvalid_1's rmse: 3.45248\n",
      "Early stopping, best iteration is:\n",
      "[814]\ttraining's rmse: 3.53366\tvalid_1's rmse: 3.45234\n",
      "Fold 9 RMSE: 3.45234\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64671\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# We will cut the dataset with the threshold\n",
    "avg_importance = (feature_importance_df_lgb\n",
    "                  .groupby('Feature')['importance']\n",
    "                  .mean()\n",
    "                  .sort_values(ascending=False))\n",
    "\n",
    "# Decide a threshold (example: drop features with importance < 15)\n",
    "threshold = 23.111111\n",
    "selected_features = avg_importance[avg_importance >= threshold].index.tolist()\n",
    "discarded_features = avg_importance[avg_importance < threshold].index.tolist()\n",
    "\n",
    "print(f\"Retaining {len(selected_features)} features. Dropping {len(discarded_features)}.\")\n",
    "lightbgm_reg_final, pred_y_train_final, pred_y_test_final, feature_importance_final, rmse_lgb_final = prediction_with_best_parameters(\n",
    "    best_params=param,\n",
    "    n_splits=9,\n",
    "    X_train=X_train[selected_features],\n",
    "    y_train=y_train,\n",
    "    test_df=test[selected_features],\n",
    "    num_round=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-4.320745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.187454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-1.190990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.125820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.417582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123618</th>\n",
       "      <td>C_ID_7a239d2eda</td>\n",
       "      <td>0.757834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123619</th>\n",
       "      <td>C_ID_75ace375ae</td>\n",
       "      <td>-0.568017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123620</th>\n",
       "      <td>C_ID_21d56d950c</td>\n",
       "      <td>0.539706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123621</th>\n",
       "      <td>C_ID_6c46fc5a9d</td>\n",
       "      <td>-3.891313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123622</th>\n",
       "      <td>C_ID_87e7979a5f</td>\n",
       "      <td>0.158315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123623 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id    target\n",
       "0       C_ID_0ab67a22ab -4.320745\n",
       "1       C_ID_130fd0cbdd -0.187454\n",
       "2       C_ID_b709037bc5 -1.190990\n",
       "3       C_ID_d27d835a9f -0.125820\n",
       "4       C_ID_2b5e3df5c2 -1.417582\n",
       "...                 ...       ...\n",
       "123618  C_ID_7a239d2eda  0.757834\n",
       "123619  C_ID_75ace375ae -0.568017\n",
       "123620  C_ID_21d56d950c  0.539706\n",
       "123621  C_ID_6c46fc5a9d -3.891313\n",
       "123622  C_ID_87e7979a5f  0.158315\n",
       "\n",
       "[123623 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgb_fs = test[[\"card_id\"]].copy()\n",
    "best_lgb_fs[\"target\"] = pred_y_test_final\n",
    "best_lgb_fs.to_csv(\"lgb_fs_latest.csv\", index=False)\n",
    "best_lgb_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost] Top 90% ‚Üí 209 features (threshold ‚âà 190.3247)\n",
      "Starting 9-Fold CV with XGBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "[0]\ttrain-rmse:3.82643\tvalid-rmse:3.95369\n",
      "[200]\ttrain-rmse:3.53023\tvalid-rmse:3.77827\n",
      "[400]\ttrain-rmse:3.44476\tvalid-rmse:3.76149\n",
      "[600]\ttrain-rmse:3.39451\tvalid-rmse:3.75692\n",
      "[800]\ttrain-rmse:3.35068\tvalid-rmse:3.75452\n",
      "[997]\ttrain-rmse:3.30839\tvalid-rmse:3.75521\n",
      "Fold 1 RMSE: 3.75408\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.85919\tvalid-rmse:3.68865\n",
      "[200]\ttrain-rmse:3.55988\tvalid-rmse:3.53050\n",
      "[400]\ttrain-rmse:3.47526\tvalid-rmse:3.51625\n",
      "[600]\ttrain-rmse:3.42433\tvalid-rmse:3.51275\n",
      "[800]\ttrain-rmse:3.37965\tvalid-rmse:3.51244\n",
      "[858]\ttrain-rmse:3.36656\tvalid-rmse:3.51250\n",
      "Fold 2 RMSE: 3.51237\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83765\tvalid-rmse:3.86333\n",
      "[200]\ttrain-rmse:3.53929\tvalid-rmse:3.70337\n",
      "[400]\ttrain-rmse:3.45117\tvalid-rmse:3.69379\n",
      "[534]\ttrain-rmse:3.41338\tvalid-rmse:3.69350\n",
      "Fold 3 RMSE: 3.69334\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83842\tvalid-rmse:3.85915\n",
      "[200]\ttrain-rmse:3.54028\tvalid-rmse:3.69507\n",
      "[400]\ttrain-rmse:3.45232\tvalid-rmse:3.68390\n",
      "[600]\ttrain-rmse:3.39748\tvalid-rmse:3.68267\n",
      "[624]\ttrain-rmse:3.39153\tvalid-rmse:3.68274\n",
      "Fold 4 RMSE: 3.68261\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83460\tvalid-rmse:3.88810\n",
      "[200]\ttrain-rmse:3.54294\tvalid-rmse:3.70137\n",
      "[400]\ttrain-rmse:3.45609\tvalid-rmse:3.68755\n",
      "[600]\ttrain-rmse:3.40589\tvalid-rmse:3.68621\n",
      "[800]\ttrain-rmse:3.36219\tvalid-rmse:3.68567\n",
      "[991]\ttrain-rmse:3.32304\tvalid-rmse:3.68557\n",
      "Fold 5 RMSE: 3.68520\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83076\tvalid-rmse:3.92027\n",
      "[200]\ttrain-rmse:3.54236\tvalid-rmse:3.69796\n",
      "[400]\ttrain-rmse:3.45911\tvalid-rmse:3.67290\n",
      "[600]\ttrain-rmse:3.40642\tvalid-rmse:3.66444\n",
      "[800]\ttrain-rmse:3.36201\tvalid-rmse:3.65908\n",
      "[1000]\ttrain-rmse:3.31992\tvalid-rmse:3.65729\n",
      "[1200]\ttrain-rmse:3.28157\tvalid-rmse:3.65672\n",
      "[1400]\ttrain-rmse:3.24377\tvalid-rmse:3.65506\n",
      "[1570]\ttrain-rmse:3.21075\tvalid-rmse:3.65566\n",
      "Fold 6 RMSE: 3.65479\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.82519\tvalid-rmse:3.96264\n",
      "[200]\ttrain-rmse:3.52965\tvalid-rmse:3.77956\n",
      "[400]\ttrain-rmse:3.44460\tvalid-rmse:3.75807\n",
      "[600]\ttrain-rmse:3.39488\tvalid-rmse:3.75334\n",
      "[800]\ttrain-rmse:3.35463\tvalid-rmse:3.75168\n",
      "[1000]\ttrain-rmse:3.31450\tvalid-rmse:3.75005\n",
      "[1118]\ttrain-rmse:3.29108\tvalid-rmse:3.74981\n",
      "Fold 7 RMSE: 3.74972\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.84463\tvalid-rmse:3.80949\n",
      "[200]\ttrain-rmse:3.55088\tvalid-rmse:3.62136\n",
      "[400]\ttrain-rmse:3.46190\tvalid-rmse:3.60602\n",
      "[600]\ttrain-rmse:3.40684\tvalid-rmse:3.60317\n",
      "[714]\ttrain-rmse:3.38234\tvalid-rmse:3.60392\n",
      "Fold 8 RMSE: 3.60270\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.86820\tvalid-rmse:3.61193\n",
      "[200]\ttrain-rmse:3.56863\tvalid-rmse:3.45149\n",
      "[400]\ttrain-rmse:3.48081\tvalid-rmse:3.44623\n",
      "[600]\ttrain-rmse:3.42651\tvalid-rmse:3.44678\n",
      "[697]\ttrain-rmse:3.40578\tvalid-rmse:3.44769\n",
      "Fold 9 RMSE: 3.44590\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64363\n",
      "===================================\n",
      "[XGBoost] Top 80% ‚Üí 186 features (threshold ‚âà 220.7812)\n",
      "Starting 9-Fold CV with XGBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "[0]\ttrain-rmse:3.82634\tvalid-rmse:3.95337\n",
      "[200]\ttrain-rmse:3.52974\tvalid-rmse:3.77987\n",
      "[400]\ttrain-rmse:3.44244\tvalid-rmse:3.76310\n",
      "[600]\ttrain-rmse:3.38641\tvalid-rmse:3.75911\n",
      "[800]\ttrain-rmse:3.33626\tvalid-rmse:3.75755\n",
      "[1000]\ttrain-rmse:3.29203\tvalid-rmse:3.75662\n",
      "[1058]\ttrain-rmse:3.27905\tvalid-rmse:3.75647\n",
      "Fold 1 RMSE: 3.75598\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.85905\tvalid-rmse:3.68836\n",
      "[200]\ttrain-rmse:3.56060\tvalid-rmse:3.52927\n",
      "[400]\ttrain-rmse:3.47277\tvalid-rmse:3.51511\n",
      "[600]\ttrain-rmse:3.41692\tvalid-rmse:3.51303\n",
      "[800]\ttrain-rmse:3.36985\tvalid-rmse:3.51258\n",
      "[840]\ttrain-rmse:3.35996\tvalid-rmse:3.51217\n",
      "Fold 2 RMSE: 3.51211\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83756\tvalid-rmse:3.86309\n",
      "[200]\ttrain-rmse:3.53944\tvalid-rmse:3.70251\n",
      "[400]\ttrain-rmse:3.45035\tvalid-rmse:3.69419\n",
      "[600]\ttrain-rmse:3.39250\tvalid-rmse:3.69284\n",
      "[800]\ttrain-rmse:3.34607\tvalid-rmse:3.69298\n",
      "[853]\ttrain-rmse:3.33454\tvalid-rmse:3.69355\n",
      "Fold 3 RMSE: 3.69232\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83820\tvalid-rmse:3.85904\n",
      "[200]\ttrain-rmse:3.54169\tvalid-rmse:3.69596\n",
      "[400]\ttrain-rmse:3.45058\tvalid-rmse:3.68418\n",
      "[600]\ttrain-rmse:3.39308\tvalid-rmse:3.68225\n",
      "[800]\ttrain-rmse:3.34538\tvalid-rmse:3.68208\n",
      "[819]\ttrain-rmse:3.34093\tvalid-rmse:3.68245\n",
      "Fold 4 RMSE: 3.68164\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83453\tvalid-rmse:3.88776\n",
      "[200]\ttrain-rmse:3.54178\tvalid-rmse:3.70257\n",
      "[400]\ttrain-rmse:3.45446\tvalid-rmse:3.68825\n",
      "[600]\ttrain-rmse:3.40001\tvalid-rmse:3.68584\n",
      "[800]\ttrain-rmse:3.35622\tvalid-rmse:3.68554\n",
      "[1000]\ttrain-rmse:3.31134\tvalid-rmse:3.68605\n",
      "[1013]\ttrain-rmse:3.30847\tvalid-rmse:3.68599\n",
      "Fold 5 RMSE: 3.68507\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83046\tvalid-rmse:3.92012\n",
      "[200]\ttrain-rmse:3.54219\tvalid-rmse:3.69612\n",
      "[400]\ttrain-rmse:3.45645\tvalid-rmse:3.66973\n",
      "[600]\ttrain-rmse:3.40093\tvalid-rmse:3.66250\n",
      "[800]\ttrain-rmse:3.35424\tvalid-rmse:3.65869\n",
      "[1000]\ttrain-rmse:3.30894\tvalid-rmse:3.65647\n",
      "[1200]\ttrain-rmse:3.26809\tvalid-rmse:3.65468\n",
      "[1400]\ttrain-rmse:3.22504\tvalid-rmse:3.65356\n",
      "[1600]\ttrain-rmse:3.18519\tvalid-rmse:3.65194\n",
      "[1800]\ttrain-rmse:3.14394\tvalid-rmse:3.65198\n",
      "[1863]\ttrain-rmse:3.13261\tvalid-rmse:3.65229\n",
      "Fold 6 RMSE: 3.65132\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.82501\tvalid-rmse:3.96258\n",
      "[200]\ttrain-rmse:3.53220\tvalid-rmse:3.77790\n",
      "[400]\ttrain-rmse:3.44381\tvalid-rmse:3.75700\n",
      "[600]\ttrain-rmse:3.38980\tvalid-rmse:3.75224\n",
      "[800]\ttrain-rmse:3.34329\tvalid-rmse:3.74956\n",
      "[1000]\ttrain-rmse:3.29770\tvalid-rmse:3.74694\n",
      "[1200]\ttrain-rmse:3.25525\tvalid-rmse:3.74612\n",
      "[1367]\ttrain-rmse:3.22112\tvalid-rmse:3.74582\n",
      "Fold 7 RMSE: 3.74581\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.84441\tvalid-rmse:3.80915\n",
      "[200]\ttrain-rmse:3.54995\tvalid-rmse:3.62105\n",
      "[400]\ttrain-rmse:3.46125\tvalid-rmse:3.60527\n",
      "[600]\ttrain-rmse:3.40510\tvalid-rmse:3.60151\n",
      "[800]\ttrain-rmse:3.35780\tvalid-rmse:3.60140\n",
      "[1000]\ttrain-rmse:3.31397\tvalid-rmse:3.60098\n",
      "[1200]\ttrain-rmse:3.27419\tvalid-rmse:3.60113\n",
      "[1213]\ttrain-rmse:3.27135\tvalid-rmse:3.60122\n",
      "Fold 8 RMSE: 3.60045\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.86805\tvalid-rmse:3.61172\n",
      "[200]\ttrain-rmse:3.56777\tvalid-rmse:3.45431\n",
      "[400]\ttrain-rmse:3.47901\tvalid-rmse:3.44717\n",
      "[600]\ttrain-rmse:3.42356\tvalid-rmse:3.44591\n",
      "[739]\ttrain-rmse:3.38880\tvalid-rmse:3.44694\n",
      "Fold 9 RMSE: 3.44573\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64249\n",
      "===================================\n",
      "[XGBoost] Top 70% ‚Üí 163 features (threshold ‚âà 242.1383)\n",
      "Starting 9-Fold CV with XGBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "[0]\ttrain-rmse:3.82618\tvalid-rmse:3.95351\n",
      "[200]\ttrain-rmse:3.52894\tvalid-rmse:3.77923\n",
      "[400]\ttrain-rmse:3.44404\tvalid-rmse:3.76419\n",
      "[600]\ttrain-rmse:3.38816\tvalid-rmse:3.76053\n",
      "[800]\ttrain-rmse:3.33601\tvalid-rmse:3.76161\n",
      "[851]\ttrain-rmse:3.32343\tvalid-rmse:3.76172\n",
      "Fold 1 RMSE: 3.75993\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.85898\tvalid-rmse:3.68866\n",
      "[200]\ttrain-rmse:3.56223\tvalid-rmse:3.53043\n",
      "[400]\ttrain-rmse:3.47554\tvalid-rmse:3.51456\n",
      "[600]\ttrain-rmse:3.42027\tvalid-rmse:3.51062\n",
      "[800]\ttrain-rmse:3.37033\tvalid-rmse:3.51082\n",
      "[1000]\ttrain-rmse:3.32355\tvalid-rmse:3.51018\n",
      "[1200]\ttrain-rmse:3.27708\tvalid-rmse:3.50961\n",
      "[1332]\ttrain-rmse:3.24874\tvalid-rmse:3.50985\n",
      "Fold 2 RMSE: 3.50933\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83766\tvalid-rmse:3.86326\n",
      "[200]\ttrain-rmse:3.54091\tvalid-rmse:3.70355\n",
      "[400]\ttrain-rmse:3.45392\tvalid-rmse:3.69535\n",
      "[600]\ttrain-rmse:3.39591\tvalid-rmse:3.69264\n",
      "[800]\ttrain-rmse:3.34751\tvalid-rmse:3.69159\n",
      "[1000]\ttrain-rmse:3.30034\tvalid-rmse:3.69099\n",
      "[1138]\ttrain-rmse:3.26941\tvalid-rmse:3.69196\n",
      "Fold 3 RMSE: 3.69080\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83813\tvalid-rmse:3.85888\n",
      "[200]\ttrain-rmse:3.54348\tvalid-rmse:3.69726\n",
      "[400]\ttrain-rmse:3.45374\tvalid-rmse:3.68375\n",
      "[600]\ttrain-rmse:3.39334\tvalid-rmse:3.68181\n",
      "[796]\ttrain-rmse:3.34405\tvalid-rmse:3.68233\n",
      "Fold 4 RMSE: 3.68089\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83453\tvalid-rmse:3.88787\n",
      "[200]\ttrain-rmse:3.54278\tvalid-rmse:3.70095\n",
      "[400]\ttrain-rmse:3.45660\tvalid-rmse:3.68790\n",
      "[600]\ttrain-rmse:3.40202\tvalid-rmse:3.68500\n",
      "[800]\ttrain-rmse:3.35479\tvalid-rmse:3.68403\n",
      "[936]\ttrain-rmse:3.32483\tvalid-rmse:3.68420\n",
      "Fold 5 RMSE: 3.68383\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83060\tvalid-rmse:3.92038\n",
      "[200]\ttrain-rmse:3.54416\tvalid-rmse:3.69629\n",
      "[400]\ttrain-rmse:3.45793\tvalid-rmse:3.67184\n",
      "[600]\ttrain-rmse:3.39981\tvalid-rmse:3.66427\n",
      "[800]\ttrain-rmse:3.35355\tvalid-rmse:3.66133\n",
      "[1000]\ttrain-rmse:3.30872\tvalid-rmse:3.65896\n",
      "[1200]\ttrain-rmse:3.26408\tvalid-rmse:3.65688\n",
      "[1400]\ttrain-rmse:3.22033\tvalid-rmse:3.65570\n",
      "[1600]\ttrain-rmse:3.17863\tvalid-rmse:3.65371\n",
      "[1800]\ttrain-rmse:3.13804\tvalid-rmse:3.65374\n",
      "[1872]\ttrain-rmse:3.12418\tvalid-rmse:3.65376\n",
      "Fold 6 RMSE: 3.65293\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.82498\tvalid-rmse:3.96265\n",
      "[200]\ttrain-rmse:3.53282\tvalid-rmse:3.77587\n",
      "[400]\ttrain-rmse:3.44584\tvalid-rmse:3.75732\n",
      "[600]\ttrain-rmse:3.38951\tvalid-rmse:3.75142\n",
      "[800]\ttrain-rmse:3.34398\tvalid-rmse:3.74880\n",
      "[1000]\ttrain-rmse:3.29876\tvalid-rmse:3.74783\n",
      "[1200]\ttrain-rmse:3.25648\tvalid-rmse:3.74740\n",
      "[1400]\ttrain-rmse:3.21454\tvalid-rmse:3.74662\n",
      "[1427]\ttrain-rmse:3.20910\tvalid-rmse:3.74656\n",
      "Fold 7 RMSE: 3.74622\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.84471\tvalid-rmse:3.80971\n",
      "[200]\ttrain-rmse:3.55162\tvalid-rmse:3.61958\n",
      "[400]\ttrain-rmse:3.46235\tvalid-rmse:3.60272\n",
      "[600]\ttrain-rmse:3.40561\tvalid-rmse:3.59982\n",
      "[800]\ttrain-rmse:3.35808\tvalid-rmse:3.59822\n",
      "[1000]\ttrain-rmse:3.31054\tvalid-rmse:3.59568\n",
      "[1200]\ttrain-rmse:3.26729\tvalid-rmse:3.59552\n",
      "[1207]\ttrain-rmse:3.26542\tvalid-rmse:3.59548\n",
      "Fold 8 RMSE: 3.59505\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.86809\tvalid-rmse:3.61171\n",
      "[200]\ttrain-rmse:3.56841\tvalid-rmse:3.45405\n",
      "[400]\ttrain-rmse:3.47794\tvalid-rmse:3.44987\n",
      "[591]\ttrain-rmse:3.42302\tvalid-rmse:3.45065\n",
      "Fold 9 RMSE: 3.44953\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64228\n",
      "===================================\n",
      "[XGBoost] Top 60% ‚Üí 139 features (threshold ‚âà 263.4947)\n",
      "Starting 9-Fold CV with XGBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "[0]\ttrain-rmse:3.82617\tvalid-rmse:3.95333\n",
      "[200]\ttrain-rmse:3.53854\tvalid-rmse:3.78015\n",
      "[400]\ttrain-rmse:3.45117\tvalid-rmse:3.76625\n",
      "[600]\ttrain-rmse:3.39547\tvalid-rmse:3.76097\n",
      "[800]\ttrain-rmse:3.34592\tvalid-rmse:3.75991\n",
      "[1000]\ttrain-rmse:3.30192\tvalid-rmse:3.75901\n",
      "[1089]\ttrain-rmse:3.28206\tvalid-rmse:3.75920\n",
      "Fold 1 RMSE: 3.75830\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.85913\tvalid-rmse:3.68845\n",
      "[200]\ttrain-rmse:3.56700\tvalid-rmse:3.53383\n",
      "[400]\ttrain-rmse:3.47973\tvalid-rmse:3.51924\n",
      "[600]\ttrain-rmse:3.42604\tvalid-rmse:3.51659\n",
      "[762]\ttrain-rmse:3.38663\tvalid-rmse:3.51690\n",
      "Fold 2 RMSE: 3.51649\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83770\tvalid-rmse:3.86319\n",
      "[200]\ttrain-rmse:3.54527\tvalid-rmse:3.70657\n",
      "[400]\ttrain-rmse:3.45580\tvalid-rmse:3.69774\n",
      "[600]\ttrain-rmse:3.39748\tvalid-rmse:3.69707\n",
      "[636]\ttrain-rmse:3.38832\tvalid-rmse:3.69668\n",
      "Fold 3 RMSE: 3.69660\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83826\tvalid-rmse:3.85915\n",
      "[200]\ttrain-rmse:3.54765\tvalid-rmse:3.69768\n",
      "[400]\ttrain-rmse:3.45929\tvalid-rmse:3.68622\n",
      "[600]\ttrain-rmse:3.40320\tvalid-rmse:3.68272\n",
      "[800]\ttrain-rmse:3.35558\tvalid-rmse:3.68214\n",
      "[980]\ttrain-rmse:3.31476\tvalid-rmse:3.68238\n",
      "Fold 4 RMSE: 3.68151\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83472\tvalid-rmse:3.88808\n",
      "[200]\ttrain-rmse:3.54754\tvalid-rmse:3.70283\n",
      "[400]\ttrain-rmse:3.45935\tvalid-rmse:3.68686\n",
      "[600]\ttrain-rmse:3.40518\tvalid-rmse:3.68453\n",
      "[800]\ttrain-rmse:3.35759\tvalid-rmse:3.68375\n",
      "[983]\ttrain-rmse:3.31726\tvalid-rmse:3.68332\n",
      "Fold 5 RMSE: 3.68292\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83042\tvalid-rmse:3.92011\n",
      "[200]\ttrain-rmse:3.54965\tvalid-rmse:3.69678\n",
      "[400]\ttrain-rmse:3.46488\tvalid-rmse:3.67211\n",
      "[600]\ttrain-rmse:3.40796\tvalid-rmse:3.66568\n",
      "[800]\ttrain-rmse:3.36094\tvalid-rmse:3.66219\n",
      "[1000]\ttrain-rmse:3.31300\tvalid-rmse:3.66099\n",
      "[1200]\ttrain-rmse:3.26998\tvalid-rmse:3.65982\n",
      "[1400]\ttrain-rmse:3.22974\tvalid-rmse:3.65862\n",
      "[1589]\ttrain-rmse:3.19363\tvalid-rmse:3.65851\n",
      "Fold 6 RMSE: 3.65829\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.82505\tvalid-rmse:3.96234\n",
      "[200]\ttrain-rmse:3.53611\tvalid-rmse:3.77735\n",
      "[400]\ttrain-rmse:3.44846\tvalid-rmse:3.75654\n",
      "[600]\ttrain-rmse:3.39474\tvalid-rmse:3.75186\n",
      "[800]\ttrain-rmse:3.34860\tvalid-rmse:3.74843\n",
      "[1000]\ttrain-rmse:3.30583\tvalid-rmse:3.74719\n",
      "[1200]\ttrain-rmse:3.26169\tvalid-rmse:3.74540\n",
      "[1400]\ttrain-rmse:3.21969\tvalid-rmse:3.74354\n",
      "[1600]\ttrain-rmse:3.18091\tvalid-rmse:3.74310\n",
      "[1686]\ttrain-rmse:3.16455\tvalid-rmse:3.74347\n",
      "Fold 7 RMSE: 3.74287\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.84474\tvalid-rmse:3.80956\n",
      "[200]\ttrain-rmse:3.55731\tvalid-rmse:3.62205\n",
      "[400]\ttrain-rmse:3.46820\tvalid-rmse:3.60729\n",
      "[600]\ttrain-rmse:3.41491\tvalid-rmse:3.60294\n",
      "[800]\ttrain-rmse:3.36898\tvalid-rmse:3.60168\n",
      "[1000]\ttrain-rmse:3.32333\tvalid-rmse:3.60081\n",
      "[1006]\ttrain-rmse:3.32201\tvalid-rmse:3.60088\n",
      "Fold 8 RMSE: 3.60078\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.86819\tvalid-rmse:3.61182\n",
      "[200]\ttrain-rmse:3.57411\tvalid-rmse:3.45643\n",
      "[400]\ttrain-rmse:3.48721\tvalid-rmse:3.45111\n",
      "[600]\ttrain-rmse:3.43139\tvalid-rmse:3.45169\n",
      "[662]\ttrain-rmse:3.41587\tvalid-rmse:3.45152\n",
      "Fold 9 RMSE: 3.45090\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64447\n",
      "===================================\n",
      "\n",
      "Best Percentile Threshold Summary\n",
      "========================================\n",
      "percentile          70.000000\n",
      "threshold_value    242.138268\n",
      "num_features       163.000000\n",
      "rmse                 3.642282\n",
      "Name: 2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective': 'reg:squarederror',               # XGBoost regression objective\n",
    "    'eval_metric': 'rmse',                         # Evaluation metric\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 37.21919431321118,\n",
    "    'subsample':  0.8199037878263149,\n",
    "    'colsample_bytree': 0.5893702702557324,\n",
    "    'reg_lambda': 2.6736872463331904,              # L2 regularization\n",
    "    'reg_alpha': 6.053754999193514,               # L1 regularization\n",
    "    'verbosity': 0,                                # Quiet logging\n",
    "    'tree_method': 'auto',                         # Set to 'gpu_hist' if using GPU\n",
    "    'seed': 42\n",
    "}\n",
    "best_xgb_thresh, xgb_thresh_results = find_best_feature_percentile(\n",
    "    model_fn=prediction_with_best_parameters_XgBoost,\n",
    "    feature_df=feature_importance_df_xgboost,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    test_df=test,\n",
    "    param=param,\n",
    "    model_name=\"XGBoost\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 9-Fold CV with XGBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "[0]\ttrain-rmse:3.82641\tvalid-rmse:3.95341\n",
      "[200]\ttrain-rmse:3.52968\tvalid-rmse:3.78084\n",
      "[400]\ttrain-rmse:3.44230\tvalid-rmse:3.76551\n",
      "[600]\ttrain-rmse:3.39276\tvalid-rmse:3.75995\n",
      "[800]\ttrain-rmse:3.34771\tvalid-rmse:3.75861\n",
      "[1000]\ttrain-rmse:3.30632\tvalid-rmse:3.75816\n",
      "[1113]\ttrain-rmse:3.28468\tvalid-rmse:3.75816\n",
      "Fold 1 RMSE: 3.75726\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.85925\tvalid-rmse:3.68855\n",
      "[200]\ttrain-rmse:3.56041\tvalid-rmse:3.53258\n",
      "[400]\ttrain-rmse:3.47415\tvalid-rmse:3.51935\n",
      "[600]\ttrain-rmse:3.42366\tvalid-rmse:3.51655\n",
      "[800]\ttrain-rmse:3.37948\tvalid-rmse:3.51545\n",
      "[901]\ttrain-rmse:3.35871\tvalid-rmse:3.51536\n",
      "Fold 2 RMSE: 3.51508\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83770\tvalid-rmse:3.86330\n",
      "[200]\ttrain-rmse:3.53909\tvalid-rmse:3.70485\n",
      "[400]\ttrain-rmse:3.44935\tvalid-rmse:3.69425\n",
      "[600]\ttrain-rmse:3.39845\tvalid-rmse:3.69352\n",
      "[800]\ttrain-rmse:3.35499\tvalid-rmse:3.69250\n",
      "[834]\ttrain-rmse:3.34733\tvalid-rmse:3.69307\n",
      "Fold 3 RMSE: 3.69215\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83817\tvalid-rmse:3.85911\n",
      "[200]\ttrain-rmse:3.54094\tvalid-rmse:3.69585\n",
      "[400]\ttrain-rmse:3.45218\tvalid-rmse:3.68366\n",
      "[600]\ttrain-rmse:3.40107\tvalid-rmse:3.68114\n",
      "[749]\ttrain-rmse:3.36740\tvalid-rmse:3.68232\n",
      "Fold 4 RMSE: 3.68107\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83470\tvalid-rmse:3.88806\n",
      "[200]\ttrain-rmse:3.54246\tvalid-rmse:3.70129\n",
      "[400]\ttrain-rmse:3.45602\tvalid-rmse:3.68757\n",
      "[600]\ttrain-rmse:3.40610\tvalid-rmse:3.68600\n",
      "[800]\ttrain-rmse:3.36524\tvalid-rmse:3.68572\n",
      "[944]\ttrain-rmse:3.33671\tvalid-rmse:3.68605\n",
      "Fold 5 RMSE: 3.68561\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.83066\tvalid-rmse:3.92033\n",
      "[200]\ttrain-rmse:3.54407\tvalid-rmse:3.69402\n",
      "[400]\ttrain-rmse:3.46091\tvalid-rmse:3.67016\n",
      "[600]\ttrain-rmse:3.40970\tvalid-rmse:3.66238\n",
      "[800]\ttrain-rmse:3.36653\tvalid-rmse:3.65947\n",
      "[1000]\ttrain-rmse:3.32723\tvalid-rmse:3.65768\n",
      "[1200]\ttrain-rmse:3.28931\tvalid-rmse:3.65705\n",
      "[1400]\ttrain-rmse:3.25305\tvalid-rmse:3.65623\n",
      "[1600]\ttrain-rmse:3.21664\tvalid-rmse:3.65491\n",
      "[1800]\ttrain-rmse:3.17999\tvalid-rmse:3.65457\n",
      "[2000]\ttrain-rmse:3.14523\tvalid-rmse:3.65403\n",
      "[2200]\ttrain-rmse:3.11069\tvalid-rmse:3.65349\n",
      "[2400]\ttrain-rmse:3.07768\tvalid-rmse:3.65339\n",
      "[2484]\ttrain-rmse:3.06316\tvalid-rmse:3.65356\n",
      "Fold 6 RMSE: 3.65307\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.82512\tvalid-rmse:3.96242\n",
      "[200]\ttrain-rmse:3.53010\tvalid-rmse:3.77783\n",
      "[400]\ttrain-rmse:3.44424\tvalid-rmse:3.75858\n",
      "[600]\ttrain-rmse:3.39625\tvalid-rmse:3.75404\n",
      "[800]\ttrain-rmse:3.35570\tvalid-rmse:3.75202\n",
      "[1000]\ttrain-rmse:3.31810\tvalid-rmse:3.75069\n",
      "[1200]\ttrain-rmse:3.27967\tvalid-rmse:3.75045\n",
      "[1222]\ttrain-rmse:3.27570\tvalid-rmse:3.75031\n",
      "Fold 7 RMSE: 3.75018\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.84446\tvalid-rmse:3.80906\n",
      "[200]\ttrain-rmse:3.55109\tvalid-rmse:3.62245\n",
      "[400]\ttrain-rmse:3.46197\tvalid-rmse:3.60725\n",
      "[600]\ttrain-rmse:3.41024\tvalid-rmse:3.60308\n",
      "[800]\ttrain-rmse:3.36646\tvalid-rmse:3.60265\n",
      "[935]\ttrain-rmse:3.33948\tvalid-rmse:3.60281\n",
      "Fold 8 RMSE: 3.60246\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "[0]\ttrain-rmse:3.86823\tvalid-rmse:3.61186\n",
      "[200]\ttrain-rmse:3.56903\tvalid-rmse:3.45493\n",
      "[400]\ttrain-rmse:3.48080\tvalid-rmse:3.45135\n",
      "[545]\ttrain-rmse:3.44354\tvalid-rmse:3.45215\n",
      "Fold 9 RMSE: 3.45117\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64441\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# We will cut the dataset with the threshold\n",
    "avg_importance = (feature_importance_df_xgboost\n",
    "                  .groupby('Feature')['importance']\n",
    "                  .mean()\n",
    "                  .sort_values(ascending=False))\n",
    "\n",
    "# Decide a threshold (example: drop features with importance < 15)\n",
    "threshold = 176.911480\n",
    "selected_features_xg = avg_importance[avg_importance >= threshold].index.tolist()\n",
    "discarded_features_xg = avg_importance[avg_importance < threshold].index.tolist()\n",
    "xgboost_reg_final, pred_y_train_final1, pred_y_test_final1, feature_importance_final1, rmse_xgb_final  = prediction_with_best_parameters_XgBoost(\n",
    "    best_params=param,\n",
    "    n_splits=9,\n",
    "    X_train=X_train[selected_features_xg],\n",
    "    y_train=y_train,\n",
    "    test_df=test[selected_features_xg],\n",
    "    num_round=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-3.484857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.313242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.981762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.120042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.641953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123618</th>\n",
       "      <td>C_ID_7a239d2eda</td>\n",
       "      <td>0.808719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123619</th>\n",
       "      <td>C_ID_75ace375ae</td>\n",
       "      <td>-0.505109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123620</th>\n",
       "      <td>C_ID_21d56d950c</td>\n",
       "      <td>0.603618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123621</th>\n",
       "      <td>C_ID_6c46fc5a9d</td>\n",
       "      <td>-3.520573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123622</th>\n",
       "      <td>C_ID_87e7979a5f</td>\n",
       "      <td>0.070586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123623 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id    target\n",
       "0       C_ID_0ab67a22ab -3.484857\n",
       "1       C_ID_130fd0cbdd -0.313242\n",
       "2       C_ID_b709037bc5 -0.981762\n",
       "3       C_ID_d27d835a9f -0.120042\n",
       "4       C_ID_2b5e3df5c2 -1.641953\n",
       "...                 ...       ...\n",
       "123618  C_ID_7a239d2eda  0.808719\n",
       "123619  C_ID_75ace375ae -0.505109\n",
       "123620  C_ID_21d56d950c  0.603618\n",
       "123621  C_ID_6c46fc5a9d -3.520573\n",
       "123622  C_ID_87e7979a5f  0.070586\n",
       "\n",
       "[123623 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_fs = test[[\"card_id\"]].copy()\n",
    "best_xgb_fs[\"target\"] = pred_y_test_final1\n",
    "best_xgb_fs.to_csv(\"xgb_fs_latest.csv\", index=False)\n",
    "best_xgb_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_params = {\n",
    "    'learning_rate': 0.01,                         # Assuming you use the same learning rate\n",
    "    'max_depth': 9,\n",
    "    'reg_lambda': 2.5402159444927617,              # L2 regularization (CatBoost: l2_leaf_reg)\n",
    "    'reg_alpha': 0.21948592159535407,              # Random strength (acts similar to L1)\n",
    "    'subsample': 0.41414360841134634,              # bagging_temperature\n",
    "    'colsample_bytree': 0.739079421019534,         # rsm (feature sampling ratio)\n",
    "    'border_count': 33                             # Used in CatBoost for binarization\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] Top 90% ‚Üí 213 features (threshold ‚âà 0.0173)\n",
      "Starting 9-Fold CV with CatBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "0:\tlearn: 3.8267586\ttest: 3.9537581\tbest: 3.9537581 (0)\ttotal: 85.9ms\tremaining: 14m 18s\n",
      "200:\tlearn: 3.5956268\ttest: 3.7958232\tbest: 3.7958232 (200)\ttotal: 17.6s\tremaining: 14m 17s\n",
      "400:\tlearn: 3.5411337\ttest: 3.7806585\tbest: 3.7806585 (400)\ttotal: 33.9s\tremaining: 13m 31s\n",
      "600:\tlearn: 3.5027961\ttest: 3.7746793\tbest: 3.7746793 (600)\ttotal: 50.3s\tremaining: 13m 6s\n",
      "800:\tlearn: 3.4674726\ttest: 3.7698424\tbest: 3.7698424 (800)\ttotal: 1m 6s\tremaining: 12m 44s\n",
      "1000:\tlearn: 3.4338927\ttest: 3.7670376\tbest: 3.7669789 (988)\ttotal: 1m 22s\tremaining: 12m 23s\n",
      "1200:\tlearn: 3.4039174\ttest: 3.7654142\tbest: 3.7654142 (1200)\ttotal: 1m 38s\tremaining: 12m 4s\n",
      "1400:\tlearn: 3.3764849\ttest: 3.7640876\tbest: 3.7640692 (1399)\ttotal: 1m 55s\tremaining: 11m 46s\n",
      "1600:\tlearn: 3.3471960\ttest: 3.7630871\tbest: 3.7630827 (1598)\ttotal: 2m 10s\tremaining: 11m 26s\n",
      "1800:\tlearn: 3.3207619\ttest: 3.7625010\tbest: 3.7623430 (1726)\ttotal: 2m 26s\tremaining: 11m 8s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.76234301\n",
      "bestIteration = 1726\n",
      "\n",
      "Shrink model to first 1727 iterations.\n",
      "Fold 1 RMSE: 3.76234\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8596037\ttest: 3.6888412\tbest: 3.6888412 (0)\ttotal: 67.7ms\tremaining: 11m 17s\n",
      "200:\tlearn: 3.6284847\ttest: 3.5481218\tbest: 3.5481218 (200)\ttotal: 17.4s\tremaining: 14m 6s\n",
      "400:\tlearn: 3.5693254\ttest: 3.5349982\tbest: 3.5349525 (398)\ttotal: 33.6s\tremaining: 13m 24s\n",
      "600:\tlearn: 3.5258334\ttest: 3.5305980\tbest: 3.5305980 (600)\ttotal: 49.7s\tremaining: 12m 57s\n",
      "800:\tlearn: 3.4893249\ttest: 3.5274747\tbest: 3.5274747 (800)\ttotal: 1m 5s\tremaining: 12m 36s\n",
      "1000:\tlearn: 3.4566118\ttest: 3.5247925\tbest: 3.5247900 (999)\ttotal: 1m 21s\tremaining: 12m 14s\n",
      "1200:\tlearn: 3.4292240\ttest: 3.5237795\tbest: 3.5237395 (1189)\ttotal: 1m 37s\tremaining: 11m 55s\n",
      "1400:\tlearn: 3.4012675\ttest: 3.5230854\tbest: 3.5229681 (1389)\ttotal: 1m 53s\tremaining: 11m 35s\n",
      "1600:\tlearn: 3.3753988\ttest: 3.5228239\tbest: 3.5226402 (1509)\ttotal: 2m 8s\tremaining: 11m 16s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.522640242\n",
      "bestIteration = 1509\n",
      "\n",
      "Shrink model to first 1510 iterations.\n",
      "Fold 2 RMSE: 3.52264\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8383361\ttest: 3.8637772\tbest: 3.8637772 (0)\ttotal: 72.7ms\tremaining: 12m 6s\n",
      "200:\tlearn: 3.6078929\ttest: 3.7149586\tbest: 3.7149586 (200)\ttotal: 17.1s\tremaining: 13m 54s\n",
      "400:\tlearn: 3.5474814\ttest: 3.7026684\tbest: 3.7026166 (393)\ttotal: 33.8s\tremaining: 13m 28s\n",
      "600:\tlearn: 3.5032163\ttest: 3.6995107\tbest: 3.6995107 (600)\ttotal: 50.1s\tremaining: 13m 3s\n",
      "800:\tlearn: 3.4676413\ttest: 3.6977953\tbest: 3.6977683 (799)\ttotal: 1m 6s\tremaining: 12m 41s\n",
      "1000:\tlearn: 3.4348719\ttest: 3.6959936\tbest: 3.6958598 (982)\ttotal: 1m 22s\tremaining: 12m 20s\n",
      "1200:\tlearn: 3.4065474\ttest: 3.6952771\tbest: 3.6952111 (1190)\ttotal: 1m 38s\tremaining: 11m 58s\n",
      "1400:\tlearn: 3.3804840\ttest: 3.6948974\tbest: 3.6945925 (1366)\ttotal: 1m 54s\tremaining: 11m 40s\n",
      "1600:\tlearn: 3.3557708\ttest: 3.6944062\tbest: 3.6944062 (1600)\ttotal: 2m 9s\tremaining: 11m 21s\n",
      "1800:\tlearn: 3.3314099\ttest: 3.6938750\tbest: 3.6938011 (1789)\ttotal: 2m 25s\tremaining: 11m 3s\n",
      "2000:\tlearn: 3.3082733\ttest: 3.6939542\tbest: 3.6935872 (1897)\ttotal: 2m 41s\tremaining: 10m 45s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.693587246\n",
      "bestIteration = 1897\n",
      "\n",
      "Shrink model to first 1898 iterations.\n",
      "Fold 3 RMSE: 3.69359\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8388136\ttest: 3.8591231\tbest: 3.8591231 (0)\ttotal: 61.8ms\tremaining: 10m 17s\n",
      "200:\tlearn: 3.6088278\ttest: 3.7086387\tbest: 3.7086387 (200)\ttotal: 17.3s\tremaining: 14m 3s\n",
      "400:\tlearn: 3.5485019\ttest: 3.6935923\tbest: 3.6935923 (400)\ttotal: 33.6s\tremaining: 13m 25s\n",
      "600:\tlearn: 3.5047738\ttest: 3.6894876\tbest: 3.6894876 (600)\ttotal: 49.7s\tremaining: 12m 56s\n",
      "800:\tlearn: 3.4699832\ttest: 3.6877222\tbest: 3.6877222 (800)\ttotal: 1m 5s\tremaining: 12m 31s\n",
      "1000:\tlearn: 3.4386408\ttest: 3.6871842\tbest: 3.6871792 (999)\ttotal: 1m 21s\tremaining: 12m 10s\n",
      "1200:\tlearn: 3.4105818\ttest: 3.6862825\tbest: 3.6861734 (1190)\ttotal: 1m 36s\tremaining: 11m 50s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.68617335\n",
      "bestIteration = 1190\n",
      "\n",
      "Shrink model to first 1191 iterations.\n",
      "Fold 4 RMSE: 3.68617\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8351277\ttest: 3.8883937\tbest: 3.8883937 (0)\ttotal: 81.3ms\tremaining: 13m 33s\n",
      "200:\tlearn: 3.6055062\ttest: 3.7172731\tbest: 3.7172731 (200)\ttotal: 17.6s\tremaining: 14m 19s\n",
      "400:\tlearn: 3.5440979\ttest: 3.7001967\tbest: 3.7001967 (400)\ttotal: 34.1s\tremaining: 13m 37s\n",
      "600:\tlearn: 3.4998679\ttest: 3.6948411\tbest: 3.6948051 (598)\ttotal: 50.5s\tremaining: 13m 10s\n",
      "800:\tlearn: 3.4630060\ttest: 3.6915703\tbest: 3.6915703 (800)\ttotal: 1m 6s\tremaining: 12m 45s\n",
      "1000:\tlearn: 3.4318862\ttest: 3.6904670\tbest: 3.6904281 (993)\ttotal: 1m 22s\tremaining: 12m 25s\n",
      "1200:\tlearn: 3.4017547\ttest: 3.6894438\tbest: 3.6894438 (1200)\ttotal: 1m 39s\tremaining: 12m 6s\n",
      "1400:\tlearn: 3.3731938\ttest: 3.6888750\tbest: 3.6887817 (1367)\ttotal: 1m 55s\tremaining: 11m 47s\n",
      "1600:\tlearn: 3.3466519\ttest: 3.6882151\tbest: 3.6880780 (1593)\ttotal: 2m 11s\tremaining: 11m 27s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.688077973\n",
      "bestIteration = 1593\n",
      "\n",
      "Shrink model to first 1594 iterations.\n",
      "Fold 5 RMSE: 3.68808\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8310986\ttest: 3.9206032\tbest: 3.9206032 (0)\ttotal: 89.3ms\tremaining: 14m 53s\n",
      "200:\tlearn: 3.6073655\ttest: 3.7199798\tbest: 3.7199798 (200)\ttotal: 17.5s\tremaining: 14m 11s\n",
      "400:\tlearn: 3.5517642\ttest: 3.6989745\tbest: 3.6989745 (400)\ttotal: 34s\tremaining: 13m 34s\n",
      "600:\tlearn: 3.5100720\ttest: 3.6880695\tbest: 3.6880695 (600)\ttotal: 50.2s\tremaining: 13m 4s\n",
      "800:\tlearn: 3.4760508\ttest: 3.6822707\tbest: 3.6822707 (800)\ttotal: 1m 5s\tremaining: 12m 37s\n",
      "1000:\tlearn: 3.4471791\ttest: 3.6793473\tbest: 3.6793446 (994)\ttotal: 1m 21s\tremaining: 12m 16s\n",
      "1200:\tlearn: 3.4207999\ttest: 3.6769582\tbest: 3.6769499 (1199)\ttotal: 1m 37s\tremaining: 11m 54s\n",
      "1400:\tlearn: 3.3949949\ttest: 3.6744685\tbest: 3.6744685 (1400)\ttotal: 1m 53s\tremaining: 11m 35s\n",
      "1600:\tlearn: 3.3705920\ttest: 3.6724405\tbest: 3.6723861 (1596)\ttotal: 2m 8s\tremaining: 11m 16s\n",
      "1800:\tlearn: 3.3476265\ttest: 3.6713873\tbest: 3.6713296 (1785)\ttotal: 2m 24s\tremaining: 10m 58s\n",
      "2000:\tlearn: 3.3258156\ttest: 3.6703727\tbest: 3.6703633 (1999)\ttotal: 2m 40s\tremaining: 10m 40s\n",
      "2200:\tlearn: 3.3033931\ttest: 3.6688015\tbest: 3.6688015 (2200)\ttotal: 2m 55s\tremaining: 10m 23s\n",
      "2400:\tlearn: 3.2820621\ttest: 3.6680077\tbest: 3.6679183 (2394)\ttotal: 3m 11s\tremaining: 10m 6s\n",
      "2600:\tlearn: 3.2620414\ttest: 3.6674240\tbest: 3.6673437 (2521)\ttotal: 3m 27s\tremaining: 9m 50s\n",
      "2800:\tlearn: 3.2435697\ttest: 3.6659998\tbest: 3.6659603 (2798)\ttotal: 3m 43s\tremaining: 9m 33s\n",
      "3000:\tlearn: 3.2242669\ttest: 3.6644153\tbest: 3.6644153 (3000)\ttotal: 3m 58s\tremaining: 9m 17s\n",
      "3200:\tlearn: 3.2053653\ttest: 3.6638268\tbest: 3.6637516 (3162)\ttotal: 4m 14s\tremaining: 9m 1s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.663712999\n",
      "bestIteration = 3233\n",
      "\n",
      "Shrink model to first 3234 iterations.\n",
      "Fold 6 RMSE: 3.66371\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8257763\ttest: 3.9630360\tbest: 3.9630360 (0)\ttotal: 68.3ms\tremaining: 11m 22s\n",
      "200:\tlearn: 3.6015396\ttest: 3.7921300\tbest: 3.7921300 (200)\ttotal: 17.2s\tremaining: 13m 59s\n",
      "400:\tlearn: 3.5425164\ttest: 3.7761773\tbest: 3.7761427 (399)\ttotal: 33.7s\tremaining: 13m 25s\n",
      "600:\tlearn: 3.5024365\ttest: 3.7697562\tbest: 3.7697562 (600)\ttotal: 49.8s\tremaining: 12m 59s\n",
      "800:\tlearn: 3.4672072\ttest: 3.7657530\tbest: 3.7657332 (797)\ttotal: 1m 5s\tremaining: 12m 33s\n",
      "1000:\tlearn: 3.4375692\ttest: 3.7632215\tbest: 3.7632215 (1000)\ttotal: 1m 21s\tremaining: 12m 11s\n",
      "1200:\tlearn: 3.4107187\ttest: 3.7601245\tbest: 3.7601245 (1200)\ttotal: 1m 36s\tremaining: 11m 50s\n",
      "1400:\tlearn: 3.3840300\ttest: 3.7587260\tbest: 3.7586873 (1396)\ttotal: 1m 52s\tremaining: 11m 31s\n",
      "1600:\tlearn: 3.3597577\ttest: 3.7567704\tbest: 3.7566721 (1589)\ttotal: 2m 8s\tremaining: 11m 12s\n",
      "1800:\tlearn: 3.3363198\ttest: 3.7555670\tbest: 3.7555670 (1800)\ttotal: 2m 24s\tremaining: 10m 55s\n",
      "2000:\tlearn: 3.3124176\ttest: 3.7545355\tbest: 3.7544973 (1998)\ttotal: 2m 39s\tremaining: 10m 37s\n",
      "2200:\tlearn: 3.2907504\ttest: 3.7534349\tbest: 3.7533736 (2163)\ttotal: 2m 55s\tremaining: 10m 21s\n",
      "2400:\tlearn: 3.2704635\ttest: 3.7528051\tbest: 3.7526757 (2384)\ttotal: 3m 10s\tremaining: 10m 4s\n",
      "2600:\tlearn: 3.2491183\ttest: 3.7522506\tbest: 3.7521620 (2509)\ttotal: 3m 26s\tremaining: 9m 48s\n",
      "2800:\tlearn: 3.2278795\ttest: 3.7515996\tbest: 3.7515121 (2780)\ttotal: 3m 42s\tremaining: 9m 31s\n",
      "3000:\tlearn: 3.2080533\ttest: 3.7511538\tbest: 3.7510900 (2993)\ttotal: 3m 57s\tremaining: 9m 15s\n",
      "3200:\tlearn: 3.1879120\ttest: 3.7507863\tbest: 3.7505707 (3147)\ttotal: 4m 13s\tremaining: 8m 58s\n",
      "3400:\tlearn: 3.1686432\ttest: 3.7503136\tbest: 3.7502897 (3351)\ttotal: 4m 29s\tremaining: 8m 43s\n",
      "3600:\tlearn: 3.1497009\ttest: 3.7490950\tbest: 3.7490949 (3599)\ttotal: 4m 45s\tremaining: 8m 27s\n",
      "3800:\tlearn: 3.1304814\ttest: 3.7481704\tbest: 3.7481704 (3800)\ttotal: 5m 1s\tremaining: 8m 10s\n",
      "4000:\tlearn: 3.1112687\ttest: 3.7476174\tbest: 3.7475746 (3987)\ttotal: 5m 16s\tremaining: 7m 54s\n",
      "4200:\tlearn: 3.0943327\ttest: 3.7473673\tbest: 3.7473261 (4141)\ttotal: 5m 32s\tremaining: 7m 38s\n",
      "4400:\tlearn: 3.0765359\ttest: 3.7472759\tbest: 3.7470892 (4257)\ttotal: 5m 48s\tremaining: 7m 22s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.747089168\n",
      "bestIteration = 4257\n",
      "\n",
      "Shrink model to first 4258 iterations.\n",
      "Fold 7 RMSE: 3.74709\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8449635\ttest: 3.8094635\tbest: 3.8094635 (0)\ttotal: 82.5ms\tremaining: 13m 45s\n",
      "200:\tlearn: 3.6166728\ttest: 3.6414594\tbest: 3.6414594 (200)\ttotal: 17.1s\tremaining: 13m 53s\n",
      "400:\tlearn: 3.5518306\ttest: 3.6245993\tbest: 3.6245993 (400)\ttotal: 33.5s\tremaining: 13m 22s\n",
      "600:\tlearn: 3.5059737\ttest: 3.6187189\tbest: 3.6187189 (600)\ttotal: 49.7s\tremaining: 12m 56s\n",
      "800:\tlearn: 3.4692418\ttest: 3.6144060\tbest: 3.6144060 (800)\ttotal: 1m 5s\tremaining: 12m 32s\n",
      "1000:\tlearn: 3.4374606\ttest: 3.6116332\tbest: 3.6116332 (1000)\ttotal: 1m 21s\tremaining: 12m 11s\n",
      "1200:\tlearn: 3.4096261\ttest: 3.6096246\tbest: 3.6096246 (1200)\ttotal: 1m 37s\tremaining: 11m 51s\n",
      "1400:\tlearn: 3.3843624\ttest: 3.6085937\tbest: 3.6085282 (1397)\ttotal: 1m 52s\tremaining: 11m 31s\n",
      "1600:\tlearn: 3.3584366\ttest: 3.6081611\tbest: 3.6079994 (1584)\ttotal: 2m 8s\tremaining: 11m 13s\n",
      "1800:\tlearn: 3.3339564\ttest: 3.6074501\tbest: 3.6074501 (1800)\ttotal: 2m 24s\tremaining: 10m 56s\n",
      "2000:\tlearn: 3.3107885\ttest: 3.6070984\tbest: 3.6069504 (1963)\ttotal: 2m 39s\tremaining: 10m 37s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.606950415\n",
      "bestIteration = 1963\n",
      "\n",
      "Shrink model to first 1964 iterations.\n",
      "Fold 8 RMSE: 3.60695\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8686953\ttest: 3.6121824\tbest: 3.6121824 (0)\ttotal: 73.5ms\tremaining: 12m 15s\n",
      "200:\tlearn: 3.6354104\ttest: 3.4692651\tbest: 3.4692651 (200)\ttotal: 17.4s\tremaining: 14m 6s\n",
      "400:\tlearn: 3.5721467\ttest: 3.4580446\tbest: 3.4580446 (400)\ttotal: 33.5s\tremaining: 13m 22s\n",
      "600:\tlearn: 3.5276774\ttest: 3.4545752\tbest: 3.4545752 (600)\ttotal: 49.6s\tremaining: 12m 56s\n",
      "800:\tlearn: 3.4921587\ttest: 3.4533279\tbest: 3.4532891 (792)\ttotal: 1m 5s\tremaining: 12m 32s\n",
      "1000:\tlearn: 3.4618640\ttest: 3.4527943\tbest: 3.4524940 (913)\ttotal: 1m 21s\tremaining: 12m 11s\n",
      "1200:\tlearn: 3.4336850\ttest: 3.4515390\tbest: 3.4515156 (1195)\ttotal: 1m 36s\tremaining: 11m 50s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.451386775\n",
      "bestIteration = 1212\n",
      "\n",
      "Shrink model to first 1213 iterations.\n",
      "Fold 9 RMSE: 3.45139\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64817\n",
      "===================================\n",
      "[CatBoost] Top 80% ‚Üí 189 features (threshold ‚âà 0.0499)\n",
      "Starting 9-Fold CV with CatBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "0:\tlearn: 3.8266566\ttest: 3.9536292\tbest: 3.9536292 (0)\ttotal: 93.2ms\tremaining: 15m 32s\n",
      "200:\tlearn: 3.5955664\ttest: 3.7961178\tbest: 3.7961178 (200)\ttotal: 17.2s\tremaining: 14m\n",
      "400:\tlearn: 3.5406897\ttest: 3.7807403\tbest: 3.7807403 (400)\ttotal: 33.6s\tremaining: 13m 23s\n",
      "600:\tlearn: 3.4996401\ttest: 3.7745998\tbest: 3.7745968 (599)\ttotal: 50.1s\tremaining: 13m 3s\n",
      "800:\tlearn: 3.4646746\ttest: 3.7712274\tbest: 3.7712274 (800)\ttotal: 1m 6s\tremaining: 12m 42s\n",
      "1000:\tlearn: 3.4318718\ttest: 3.7685862\tbest: 3.7685862 (1000)\ttotal: 1m 22s\tremaining: 12m 23s\n",
      "1200:\tlearn: 3.4037676\ttest: 3.7665614\tbest: 3.7664854 (1185)\ttotal: 1m 38s\tremaining: 12m 4s\n",
      "1400:\tlearn: 3.3756379\ttest: 3.7647313\tbest: 3.7646842 (1397)\ttotal: 1m 55s\tremaining: 11m 47s\n",
      "1600:\tlearn: 3.3474858\ttest: 3.7640316\tbest: 3.7637893 (1548)\ttotal: 2m 11s\tremaining: 11m 30s\n",
      "1800:\tlearn: 3.3212801\ttest: 3.7639320\tbest: 3.7636143 (1722)\ttotal: 2m 27s\tremaining: 11m 13s\n",
      "2000:\tlearn: 3.2977402\ttest: 3.7628409\tbest: 3.7628295 (1999)\ttotal: 2m 44s\tremaining: 10m 55s\n",
      "2200:\tlearn: 3.2755924\ttest: 3.7627750\tbest: 3.7624553 (2109)\ttotal: 3m\tremaining: 10m 38s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.762455341\n",
      "bestIteration = 2109\n",
      "\n",
      "Shrink model to first 2110 iterations.\n",
      "Fold 1 RMSE: 3.76246\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8595803\ttest: 3.6884767\tbest: 3.6884767 (0)\ttotal: 107ms\tremaining: 17m 54s\n",
      "200:\tlearn: 3.6288774\ttest: 3.5480599\tbest: 3.5480599 (200)\ttotal: 16.8s\tremaining: 13m 37s\n",
      "400:\tlearn: 3.5685489\ttest: 3.5347800\tbest: 3.5347753 (399)\ttotal: 33.4s\tremaining: 13m 18s\n",
      "600:\tlearn: 3.5254512\ttest: 3.5305140\tbest: 3.5305140 (600)\ttotal: 49.7s\tremaining: 12m 57s\n",
      "800:\tlearn: 3.4881663\ttest: 3.5265287\tbest: 3.5265236 (789)\ttotal: 1m 6s\tremaining: 12m 42s\n",
      "1000:\tlearn: 3.4577940\ttest: 3.5242578\tbest: 3.5242578 (1000)\ttotal: 1m 22s\tremaining: 12m 23s\n",
      "1200:\tlearn: 3.4287014\ttest: 3.5236552\tbest: 3.5235434 (1178)\ttotal: 1m 38s\tremaining: 12m 3s\n",
      "1400:\tlearn: 3.4010872\ttest: 3.5227283\tbest: 3.5226587 (1396)\ttotal: 1m 55s\tremaining: 11m 48s\n",
      "1600:\tlearn: 3.3729367\ttest: 3.5222410\tbest: 3.5221987 (1519)\ttotal: 2m 11s\tremaining: 11m 30s\n",
      "1800:\tlearn: 3.3469955\ttest: 3.5216211\tbest: 3.5215795 (1798)\ttotal: 2m 27s\tremaining: 11m 13s\n",
      "2000:\tlearn: 3.3231617\ttest: 3.5206983\tbest: 3.5206916 (1999)\ttotal: 2m 43s\tremaining: 10m 55s\n",
      "2200:\tlearn: 3.2986228\ttest: 3.5204495\tbest: 3.5204314 (2197)\ttotal: 3m\tremaining: 10m 40s\n",
      "2400:\tlearn: 3.2758311\ttest: 3.5200414\tbest: 3.5198385 (2310)\ttotal: 3m 18s\tremaining: 10m 27s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.519838519\n",
      "bestIteration = 2310\n",
      "\n",
      "Shrink model to first 2311 iterations.\n",
      "Fold 2 RMSE: 3.51984\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8381230\ttest: 3.8633585\tbest: 3.8633585 (0)\ttotal: 102ms\tremaining: 17m\n",
      "200:\tlearn: 3.6080522\ttest: 3.7148169\tbest: 3.7148169 (200)\ttotal: 17.7s\tremaining: 14m 20s\n",
      "400:\tlearn: 3.5466373\ttest: 3.7020436\tbest: 3.7020436 (400)\ttotal: 35.4s\tremaining: 14m 6s\n",
      "600:\tlearn: 3.5025753\ttest: 3.6971972\tbest: 3.6971972 (600)\ttotal: 52.7s\tremaining: 13m 44s\n",
      "800:\tlearn: 3.4663495\ttest: 3.6943699\tbest: 3.6943668 (798)\ttotal: 1m 9s\tremaining: 13m 21s\n",
      "1000:\tlearn: 3.4352354\ttest: 3.6938718\tbest: 3.6936591 (926)\ttotal: 1m 26s\tremaining: 13m\n",
      "1200:\tlearn: 3.4064875\ttest: 3.6927558\tbest: 3.6927541 (1196)\ttotal: 1m 43s\tremaining: 12m 40s\n",
      "1400:\tlearn: 3.3795724\ttest: 3.6923354\tbest: 3.6920851 (1306)\ttotal: 2m\tremaining: 12m 21s\n",
      "1600:\tlearn: 3.3529538\ttest: 3.6915989\tbest: 3.6914700 (1566)\ttotal: 2m 17s\tremaining: 12m 3s\n",
      "1800:\tlearn: 3.3288089\ttest: 3.6907797\tbest: 3.6907746 (1798)\ttotal: 2m 34s\tremaining: 11m 45s\n",
      "2000:\tlearn: 3.3052172\ttest: 3.6911103\tbest: 3.6906944 (1900)\ttotal: 2m 51s\tremaining: 11m 26s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.690694423\n",
      "bestIteration = 1900\n",
      "\n",
      "Shrink model to first 1901 iterations.\n",
      "Fold 3 RMSE: 3.69069\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8386982\ttest: 3.8592799\tbest: 3.8592799 (0)\ttotal: 80.8ms\tremaining: 13m 28s\n",
      "200:\tlearn: 3.6073483\ttest: 3.7078997\tbest: 3.7078997 (200)\ttotal: 17.3s\tremaining: 14m 3s\n",
      "400:\tlearn: 3.5450282\ttest: 3.6927872\tbest: 3.6927872 (400)\ttotal: 34.4s\tremaining: 13m 43s\n",
      "600:\tlearn: 3.5017947\ttest: 3.6884716\tbest: 3.6884716 (600)\ttotal: 51.6s\tremaining: 13m 27s\n",
      "800:\tlearn: 3.4662759\ttest: 3.6859270\tbest: 3.6859270 (800)\ttotal: 1m 8s\tremaining: 13m 11s\n",
      "1000:\tlearn: 3.4360240\ttest: 3.6852031\tbest: 3.6852001 (988)\ttotal: 1m 25s\tremaining: 12m 50s\n",
      "1200:\tlearn: 3.4077793\ttest: 3.6853706\tbest: 3.6850280 (1127)\ttotal: 1m 42s\tremaining: 12m 34s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.685028017\n",
      "bestIteration = 1127\n",
      "\n",
      "Shrink model to first 1128 iterations.\n",
      "Fold 4 RMSE: 3.68503\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8349960\ttest: 3.8884638\tbest: 3.8884638 (0)\ttotal: 72.3ms\tremaining: 12m 3s\n",
      "200:\tlearn: 3.6064633\ttest: 3.7167366\tbest: 3.7167366 (200)\ttotal: 17.6s\tremaining: 14m 18s\n",
      "400:\tlearn: 3.5442786\ttest: 3.7007484\tbest: 3.7007484 (400)\ttotal: 34.7s\tremaining: 13m 51s\n",
      "600:\tlearn: 3.5004595\ttest: 3.6951719\tbest: 3.6951719 (600)\ttotal: 52s\tremaining: 13m 33s\n",
      "800:\tlearn: 3.4630386\ttest: 3.6917913\tbest: 3.6917913 (800)\ttotal: 1m 9s\tremaining: 13m 13s\n",
      "1000:\tlearn: 3.4306471\ttest: 3.6906676\tbest: 3.6906676 (1000)\ttotal: 1m 26s\tremaining: 12m 54s\n",
      "1200:\tlearn: 3.4030069\ttest: 3.6894266\tbest: 3.6893769 (1198)\ttotal: 1m 43s\tremaining: 12m 38s\n",
      "1400:\tlearn: 3.3753171\ttest: 3.6884626\tbest: 3.6884613 (1390)\ttotal: 2m\tremaining: 12m 21s\n",
      "1600:\tlearn: 3.3476095\ttest: 3.6880448\tbest: 3.6875976 (1528)\ttotal: 2m 17s\tremaining: 12m 3s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.687597551\n",
      "bestIteration = 1528\n",
      "\n",
      "Shrink model to first 1529 iterations.\n",
      "Fold 5 RMSE: 3.68760\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8309470\ttest: 3.9205602\tbest: 3.9205602 (0)\ttotal: 76ms\tremaining: 12m 40s\n",
      "200:\tlearn: 3.6086811\ttest: 3.7201856\tbest: 3.7201856 (200)\ttotal: 17.3s\tremaining: 14m 3s\n",
      "400:\tlearn: 3.5528519\ttest: 3.6986025\tbest: 3.6986025 (400)\ttotal: 34.5s\tremaining: 13m 45s\n",
      "600:\tlearn: 3.5111059\ttest: 3.6886752\tbest: 3.6886349 (599)\ttotal: 51.5s\tremaining: 13m 25s\n",
      "800:\tlearn: 3.4777477\ttest: 3.6820517\tbest: 3.6820517 (800)\ttotal: 1m 8s\tremaining: 13m 7s\n",
      "1000:\tlearn: 3.4480057\ttest: 3.6779627\tbest: 3.6779627 (1000)\ttotal: 1m 25s\tremaining: 12m 50s\n",
      "1200:\tlearn: 3.4194846\ttest: 3.6751396\tbest: 3.6751234 (1199)\ttotal: 1m 42s\tremaining: 12m 30s\n",
      "1400:\tlearn: 3.3947820\ttest: 3.6732343\tbest: 3.6732309 (1396)\ttotal: 1m 59s\tremaining: 12m 11s\n",
      "1600:\tlearn: 3.3708887\ttest: 3.6714621\tbest: 3.6714282 (1597)\ttotal: 2m 16s\tremaining: 11m 53s\n",
      "1800:\tlearn: 3.3472083\ttest: 3.6692673\tbest: 3.6692673 (1800)\ttotal: 2m 32s\tremaining: 11m 36s\n",
      "2000:\tlearn: 3.3243632\ttest: 3.6679390\tbest: 3.6679225 (1992)\ttotal: 2m 49s\tremaining: 11m 18s\n",
      "2200:\tlearn: 3.3015008\ttest: 3.6673590\tbest: 3.6671387 (2177)\ttotal: 3m 6s\tremaining: 11m\n",
      "2400:\tlearn: 3.2800766\ttest: 3.6656407\tbest: 3.6656395 (2399)\ttotal: 3m 22s\tremaining: 10m 41s\n",
      "2600:\tlearn: 3.2584233\ttest: 3.6649549\tbest: 3.6647947 (2585)\ttotal: 3m 39s\tremaining: 10m 23s\n",
      "2800:\tlearn: 3.2395854\ttest: 3.6641357\tbest: 3.6641357 (2800)\ttotal: 3m 55s\tremaining: 10m 4s\n",
      "3000:\tlearn: 3.2200336\ttest: 3.6630061\tbest: 3.6629634 (2994)\ttotal: 4m 11s\tremaining: 9m 46s\n",
      "3200:\tlearn: 3.2019786\ttest: 3.6622737\tbest: 3.6621232 (3180)\ttotal: 4m 27s\tremaining: 9m 28s\n",
      "3400:\tlearn: 3.1840615\ttest: 3.6612894\tbest: 3.6611551 (3378)\ttotal: 4m 43s\tremaining: 9m 10s\n",
      "3600:\tlearn: 3.1659654\ttest: 3.6607625\tbest: 3.6604443 (3558)\ttotal: 5m\tremaining: 8m 53s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.660444333\n",
      "bestIteration = 3558\n",
      "\n",
      "Shrink model to first 3559 iterations.\n",
      "Fold 6 RMSE: 3.66044\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8255077\ttest: 3.9626052\tbest: 3.9626052 (0)\ttotal: 67.9ms\tremaining: 11m 18s\n",
      "200:\tlearn: 3.6002551\ttest: 3.7912476\tbest: 3.7912476 (200)\ttotal: 17.1s\tremaining: 13m 55s\n",
      "400:\tlearn: 3.5426827\ttest: 3.7744718\tbest: 3.7744676 (398)\ttotal: 33.8s\tremaining: 13m 28s\n",
      "600:\tlearn: 3.5031228\ttest: 3.7682897\tbest: 3.7682897 (600)\ttotal: 50.2s\tremaining: 13m 4s\n",
      "800:\tlearn: 3.4691038\ttest: 3.7647886\tbest: 3.7646754 (776)\ttotal: 1m 6s\tremaining: 12m 46s\n",
      "1000:\tlearn: 3.4391104\ttest: 3.7618341\tbest: 3.7618341 (1000)\ttotal: 1m 23s\tremaining: 12m 28s\n",
      "1200:\tlearn: 3.4119947\ttest: 3.7593647\tbest: 3.7593044 (1197)\ttotal: 1m 39s\tremaining: 12m 8s\n",
      "1400:\tlearn: 3.3864179\ttest: 3.7577823\tbest: 3.7576788 (1392)\ttotal: 1m 56s\tremaining: 11m 52s\n",
      "1600:\tlearn: 3.3605907\ttest: 3.7555039\tbest: 3.7554909 (1599)\ttotal: 2m 12s\tremaining: 11m 34s\n",
      "1800:\tlearn: 3.3352813\ttest: 3.7544518\tbest: 3.7544518 (1800)\ttotal: 2m 28s\tremaining: 11m 15s\n",
      "2000:\tlearn: 3.3135303\ttest: 3.7534593\tbest: 3.7533395 (1985)\ttotal: 2m 44s\tremaining: 10m 57s\n",
      "2200:\tlearn: 3.2918714\ttest: 3.7528070\tbest: 3.7528070 (2200)\ttotal: 3m\tremaining: 10m 40s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.752620527\n",
      "bestIteration = 2223\n",
      "\n",
      "Shrink model to first 2224 iterations.\n",
      "Fold 7 RMSE: 3.75262\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8448822\ttest: 3.8093709\tbest: 3.8093709 (0)\ttotal: 100ms\tremaining: 16m 44s\n",
      "200:\tlearn: 3.6173020\ttest: 3.6415716\tbest: 3.6415716 (200)\ttotal: 17.2s\tremaining: 13m 57s\n",
      "400:\tlearn: 3.5504640\ttest: 3.6240877\tbest: 3.6240877 (400)\ttotal: 34.1s\tremaining: 13m 36s\n",
      "600:\tlearn: 3.5061658\ttest: 3.6177760\tbest: 3.6177760 (600)\ttotal: 50.8s\tremaining: 13m 14s\n",
      "800:\tlearn: 3.4712997\ttest: 3.6133311\tbest: 3.6133311 (800)\ttotal: 1m 7s\tremaining: 12m 56s\n",
      "1000:\tlearn: 3.4392252\ttest: 3.6107507\tbest: 3.6107217 (998)\ttotal: 1m 24s\tremaining: 12m 38s\n",
      "1200:\tlearn: 3.4087366\ttest: 3.6085692\tbest: 3.6084761 (1188)\ttotal: 1m 41s\tremaining: 12m 20s\n",
      "1400:\tlearn: 3.3813664\ttest: 3.6071333\tbest: 3.6071222 (1399)\ttotal: 1m 57s\tremaining: 12m 1s\n",
      "1600:\tlearn: 3.3553961\ttest: 3.6065087\tbest: 3.6064537 (1572)\ttotal: 2m 13s\tremaining: 11m 42s\n",
      "1800:\tlearn: 3.3313051\ttest: 3.6058369\tbest: 3.6055972 (1766)\ttotal: 2m 30s\tremaining: 11m 24s\n",
      "2000:\tlearn: 3.3087580\ttest: 3.6051673\tbest: 3.6051063 (1990)\ttotal: 2m 46s\tremaining: 11m 6s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.605106285\n",
      "bestIteration = 1990\n",
      "\n",
      "Shrink model to first 1991 iterations.\n",
      "Fold 8 RMSE: 3.60511\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8685898\ttest: 3.6120214\tbest: 3.6120214 (0)\ttotal: 117ms\tremaining: 19m 31s\n",
      "200:\tlearn: 3.6348546\ttest: 3.4691407\tbest: 3.4691407 (200)\ttotal: 17.5s\tremaining: 14m 11s\n",
      "400:\tlearn: 3.5720353\ttest: 3.4598401\tbest: 3.4598401 (400)\ttotal: 34.4s\tremaining: 13m 43s\n",
      "600:\tlearn: 3.5282680\ttest: 3.4563094\tbest: 3.4563094 (600)\ttotal: 50.9s\tremaining: 13m 16s\n",
      "800:\tlearn: 3.4900936\ttest: 3.4538766\tbest: 3.4538605 (789)\ttotal: 1m 7s\tremaining: 12m 55s\n",
      "1000:\tlearn: 3.4601463\ttest: 3.4521156\tbest: 3.4520245 (989)\ttotal: 1m 23s\tremaining: 12m 34s\n",
      "1200:\tlearn: 3.4328466\ttest: 3.4516008\tbest: 3.4515749 (1168)\ttotal: 1m 40s\tremaining: 12m 13s\n",
      "1400:\tlearn: 3.4077632\ttest: 3.4506784\tbest: 3.4506222 (1367)\ttotal: 1m 56s\tremaining: 11m 54s\n",
      "1600:\tlearn: 3.3815888\ttest: 3.4502418\tbest: 3.4499413 (1528)\ttotal: 2m 12s\tremaining: 11m 36s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.449941338\n",
      "bestIteration = 1528\n",
      "\n",
      "Shrink model to first 1529 iterations.\n",
      "Fold 9 RMSE: 3.44994\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64729\n",
      "===================================\n",
      "[CatBoost] Top 70% ‚Üí 165 features (threshold ‚âà 0.0738)\n",
      "Starting 9-Fold CV with CatBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "0:\tlearn: 3.8266652\ttest: 3.9535219\tbest: 3.9535219 (0)\ttotal: 73.8ms\tremaining: 12m 17s\n",
      "200:\tlearn: 3.5957422\ttest: 3.7960892\tbest: 3.7960892 (200)\ttotal: 16.7s\tremaining: 13m 35s\n",
      "400:\tlearn: 3.5410693\ttest: 3.7794693\tbest: 3.7794693 (400)\ttotal: 32.7s\tremaining: 13m 2s\n",
      "600:\tlearn: 3.4999892\ttest: 3.7735477\tbest: 3.7735469 (599)\ttotal: 49.1s\tremaining: 12m 47s\n",
      "800:\tlearn: 3.4615594\ttest: 3.7684601\tbest: 3.7684601 (800)\ttotal: 1m 6s\tremaining: 12m 43s\n",
      "1000:\tlearn: 3.4277071\ttest: 3.7648975\tbest: 3.7648866 (994)\ttotal: 1m 22s\tremaining: 12m 26s\n",
      "1200:\tlearn: 3.3994167\ttest: 3.7627794\tbest: 3.7627794 (1200)\ttotal: 1m 38s\tremaining: 12m 5s\n",
      "1400:\tlearn: 3.3713499\ttest: 3.7612445\tbest: 3.7612445 (1400)\ttotal: 1m 55s\tremaining: 11m 46s\n",
      "1600:\tlearn: 3.3429011\ttest: 3.7605068\tbest: 3.7603882 (1487)\ttotal: 2m 11s\tremaining: 11m 27s\n",
      "1800:\tlearn: 3.3178408\ttest: 3.7599102\tbest: 3.7598056 (1755)\ttotal: 2m 26s\tremaining: 11m 7s\n",
      "2000:\tlearn: 3.2946447\ttest: 3.7596123\tbest: 3.7594128 (1866)\ttotal: 2m 42s\tremaining: 10m 50s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.759412757\n",
      "bestIteration = 1866\n",
      "\n",
      "Shrink model to first 1867 iterations.\n",
      "Fold 1 RMSE: 3.75941\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8595215\ttest: 3.6888460\tbest: 3.6888460 (0)\ttotal: 68.6ms\tremaining: 11m 25s\n",
      "200:\tlearn: 3.6276768\ttest: 3.5498929\tbest: 3.5498929 (200)\ttotal: 16.5s\tremaining: 13m 25s\n",
      "400:\tlearn: 3.5682032\ttest: 3.5376057\tbest: 3.5376057 (400)\ttotal: 32.4s\tremaining: 12m 56s\n",
      "600:\tlearn: 3.5253271\ttest: 3.5318335\tbest: 3.5318171 (596)\ttotal: 48.4s\tremaining: 12m 36s\n",
      "800:\tlearn: 3.4883229\ttest: 3.5284644\tbest: 3.5284085 (797)\ttotal: 1m 4s\tremaining: 12m 18s\n",
      "1000:\tlearn: 3.4567723\ttest: 3.5261809\tbest: 3.5261718 (999)\ttotal: 1m 20s\tremaining: 11m 59s\n",
      "1200:\tlearn: 3.4272615\ttest: 3.5249968\tbest: 3.5249506 (1195)\ttotal: 1m 35s\tremaining: 11m 41s\n",
      "1400:\tlearn: 3.4005726\ttest: 3.5243905\tbest: 3.5242353 (1365)\ttotal: 1m 51s\tremaining: 11m 24s\n",
      "1600:\tlearn: 3.3744577\ttest: 3.5242785\tbest: 3.5237963 (1528)\ttotal: 2m 7s\tremaining: 11m 8s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.523796319\n",
      "bestIteration = 1528\n",
      "\n",
      "Shrink model to first 1529 iterations.\n",
      "Fold 2 RMSE: 3.52380\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8381801\ttest: 3.8635084\tbest: 3.8635084 (0)\ttotal: 70.7ms\tremaining: 11m 46s\n",
      "200:\tlearn: 3.6076850\ttest: 3.7146745\tbest: 3.7146745 (200)\ttotal: 16.6s\tremaining: 13m 27s\n",
      "400:\tlearn: 3.5461235\ttest: 3.7017431\tbest: 3.7017224 (399)\ttotal: 32.6s\tremaining: 12m 59s\n",
      "600:\tlearn: 3.5029972\ttest: 3.6982650\tbest: 3.6982650 (600)\ttotal: 48.7s\tremaining: 12m 41s\n",
      "800:\tlearn: 3.4666543\ttest: 3.6959156\tbest: 3.6958911 (788)\ttotal: 1m 4s\tremaining: 12m 25s\n",
      "1000:\tlearn: 3.4352595\ttest: 3.6942439\tbest: 3.6942439 (1000)\ttotal: 1m 20s\tremaining: 12m 7s\n",
      "1200:\tlearn: 3.4051985\ttest: 3.6937217\tbest: 3.6935910 (1054)\ttotal: 1m 36s\tremaining: 11m 49s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.693590961\n",
      "bestIteration = 1054\n",
      "\n",
      "Shrink model to first 1055 iterations.\n",
      "Fold 3 RMSE: 3.69359\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8387019\ttest: 3.8592555\tbest: 3.8592555 (0)\ttotal: 99.3ms\tremaining: 16m 33s\n",
      "200:\tlearn: 3.6088104\ttest: 3.7089214\tbest: 3.7089214 (200)\ttotal: 16.8s\tremaining: 13m 39s\n",
      "400:\tlearn: 3.5465466\ttest: 3.6937461\tbest: 3.6937461 (400)\ttotal: 32.9s\tremaining: 13m 8s\n",
      "600:\tlearn: 3.5037746\ttest: 3.6890214\tbest: 3.6890214 (600)\ttotal: 49.1s\tremaining: 12m 47s\n",
      "800:\tlearn: 3.4666720\ttest: 3.6877494\tbest: 3.6876382 (780)\ttotal: 1m 5s\tremaining: 12m 27s\n",
      "1000:\tlearn: 3.4376481\ttest: 3.6867884\tbest: 3.6867288 (996)\ttotal: 1m 20s\tremaining: 12m 6s\n",
      "1200:\tlearn: 3.4092571\ttest: 3.6862942\tbest: 3.6861776 (1105)\ttotal: 1m 36s\tremaining: 11m 49s\n",
      "1400:\tlearn: 3.3819909\ttest: 3.6855929\tbest: 3.6855267 (1397)\ttotal: 1m 52s\tremaining: 11m 33s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.685450654\n",
      "bestIteration = 1445\n",
      "\n",
      "Shrink model to first 1446 iterations.\n",
      "Fold 4 RMSE: 3.68545\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8350915\ttest: 3.8882145\tbest: 3.8882145 (0)\ttotal: 89.7ms\tremaining: 14m 57s\n",
      "200:\tlearn: 3.6057130\ttest: 3.7160828\tbest: 3.7160828 (200)\ttotal: 16.7s\tremaining: 13m 32s\n",
      "400:\tlearn: 3.5438270\ttest: 3.7006248\tbest: 3.7006248 (400)\ttotal: 32.7s\tremaining: 13m 2s\n",
      "600:\tlearn: 3.5003687\ttest: 3.6953534\tbest: 3.6953249 (599)\ttotal: 49s\tremaining: 12m 46s\n",
      "800:\tlearn: 3.4620937\ttest: 3.6928390\tbest: 3.6928390 (800)\ttotal: 1m 4s\tremaining: 12m 26s\n",
      "1000:\tlearn: 3.4328473\ttest: 3.6911986\tbest: 3.6911986 (1000)\ttotal: 1m 20s\tremaining: 12m 7s\n",
      "1200:\tlearn: 3.4029337\ttest: 3.6899180\tbest: 3.6898889 (1198)\ttotal: 1m 36s\tremaining: 11m 48s\n",
      "1400:\tlearn: 3.3753233\ttest: 3.6899323\tbest: 3.6897057 (1256)\ttotal: 1m 52s\tremaining: 11m 32s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.689705708\n",
      "bestIteration = 1256\n",
      "\n",
      "Shrink model to first 1257 iterations.\n",
      "Fold 5 RMSE: 3.68971\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8309729\ttest: 3.9204200\tbest: 3.9204200 (0)\ttotal: 66ms\tremaining: 11m\n",
      "200:\tlearn: 3.6084196\ttest: 3.7210775\tbest: 3.7210775 (200)\ttotal: 16.9s\tremaining: 13m 42s\n",
      "400:\tlearn: 3.5512016\ttest: 3.6979481\tbest: 3.6979481 (400)\ttotal: 32.9s\tremaining: 13m 7s\n",
      "600:\tlearn: 3.5100350\ttest: 3.6880169\tbest: 3.6880169 (600)\ttotal: 49s\tremaining: 12m 47s\n",
      "800:\tlearn: 3.4764304\ttest: 3.6832143\tbest: 3.6832143 (800)\ttotal: 1m 4s\tremaining: 12m 25s\n",
      "1000:\tlearn: 3.4466400\ttest: 3.6792170\tbest: 3.6792170 (1000)\ttotal: 1m 20s\tremaining: 12m 6s\n",
      "1200:\tlearn: 3.4190185\ttest: 3.6762374\tbest: 3.6762237 (1194)\ttotal: 1m 36s\tremaining: 11m 49s\n",
      "1400:\tlearn: 3.3930750\ttest: 3.6730616\tbest: 3.6730616 (1400)\ttotal: 1m 53s\tremaining: 11m 33s\n",
      "1600:\tlearn: 3.3666277\ttest: 3.6702197\tbest: 3.6702197 (1600)\ttotal: 2m 9s\tremaining: 11m 18s\n",
      "1800:\tlearn: 3.3435065\ttest: 3.6678234\tbest: 3.6678161 (1798)\ttotal: 2m 24s\tremaining: 10m 59s\n",
      "2000:\tlearn: 3.3213621\ttest: 3.6665419\tbest: 3.6665419 (2000)\ttotal: 2m 40s\tremaining: 10m 43s\n",
      "2200:\tlearn: 3.2991561\ttest: 3.6651743\tbest: 3.6651411 (2191)\ttotal: 2m 56s\tremaining: 10m 26s\n",
      "2400:\tlearn: 3.2768133\ttest: 3.6636575\tbest: 3.6636575 (2400)\ttotal: 3m 12s\tremaining: 10m 9s\n",
      "2600:\tlearn: 3.2552974\ttest: 3.6630997\tbest: 3.6629183 (2548)\ttotal: 3m 28s\tremaining: 9m 53s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.662918282\n",
      "bestIteration = 2548\n",
      "\n",
      "Shrink model to first 2549 iterations.\n",
      "Fold 6 RMSE: 3.66292\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8255155\ttest: 3.9625198\tbest: 3.9625198 (0)\ttotal: 84.6ms\tremaining: 14m 5s\n",
      "200:\tlearn: 3.5992181\ttest: 3.7900176\tbest: 3.7900176 (200)\ttotal: 16.6s\tremaining: 13m 31s\n",
      "400:\tlearn: 3.5404759\ttest: 3.7728400\tbest: 3.7728400 (400)\ttotal: 32.9s\tremaining: 13m 7s\n",
      "600:\tlearn: 3.5019484\ttest: 3.7670755\tbest: 3.7670755 (600)\ttotal: 49.1s\tremaining: 12m 48s\n",
      "800:\tlearn: 3.4660103\ttest: 3.7624081\tbest: 3.7624081 (800)\ttotal: 1m 5s\tremaining: 12m 29s\n",
      "1000:\tlearn: 3.4366887\ttest: 3.7593171\tbest: 3.7592600 (997)\ttotal: 1m 21s\tremaining: 12m 8s\n",
      "1200:\tlearn: 3.4093923\ttest: 3.7569918\tbest: 3.7569754 (1198)\ttotal: 1m 37s\tremaining: 11m 52s\n",
      "1400:\tlearn: 3.3825905\ttest: 3.7540256\tbest: 3.7540194 (1398)\ttotal: 1m 53s\tremaining: 11m 33s\n",
      "1600:\tlearn: 3.3576971\ttest: 3.7529515\tbest: 3.7527976 (1577)\ttotal: 2m 8s\tremaining: 11m 16s\n",
      "1800:\tlearn: 3.3329273\ttest: 3.7514701\tbest: 3.7514701 (1800)\ttotal: 2m 24s\tremaining: 10m 58s\n",
      "2000:\tlearn: 3.3092981\ttest: 3.7504143\tbest: 3.7503377 (1991)\ttotal: 2m 40s\tremaining: 10m 42s\n",
      "2200:\tlearn: 3.2860201\ttest: 3.7490416\tbest: 3.7490060 (2197)\ttotal: 2m 56s\tremaining: 10m 25s\n",
      "2400:\tlearn: 3.2627274\ttest: 3.7479486\tbest: 3.7478475 (2398)\ttotal: 3m 12s\tremaining: 10m 8s\n",
      "2600:\tlearn: 3.2411249\ttest: 3.7470812\tbest: 3.7470764 (2593)\ttotal: 3m 28s\tremaining: 9m 52s\n",
      "2800:\tlearn: 3.2195180\ttest: 3.7461419\tbest: 3.7461293 (2797)\ttotal: 3m 43s\tremaining: 9m 35s\n",
      "3000:\tlearn: 3.1981578\ttest: 3.7456574\tbest: 3.7455583 (2970)\ttotal: 3m 59s\tremaining: 9m 19s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.745558296\n",
      "bestIteration = 2970\n",
      "\n",
      "Shrink model to first 2971 iterations.\n",
      "Fold 7 RMSE: 3.74556\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8448806\ttest: 3.8093472\tbest: 3.8093472 (0)\ttotal: 82.7ms\tremaining: 13m 47s\n",
      "200:\tlearn: 3.6172424\ttest: 3.6412738\tbest: 3.6412738 (200)\ttotal: 16.5s\tremaining: 13m 23s\n",
      "400:\tlearn: 3.5544818\ttest: 3.6249685\tbest: 3.6249685 (400)\ttotal: 32.5s\tremaining: 12m 58s\n",
      "600:\tlearn: 3.5077822\ttest: 3.6185340\tbest: 3.6185340 (600)\ttotal: 48.7s\tremaining: 12m 41s\n",
      "800:\tlearn: 3.4700745\ttest: 3.6138665\tbest: 3.6138665 (800)\ttotal: 1m 4s\tremaining: 12m 21s\n",
      "1000:\tlearn: 3.4375203\ttest: 3.6110494\tbest: 3.6110494 (1000)\ttotal: 1m 20s\tremaining: 12m 3s\n",
      "1200:\tlearn: 3.4091149\ttest: 3.6090656\tbest: 3.6090302 (1199)\ttotal: 1m 36s\tremaining: 11m 47s\n",
      "1400:\tlearn: 3.3811532\ttest: 3.6080037\tbest: 3.6079927 (1399)\ttotal: 1m 52s\tremaining: 11m 31s\n",
      "1600:\tlearn: 3.3537500\ttest: 3.6075137\tbest: 3.6072098 (1543)\ttotal: 2m 8s\tremaining: 11m 15s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.607209826\n",
      "bestIteration = 1543\n",
      "\n",
      "Shrink model to first 1544 iterations.\n",
      "Fold 8 RMSE: 3.60721\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8685755\ttest: 3.6118712\tbest: 3.6118712 (0)\ttotal: 82.1ms\tremaining: 13m 41s\n",
      "200:\tlearn: 3.6355488\ttest: 3.4706770\tbest: 3.4706770 (200)\ttotal: 16.6s\tremaining: 13m 30s\n",
      "400:\tlearn: 3.5706150\ttest: 3.4592988\tbest: 3.4592906 (399)\ttotal: 32.7s\tremaining: 13m 3s\n",
      "600:\tlearn: 3.5273921\ttest: 3.4561853\tbest: 3.4561853 (600)\ttotal: 48.9s\tremaining: 12m 44s\n",
      "800:\tlearn: 3.4911537\ttest: 3.4545079\tbest: 3.4545079 (800)\ttotal: 1m 4s\tremaining: 12m 25s\n",
      "1000:\tlearn: 3.4597384\ttest: 3.4534329\tbest: 3.4533996 (993)\ttotal: 1m 21s\tremaining: 12m 8s\n",
      "1200:\tlearn: 3.4331077\ttest: 3.4523989\tbest: 3.4523989 (1200)\ttotal: 1m 36s\tremaining: 11m 50s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.452361911\n",
      "bestIteration = 1209\n",
      "\n",
      "Shrink model to first 1210 iterations.\n",
      "Fold 9 RMSE: 3.45236\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64793\n",
      "===================================\n",
      "[CatBoost] Top 60% ‚Üí 142 features (threshold ‚âà 0.1282)\n",
      "Starting 9-Fold CV with CatBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "0:\tlearn: 3.8267982\ttest: 3.9537184\tbest: 3.9537184 (0)\ttotal: 86.1ms\tremaining: 14m 20s\n",
      "200:\tlearn: 3.5962155\ttest: 3.7949941\tbest: 3.7949941 (200)\ttotal: 13.7s\tremaining: 11m 8s\n",
      "400:\tlearn: 3.5408135\ttest: 3.7801932\tbest: 3.7801932 (400)\ttotal: 27.5s\tremaining: 10m 59s\n",
      "600:\tlearn: 3.4982333\ttest: 3.7740039\tbest: 3.7740039 (600)\ttotal: 41.2s\tremaining: 10m 44s\n",
      "800:\tlearn: 3.4598644\ttest: 3.7700532\tbest: 3.7700179 (796)\ttotal: 54.9s\tremaining: 10m 30s\n",
      "1000:\tlearn: 3.4262824\ttest: 3.7669502\tbest: 3.7669153 (999)\ttotal: 1m 8s\tremaining: 10m 16s\n",
      "1200:\tlearn: 3.3958097\ttest: 3.7651696\tbest: 3.7651637 (1197)\ttotal: 1m 22s\tremaining: 10m 1s\n",
      "1400:\tlearn: 3.3670295\ttest: 3.7640538\tbest: 3.7640056 (1397)\ttotal: 1m 35s\tremaining: 9m 47s\n",
      "1600:\tlearn: 3.3378976\ttest: 3.7632326\tbest: 3.7631716 (1546)\ttotal: 1m 49s\tremaining: 9m 32s\n",
      "1800:\tlearn: 3.3109452\ttest: 3.7627344\tbest: 3.7625257 (1763)\ttotal: 2m 2s\tremaining: 9m 18s\n",
      "2000:\tlearn: 3.2839897\ttest: 3.7628852\tbest: 3.7625106 (1862)\ttotal: 2m 16s\tremaining: 9m 4s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.762510579\n",
      "bestIteration = 1862\n",
      "\n",
      "Shrink model to first 1863 iterations.\n",
      "Fold 1 RMSE: 3.76251\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8595161\ttest: 3.6888027\tbest: 3.6888027 (0)\ttotal: 105ms\tremaining: 17m 32s\n",
      "200:\tlearn: 3.6298864\ttest: 3.5487360\tbest: 3.5487360 (200)\ttotal: 13.8s\tremaining: 11m 13s\n",
      "400:\tlearn: 3.5689818\ttest: 3.5354001\tbest: 3.5354001 (400)\ttotal: 27.6s\tremaining: 11m\n",
      "600:\tlearn: 3.5251607\ttest: 3.5297360\tbest: 3.5297360 (600)\ttotal: 41.5s\tremaining: 10m 48s\n",
      "800:\tlearn: 3.4861308\ttest: 3.5256814\tbest: 3.5256814 (800)\ttotal: 55s\tremaining: 10m 31s\n",
      "1000:\tlearn: 3.4540559\ttest: 3.5232011\tbest: 3.5232011 (1000)\ttotal: 1m 8s\tremaining: 10m 17s\n",
      "1200:\tlearn: 3.4244415\ttest: 3.5220494\tbest: 3.5220331 (1187)\ttotal: 1m 22s\tremaining: 10m 2s\n",
      "1400:\tlearn: 3.3945483\ttest: 3.5215454\tbest: 3.5215376 (1399)\ttotal: 1m 35s\tremaining: 9m 47s\n",
      "1600:\tlearn: 3.3652876\ttest: 3.5213775\tbest: 3.5212223 (1469)\ttotal: 1m 49s\tremaining: 9m 33s\n",
      "1800:\tlearn: 3.3367374\ttest: 3.5205978\tbest: 3.5204073 (1760)\ttotal: 2m 2s\tremaining: 9m 19s\n",
      "2000:\tlearn: 3.3105461\ttest: 3.5202770\tbest: 3.5202154 (1992)\ttotal: 2m 16s\tremaining: 9m 5s\n",
      "2200:\tlearn: 3.2863756\ttest: 3.5200108\tbest: 3.5199272 (2192)\ttotal: 2m 30s\tremaining: 8m 52s\n",
      "2400:\tlearn: 3.2614759\ttest: 3.5193246\tbest: 3.5192756 (2396)\ttotal: 2m 44s\tremaining: 8m 39s\n",
      "2600:\tlearn: 3.2383315\ttest: 3.5189593\tbest: 3.5189053 (2590)\ttotal: 2m 58s\tremaining: 8m 26s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.518905346\n",
      "bestIteration = 2590\n",
      "\n",
      "Shrink model to first 2591 iterations.\n",
      "Fold 2 RMSE: 3.51891\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8383300\ttest: 3.8633554\tbest: 3.8633554 (0)\ttotal: 80.8ms\tremaining: 13m 27s\n",
      "200:\tlearn: 3.6081766\ttest: 3.7163484\tbest: 3.7163484 (200)\ttotal: 13.9s\tremaining: 11m 18s\n",
      "400:\tlearn: 3.5442004\ttest: 3.7032672\tbest: 3.7032366 (397)\ttotal: 27.8s\tremaining: 11m 6s\n",
      "600:\tlearn: 3.4989249\ttest: 3.6998310\tbest: 3.6997316 (596)\ttotal: 41.6s\tremaining: 10m 50s\n",
      "800:\tlearn: 3.4626519\ttest: 3.6978181\tbest: 3.6977196 (750)\ttotal: 55.2s\tremaining: 10m 34s\n",
      "1000:\tlearn: 3.4283087\ttest: 3.6962896\tbest: 3.6962878 (999)\ttotal: 1m 8s\tremaining: 10m 19s\n",
      "1200:\tlearn: 3.3970515\ttest: 3.6958463\tbest: 3.6956132 (1191)\ttotal: 1m 22s\tremaining: 10m 5s\n",
      "1400:\tlearn: 3.3664959\ttest: 3.6952443\tbest: 3.6951926 (1386)\ttotal: 1m 36s\tremaining: 9m 50s\n",
      "1600:\tlearn: 3.3372941\ttest: 3.6950567\tbest: 3.6947266 (1486)\ttotal: 1m 49s\tremaining: 9m 36s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.694726615\n",
      "bestIteration = 1486\n",
      "\n",
      "Shrink model to first 1487 iterations.\n",
      "Fold 3 RMSE: 3.69473\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8386944\ttest: 3.8593439\tbest: 3.8593439 (0)\ttotal: 62.2ms\tremaining: 10m 22s\n",
      "200:\tlearn: 3.6074986\ttest: 3.7085465\tbest: 3.7085465 (200)\ttotal: 13.7s\tremaining: 11m 10s\n",
      "400:\tlearn: 3.5456726\ttest: 3.6929532\tbest: 3.6929532 (400)\ttotal: 27.4s\tremaining: 10m 56s\n",
      "600:\tlearn: 3.5013272\ttest: 3.6882634\tbest: 3.6882535 (598)\ttotal: 41s\tremaining: 10m 41s\n",
      "800:\tlearn: 3.4637322\ttest: 3.6859701\tbest: 3.6859481 (796)\ttotal: 54.6s\tremaining: 10m 26s\n",
      "1000:\tlearn: 3.4325637\ttest: 3.6846514\tbest: 3.6845064 (988)\ttotal: 1m 8s\tremaining: 10m 12s\n",
      "1200:\tlearn: 3.4026115\ttest: 3.6837740\tbest: 3.6836181 (1191)\ttotal: 1m 21s\tremaining: 9m 58s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.683456981\n",
      "bestIteration = 1234\n",
      "\n",
      "Shrink model to first 1235 iterations.\n",
      "Fold 4 RMSE: 3.68346\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8350905\ttest: 3.8883416\tbest: 3.8883416 (0)\ttotal: 53.2ms\tremaining: 8m 51s\n",
      "200:\tlearn: 3.6074451\ttest: 3.7157428\tbest: 3.7157428 (200)\ttotal: 13.9s\tremaining: 11m 15s\n",
      "400:\tlearn: 3.5458473\ttest: 3.7006349\tbest: 3.7006349 (400)\ttotal: 27.5s\tremaining: 10m 57s\n",
      "600:\tlearn: 3.5021779\ttest: 3.6955057\tbest: 3.6954652 (596)\ttotal: 41.5s\tremaining: 10m 48s\n",
      "800:\tlearn: 3.4644543\ttest: 3.6920841\tbest: 3.6920730 (795)\ttotal: 55.2s\tremaining: 10m 33s\n",
      "1000:\tlearn: 3.4325509\ttest: 3.6906364\tbest: 3.6904861 (986)\ttotal: 1m 8s\tremaining: 10m 19s\n",
      "1200:\tlearn: 3.4013744\ttest: 3.6896436\tbest: 3.6894335 (1154)\ttotal: 1m 22s\tremaining: 10m 3s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.689433512\n",
      "bestIteration = 1154\n",
      "\n",
      "Shrink model to first 1155 iterations.\n",
      "Fold 5 RMSE: 3.68943\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8309919\ttest: 3.9206685\tbest: 3.9206685 (0)\ttotal: 65.5ms\tremaining: 10m 54s\n",
      "200:\tlearn: 3.6094079\ttest: 3.7183876\tbest: 3.7183876 (200)\ttotal: 13.5s\tremaining: 11m\n",
      "400:\tlearn: 3.5533638\ttest: 3.6965803\tbest: 3.6965803 (400)\ttotal: 27.4s\tremaining: 10m 56s\n",
      "600:\tlearn: 3.5106822\ttest: 3.6860601\tbest: 3.6860601 (600)\ttotal: 41s\tremaining: 10m 40s\n",
      "800:\tlearn: 3.4742126\ttest: 3.6793585\tbest: 3.6793585 (800)\ttotal: 54.9s\tremaining: 10m 30s\n",
      "1000:\tlearn: 3.4428760\ttest: 3.6750356\tbest: 3.6750356 (1000)\ttotal: 1m 8s\tremaining: 10m 16s\n",
      "1200:\tlearn: 3.4130211\ttest: 3.6722915\tbest: 3.6722737 (1199)\ttotal: 1m 22s\tremaining: 10m 1s\n",
      "1400:\tlearn: 3.3836843\ttest: 3.6688231\tbest: 3.6688005 (1399)\ttotal: 1m 35s\tremaining: 9m 45s\n",
      "1600:\tlearn: 3.3562726\ttest: 3.6670980\tbest: 3.6670980 (1600)\ttotal: 1m 48s\tremaining: 9m 31s\n",
      "1800:\tlearn: 3.3315008\ttest: 3.6654779\tbest: 3.6654351 (1771)\ttotal: 2m 2s\tremaining: 9m 17s\n",
      "2000:\tlearn: 3.3068700\ttest: 3.6639828\tbest: 3.6638726 (1979)\ttotal: 2m 15s\tremaining: 9m 3s\n",
      "2200:\tlearn: 3.2840923\ttest: 3.6624622\tbest: 3.6624622 (2200)\ttotal: 2m 29s\tremaining: 8m 49s\n",
      "2400:\tlearn: 3.2633654\ttest: 3.6614010\tbest: 3.6613370 (2377)\ttotal: 2m 42s\tremaining: 8m 34s\n",
      "2600:\tlearn: 3.2423466\ttest: 3.6606108\tbest: 3.6605176 (2558)\ttotal: 2m 56s\tremaining: 8m 21s\n",
      "2800:\tlearn: 3.2219059\ttest: 3.6594045\tbest: 3.6594045 (2800)\ttotal: 3m 9s\tremaining: 8m 7s\n",
      "3000:\tlearn: 3.2012073\ttest: 3.6581185\tbest: 3.6580692 (2996)\ttotal: 3m 23s\tremaining: 7m 54s\n",
      "3200:\tlearn: 3.1808258\ttest: 3.6577122\tbest: 3.6576971 (3197)\ttotal: 3m 36s\tremaining: 7m 40s\n",
      "3400:\tlearn: 3.1618541\ttest: 3.6569311\tbest: 3.6568555 (3392)\ttotal: 3m 50s\tremaining: 7m 26s\n",
      "3600:\tlearn: 3.1425368\ttest: 3.6561353\tbest: 3.6561353 (3600)\ttotal: 4m 3s\tremaining: 7m 12s\n",
      "3800:\tlearn: 3.1235199\ttest: 3.6551603\tbest: 3.6551321 (3797)\ttotal: 4m 17s\tremaining: 6m 59s\n",
      "4000:\tlearn: 3.1041923\ttest: 3.6550593\tbest: 3.6550488 (3995)\ttotal: 4m 30s\tremaining: 6m 45s\n",
      "4200:\tlearn: 3.0862721\ttest: 3.6540079\tbest: 3.6539681 (4196)\ttotal: 4m 44s\tremaining: 6m 32s\n",
      "4400:\tlearn: 3.0679991\ttest: 3.6534284\tbest: 3.6531341 (4372)\ttotal: 4m 58s\tremaining: 6m 19s\n",
      "4600:\tlearn: 3.0488024\ttest: 3.6527373\tbest: 3.6527237 (4598)\ttotal: 5m 11s\tremaining: 6m 5s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.652713299\n",
      "bestIteration = 4604\n",
      "\n",
      "Shrink model to first 4605 iterations.\n",
      "Fold 6 RMSE: 3.65271\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8255311\ttest: 3.9627114\tbest: 3.9627114 (0)\ttotal: 57.3ms\tremaining: 9m 33s\n",
      "200:\tlearn: 3.6000828\ttest: 3.7907393\tbest: 3.7907393 (200)\ttotal: 13.7s\tremaining: 11m 6s\n",
      "400:\tlearn: 3.5414302\ttest: 3.7739700\tbest: 3.7739700 (400)\ttotal: 27.3s\tremaining: 10m 52s\n",
      "600:\tlearn: 3.5008147\ttest: 3.7685695\tbest: 3.7685580 (599)\ttotal: 40.8s\tremaining: 10m 37s\n",
      "800:\tlearn: 3.4642642\ttest: 3.7653106\tbest: 3.7653099 (799)\ttotal: 54.4s\tremaining: 10m 24s\n",
      "1000:\tlearn: 3.4327638\ttest: 3.7623540\tbest: 3.7623220 (995)\ttotal: 1m 7s\tremaining: 10m 10s\n",
      "1200:\tlearn: 3.4039565\ttest: 3.7606950\tbest: 3.7605119 (1178)\ttotal: 1m 21s\tremaining: 9m 57s\n",
      "1400:\tlearn: 3.3770849\ttest: 3.7594620\tbest: 3.7594591 (1399)\ttotal: 1m 34s\tremaining: 9m 42s\n",
      "1600:\tlearn: 3.3495370\ttest: 3.7578286\tbest: 3.7578250 (1597)\ttotal: 1m 48s\tremaining: 9m 28s\n",
      "1800:\tlearn: 3.3210570\ttest: 3.7565292\tbest: 3.7564071 (1798)\ttotal: 2m 2s\tremaining: 9m 15s\n",
      "2000:\tlearn: 3.2956894\ttest: 3.7558625\tbest: 3.7558338 (1939)\ttotal: 2m 16s\tremaining: 9m 5s\n",
      "2200:\tlearn: 3.2709237\ttest: 3.7553127\tbest: 3.7553127 (2200)\ttotal: 2m 30s\tremaining: 8m 51s\n",
      "2400:\tlearn: 3.2466684\ttest: 3.7551689\tbest: 3.7549017 (2351)\ttotal: 2m 43s\tremaining: 8m 37s\n",
      "2600:\tlearn: 3.2224043\ttest: 3.7538079\tbest: 3.7537841 (2591)\ttotal: 2m 57s\tremaining: 8m 24s\n",
      "2800:\tlearn: 3.1993508\ttest: 3.7531419\tbest: 3.7530616 (2779)\ttotal: 3m 10s\tremaining: 8m 10s\n",
      "3000:\tlearn: 3.1762292\ttest: 3.7528331\tbest: 3.7526647 (2957)\ttotal: 3m 24s\tremaining: 7m 57s\n",
      "3200:\tlearn: 3.1553951\ttest: 3.7522128\tbest: 3.7521944 (3190)\ttotal: 3m 38s\tremaining: 7m 43s\n",
      "3400:\tlearn: 3.1364533\ttest: 3.7520266\tbest: 3.7518137 (3355)\ttotal: 3m 51s\tremaining: 7m 29s\n",
      "3600:\tlearn: 3.1152970\ttest: 3.7515430\tbest: 3.7514982 (3598)\ttotal: 4m 5s\tremaining: 7m 16s\n",
      "3800:\tlearn: 3.0955029\ttest: 3.7507296\tbest: 3.7507296 (3800)\ttotal: 4m 19s\tremaining: 7m 2s\n",
      "4000:\tlearn: 3.0774943\ttest: 3.7504534\tbest: 3.7502982 (3910)\ttotal: 4m 33s\tremaining: 6m 49s\n",
      "4200:\tlearn: 3.0589851\ttest: 3.7497835\tbest: 3.7497262 (4162)\ttotal: 4m 46s\tremaining: 6m 35s\n",
      "4400:\tlearn: 3.0393674\ttest: 3.7494521\tbest: 3.7493691 (4335)\ttotal: 5m\tremaining: 6m 22s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.749357835\n",
      "bestIteration = 4414\n",
      "\n",
      "Shrink model to first 4415 iterations.\n",
      "Fold 7 RMSE: 3.74936\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8449045\ttest: 3.8095379\tbest: 3.8095379 (0)\ttotal: 68.7ms\tremaining: 11m 26s\n",
      "200:\tlearn: 3.6163482\ttest: 3.6429260\tbest: 3.6429260 (200)\ttotal: 13.7s\tremaining: 11m 6s\n",
      "400:\tlearn: 3.5526902\ttest: 3.6241928\tbest: 3.6241928 (400)\ttotal: 27.6s\tremaining: 11m\n",
      "600:\tlearn: 3.5073639\ttest: 3.6182053\tbest: 3.6182053 (600)\ttotal: 41.2s\tremaining: 10m 45s\n",
      "800:\tlearn: 3.4704771\ttest: 3.6141084\tbest: 3.6140826 (798)\ttotal: 55s\tremaining: 10m 31s\n",
      "1000:\tlearn: 3.4374750\ttest: 3.6111271\tbest: 3.6111052 (997)\ttotal: 1m 8s\tremaining: 10m 18s\n",
      "1200:\tlearn: 3.4066715\ttest: 3.6097870\tbest: 3.6097388 (1173)\ttotal: 1m 22s\tremaining: 10m 3s\n",
      "1400:\tlearn: 3.3763898\ttest: 3.6090853\tbest: 3.6090788 (1399)\ttotal: 1m 35s\tremaining: 9m 48s\n",
      "1600:\tlearn: 3.3482859\ttest: 3.6082354\tbest: 3.6081243 (1562)\ttotal: 1m 49s\tremaining: 9m 33s\n",
      "1800:\tlearn: 3.3210620\ttest: 3.6074845\tbest: 3.6074172 (1795)\ttotal: 2m 2s\tremaining: 9m 19s\n",
      "2000:\tlearn: 3.2953393\ttest: 3.6073577\tbest: 3.6073017 (1981)\ttotal: 2m 16s\tremaining: 9m 6s\n",
      "2200:\tlearn: 3.2706976\ttest: 3.6068736\tbest: 3.6066960 (2187)\ttotal: 2m 30s\tremaining: 8m 52s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.606696031\n",
      "bestIteration = 2187\n",
      "\n",
      "Shrink model to first 2188 iterations.\n",
      "Fold 8 RMSE: 3.60670\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8686960\ttest: 3.6121003\tbest: 3.6121003 (0)\ttotal: 64.3ms\tremaining: 10m 42s\n",
      "200:\tlearn: 3.6340213\ttest: 3.4701257\tbest: 3.4701257 (200)\ttotal: 14s\tremaining: 11m 23s\n",
      "400:\tlearn: 3.5708103\ttest: 3.4607397\tbest: 3.4607161 (399)\ttotal: 27.8s\tremaining: 11m 5s\n",
      "600:\tlearn: 3.5276408\ttest: 3.4568401\tbest: 3.4568395 (599)\ttotal: 41.6s\tremaining: 10m 50s\n",
      "800:\tlearn: 3.4899956\ttest: 3.4541783\tbest: 3.4541783 (800)\ttotal: 55.3s\tremaining: 10m 35s\n",
      "1000:\tlearn: 3.4564578\ttest: 3.4522981\tbest: 3.4521607 (993)\ttotal: 1m 9s\tremaining: 10m 23s\n",
      "1200:\tlearn: 3.4268953\ttest: 3.4509337\tbest: 3.4509274 (1199)\ttotal: 1m 22s\tremaining: 10m 7s\n",
      "1400:\tlearn: 3.3989114\ttest: 3.4509566\tbest: 3.4506660 (1269)\ttotal: 1m 36s\tremaining: 9m 51s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.450666046\n",
      "bestIteration = 1269\n",
      "\n",
      "Shrink model to first 1270 iterations.\n",
      "Fold 9 RMSE: 3.45067\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64669\n",
      "===================================\n",
      "\n",
      "Best Percentile Threshold Summary\n",
      "========================================\n",
      "percentile          60.000000\n",
      "threshold_value      0.128169\n",
      "num_features       142.000000\n",
      "rmse                 3.646693\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "best_cat_thresh, cat_thresh_results = find_best_feature_percentile(\n",
    "    model_fn=prediction_with_best_parameters_CatBoost,\n",
    "    feature_df=feature_importance_df_cat,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    test_df=test[df_train_columns],\n",
    "    param=cat_params,\n",
    "    model_name=\"CatBoost\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ed863ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 190 features. Discarded 47 features.\n",
      "Starting 9-Fold CV with CatBoost...\n",
      "\n",
      "Fold 1 | Train size: 143584 | Validation size: 17949\n",
      "0:\tlearn: 3.8266416\ttest: 3.9536118\tbest: 3.9536118 (0)\ttotal: 77ms\tremaining: 12m 50s\n",
      "200:\tlearn: 3.5964305\ttest: 3.7971498\tbest: 3.7971498 (200)\ttotal: 17.1s\tremaining: 13m 55s\n",
      "400:\tlearn: 3.5418248\ttest: 3.7801310\tbest: 3.7801310 (400)\ttotal: 33.7s\tremaining: 13m 27s\n",
      "600:\tlearn: 3.4980209\ttest: 3.7736236\tbest: 3.7735840 (599)\ttotal: 50.3s\tremaining: 13m 6s\n",
      "800:\tlearn: 3.4617539\ttest: 3.7691194\tbest: 3.7691194 (800)\ttotal: 1m 6s\tremaining: 12m 45s\n",
      "1000:\tlearn: 3.4290315\ttest: 3.7666446\tbest: 3.7665957 (991)\ttotal: 1m 23s\tremaining: 12m 26s\n",
      "1200:\tlearn: 3.3993599\ttest: 3.7656682\tbest: 3.7656167 (1189)\ttotal: 1m 39s\tremaining: 12m 8s\n",
      "1400:\tlearn: 3.3711255\ttest: 3.7646501\tbest: 3.7646025 (1373)\ttotal: 1m 55s\tremaining: 11m 50s\n",
      "1600:\tlearn: 3.3422743\ttest: 3.7634645\tbest: 3.7634617 (1598)\ttotal: 2m 12s\tremaining: 11m 34s\n",
      "1800:\tlearn: 3.3153403\ttest: 3.7628981\tbest: 3.7627088 (1781)\ttotal: 2m 28s\tremaining: 11m 17s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.762708837\n",
      "bestIteration = 1781\n",
      "\n",
      "Shrink model to first 1782 iterations.\n",
      "Fold 1 RMSE: 3.76271\n",
      "\n",
      "Fold 2 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8596185\ttest: 3.6888087\tbest: 3.6888087 (0)\ttotal: 89.4ms\tremaining: 14m 53s\n",
      "200:\tlearn: 3.6291780\ttest: 3.5483488\tbest: 3.5483488 (200)\ttotal: 17.1s\tremaining: 13m 51s\n",
      "400:\tlearn: 3.5686829\ttest: 3.5341048\tbest: 3.5341048 (400)\ttotal: 33.9s\tremaining: 13m 31s\n",
      "600:\tlearn: 3.5256346\ttest: 3.5291750\tbest: 3.5291750 (600)\ttotal: 50.8s\tremaining: 13m 14s\n",
      "800:\tlearn: 3.4905719\ttest: 3.5261913\tbest: 3.5261583 (797)\ttotal: 1m 7s\tremaining: 12m 54s\n",
      "1000:\tlearn: 3.4579795\ttest: 3.5242625\tbest: 3.5242625 (1000)\ttotal: 1m 23s\tremaining: 12m 33s\n",
      "1200:\tlearn: 3.4305747\ttest: 3.5237118\tbest: 3.5235839 (1183)\ttotal: 1m 40s\tremaining: 12m 14s\n",
      "1400:\tlearn: 3.4002560\ttest: 3.5227416\tbest: 3.5226911 (1399)\ttotal: 1m 56s\tremaining: 11m 57s\n",
      "1600:\tlearn: 3.3729200\ttest: 3.5223294\tbest: 3.5223294 (1600)\ttotal: 2m 13s\tremaining: 11m 39s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.522278117\n",
      "bestIteration = 1609\n",
      "\n",
      "Shrink model to first 1610 iterations.\n",
      "Fold 2 RMSE: 3.52228\n",
      "\n",
      "Fold 3 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8382117\ttest: 3.8635556\tbest: 3.8635556 (0)\ttotal: 105ms\tremaining: 17m 30s\n",
      "200:\tlearn: 3.6084752\ttest: 3.7148072\tbest: 3.7148072 (200)\ttotal: 17s\tremaining: 13m 50s\n",
      "400:\tlearn: 3.5455412\ttest: 3.7026470\tbest: 3.7026470 (400)\ttotal: 33.9s\tremaining: 13m 31s\n",
      "600:\tlearn: 3.5014563\ttest: 3.6987413\tbest: 3.6987166 (599)\ttotal: 50.5s\tremaining: 13m 9s\n",
      "800:\tlearn: 3.4656226\ttest: 3.6962352\tbest: 3.6962289 (799)\ttotal: 1m 6s\tremaining: 12m 47s\n",
      "1000:\tlearn: 3.4344209\ttest: 3.6947696\tbest: 3.6947122 (985)\ttotal: 1m 23s\tremaining: 12m 29s\n",
      "1200:\tlearn: 3.4056806\ttest: 3.6940439\tbest: 3.6939564 (1173)\ttotal: 1m 39s\tremaining: 12m 10s\n",
      "1400:\tlearn: 3.3783310\ttest: 3.6929174\tbest: 3.6928018 (1379)\ttotal: 1m 56s\tremaining: 11m 54s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.692801779\n",
      "bestIteration = 1379\n",
      "\n",
      "Shrink model to first 1380 iterations.\n",
      "Fold 3 RMSE: 3.69280\n",
      "\n",
      "Fold 4 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8387094\ttest: 3.8591639\tbest: 3.8591639 (0)\ttotal: 65.4ms\tremaining: 10m 53s\n",
      "200:\tlearn: 3.6076565\ttest: 3.7089112\tbest: 3.7089112 (200)\ttotal: 17.1s\tremaining: 13m 51s\n",
      "400:\tlearn: 3.5449946\ttest: 3.6939834\tbest: 3.6939834 (400)\ttotal: 33.9s\tremaining: 13m 32s\n",
      "600:\tlearn: 3.4996655\ttest: 3.6900526\tbest: 3.6900526 (600)\ttotal: 50.5s\tremaining: 13m 9s\n",
      "800:\tlearn: 3.4658404\ttest: 3.6879591\tbest: 3.6879499 (799)\ttotal: 1m 6s\tremaining: 12m 48s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.687866115\n",
      "bestIteration = 804\n",
      "\n",
      "Shrink model to first 805 iterations.\n",
      "Fold 4 RMSE: 3.68787\n",
      "\n",
      "Fold 5 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8350967\ttest: 3.8882848\tbest: 3.8882848 (0)\ttotal: 74.6ms\tremaining: 12m 26s\n",
      "200:\tlearn: 3.6077490\ttest: 3.7161110\tbest: 3.7161110 (200)\ttotal: 17.4s\tremaining: 14m 7s\n",
      "400:\tlearn: 3.5443197\ttest: 3.6992077\tbest: 3.6992077 (400)\ttotal: 34.2s\tremaining: 13m 38s\n",
      "600:\tlearn: 3.5022900\ttest: 3.6941766\tbest: 3.6940729 (593)\ttotal: 50.6s\tremaining: 13m 11s\n",
      "800:\tlearn: 3.4658475\ttest: 3.6912504\tbest: 3.6912504 (800)\ttotal: 1m 7s\tremaining: 12m 53s\n",
      "1000:\tlearn: 3.4340644\ttest: 3.6894894\tbest: 3.6894788 (999)\ttotal: 1m 24s\tremaining: 12m 35s\n",
      "1200:\tlearn: 3.4052911\ttest: 3.6886665\tbest: 3.6886556 (1179)\ttotal: 1m 40s\tremaining: 12m 15s\n",
      "1400:\tlearn: 3.3777934\ttest: 3.6876407\tbest: 3.6875558 (1396)\ttotal: 1m 56s\tremaining: 11m 56s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.687555826\n",
      "bestIteration = 1396\n",
      "\n",
      "Shrink model to first 1397 iterations.\n",
      "Fold 5 RMSE: 3.68756\n",
      "\n",
      "Fold 6 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8310267\ttest: 3.9205809\tbest: 3.9205809 (0)\ttotal: 78.6ms\tremaining: 13m 5s\n",
      "200:\tlearn: 3.6088800\ttest: 3.7210368\tbest: 3.7210368 (200)\ttotal: 17.3s\tremaining: 14m 3s\n",
      "400:\tlearn: 3.5520313\ttest: 3.6971593\tbest: 3.6971593 (400)\ttotal: 34.3s\tremaining: 13m 40s\n",
      "600:\tlearn: 3.5113985\ttest: 3.6871316\tbest: 3.6871316 (600)\ttotal: 50.8s\tremaining: 13m 14s\n",
      "800:\tlearn: 3.4769934\ttest: 3.6816413\tbest: 3.6816413 (800)\ttotal: 1m 7s\tremaining: 12m 53s\n",
      "1000:\tlearn: 3.4478064\ttest: 3.6780870\tbest: 3.6780870 (1000)\ttotal: 1m 23s\tremaining: 12m 33s\n",
      "1200:\tlearn: 3.4205689\ttest: 3.6752595\tbest: 3.6751526 (1196)\ttotal: 1m 40s\tremaining: 12m 13s\n",
      "1400:\tlearn: 3.3951969\ttest: 3.6730527\tbest: 3.6730055 (1397)\ttotal: 1m 56s\tremaining: 11m 54s\n",
      "1600:\tlearn: 3.3703291\ttest: 3.6716527\tbest: 3.6716527 (1600)\ttotal: 2m 12s\tremaining: 11m 35s\n",
      "1800:\tlearn: 3.3464451\ttest: 3.6704604\tbest: 3.6704603 (1794)\ttotal: 2m 28s\tremaining: 11m 17s\n",
      "2000:\tlearn: 3.3246797\ttest: 3.6687851\tbest: 3.6687851 (2000)\ttotal: 2m 45s\tremaining: 11m\n",
      "2200:\tlearn: 3.3030089\ttest: 3.6672927\tbest: 3.6672927 (2200)\ttotal: 3m 1s\tremaining: 10m 43s\n",
      "2400:\tlearn: 3.2823014\ttest: 3.6659647\tbest: 3.6659647 (2400)\ttotal: 3m 17s\tremaining: 10m 25s\n",
      "2600:\tlearn: 3.2605522\ttest: 3.6648412\tbest: 3.6648244 (2599)\ttotal: 3m 34s\tremaining: 10m 9s\n",
      "2800:\tlearn: 3.2385458\ttest: 3.6640401\tbest: 3.6638965 (2759)\ttotal: 3m 50s\tremaining: 9m 53s\n",
      "3000:\tlearn: 3.2190929\ttest: 3.6630991\tbest: 3.6629872 (2934)\ttotal: 4m 7s\tremaining: 9m 37s\n",
      "3200:\tlearn: 3.1995250\ttest: 3.6622343\tbest: 3.6622343 (3200)\ttotal: 4m 23s\tremaining: 9m 20s\n",
      "3400:\tlearn: 3.1818670\ttest: 3.6616432\tbest: 3.6616249 (3358)\ttotal: 4m 40s\tremaining: 9m 3s\n",
      "3600:\tlearn: 3.1634533\ttest: 3.6612232\tbest: 3.6611662 (3599)\ttotal: 4m 56s\tremaining: 8m 47s\n",
      "3800:\tlearn: 3.1448913\ttest: 3.6604788\tbest: 3.6604788 (3800)\ttotal: 5m 12s\tremaining: 8m 30s\n",
      "4000:\tlearn: 3.1273334\ttest: 3.6600845\tbest: 3.6599206 (3963)\ttotal: 5m 29s\tremaining: 8m 14s\n",
      "4200:\tlearn: 3.1090279\ttest: 3.6596465\tbest: 3.6596465 (4200)\ttotal: 5m 45s\tremaining: 7m 57s\n",
      "4400:\tlearn: 3.0906700\ttest: 3.6591082\tbest: 3.6590227 (4370)\ttotal: 6m 2s\tremaining: 7m 41s\n",
      "4600:\tlearn: 3.0714968\ttest: 3.6587575\tbest: 3.6586390 (4536)\ttotal: 6m 19s\tremaining: 7m 24s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.658639041\n",
      "bestIteration = 4536\n",
      "\n",
      "Shrink model to first 4537 iterations.\n",
      "Fold 6 RMSE: 3.65864\n",
      "\n",
      "Fold 7 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8255142\ttest: 3.9625627\tbest: 3.9625627 (0)\ttotal: 123ms\tremaining: 20m 32s\n",
      "200:\tlearn: 3.6000365\ttest: 3.7889060\tbest: 3.7889060 (200)\ttotal: 17.2s\tremaining: 13m 59s\n",
      "400:\tlearn: 3.5400734\ttest: 3.7716134\tbest: 3.7716134 (400)\ttotal: 34.2s\tremaining: 13m 37s\n",
      "600:\tlearn: 3.4995161\ttest: 3.7654195\tbest: 3.7654038 (597)\ttotal: 50.8s\tremaining: 13m 14s\n",
      "800:\tlearn: 3.4645133\ttest: 3.7614213\tbest: 3.7614213 (800)\ttotal: 1m 7s\tremaining: 12m 51s\n",
      "1000:\tlearn: 3.4344998\ttest: 3.7594585\tbest: 3.7594255 (984)\ttotal: 1m 23s\tremaining: 12m 32s\n",
      "1200:\tlearn: 3.4073765\ttest: 3.7578204\tbest: 3.7578038 (1197)\ttotal: 1m 40s\tremaining: 12m 15s\n",
      "1400:\tlearn: 3.3814964\ttest: 3.7560708\tbest: 3.7560474 (1399)\ttotal: 1m 56s\tremaining: 11m 55s\n",
      "1600:\tlearn: 3.3563866\ttest: 3.7542776\tbest: 3.7542190 (1595)\ttotal: 2m 12s\tremaining: 11m 37s\n",
      "1800:\tlearn: 3.3325006\ttest: 3.7538247\tbest: 3.7538014 (1796)\ttotal: 2m 29s\tremaining: 11m 19s\n",
      "2000:\tlearn: 3.3081180\ttest: 3.7527555\tbest: 3.7526987 (1996)\ttotal: 2m 45s\tremaining: 11m 1s\n",
      "2200:\tlearn: 3.2860146\ttest: 3.7525265\tbest: 3.7523436 (2062)\ttotal: 3m 1s\tremaining: 10m 44s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.752343585\n",
      "bestIteration = 2062\n",
      "\n",
      "Shrink model to first 2063 iterations.\n",
      "Fold 7 RMSE: 3.75234\n",
      "\n",
      "Fold 8 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8449409\ttest: 3.8094985\tbest: 3.8094985 (0)\ttotal: 114ms\tremaining: 19m 3s\n",
      "200:\tlearn: 3.6165393\ttest: 3.6406633\tbest: 3.6406633 (200)\ttotal: 17.3s\tremaining: 14m 5s\n",
      "400:\tlearn: 3.5518564\ttest: 3.6246222\tbest: 3.6245970 (395)\ttotal: 34.4s\tremaining: 13m 44s\n",
      "600:\tlearn: 3.5066155\ttest: 3.6184008\tbest: 3.6184008 (600)\ttotal: 51.1s\tremaining: 13m 19s\n",
      "800:\tlearn: 3.4698619\ttest: 3.6147142\tbest: 3.6147142 (800)\ttotal: 1m 7s\tremaining: 12m 58s\n",
      "1000:\tlearn: 3.4368609\ttest: 3.6125286\tbest: 3.6125016 (999)\ttotal: 1m 24s\tremaining: 12m 37s\n",
      "1200:\tlearn: 3.4089671\ttest: 3.6106843\tbest: 3.6106648 (1193)\ttotal: 1m 40s\tremaining: 12m 17s\n",
      "1400:\tlearn: 3.3822714\ttest: 3.6097966\tbest: 3.6097642 (1394)\ttotal: 1m 56s\tremaining: 11m 56s\n",
      "1600:\tlearn: 3.3570488\ttest: 3.6093986\tbest: 3.6092644 (1543)\ttotal: 2m 13s\tremaining: 11m 37s\n",
      "1800:\tlearn: 3.3314372\ttest: 3.6081513\tbest: 3.6080422 (1778)\ttotal: 2m 29s\tremaining: 11m 20s\n",
      "2000:\tlearn: 3.3076531\ttest: 3.6076001\tbest: 3.6075999 (1999)\ttotal: 2m 45s\tremaining: 11m 2s\n",
      "2200:\tlearn: 3.2836559\ttest: 3.6070010\tbest: 3.6068331 (2168)\ttotal: 3m 1s\tremaining: 10m 44s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.606620511\n",
      "bestIteration = 2236\n",
      "\n",
      "Shrink model to first 2237 iterations.\n",
      "Fold 8 RMSE: 3.60662\n",
      "\n",
      "Fold 9 | Train size: 143585 | Validation size: 17948\n",
      "0:\tlearn: 3.8685534\ttest: 3.6118717\tbest: 3.6118717 (0)\ttotal: 84.9ms\tremaining: 14m 8s\n",
      "200:\tlearn: 3.6346381\ttest: 3.4712275\tbest: 3.4712275 (200)\ttotal: 17s\tremaining: 13m 47s\n",
      "400:\tlearn: 3.5703876\ttest: 3.4605373\tbest: 3.4605022 (399)\ttotal: 33.8s\tremaining: 13m 29s\n",
      "600:\tlearn: 3.5283970\ttest: 3.4576299\tbest: 3.4575499 (576)\ttotal: 50.4s\tremaining: 13m 8s\n",
      "800:\tlearn: 3.4933162\ttest: 3.4561498\tbest: 3.4560494 (793)\ttotal: 1m 6s\tremaining: 12m 48s\n",
      "1000:\tlearn: 3.4618343\ttest: 3.4543546\tbest: 3.4543485 (999)\ttotal: 1m 23s\tremaining: 12m 28s\n",
      "1200:\tlearn: 3.4338320\ttest: 3.4536642\tbest: 3.4536642 (1200)\ttotal: 1m 39s\tremaining: 12m 9s\n",
      "1400:\tlearn: 3.4095583\ttest: 3.4537983\tbest: 3.4534453 (1285)\ttotal: 1m 55s\tremaining: 11m 49s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 3.453445281\n",
      "bestIteration = 1285\n",
      "\n",
      "Shrink model to first 1286 iterations.\n",
      "Fold 9 RMSE: 3.45345\n",
      "\n",
      "Cross-Validated RMSE Summary\n",
      "===================================\n",
      "Overall Validation RMSE: 3.64843\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# Compute average feature importance from CatBoost\n",
    "avg_importance_cat = (\n",
    "    feature_importance_df_cat\n",
    "    .groupby('Feature')['importance']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Apply your chosen threshold\n",
    "threshold_cat = 0.047604  # Example threshold value, replace with your actual\n",
    "selected_features_cat = avg_importance_cat[avg_importance_cat >= threshold_cat].index.tolist()\n",
    "discarded_features_cat = avg_importance_cat[avg_importance_cat < threshold_cat].index.tolist()\n",
    "\n",
    "print(f\"Selected {len(selected_features_cat)} features. Discarded {len(discarded_features_cat)} features.\")\n",
    "\n",
    "# Final training using selected CatBoost features\n",
    "catboost_reg_final, pred_y_train_final2, pred_y_test_final2, feature_importance_final2, rmse_cat_final = prediction_with_best_parameters_CatBoost(\n",
    "    best_params=cat_params,\n",
    "    n_splits=9,\n",
    "    X_train=X_train[selected_features_cat],\n",
    "    y_train=y_train,\n",
    "    test_df=test[selected_features_cat],\n",
    "    num_round=10000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "facb1ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-4.076781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.308234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-1.047639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.087285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.414657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123618</th>\n",
       "      <td>C_ID_7a239d2eda</td>\n",
       "      <td>0.811976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123619</th>\n",
       "      <td>C_ID_75ace375ae</td>\n",
       "      <td>-0.384975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123620</th>\n",
       "      <td>C_ID_21d56d950c</td>\n",
       "      <td>0.676988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123621</th>\n",
       "      <td>C_ID_6c46fc5a9d</td>\n",
       "      <td>-3.577420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123622</th>\n",
       "      <td>C_ID_87e7979a5f</td>\n",
       "      <td>0.219001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123623 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id    target\n",
       "0       C_ID_0ab67a22ab -4.076781\n",
       "1       C_ID_130fd0cbdd -0.308234\n",
       "2       C_ID_b709037bc5 -1.047639\n",
       "3       C_ID_d27d835a9f -0.087285\n",
       "4       C_ID_2b5e3df5c2 -1.414657\n",
       "...                 ...       ...\n",
       "123618  C_ID_7a239d2eda  0.811976\n",
       "123619  C_ID_75ace375ae -0.384975\n",
       "123620  C_ID_21d56d950c  0.676988\n",
       "123621  C_ID_6c46fc5a9d -3.577420\n",
       "123622  C_ID_87e7979a5f  0.219001\n",
       "\n",
       "[123623 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cb_fs = test[[\"card_id\"]].copy()\n",
    "best_cb_fs[\"target\"] = pred_y_test_final2\n",
    "best_cb_fs.to_csv(\"cb_fs_latest.csv\", index=False)\n",
    "best_cb_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Averaging\n",
    "\n",
    "Simple weighted rsme averaging based on Bayesian Model Averaging : \n",
    "\n",
    "https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/steel/steel_homepage/publ/bma_wsr.pdf\n",
    "\n",
    "We remove linear regression as it solely uses the hist_purchase_amt to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "114d1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_fs = pd.read_csv('xgb_fs_latest.csv')\n",
    "best_cb_fs = pd.read_csv('cb_fs_latest.csv')\n",
    "best_lgb_fs = pd.read_csv('lgb_fs_latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds_boosting = {\n",
    "    'XGBoost': best_xgb_fs[\"target\"],\n",
    "    'CatBoost': best_cb_fs[\"target\"],\n",
    "    'LightGBM': best_lgb_fs[\"target\"]\n",
    "}\n",
    "\n",
    "model_rmses_boosting = {\n",
    "    'XGBoost': rmse_xgb_final,\n",
    "    'CatBoost': rmse_cat_final,\n",
    "    'LightGBM': rmse_lgb_final\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inv_rmses = {k: 1 / v**2 for k, v in model_rmses_boosting.items()}\n",
    "total = sum(inv_rmses.values())\n",
    "model_weights = {k: v / total for k, v in inv_rmses.items()}\n",
    "# Weighted ensemble prediction\n",
    "bma_test_pred_boosting= sum(model_weights[name] * model_preds_boosting[name] for name in model_preds_boosting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-4.054263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.394248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.983232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.107130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.431350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123618</th>\n",
       "      <td>C_ID_7a239d2eda</td>\n",
       "      <td>0.813895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123619</th>\n",
       "      <td>C_ID_75ace375ae</td>\n",
       "      <td>-0.384389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123620</th>\n",
       "      <td>C_ID_21d56d950c</td>\n",
       "      <td>0.674899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123621</th>\n",
       "      <td>C_ID_6c46fc5a9d</td>\n",
       "      <td>-3.451968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123622</th>\n",
       "      <td>C_ID_87e7979a5f</td>\n",
       "      <td>0.206487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123623 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id    target\n",
       "0       C_ID_0ab67a22ab -4.054263\n",
       "1       C_ID_130fd0cbdd -0.394248\n",
       "2       C_ID_b709037bc5 -0.983232\n",
       "3       C_ID_d27d835a9f -0.107130\n",
       "4       C_ID_2b5e3df5c2 -1.431350\n",
       "...                 ...       ...\n",
       "123618  C_ID_7a239d2eda  0.813895\n",
       "123619  C_ID_75ace375ae -0.384389\n",
       "123620  C_ID_21d56d950c  0.674899\n",
       "123621  C_ID_6c46fc5a9d -3.451968\n",
       "123622  C_ID_87e7979a5f  0.206487\n",
       "\n",
       "[123623 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ma = test[[\"card_id\"]].copy()\n",
    "best_ma[\"target\"] = pred_y_test\n",
    "best_ma.to_csv(\"ma_latest.csv\", index=False)\n",
    "best_ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Stacking\n",
    "https://medium.com/@brijesh_soni/stacking-to-improve-model-performance-a-comprehensive-guide-on-ensemble-learning-in-python-9ed53c93ce28\n",
    "\n",
    "The predictions of the base models will be taken as the input and be used to make the final prediction. \n",
    "\n",
    "All the base models have to be trained on the same validation set, for boosting models we used objective functions which internally split the dataset into train and validation set, hence to standardise we train the base models for the boosting models again with their best tuned parameters\n",
    "\n",
    "https://www.kaggle.com/code/hygaokaggle/elo-merchant-category-recommendation-stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrain base models\n",
    "param = {\n",
    "    'objective'         : 'regression',\n",
    "    'boosting_type'     : 'gbdt',\n",
    "    'metric'            : 'rmse',\n",
    "    'learning_rate'     : 0.01,\n",
    "    'num_leaves': 43,\n",
    "    'colsample_bytree': 0.37833128023384316,\n",
    "    'subsample': 0.020581374607877696,\n",
    "    'max_depth': 11,\n",
    "    'reg_alpha': 4.926058053299857,\n",
    "    'reg_lambda': 8.077177812556824,\n",
    "    'min_split_gain': 4.326677551210331,\n",
    "    'min_child_weight': 441.95211148401055,\n",
    "    'min_data_in_leaf': 16,\n",
    "    'nthread'           : 8\n",
    "    \n",
    "} \n",
    "dtrain = lgb.Dataset(X_train[selected_features], label=y_train)\n",
    "model_lgb = lgb.train(param, dtrain, num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d524985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation predictions (for training the meta-model)\n",
    "y_pred_val_lgb = model_lgb.predict(X_test[selected_features])\n",
    "# Test predictions (for final stacked output)\n",
    "y_pred_test_lgb = model_lgb.predict(test[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42e02da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',               # XGBoost regression objective\n",
    "    'eval_metric': 'rmse',                         # Evaluation metric\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 37.21919431321118,\n",
    "    'subsample':  0.8199037878263149,\n",
    "    'colsample_bytree': 0.5893702702557324,\n",
    "    'reg_lambda': 2.6736872463331904,              # L2 regularization\n",
    "    'reg_alpha': 6.053754999193514,               # L1 regularization\n",
    "    'verbosity': 0,                                # Quiet logging\n",
    "    'tree_method': 'auto',                         # Set to 'gpu_hist' if using GPU\n",
    "    'seed': 42\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_train[selected_features_xg], label=y_train)\n",
    "\n",
    "# Train model\n",
    "model_xgb = xgb.train(params=xgb_params, dtrain=dtrain, num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e57e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "dval = xgb.DMatrix(X_test[selected_features_xg])\n",
    "dtest = xgb.DMatrix(test[selected_features_xg])\n",
    "\n",
    "# Predictions\n",
    "y_pred_val_xgb = model_xgb.predict(dval)\n",
    "y_pred_test_xgb = model_xgb.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac5db941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x251dcf24f50>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'learning_rate': 0.01,\n",
    "    'depth': 9,\n",
    "    'l2_leaf_reg': 9.854664108589615,\n",
    "    'random_strength': 4.480905110345212,  # Similar to reg_alpha\n",
    "    'subsample': 0.7100013822957487,\n",
    "    'rsm': 0.8793537689395765,  # Equivalent to colsample_bytree\n",
    "    'verbose': 0,\n",
    "    'random_seed': 42\n",
    "}\n",
    "model_cat = CatBoostRegressor(**catboost_params)\n",
    "model_cat.fit(X_train[selected_features_cat], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53c86c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation predictions for training meta-model\n",
    "y_pred_val_cat = model_cat.predict(X_test[selected_features_cat])\n",
    "\n",
    "# Final test set predictions\n",
    "y_pred_test_cat = model_cat.predict(test[selected_features_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce46307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta model train input (validation predictions from base models)\n",
    "#train dataset x, y and test dataset x? \n",
    "#Train dataset (Validation predictions)\n",
    "stack_X_val = pd.DataFrame({\n",
    "    'lgb': y_pred_val_lgb,\n",
    "    'xgb': y_pred_val_xgb,\n",
    "    'cat': y_pred_val_cat,\n",
    "}) #validation set\n",
    "stack_y_val = y_test #actual validation output\n",
    "\n",
    "#Test dataset\n",
    "# Meta model test input (base model test predictions)\n",
    "stack_X_test = pd.DataFrame({\n",
    "    'lgb': y_pred_test_lgb,\n",
    "    'xgb': y_pred_test_xgb,\n",
    "    'cat': y_pred_test_cat,\n",
    "\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b50046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "\n",
    "def stacking(train_pred, train_val, test_pred, test_col):\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=2024)\n",
    "    \n",
    "    # Create result DataFrame to store test predictions\n",
    "    res = pd.DataFrame(0, index=test_col, columns=[\"target\"])\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    # K-Fold cross-validation\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_pred)):\n",
    "        train_d, train_y = train_pred.iloc[train_index], train_val.iloc[train_index]\n",
    "        val_d, val_y = train_pred.iloc[val_index], train_val.iloc[val_index]\n",
    "        \n",
    "        model = BayesianRidge()\n",
    "        model.fit(train_d, train_y)\n",
    "\n",
    "        # Predict on test set and accumulate the result\n",
    "        res[\"target\"] += model.predict(test_pred)\n",
    "\n",
    "        # Predict on validation set for performance tracking\n",
    "        val_pred = pd.Series(model.predict(val_d))\n",
    "        mse = mean_squared_error(val_pred.values, val_y.values)\n",
    "        scores.append(mse)\n",
    "        print(f\"Fold {fold+1} MSE: {mse}\")\n",
    "\n",
    "    # Average the test predictions across all folds\n",
    "    res[\"target\"] /= k\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c74d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MSE: 11.625747553333179\n",
      "Fold 2 MSE: 12.900489784559188\n",
      "Fold 3 MSE: 13.925899355469666\n",
      "Fold 4 MSE: 15.89754759004609\n",
      "Fold 5 MSE: 13.461746354975784\n"
     ]
    }
   ],
   "source": [
    "final_preds = stacking(\n",
    "    train_pred=stack_X_val,\n",
    "    train_val=stack_y_val,\n",
    "    test_pred=stack_X_test,\n",
    "    test_col=stack_X_test.index\n",
    ")\n",
    "final_preds\n",
    "best_sub_stacking= pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "best_sub_stacking[\"target\"] = final_preds\n",
    "best_sub_stacking.to_csv('ms_latest.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
